{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee754ff-2a3d-4760-9dde-f35b5079e53b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training epoch took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5af6c94-0780-4733-88b7-286a4a08728a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training IGMC model on the MovieLens dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "from shutil import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from explicit_model_rotten import IGMC\n",
    "from explicit_data_rotten import RottenTomato\n",
    "from explicit_dataset_rotten import (RottenTomatoDataset, collate_rotten_tomato,\n",
    "                                     MultiRottenTomatoDataset, multi_collate_rotten_tomato)\n",
    "from utils import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c1bb83-260d-40b8-900b-6c27d7da5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    predict_list = list()\n",
    "    label_list = list()\n",
    "    \n",
    "    # Evaluate RMSE\n",
    "    model.eval()\n",
    "    mse = 0.\n",
    "    for iter_idx, batch in enumerate(loader):\n",
    "        with th.no_grad():\n",
    "            block_r = batch[0][0].to(device)\n",
    "            block_s = batch[0][1].to(device)\n",
    "            block_e = batch[0][2].to(device)\n",
    "            tmp = model(block_r, block_s, block_e)\n",
    "            preds = (tmp + 1)/2\n",
    "        \n",
    "        tmp_rating = batch[1][0].to(device) # 정답 rating labels\n",
    "        labels = (tmp_rating+1)/2\n",
    "        mse += ((preds - labels) ** 2).sum().item()\n",
    "        \n",
    "        predict_list.append(preds.tolist()) # 예측값 저장\n",
    "        label_list.append(labels.tolist()) # 정답값 저장\n",
    "        \n",
    "        # 2차원 -> 1차원 리스트 변형\n",
    "    predict_list = [element for array in predict_list for element in array]\n",
    "    label_list = [element for array in label_list for element in array]    \n",
    "        \n",
    "    mse /= len(loader.dataset)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse, predict_list, label_list\n",
    "\n",
    "def adj_rating_reg_r(model):\n",
    "    arr_loss = 0\n",
    "    for conv in model.convs_r:\n",
    "        weight = conv.weight.view(conv.num_bases, conv.in_feat * conv.out_feat)\n",
    "        weight = th.matmul(conv.w_comp, weight).view(conv.num_rels, conv.in_feat, conv.out_feat)\n",
    "        arr_loss += th.sum((weight[1:, :, :] - weight[:-1, :, :])**2)\n",
    "    return arr_loss\n",
    "\n",
    "def adj_rating_reg_s(model):\n",
    "    arr_loss = 0\n",
    "    for conv in model.convs_s:\n",
    "        weight = conv.weight.view(conv.num_bases, conv.in_feat * conv.out_feat)\n",
    "        weight = th.matmul(conv.w_comp, weight).view(conv.num_rels, conv.in_feat, conv.out_feat)\n",
    "        arr_loss += th.sum((weight[1:, :, :] - weight[:-1, :, :])**2)\n",
    "    return arr_loss\n",
    "\n",
    "# rating, sentiment, emotion loader를 받음\n",
    "def train_epoch(model, loss_fn, optimizer, arr_lambda, loader, device, log_interval):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.\n",
    "    iter_loss = 0.\n",
    "    iter_mse = 0.\n",
    "    iter_cnt = 0\n",
    "    iter_dur = []\n",
    "\n",
    "    iter_idx = 0\n",
    "    \n",
    "    # 저장 리스트(예측, 정답)\n",
    "    predict_list = list()\n",
    "    label_list = list()\n",
    "    \n",
    "    for iter_idx, batch in enumerate(loader, start=1):\n",
    "        t_start = time.time()\n",
    "        \n",
    "        # rating\n",
    "        inputs_r = batch[0][0].to(device)\n",
    "        labels_r = batch[1][0].to(device)\n",
    "        # sentiment\n",
    "        inputs_s = batch[0][1].to(device)\n",
    "        labels_s = batch[1][1].to(device)\n",
    "        # emotion\n",
    "        inputs_e = batch[0][2].to(device)\n",
    "        labels_e = batch[1][2].to(device)\n",
    "    \n",
    "        preds = model(inputs_r, inputs_s, inputs_e)\n",
    "        preds  = (preds + 1)/2\n",
    "        labels_r = (labels_r + 1)/2\n",
    "        loss = loss_fn(preds, labels_r).mean() + arr_lambda * adj_rating_reg_r(model) + arr_lambda * adj_rating_reg_s(model)\n",
    "#         loss = loss_fn(preds, labels_r).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * preds.shape[0]\n",
    "        iter_loss += loss.item() * preds.shape[0]\n",
    "        iter_mse += ((preds - labels_r) ** 2).sum().item()\n",
    "        iter_cnt += preds.shape[0]\n",
    "        iter_dur.append(time.time() - t_start)\n",
    "\n",
    "        predict_list.append(preds.tolist()) # 예측값 저장\n",
    "        label_list.append(labels_r.tolist()) # 정답값 저장\n",
    "        \n",
    "        if iter_idx % log_interval == 0:\n",
    "            print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "                iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "            iter_loss = 0.\n",
    "            iter_mse = 0.\n",
    "            iter_cnt = 0\n",
    "        \n",
    "    # 2차원 -> 1차원 리스트 변형\n",
    "    predict_list = [element for array in predict_list for element in array]\n",
    "    label_list = [element for array in label_list for element in array]\n",
    "\n",
    "    train_epoch_loss = epoch_loss / len(loader.dataset)  \n",
    "    return train_epoch_loss, predict_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff187c-d0a5-44d6-bf40-12a1c7927a3b",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0218e93a-7bb0-4007-a0d4-194dfbf0fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({ \n",
    "    'data_name':            'rotten',\n",
    "    'testing':     \t        True,\n",
    "    'device':      \t        0,\n",
    "    'seed':        \t        1234,\n",
    "    'data_test_ratio':      0.1,\n",
    "    'num_workers':   \t    8,\n",
    "    'data_valid_ratio':     0.2,\n",
    "    'train_log_interval':   200,\n",
    "    'valid_log_interval':   10,\n",
    "    'save_appendix':   \t    'debug',\n",
    "    'hop':   \t            1,\n",
    "    'sample_ratio':    \t    1.0,\n",
    "    'max_nodes_per_hop':    100,\n",
    "    'edge_dropout':   \t    0.2,\n",
    "    'force_undirected':     False,\n",
    "    'train_lr':   \t        1e-3,\n",
    "    'train_min_lr':   \t    1e-6,\n",
    "    'train_lr_decay_factor':0.1,\n",
    "    'train_lr_decay_step':  50,\n",
    "    'train_epochs':   \t    10,\n",
    "    'batch_size':   \t    16,\n",
    "    'arr_lambda':   \t    0.001,\n",
    "    'num_rgcn_bases':   \t4,\n",
    "    'train_epochs':   \t    1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eefc4e0-e1a6-47fa-af1b-3f79a748f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_name': 'rotten', 'testing': True, 'device': 0, 'seed': 1234, 'data_test_ratio': 0.1, 'num_workers': 8, 'data_valid_ratio': 0.2, 'train_log_interval': 200, 'valid_log_interval': 10, 'save_appendix': 'debug', 'hop': 1, 'sample_ratio': 1.0, 'max_nodes_per_hop': 100, 'edge_dropout': 0.2, 'force_undirected': False, 'train_lr': 0.001, 'train_min_lr': 1e-06, 'train_lr_decay_factor': 0.1, 'train_lr_decay_step': 50, 'train_epochs': 1, 'batch_size': 16, 'arr_lambda': 0.001, 'num_rgcn_bases': 4, 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\IGMC_CX\\\\log/rotten_debug_testmode_2111211722'}\n",
      "Command line input: python3 C:\\Users\\user\\anaconda3\\envs\\graph\\lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\user\\AppData\\Roaming\\jupyter\\runtime\\kernel-2aa2e963-68cd-4b84-8169-2fdecc07b3a6.json is saved.\n"
     ]
    }
   ],
   "source": [
    "### set save_dir according to localtime and test mode\n",
    "file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "args.save_dir = os.path.join(\n",
    "    file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "        args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "    )\n",
    ")\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir) \n",
    "print(args)\n",
    "\n",
    "# backup current .py files\n",
    "for f in glob.glob(r\"*.py\"):\n",
    "    copy(f, args.save_dir)\n",
    "\n",
    "# save command line input\n",
    "cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "    f.write(cmd_input)\n",
    "    f.write(\"\\n\")\n",
    "print('Command line input: ' + cmd_input + ' is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0952c8a-5880-48c8-a6b0-76fa1226074e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_name': 'rotten',\n",
       " 'testing': True,\n",
       " 'device': 0,\n",
       " 'seed': 1234,\n",
       " 'data_test_ratio': 0.1,\n",
       " 'num_workers': 8,\n",
       " 'data_valid_ratio': 0.2,\n",
       " 'train_log_interval': 200,\n",
       " 'valid_log_interval': 10,\n",
       " 'save_appendix': 'debug',\n",
       " 'hop': 1,\n",
       " 'sample_ratio': 1.0,\n",
       " 'max_nodes_per_hop': 100,\n",
       " 'edge_dropout': 0.2,\n",
       " 'force_undirected': False,\n",
       " 'train_lr': 0.001,\n",
       " 'train_min_lr': 1e-06,\n",
       " 'train_lr_decay_factor': 0.1,\n",
       " 'train_lr_decay_step': 50,\n",
       " 'train_epochs': 1,\n",
       " 'batch_size': 16,\n",
       " 'arr_lambda': 0.001,\n",
       " 'num_rgcn_bases': 4,\n",
       " 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\IGMC_CX\\\\log/rotten_debug_testmode_2111211722'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e5af39-9646-43f8-87d2-8d9c498b7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "th.manual_seed(args.seed)\n",
    "if th.cuda.is_available():\n",
    "    th.cuda.manual_seed_all(args.seed)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd9d7e-1617-4c32-a8bc-006d4a49ca35",
   "metadata": {},
   "source": [
    "## 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c44d14-7115-4e81-9c99-99f370f93129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label_type: rating\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n",
      "Label_type: sentiment\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n",
      "Label_type: emotion\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n"
     ]
    }
   ],
   "source": [
    "### prepare data and set model\n",
    "path = './raw_data/rotten_tomato/'\n",
    "rotten_tomato_r = RottenTomato('rating',    path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "rotten_tomato_s = RottenTomato('sentiment', path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "rotten_tomato_e = RottenTomato('emotion',   path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530daf78-1abb-45fc-8e29-7f13a1761c55",
   "metadata": {},
   "source": [
    "### 2-1. multi_rotten_tomato_dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb69f150-c705-4520-914c-998f819fd282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 수정한 것 (단, 그래프의 모든 행의 길이 동일함)\n",
    "train_rating_pairs  = [rotten_tomato_r.train_rating_pairs, rotten_tomato_s.train_rating_pairs, rotten_tomato_e.train_rating_pairs]\n",
    "train_rating_values = [rotten_tomato_r.train_rating_values, rotten_tomato_s.train_rating_values, rotten_tomato_e.train_rating_values]\n",
    "train_graph         = [rotten_tomato_r.train_graph, rotten_tomato_s.train_graph, rotten_tomato_e.train_graph]\n",
    "\n",
    "test_rating_pairs  = [rotten_tomato_r.test_rating_pairs, rotten_tomato_s.test_rating_pairs, rotten_tomato_e.test_rating_pairs]\n",
    "test_rating_values = [rotten_tomato_r.test_rating_values, rotten_tomato_s.test_rating_values, rotten_tomato_e.test_rating_values]\n",
    "test_graph         = [rotten_tomato_r.train_graph, rotten_tomato_s.train_graph, rotten_tomato_e.train_graph]\n",
    "\n",
    "valid_rating_pairs  = [rotten_tomato_r.valid_rating_pairs, rotten_tomato_s.valid_rating_pairs, rotten_tomato_e.valid_rating_pairs]\n",
    "valid_rating_values = [rotten_tomato_r.valid_rating_values, rotten_tomato_s.valid_rating_values, rotten_tomato_e.valid_rating_values]\n",
    "valid_graph         = [rotten_tomato_r.train_graph, rotten_tomato_s.train_graph, rotten_tomato_e.train_graph]\n",
    "\n",
    "hop = [1, 1, 1]\n",
    "sample_ratio = [1.0, 1.0, 1.0]\n",
    "max_nodes_per_hop = [200, 200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af177066-b960-4e61-8bb6-f993f4644086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultiRottenTomatoDataset(train_rating_pairs, train_rating_values, train_graph, hop, sample_ratio, max_nodes_per_hop)\n",
    "train_loader = th.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, \n",
    "                        num_workers=0, collate_fn=multi_collate_rotten_tomato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bb2a9bc-37f2-4178-a458-efab36ebd80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    }
   ],
   "source": [
    "if args.testing:\n",
    "    print('testing')\n",
    "    test_dataset = MultiRottenTomatoDataset(test_rating_pairs, test_rating_values, test_graph, hop, sample_ratio, max_nodes_per_hop)\n",
    "    test_loader = th.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, \n",
    "                            num_workers=0, collate_fn=multi_collate_rotten_tomato)\n",
    "else:\n",
    "    print('valid')\n",
    "    test_dataset = MultiRottenTomatoDataset(valid_rating_pairs, valid_rating_values, valid_graph, hop, sample_ratio, max_nodes_per_hop)\n",
    "    test_loader = th.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=True, \n",
    "                            num_workers=0, collate_fn=multi_collate_rotten_tomato)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e015002-b338-488e-ad01-4cbf7b4a0715",
   "metadata": {},
   "source": [
    "테스트중입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba464e44-2833-4f50-8c5f-abac54c15ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for iter_idx, batch in enumerate(train_loader, start=1):\n",
    "    if iter_idx == 5:\n",
    "        break\n",
    "    print(iter_idx)\n",
    "    \n",
    "    device = args.device\n",
    "    \n",
    "    # rating\n",
    "    inputs_r = batch[0][0].to(device)\n",
    "    labels_r = batch[1][0].to(device)\n",
    "    # sentiment\n",
    "    inputs_s = batch[0][1].to(device)\n",
    "    labels_s = batch[1][1].to(device)\n",
    "    # emotion\n",
    "    inputs_e = batch[0][2].to(device)\n",
    "    labels_e = batch[1][2].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8fb1fe-280e-4258-93a2-2a2ef70dd385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b887251-cbc5-4f77-8959-da25848a404f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c679b72-a7a2-4abb-9c4d-efdebf97dbc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network finished ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_feats = (args.hop+1)*2 #+ rotten_tomato.train_graph.ndata['refex'].shape[1]\n",
    "model = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=10, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "loss_fn = nn.MSELoss().to(args.device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "print(\"Loading network finished ...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b4b350-a659-41eb-8f85-4baf5495fc5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=200, loss=0.6880, mse=0.6861, time=0.1299\n",
      "Iter=400, loss=0.6836, mse=0.6816, time=0.1343\n",
      "Iter=600, loss=0.6856, mse=0.6836, time=0.1362\n",
      "Iter=800, loss=0.6757, mse=0.6737, time=0.1493\n",
      "Iter=1000, loss=0.6799, mse=0.6779, time=0.1537\n",
      "Iter=1200, loss=0.6764, mse=0.6744, time=0.1608\n",
      "Iter=1400, loss=0.6864, mse=0.6843, time=0.1712\n",
      "Iter=1600, loss=0.6792, mse=0.6771, time=0.1795\n",
      "Iter=1800, loss=0.6594, mse=0.6572, time=0.1855\n",
      "Iter=2000, loss=0.6572, mse=0.6549, time=0.1907\n",
      "Iter=2200, loss=0.6624, mse=0.6602, time=0.1948\n",
      "Iter=2400, loss=0.6977, mse=0.6955, time=0.1982\n",
      "Iter=2600, loss=0.6670, mse=0.6648, time=0.2012\n",
      "Iter=2800, loss=0.6732, mse=0.6710, time=0.2035\n",
      "Iter=3000, loss=0.6472, mse=0.6450, time=0.2058\n",
      "Iter=3200, loss=0.6767, mse=0.6745, time=0.2074\n",
      "Iter=3400, loss=0.6704, mse=0.6683, time=0.2029\n",
      "Iter=3600, loss=0.6643, mse=0.6622, time=0.1981\n",
      "Iter=3800, loss=0.6794, mse=0.6773, time=0.1939\n",
      "Iter=4000, loss=0.6748, mse=0.6728, time=0.1901\n",
      "Iter=4200, loss=0.6752, mse=0.6731, time=0.1866\n",
      "Iter=4400, loss=0.6559, mse=0.6537, time=0.1835\n",
      "Iter=4600, loss=0.6582, mse=0.6560, time=0.1807\n",
      "Iter=4800, loss=0.6488, mse=0.6465, time=0.1781\n",
      "Iter=5000, loss=0.6436, mse=0.6413, time=0.1756\n",
      "Iter=5200, loss=0.6543, mse=0.6521, time=0.1735\n",
      "Iter=5400, loss=0.6531, mse=0.6511, time=0.1714\n",
      "Iter=5600, loss=0.6509, mse=0.6488, time=0.1695\n",
      "Iter=5800, loss=0.6751, mse=0.6730, time=0.1677\n",
      "Iter=6000, loss=0.6515, mse=0.6493, time=0.1661\n",
      "Iter=6200, loss=0.6532, mse=0.6511, time=0.1645\n",
      "Iter=6400, loss=0.6553, mse=0.6530, time=0.1631\n",
      "Iter=6600, loss=0.6399, mse=0.6377, time=0.1617\n",
      "=== Epoch 1, train loss 0.666279, test rmse 0.835542 ===\n",
      "  Training epoch took: 1:32:36\n",
      "Epoch 2\n",
      "Iter=200, loss=0.6693, mse=0.6672, time=0.1175\n",
      "Iter=400, loss=0.6541, mse=0.6518, time=0.1175\n",
      "Iter=600, loss=0.6392, mse=0.6371, time=0.1178\n",
      "Iter=800, loss=0.6416, mse=0.6395, time=0.1178\n",
      "Iter=1000, loss=0.6462, mse=0.6442, time=0.1178\n",
      "Iter=1200, loss=0.6540, mse=0.6520, time=0.1178\n",
      "Iter=1400, loss=0.6495, mse=0.6475, time=0.1180\n",
      "Iter=1600, loss=0.6336, mse=0.6315, time=0.1180\n",
      "Iter=1800, loss=0.6610, mse=0.6589, time=0.1181\n",
      "Iter=2000, loss=0.6517, mse=0.6496, time=0.1180\n",
      "Iter=2200, loss=0.6325, mse=0.6303, time=0.1180\n",
      "Iter=2400, loss=0.6603, mse=0.6580, time=0.1179\n",
      "Iter=2600, loss=0.6492, mse=0.6470, time=0.1180\n",
      "Iter=2800, loss=0.6543, mse=0.6521, time=0.1180\n",
      "Iter=3000, loss=0.6519, mse=0.6497, time=0.1180\n",
      "Iter=3200, loss=0.6243, mse=0.6221, time=0.1180\n",
      "Iter=3400, loss=0.6390, mse=0.6369, time=0.1180\n",
      "Iter=3600, loss=0.6466, mse=0.6443, time=0.1180\n",
      "Iter=3800, loss=0.6446, mse=0.6423, time=0.1180\n",
      "Iter=4000, loss=0.6631, mse=0.6607, time=0.1180\n",
      "Iter=4200, loss=0.6509, mse=0.6485, time=0.1180\n",
      "Iter=4400, loss=0.6360, mse=0.6337, time=0.1180\n",
      "Iter=4600, loss=0.6707, mse=0.6683, time=0.1179\n",
      "Iter=4800, loss=0.6391, mse=0.6366, time=0.1180\n",
      "Iter=5000, loss=0.6156, mse=0.6132, time=0.1179\n",
      "Iter=5200, loss=0.6128, mse=0.6105, time=0.1179\n",
      "Iter=5400, loss=0.6577, mse=0.6553, time=0.1179\n",
      "Iter=5600, loss=0.6199, mse=0.6174, time=0.1179\n",
      "Iter=5800, loss=0.6460, mse=0.6435, time=0.1179\n",
      "Iter=6000, loss=0.6206, mse=0.6182, time=0.1179\n",
      "Iter=6200, loss=0.6502, mse=0.6477, time=0.1179\n",
      "Iter=6400, loss=0.6219, mse=0.6196, time=0.1179\n",
      "Iter=6600, loss=0.5954, mse=0.5930, time=0.1180\n",
      "=== Epoch 2, train loss 0.642200, test rmse 0.815031 ===\n",
      "  Training epoch took: 2:39:44\n",
      "Epoch 3\n",
      "Iter=200, loss=0.6364, mse=0.6340, time=0.1173\n",
      "Iter=400, loss=0.6099, mse=0.6075, time=0.1179\n",
      "Iter=600, loss=0.6336, mse=0.6312, time=0.1177\n",
      "Iter=800, loss=0.6167, mse=0.6143, time=0.1179\n",
      "Iter=1000, loss=0.6374, mse=0.6349, time=0.1180\n",
      "Iter=1200, loss=0.6394, mse=0.6368, time=0.1180\n",
      "Iter=1400, loss=0.6139, mse=0.6115, time=0.1182\n",
      "Iter=1600, loss=0.6301, mse=0.6274, time=0.1182\n",
      "Iter=1800, loss=0.6161, mse=0.6136, time=0.1181\n",
      "Iter=2000, loss=0.6238, mse=0.6212, time=0.1181\n",
      "Iter=2200, loss=0.6318, mse=0.6289, time=0.1181\n",
      "Iter=2400, loss=0.6357, mse=0.6330, time=0.1182\n",
      "Iter=2600, loss=0.6310, mse=0.6285, time=0.1182\n",
      "Iter=2800, loss=0.6360, mse=0.6334, time=0.1183\n",
      "Iter=3000, loss=0.6377, mse=0.6351, time=0.1182\n",
      "Iter=3200, loss=0.6264, mse=0.6239, time=0.1181\n",
      "Iter=3400, loss=0.6221, mse=0.6196, time=0.1181\n",
      "Iter=3600, loss=0.6062, mse=0.6038, time=0.1180\n",
      "Iter=3800, loss=0.6587, mse=0.6563, time=0.1180\n",
      "Iter=4000, loss=0.5999, mse=0.5974, time=0.1180\n",
      "Iter=4200, loss=0.6263, mse=0.6240, time=0.1181\n",
      "Iter=4400, loss=0.6294, mse=0.6268, time=0.1181\n",
      "Iter=4600, loss=0.6076, mse=0.6053, time=0.1181\n",
      "Iter=4800, loss=0.6313, mse=0.6289, time=0.1181\n",
      "Iter=5000, loss=0.6123, mse=0.6099, time=0.1180\n",
      "Iter=5200, loss=0.6277, mse=0.6252, time=0.1181\n",
      "Iter=5400, loss=0.6346, mse=0.6323, time=0.1181\n",
      "Iter=5600, loss=0.6267, mse=0.6241, time=0.1181\n",
      "Iter=5800, loss=0.6297, mse=0.6273, time=0.1181\n",
      "Iter=6000, loss=0.6305, mse=0.6280, time=0.1181\n",
      "Iter=6200, loss=0.6311, mse=0.6288, time=0.1181\n",
      "Iter=6400, loss=0.6211, mse=0.6187, time=0.1181\n",
      "Iter=6600, loss=0.6134, mse=0.6111, time=0.1181\n",
      "=== Epoch 3, train loss 0.625974, test rmse 0.811793 ===\n",
      "  Training epoch took: 3:46:50\n",
      "Epoch 4\n",
      "Iter=200, loss=0.6278, mse=0.6253, time=0.1191\n",
      "Iter=400, loss=0.6399, mse=0.6374, time=0.1189\n",
      "Iter=600, loss=0.6124, mse=0.6098, time=0.1186\n",
      "Iter=800, loss=0.6241, mse=0.6216, time=0.1187\n",
      "Iter=1000, loss=0.6269, mse=0.6243, time=0.1187\n",
      "Iter=1200, loss=0.6245, mse=0.6219, time=0.1184\n",
      "Iter=1400, loss=0.6032, mse=0.6007, time=0.1184\n",
      "Iter=1600, loss=0.6115, mse=0.6090, time=0.1182\n",
      "Iter=1800, loss=0.6127, mse=0.6102, time=0.1181\n",
      "Iter=2000, loss=0.6134, mse=0.6108, time=0.1180\n",
      "Iter=2200, loss=0.6101, mse=0.6075, time=0.1179\n",
      "Iter=2400, loss=0.6059, mse=0.6033, time=0.1178\n",
      "Iter=2600, loss=0.6198, mse=0.6173, time=0.1178\n",
      "Iter=2800, loss=0.5860, mse=0.5835, time=0.1178\n",
      "Iter=3000, loss=0.6293, mse=0.6268, time=0.1178\n",
      "Iter=3200, loss=0.6053, mse=0.6029, time=0.1178\n",
      "Iter=3400, loss=0.6275, mse=0.6252, time=0.1177\n",
      "Iter=3600, loss=0.6202, mse=0.6179, time=0.1178\n",
      "Iter=3800, loss=0.6207, mse=0.6183, time=0.1178\n",
      "Iter=4000, loss=0.6251, mse=0.6226, time=0.1178\n",
      "Iter=4200, loss=0.6215, mse=0.6191, time=0.1178\n",
      "Iter=4400, loss=0.6317, mse=0.6292, time=0.1178\n",
      "Iter=4600, loss=0.6418, mse=0.6390, time=0.1178\n",
      "Iter=4800, loss=0.6092, mse=0.6066, time=0.1178\n",
      "Iter=5000, loss=0.6295, mse=0.6269, time=0.1178\n",
      "Iter=5200, loss=0.6280, mse=0.6255, time=0.1179\n",
      "Iter=5400, loss=0.6265, mse=0.6239, time=0.1179\n",
      "Iter=5600, loss=0.6350, mse=0.6326, time=0.1179\n",
      "Iter=5800, loss=0.6055, mse=0.6032, time=0.1179\n",
      "Iter=6000, loss=0.6096, mse=0.6073, time=0.1179\n",
      "Iter=6200, loss=0.6181, mse=0.6158, time=0.1179\n",
      "Iter=6400, loss=0.6099, mse=0.6075, time=0.1179\n",
      "Iter=6600, loss=0.6182, mse=0.6158, time=0.1179\n",
      "=== Epoch 4, train loss 0.619497, test rmse 0.804829 ===\n",
      "  Training epoch took: 4:53:54\n",
      "Epoch 5\n",
      "Iter=200, loss=0.5995, mse=0.5969, time=0.1195\n",
      "Iter=400, loss=0.6051, mse=0.6027, time=0.1186\n",
      "Iter=600, loss=0.5865, mse=0.5840, time=0.1182\n",
      "Iter=800, loss=0.6172, mse=0.6148, time=0.1180\n",
      "Iter=1000, loss=0.6211, mse=0.6187, time=0.1179\n",
      "Iter=1200, loss=0.6196, mse=0.6171, time=0.1180\n",
      "Iter=1400, loss=0.6161, mse=0.6135, time=0.1181\n",
      "Iter=1600, loss=0.6066, mse=0.6039, time=0.1181\n",
      "Iter=1800, loss=0.5967, mse=0.5942, time=0.1181\n",
      "Iter=2000, loss=0.6246, mse=0.6222, time=0.1182\n",
      "Iter=2200, loss=0.6155, mse=0.6130, time=0.1182\n",
      "Iter=2400, loss=0.6251, mse=0.6226, time=0.1182\n",
      "Iter=2600, loss=0.6268, mse=0.6244, time=0.1182\n",
      "Iter=2800, loss=0.6126, mse=0.6102, time=0.1182\n",
      "Iter=3000, loss=0.6124, mse=0.6100, time=0.1182\n",
      "Iter=3200, loss=0.6148, mse=0.6125, time=0.1182\n",
      "Iter=3400, loss=0.6266, mse=0.6242, time=0.1182\n",
      "Iter=3600, loss=0.6194, mse=0.6172, time=0.1182\n",
      "Iter=3800, loss=0.6333, mse=0.6310, time=0.1182\n",
      "Iter=4000, loss=0.6235, mse=0.6213, time=0.1182\n",
      "Iter=4200, loss=0.6203, mse=0.6180, time=0.1183\n",
      "Iter=4400, loss=0.6191, mse=0.6169, time=0.1183\n",
      "Iter=4600, loss=0.5931, mse=0.5909, time=0.1183\n",
      "Iter=4800, loss=0.6406, mse=0.6383, time=0.1183\n",
      "Iter=5000, loss=0.6301, mse=0.6277, time=0.1182\n",
      "Iter=5200, loss=0.6292, mse=0.6268, time=0.1182\n",
      "Iter=5400, loss=0.6293, mse=0.6270, time=0.1182\n",
      "Iter=5600, loss=0.5993, mse=0.5971, time=0.1182\n",
      "Iter=5800, loss=0.6321, mse=0.6298, time=0.1182\n",
      "Iter=6000, loss=0.6138, mse=0.6114, time=0.1182\n",
      "Iter=6200, loss=0.6262, mse=0.6238, time=0.1182\n",
      "Iter=6400, loss=0.6188, mse=0.6165, time=0.1181\n",
      "Iter=6600, loss=0.6104, mse=0.6080, time=0.1181\n",
      "=== Epoch 5, train loss 0.617222, test rmse 0.804117 ===\n",
      "  Training epoch took: 6:01:01\n",
      "Epoch 6\n",
      "Iter=200, loss=0.6193, mse=0.6170, time=0.1184\n",
      "Iter=400, loss=0.5918, mse=0.5896, time=0.1185\n",
      "Iter=600, loss=0.6046, mse=0.6023, time=0.1182\n",
      "Iter=800, loss=0.6164, mse=0.6142, time=0.1182\n",
      "Iter=1000, loss=0.6136, mse=0.6115, time=0.1181\n",
      "Iter=1200, loss=0.6354, mse=0.6332, time=0.1181\n",
      "Iter=1400, loss=0.6326, mse=0.6303, time=0.1179\n",
      "Iter=1600, loss=0.6017, mse=0.5995, time=0.1179\n",
      "Iter=1800, loss=0.6257, mse=0.6233, time=0.1179\n",
      "Iter=2000, loss=0.6034, mse=0.6010, time=0.1180\n",
      "Iter=2200, loss=0.6096, mse=0.6072, time=0.1179\n",
      "Iter=2400, loss=0.6117, mse=0.6093, time=0.1178\n",
      "Iter=2600, loss=0.6101, mse=0.6077, time=0.1178\n",
      "Iter=2800, loss=0.5994, mse=0.5969, time=0.1178\n",
      "Iter=3000, loss=0.6073, mse=0.6048, time=0.1178\n",
      "Iter=3200, loss=0.6188, mse=0.6163, time=0.1178\n",
      "Iter=3400, loss=0.6099, mse=0.6073, time=0.1185\n",
      "Iter=3600, loss=0.6186, mse=0.6160, time=0.1186\n",
      "Iter=3800, loss=0.6043, mse=0.6016, time=0.1186\n",
      "Iter=4000, loss=0.6096, mse=0.6068, time=0.1186\n",
      "Iter=4200, loss=0.6120, mse=0.6094, time=0.1186\n",
      "Iter=4400, loss=0.6363, mse=0.6338, time=0.1185\n",
      "Iter=4600, loss=0.6111, mse=0.6084, time=0.1184\n",
      "Iter=4800, loss=0.6471, mse=0.6444, time=0.1184\n",
      "Iter=5000, loss=0.6236, mse=0.6211, time=0.1184\n",
      "Iter=5200, loss=0.6166, mse=0.6140, time=0.1184\n",
      "Iter=5400, loss=0.6355, mse=0.6327, time=0.1185\n",
      "Iter=5600, loss=0.6202, mse=0.6175, time=0.1185\n",
      "Iter=5800, loss=0.6147, mse=0.6119, time=0.1184\n",
      "Iter=6000, loss=0.5956, mse=0.5928, time=0.1184\n",
      "Iter=6200, loss=0.6310, mse=0.6284, time=0.1184\n",
      "Iter=6400, loss=0.6119, mse=0.6093, time=0.1184\n",
      "Iter=6600, loss=0.6263, mse=0.6238, time=0.1184\n",
      "=== Epoch 6, train loss 0.616250, test rmse 0.801978 ===\n",
      "  Training epoch took: 7:08:26\n",
      "Epoch 7\n",
      "Iter=200, loss=0.6141, mse=0.6115, time=0.1181\n",
      "Iter=400, loss=0.6123, mse=0.6096, time=0.1179\n",
      "Iter=600, loss=0.6106, mse=0.6080, time=0.1178\n",
      "Iter=800, loss=0.6129, mse=0.6103, time=0.1177\n",
      "Iter=1000, loss=0.6089, mse=0.6063, time=0.1177\n",
      "Iter=1200, loss=0.5957, mse=0.5932, time=0.1178\n",
      "Iter=1400, loss=0.6147, mse=0.6122, time=0.1178\n",
      "Iter=1600, loss=0.6148, mse=0.6123, time=0.1180\n",
      "Iter=1800, loss=0.6370, mse=0.6345, time=0.1180\n",
      "Iter=2000, loss=0.6320, mse=0.6295, time=0.1180\n",
      "Iter=2200, loss=0.5982, mse=0.5956, time=0.1179\n",
      "Iter=2400, loss=0.5987, mse=0.5961, time=0.1179\n",
      "Iter=2600, loss=0.6178, mse=0.6152, time=0.1180\n",
      "Iter=2800, loss=0.6201, mse=0.6176, time=0.1180\n",
      "Iter=3000, loss=0.6126, mse=0.6102, time=0.1181\n",
      "Iter=3200, loss=0.6028, mse=0.6004, time=0.1181\n",
      "Iter=3400, loss=0.6041, mse=0.6017, time=0.1181\n",
      "Iter=3600, loss=0.6126, mse=0.6102, time=0.1181\n",
      "Iter=3800, loss=0.6158, mse=0.6134, time=0.1181\n",
      "Iter=4000, loss=0.6176, mse=0.6152, time=0.1180\n",
      "Iter=4200, loss=0.6123, mse=0.6099, time=0.1180\n",
      "Iter=4400, loss=0.6110, mse=0.6087, time=0.1180\n",
      "Iter=4600, loss=0.6292, mse=0.6268, time=0.1180\n",
      "Iter=4800, loss=0.6285, mse=0.6262, time=0.1181\n",
      "Iter=5000, loss=0.6185, mse=0.6160, time=0.1181\n",
      "Iter=5200, loss=0.6215, mse=0.6189, time=0.1181\n",
      "Iter=5400, loss=0.6191, mse=0.6165, time=0.1181\n",
      "Iter=5600, loss=0.6277, mse=0.6251, time=0.1181\n",
      "Iter=5800, loss=0.6057, mse=0.6032, time=0.1181\n",
      "Iter=6000, loss=0.6116, mse=0.6091, time=0.1181\n",
      "Iter=6200, loss=0.6252, mse=0.6226, time=0.1181\n",
      "Iter=6400, loss=0.6148, mse=0.6122, time=0.1181\n",
      "Iter=6600, loss=0.6132, mse=0.6107, time=0.1181\n",
      "=== Epoch 7, train loss 0.614503, test rmse 0.817756 ===\n",
      "  Training epoch took: 8:15:30\n",
      "Epoch 8\n",
      "Iter=200, loss=0.6193, mse=0.6168, time=0.1182\n",
      "Iter=400, loss=0.6323, mse=0.6298, time=0.1177\n",
      "Iter=600, loss=0.6096, mse=0.6068, time=0.1178\n",
      "Iter=800, loss=0.6269, mse=0.6242, time=0.1180\n",
      "Iter=1000, loss=0.6051, mse=0.6023, time=0.1178\n",
      "Iter=1200, loss=0.6342, mse=0.6314, time=0.1178\n",
      "Iter=1400, loss=0.6005, mse=0.5977, time=0.1178\n",
      "Iter=1600, loss=0.6173, mse=0.6147, time=0.1179\n",
      "Iter=1800, loss=0.6104, mse=0.6079, time=0.1179\n",
      "Iter=2000, loss=0.6355, mse=0.6330, time=0.1179\n",
      "Iter=2200, loss=0.6239, mse=0.6216, time=0.1179\n",
      "Iter=2400, loss=0.5978, mse=0.5954, time=0.1177\n",
      "Iter=2600, loss=0.6245, mse=0.6220, time=0.1177\n",
      "Iter=2800, loss=0.6014, mse=0.5989, time=0.1177\n",
      "Iter=3000, loss=0.6015, mse=0.5992, time=0.1176\n",
      "Iter=3200, loss=0.6310, mse=0.6287, time=0.1176\n",
      "Iter=3400, loss=0.6245, mse=0.6223, time=0.1176\n",
      "Iter=3600, loss=0.5985, mse=0.5962, time=0.1176\n",
      "Iter=3800, loss=0.6007, mse=0.5984, time=0.1176\n",
      "Iter=4000, loss=0.6041, mse=0.6019, time=0.1176\n",
      "Iter=4200, loss=0.6054, mse=0.6032, time=0.1176\n",
      "Iter=4400, loss=0.6011, mse=0.5987, time=0.1176\n",
      "Iter=4600, loss=0.6090, mse=0.6067, time=0.1177\n",
      "Iter=4800, loss=0.5962, mse=0.5939, time=0.1176\n",
      "Iter=5000, loss=0.6233, mse=0.6210, time=0.1177\n",
      "Iter=5200, loss=0.6123, mse=0.6101, time=0.1177\n",
      "Iter=5400, loss=0.6088, mse=0.6066, time=0.1177\n",
      "Iter=5600, loss=0.6258, mse=0.6235, time=0.1178\n",
      "Iter=5800, loss=0.6167, mse=0.6144, time=0.1178\n",
      "Iter=6000, loss=0.6022, mse=0.6000, time=0.1178\n",
      "Iter=6200, loss=0.6148, mse=0.6125, time=0.1178\n",
      "Iter=6400, loss=0.6328, mse=0.6305, time=0.1178\n",
      "Iter=6600, loss=0.6033, mse=0.6009, time=0.1178\n",
      "=== Epoch 8, train loss 0.613651, test rmse 0.811223 ===\n",
      "  Training epoch took: 9:22:32\n",
      "Epoch 9\n",
      "Iter=200, loss=0.5959, mse=0.5936, time=0.1183\n",
      "Iter=400, loss=0.6083, mse=0.6061, time=0.1182\n",
      "Iter=600, loss=0.5935, mse=0.5913, time=0.1179\n",
      "Iter=800, loss=0.6096, mse=0.6075, time=0.1181\n",
      "Iter=1000, loss=0.6084, mse=0.6063, time=0.1214\n",
      "Iter=1200, loss=0.6065, mse=0.6043, time=0.1210\n",
      "Iter=1400, loss=0.6299, mse=0.6277, time=0.1206\n",
      "Iter=1600, loss=0.6001, mse=0.5979, time=0.1204\n",
      "Iter=1800, loss=0.6141, mse=0.6118, time=0.1202\n",
      "Iter=2000, loss=0.6117, mse=0.6094, time=0.1200\n",
      "Iter=2200, loss=0.6160, mse=0.6136, time=0.1199\n",
      "Iter=2400, loss=0.6181, mse=0.6157, time=0.1198\n",
      "Iter=2600, loss=0.6272, mse=0.6247, time=0.1197\n",
      "Iter=2800, loss=0.6203, mse=0.6179, time=0.1196\n",
      "Iter=3000, loss=0.6187, mse=0.6162, time=0.1196\n",
      "Iter=3200, loss=0.6306, mse=0.6282, time=0.1194\n",
      "Iter=3400, loss=0.6452, mse=0.6427, time=0.1193\n",
      "Iter=3600, loss=0.6026, mse=0.6001, time=0.1194\n",
      "Iter=3800, loss=0.5922, mse=0.5898, time=0.1195\n",
      "Iter=4000, loss=0.5973, mse=0.5949, time=0.1194\n",
      "Iter=4200, loss=0.6229, mse=0.6205, time=0.1193\n",
      "Iter=4400, loss=0.6304, mse=0.6282, time=0.1192\n",
      "Iter=4600, loss=0.6232, mse=0.6209, time=0.1192\n",
      "Iter=4800, loss=0.5956, mse=0.5933, time=0.1192\n",
      "Iter=5000, loss=0.6031, mse=0.6008, time=0.1191\n",
      "Iter=5200, loss=0.6297, mse=0.6275, time=0.1191\n",
      "Iter=5400, loss=0.6353, mse=0.6330, time=0.1190\n",
      "Iter=5600, loss=0.6236, mse=0.6213, time=0.1190\n",
      "Iter=5800, loss=0.6162, mse=0.6139, time=0.1189\n",
      "Iter=6000, loss=0.6230, mse=0.6208, time=0.1189\n",
      "Iter=6200, loss=0.6010, mse=0.5987, time=0.1189\n",
      "Iter=6400, loss=0.6060, mse=0.6038, time=0.1188\n",
      "Iter=6600, loss=0.6197, mse=0.6175, time=0.1188\n",
      "=== Epoch 9, train loss 0.614455, test rmse 0.803016 ===\n",
      "  Training epoch took: 10:29:58\n",
      "Epoch 10\n",
      "Iter=200, loss=0.6294, mse=0.6270, time=0.1182\n",
      "Iter=400, loss=0.6127, mse=0.6104, time=0.1183\n",
      "Iter=600, loss=0.6353, mse=0.6330, time=0.1179\n",
      "Iter=800, loss=0.6275, mse=0.6252, time=0.1181\n",
      "Iter=1000, loss=0.6032, mse=0.6008, time=0.1180\n",
      "Iter=1200, loss=0.6001, mse=0.5979, time=0.1180\n",
      "Iter=1400, loss=0.6149, mse=0.6127, time=0.1180\n",
      "Iter=1600, loss=0.6254, mse=0.6232, time=0.1179\n",
      "Iter=1800, loss=0.6142, mse=0.6121, time=0.1179\n",
      "Iter=2000, loss=0.6029, mse=0.6007, time=0.1179\n",
      "Iter=2200, loss=0.5983, mse=0.5960, time=0.1180\n",
      "Iter=2400, loss=0.6074, mse=0.6052, time=0.1180\n",
      "Iter=2600, loss=0.6201, mse=0.6179, time=0.1181\n",
      "Iter=2800, loss=0.6259, mse=0.6236, time=0.1180\n",
      "Iter=3000, loss=0.6186, mse=0.6164, time=0.1180\n",
      "Iter=3200, loss=0.6097, mse=0.6076, time=0.1180\n",
      "Iter=3400, loss=0.5853, mse=0.5830, time=0.1180\n",
      "Iter=3600, loss=0.5980, mse=0.5958, time=0.1180\n",
      "Iter=3800, loss=0.6250, mse=0.6228, time=0.1180\n",
      "Iter=4000, loss=0.6003, mse=0.5981, time=0.1180\n",
      "Iter=4200, loss=0.6251, mse=0.6229, time=0.1180\n",
      "Iter=4400, loss=0.6059, mse=0.6037, time=0.1180\n",
      "Iter=4600, loss=0.6104, mse=0.6081, time=0.1180\n",
      "Iter=4800, loss=0.6141, mse=0.6118, time=0.1180\n",
      "Iter=5000, loss=0.6090, mse=0.6065, time=0.1180\n",
      "Iter=5200, loss=0.6168, mse=0.6143, time=0.1180\n",
      "Iter=5400, loss=0.6318, mse=0.6294, time=0.1180\n",
      "Iter=5600, loss=0.5900, mse=0.5876, time=0.1180\n",
      "Iter=5800, loss=0.6231, mse=0.6208, time=0.1180\n",
      "Iter=6000, loss=0.6061, mse=0.6038, time=0.1180\n",
      "Iter=6200, loss=0.6042, mse=0.6018, time=0.1180\n",
      "Iter=6400, loss=0.6175, mse=0.6150, time=0.1180\n",
      "Iter=6600, loss=0.6131, mse=0.6106, time=0.1180\n",
      "=== Epoch 10, train loss 0.612611, test rmse 0.804511 ===\n",
      "  Training epoch took: 11:37:05\n",
      "Epoch 11\n",
      "Iter=200, loss=0.6247, mse=0.6222, time=0.1173\n",
      "Iter=400, loss=0.6282, mse=0.6255, time=0.1178\n",
      "Iter=600, loss=0.6147, mse=0.6122, time=0.1176\n",
      "Iter=800, loss=0.6242, mse=0.6216, time=0.1177\n",
      "Iter=1000, loss=0.6072, mse=0.6047, time=0.1178\n",
      "Iter=1200, loss=0.5986, mse=0.5960, time=0.1178\n",
      "Iter=1400, loss=0.6147, mse=0.6121, time=0.1179\n",
      "Iter=1600, loss=0.5979, mse=0.5953, time=0.1179\n",
      "Iter=1800, loss=0.6046, mse=0.6019, time=0.1178\n",
      "Iter=2000, loss=0.6235, mse=0.6208, time=0.1179\n",
      "Iter=2200, loss=0.6191, mse=0.6165, time=0.1179\n",
      "Iter=2400, loss=0.5922, mse=0.5896, time=0.1179\n",
      "Iter=2600, loss=0.6071, mse=0.6046, time=0.1180\n",
      "Iter=2800, loss=0.6142, mse=0.6118, time=0.1180\n",
      "Iter=3000, loss=0.6211, mse=0.6186, time=0.1179\n",
      "Iter=3200, loss=0.6147, mse=0.6121, time=0.1179\n",
      "Iter=3400, loss=0.6237, mse=0.6211, time=0.1180\n",
      "Iter=3600, loss=0.6074, mse=0.6049, time=0.1180\n",
      "Iter=3800, loss=0.6191, mse=0.6166, time=0.1179\n",
      "Iter=4000, loss=0.5941, mse=0.5915, time=0.1180\n",
      "Iter=4200, loss=0.6217, mse=0.6193, time=0.1180\n",
      "Iter=4400, loss=0.6198, mse=0.6175, time=0.1180\n",
      "Iter=4600, loss=0.6291, mse=0.6268, time=0.1180\n",
      "Iter=4800, loss=0.5835, mse=0.5812, time=0.1180\n",
      "Iter=5000, loss=0.6146, mse=0.6121, time=0.1180\n",
      "Iter=5200, loss=0.6050, mse=0.6023, time=0.1180\n",
      "Iter=5400, loss=0.6162, mse=0.6139, time=0.1180\n",
      "Iter=5600, loss=0.6227, mse=0.6204, time=0.1180\n",
      "Iter=5800, loss=0.6362, mse=0.6338, time=0.1180\n",
      "Iter=6000, loss=0.6190, mse=0.6168, time=0.1180\n",
      "Iter=6200, loss=0.6042, mse=0.6020, time=0.1180\n",
      "Iter=6400, loss=0.6168, mse=0.6145, time=0.1180\n",
      "Iter=6600, loss=0.6203, mse=0.6180, time=0.1180\n",
      "=== Epoch 11, train loss 0.614111, test rmse 0.801641 ===\n",
      "  Training epoch took: 12:44:10\n",
      "Epoch 12\n",
      "Iter=200, loss=0.6258, mse=0.6235, time=0.1186\n",
      "Iter=400, loss=0.6006, mse=0.5983, time=0.1190\n",
      "Iter=600, loss=0.6031, mse=0.6008, time=0.1185\n",
      "Iter=800, loss=0.6201, mse=0.6178, time=0.1181\n",
      "Iter=1000, loss=0.6073, mse=0.6051, time=0.1181\n",
      "Iter=1200, loss=0.5815, mse=0.5793, time=0.1180\n",
      "Iter=1400, loss=0.6369, mse=0.6347, time=0.1181\n",
      "Iter=1600, loss=0.5986, mse=0.5963, time=0.1179\n",
      "Iter=1800, loss=0.6153, mse=0.6130, time=0.1179\n",
      "Iter=2000, loss=0.6431, mse=0.6409, time=0.1179\n",
      "Iter=2200, loss=0.6245, mse=0.6223, time=0.1177\n",
      "Iter=2400, loss=0.5999, mse=0.5979, time=0.1178\n",
      "Iter=2600, loss=0.6194, mse=0.6173, time=0.1178\n",
      "Iter=2800, loss=0.6120, mse=0.6099, time=0.1179\n",
      "Iter=3000, loss=0.6168, mse=0.6145, time=0.1179\n",
      "Iter=3200, loss=0.6022, mse=0.6000, time=0.1179\n",
      "Iter=3400, loss=0.6124, mse=0.6103, time=0.1179\n",
      "Iter=3600, loss=0.6125, mse=0.6103, time=0.1179\n",
      "Iter=3800, loss=0.6099, mse=0.6077, time=0.1179\n",
      "Iter=4000, loss=0.6083, mse=0.6063, time=0.1179\n",
      "Iter=4200, loss=0.6224, mse=0.6203, time=0.1179\n",
      "Iter=4400, loss=0.6175, mse=0.6154, time=0.1180\n",
      "Iter=4600, loss=0.6079, mse=0.6056, time=0.1180\n",
      "Iter=4800, loss=0.6106, mse=0.6084, time=0.1180\n",
      "Iter=5000, loss=0.6129, mse=0.6107, time=0.1180\n",
      "Iter=5200, loss=0.6489, mse=0.6468, time=0.1180\n",
      "Iter=5400, loss=0.6066, mse=0.6046, time=0.1180\n",
      "Iter=5600, loss=0.6215, mse=0.6194, time=0.1180\n",
      "Iter=5800, loss=0.6027, mse=0.6006, time=0.1180\n",
      "Iter=6000, loss=0.5926, mse=0.5904, time=0.1180\n",
      "Iter=6200, loss=0.6149, mse=0.6128, time=0.1181\n",
      "Iter=6400, loss=0.6273, mse=0.6251, time=0.1181\n",
      "Iter=6600, loss=0.6104, mse=0.6082, time=0.1180\n",
      "=== Epoch 12, train loss 0.613452, test rmse 0.807436 ===\n",
      "  Training epoch took: 13:51:15\n",
      "Epoch 13\n",
      "Iter=200, loss=0.6098, mse=0.6076, time=0.1183\n",
      "Iter=400, loss=0.6026, mse=0.6004, time=0.1181\n",
      "Iter=600, loss=0.6056, mse=0.6035, time=0.1182\n",
      "Iter=800, loss=0.6274, mse=0.6252, time=0.1181\n",
      "Iter=1000, loss=0.6099, mse=0.6077, time=0.1182\n",
      "Iter=1200, loss=0.6026, mse=0.6003, time=0.1182\n",
      "Iter=1400, loss=0.6196, mse=0.6173, time=0.1183\n",
      "Iter=1600, loss=0.5946, mse=0.5923, time=0.1184\n",
      "Iter=1800, loss=0.5984, mse=0.5963, time=0.1183\n",
      "Iter=2000, loss=0.6148, mse=0.6128, time=0.1182\n",
      "Iter=2200, loss=0.6028, mse=0.6008, time=0.1180\n",
      "Iter=2400, loss=0.6154, mse=0.6135, time=0.1181\n",
      "Iter=2600, loss=0.6142, mse=0.6122, time=0.1180\n",
      "Iter=2800, loss=0.6068, mse=0.6047, time=0.1180\n",
      "Iter=3000, loss=0.6036, mse=0.6015, time=0.1179\n",
      "Iter=3200, loss=0.6140, mse=0.6117, time=0.1179\n",
      "Iter=3400, loss=0.5930, mse=0.5909, time=0.1179\n",
      "Iter=3600, loss=0.6225, mse=0.6203, time=0.1179\n",
      "Iter=3800, loss=0.6127, mse=0.6105, time=0.1179\n",
      "Iter=4000, loss=0.6049, mse=0.6028, time=0.1179\n",
      "Iter=4200, loss=0.6211, mse=0.6191, time=0.1178\n",
      "Iter=4400, loss=0.6369, mse=0.6350, time=0.1178\n",
      "Iter=4600, loss=0.6072, mse=0.6051, time=0.1179\n",
      "Iter=4800, loss=0.6335, mse=0.6312, time=0.1179\n",
      "Iter=5000, loss=0.6305, mse=0.6282, time=0.1180\n",
      "Iter=5200, loss=0.6210, mse=0.6187, time=0.1179\n",
      "Iter=5400, loss=0.6226, mse=0.6203, time=0.1179\n",
      "Iter=5600, loss=0.6028, mse=0.6004, time=0.1180\n",
      "Iter=5800, loss=0.5915, mse=0.5893, time=0.1179\n",
      "Iter=6000, loss=0.6070, mse=0.6049, time=0.1179\n",
      "Iter=6200, loss=0.6106, mse=0.6086, time=0.1180\n",
      "Iter=6400, loss=0.6232, mse=0.6212, time=0.1180\n",
      "Iter=6600, loss=0.6307, mse=0.6285, time=0.1180\n",
      "=== Epoch 13, train loss 0.612549, test rmse 0.810908 ===\n",
      "  Training epoch took: 14:58:21\n",
      "Epoch 14\n",
      "Iter=200, loss=0.5962, mse=0.5938, time=0.1186\n",
      "Iter=400, loss=0.6128, mse=0.6106, time=0.1181\n",
      "Iter=600, loss=0.6025, mse=0.6004, time=0.1182\n",
      "Iter=800, loss=0.6145, mse=0.6123, time=0.1180\n",
      "Iter=1000, loss=0.6181, mse=0.6159, time=0.1181\n",
      "Iter=1200, loss=0.6287, mse=0.6267, time=0.1181\n",
      "Iter=1400, loss=0.5979, mse=0.5958, time=0.1180\n",
      "Iter=1600, loss=0.6208, mse=0.6185, time=0.1180\n",
      "Iter=1800, loss=0.6220, mse=0.6199, time=0.1181\n",
      "Iter=2000, loss=0.6263, mse=0.6241, time=0.1181\n",
      "Iter=2200, loss=0.6090, mse=0.6068, time=0.1181\n",
      "Iter=2400, loss=0.6099, mse=0.6077, time=0.1181\n",
      "Iter=2600, loss=0.6137, mse=0.6114, time=0.1181\n",
      "Iter=2800, loss=0.6389, mse=0.6368, time=0.1181\n",
      "Iter=3000, loss=0.6029, mse=0.6007, time=0.1181\n",
      "Iter=3200, loss=0.5962, mse=0.5940, time=0.1181\n",
      "Iter=3400, loss=0.6137, mse=0.6116, time=0.1181\n",
      "Iter=3600, loss=0.6391, mse=0.6369, time=0.1181\n",
      "Iter=3800, loss=0.6246, mse=0.6226, time=0.1181\n",
      "Iter=4000, loss=0.6059, mse=0.6040, time=0.1181\n",
      "Iter=4200, loss=0.6136, mse=0.6116, time=0.1181\n",
      "Iter=4400, loss=0.5978, mse=0.5959, time=0.1181\n",
      "Iter=4600, loss=0.6144, mse=0.6124, time=0.1181\n",
      "Iter=4800, loss=0.6248, mse=0.6227, time=0.1180\n",
      "Iter=5000, loss=0.6393, mse=0.6370, time=0.1180\n",
      "Iter=5200, loss=0.6153, mse=0.6132, time=0.1180\n",
      "Iter=5400, loss=0.5977, mse=0.5955, time=0.1180\n",
      "Iter=5600, loss=0.6045, mse=0.6023, time=0.1180\n",
      "Iter=5800, loss=0.5963, mse=0.5940, time=0.1180\n",
      "Iter=6000, loss=0.6360, mse=0.6336, time=0.1180\n",
      "Iter=6200, loss=0.6242, mse=0.6218, time=0.1179\n",
      "Iter=6400, loss=0.6163, mse=0.6139, time=0.1179\n",
      "Iter=6600, loss=0.6379, mse=0.6353, time=0.1179\n",
      "=== Epoch 14, train loss 0.615158, test rmse 0.811257 ===\n",
      "  Training epoch took: 16:05:25\n",
      "Epoch 15\n",
      "Iter=200, loss=0.6140, mse=0.6115, time=0.1174\n",
      "Iter=400, loss=0.6145, mse=0.6121, time=0.1178\n",
      "Iter=600, loss=0.6277, mse=0.6253, time=0.1181\n",
      "Iter=800, loss=0.6226, mse=0.6204, time=0.1182\n",
      "Iter=1000, loss=0.6100, mse=0.6077, time=0.1182\n",
      "Iter=1200, loss=0.5997, mse=0.5973, time=0.1183\n",
      "Iter=1400, loss=0.6326, mse=0.6303, time=0.1183\n",
      "Iter=1600, loss=0.6189, mse=0.6165, time=0.1183\n",
      "Iter=1800, loss=0.6062, mse=0.6037, time=0.1182\n",
      "Iter=2000, loss=0.6022, mse=0.5998, time=0.1183\n",
      "Iter=2200, loss=0.5744, mse=0.5720, time=0.1184\n",
      "Iter=2400, loss=0.6058, mse=0.6033, time=0.1184\n",
      "Iter=2600, loss=0.6129, mse=0.6106, time=0.1184\n",
      "Iter=2800, loss=0.5964, mse=0.5941, time=0.1183\n",
      "Iter=3000, loss=0.6096, mse=0.6073, time=0.1183\n",
      "Iter=3200, loss=0.5928, mse=0.5904, time=0.1182\n",
      "Iter=3400, loss=0.6141, mse=0.6117, time=0.1183\n",
      "Iter=3600, loss=0.6319, mse=0.6295, time=0.1183\n",
      "Iter=3800, loss=0.6249, mse=0.6226, time=0.1184\n",
      "Iter=4000, loss=0.6281, mse=0.6259, time=0.1191\n"
     ]
    }
   ],
   "source": [
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "for epoch_idx in range(1, 20):\n",
    "    print ('Epoch', epoch_idx)\n",
    "\n",
    "    train_loss, predict_train_list, label_train_list  = train_epoch(model, loss_fn, optimizer, args.arr_lambda, \n",
    "                            train_loader, args.device, args.train_log_interval)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(model, test_loader, args.device)\n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model, optimizer)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90669ed-13ea-413e-800d-0d14044424f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8246579296371273"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25ddbd54-1fd9-4297-acdb-8473e455fc46",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_train_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_52692/3291285701.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_emotion_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_train_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_emotion_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvalid_emotion_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_valid_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_valid_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict_train_list' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_emotion_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "# valid_emotion_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "# valid_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_emotion_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "646f6c55-8dc5-4999-b2b0-70af13b2248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ends. The best testing rmse is 0.804960 at epoch 2\n"
     ]
    }
   ],
   "source": [
    "path = './raw_data/rotten_tomato/explicit/'\n",
    "rate = 1\n",
    "train_emotion_df.to_csv(path + f'explicit_train_emotion_{rate}.csv', index=False)\n",
    "# valid_emotion_df.to_csv(path + f'explicit_valid_emotion_{rate}.csv', index=False)\n",
    "test_emotion_df.to_csv(path + f'explicit_test_emotion_{rate}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ec387-47c1-4660-87ad-f1a5138ef95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03faa981-c0e4-438c-846b-bdd142d583ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c728cd9-f005-491f-84dc-d63650c2700a",
   "metadata": {},
   "source": [
    "### Train_epoch 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4bec73f-8cab-45aa-a3cb-beccdda9bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "loss_fn = loss_fn\n",
    "optimizer = optimizer\n",
    "arr_lambda = args.arr_lambda\n",
    "loader = train_loader\n",
    "device = args.device\n",
    "log_interval = args.train_log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df6fd326-b5dc-4acd-8832-9aae253d90a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82e5500a-2408-4c15-a6dd-0275f00a2a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for iter_idx, batch in enumerate(loader, start=1):\n",
    "    print(iter_idx)\n",
    "    if iter_idx == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b454620b-9795-4b72-b151-73be1461b119",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=200, loss=5.0480, mse=5.0403, time=0.0473\n",
      "Iter=400, loss=3.2373, mse=3.2299, time=0.0425\n",
      "Iter=600, loss=3.2133, mse=3.2064, time=0.0419\n",
      "Iter=800, loss=3.1650, mse=3.1585, time=0.0415\n",
      "Iter=1000, loss=3.1144, mse=3.1082, time=0.0413\n",
      "Iter=1200, loss=3.0636, mse=3.0578, time=0.0411\n",
      "Iter=1400, loss=2.9595, mse=2.9539, time=0.0410\n",
      "Iter=1600, loss=2.9292, mse=2.9239, time=0.0408\n",
      "Iter=1800, loss=2.8808, mse=2.8756, time=0.0408\n",
      "Iter=2000, loss=2.9187, mse=2.9137, time=0.0409\n",
      "Iter=2200, loss=2.9908, mse=2.9861, time=0.0410\n",
      "Iter=2400, loss=2.9135, mse=2.9088, time=0.0412\n",
      "Iter=2600, loss=2.8839, mse=2.8795, time=0.0411\n",
      "Iter=2800, loss=2.9526, mse=2.9484, time=0.0411\n",
      "Iter=3000, loss=2.7681, mse=2.7641, time=0.0411\n",
      "Iter=3200, loss=2.9428, mse=2.9389, time=0.0410\n",
      "Iter=3400, loss=2.8883, mse=2.8843, time=0.0410\n",
      "Iter=3600, loss=2.8257, mse=2.8217, time=0.0413\n",
      "Iter=3800, loss=2.8143, mse=2.8105, time=0.0414\n",
      "Iter=4000, loss=2.8891, mse=2.8853, time=0.0417\n",
      "Iter=4200, loss=2.7421, mse=2.7384, time=0.0417\n",
      "Iter=4400, loss=2.8413, mse=2.8378, time=0.0417\n",
      "Iter=4600, loss=2.7401, mse=2.7365, time=0.0416\n",
      "Iter=4800, loss=2.8078, mse=2.8041, time=0.0416\n",
      "Iter=5000, loss=2.7927, mse=2.7891, time=0.0416\n",
      "Iter=5200, loss=2.7636, mse=2.7601, time=0.0415\n",
      "Iter=5400, loss=2.7138, mse=2.7103, time=0.0417\n",
      "Iter=5600, loss=2.7358, mse=2.7324, time=0.0417\n",
      "Iter=5800, loss=2.7588, mse=2.7552, time=0.0416\n",
      "Iter=6000, loss=2.7475, mse=2.7439, time=0.0416\n",
      "Iter=6200, loss=2.7544, mse=2.7507, time=0.0416\n",
      "Iter=6400, loss=2.8208, mse=2.8171, time=0.0415\n",
      "Iter=6600, loss=2.7839, mse=2.7801, time=0.0416\n",
      "  Time took: 0:04:58\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.train()\n",
    "\n",
    "epoch_loss = 0.\n",
    "iter_loss = 0.\n",
    "iter_mse = 0.\n",
    "iter_cnt = 0\n",
    "iter_dur = []\n",
    "\n",
    "# 서브그래프 단위로 학습\n",
    "for iter_idx, batch in enumerate(loader, start=1):\n",
    "    t_start = time.time()\n",
    "\n",
    "    inputs = batch[0].to(device)\n",
    "    labels = batch[1].to(device)\n",
    "    preds = model(inputs)\n",
    "    loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item() * preds.shape[0]\n",
    "    iter_loss += loss.item() * preds.shape[0]\n",
    "    iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "    iter_cnt += preds.shape[0]\n",
    "    iter_dur.append(time.time() - t_start)\n",
    "\n",
    "    if iter_idx % log_interval == 0:\n",
    "        print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "            iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "        iter_loss = 0.\n",
    "        iter_mse = 0.\n",
    "        iter_cnt = 0\n",
    "\n",
    "train_epoch_loss = epoch_loss / len(loader.dataset)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b29fffa-8cc3-4a70-98ed-4d22a4617f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IGMC"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d54b44e-f603-4327-9a87-904041c70d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=1120, num_edges=31588,\n",
       "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'nlabel': Scheme(shape=(4,), dtype=torch.float32), 'x': Scheme(shape=(4,), dtype=torch.float32)}\n",
       "      edata_schemes={'etype': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64), 'edge_mask': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87899af1-f644-4299-8f35-0cabadb300b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0763, 7.5723, 4.1323, 5.4378, 5.5795, 6.2285, 6.7028, 4.2875],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "992ba225-8165-40a2-8384-81b354d23b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 7., 6., 7., 7., 7., 9., 5.], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41f4dcf4-1350-4831-9dc5-c356e1daf391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9040, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "987146e4-6ad1-4339-b27f-851e94945000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f305240a-7b5c-4100-8d58-5dab9f972c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.727407252259081"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "613c9bbf-4877-49bd-9cb2-f5927bcd8038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.0923, 5.4808, 6.1765, 8.1413, 7.6566, 4.6887, 6.3527, 6.4477, 6.0566,\n",
       "        5.4327, 5.4816, 7.4522, 5.6513, 8.6706, 5.8030, 7.2858, 4.5068, 8.8621,\n",
       "        3.4885, 7.3030, 3.4780, 6.1335, 2.9561, 4.1378, 5.3948, 6.8066, 5.6749,\n",
       "        5.6852, 4.4658, 7.3438, 9.4554, 7.2134], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198de4d4-9dc0-4184-84f4-1a40cc509972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37162a-ee65-4af9-9cab-e4a795fc5099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4c6bc06-0a33-414c-a73b-e409bca5e421",
   "metadata": {},
   "source": [
    "### Evaluate 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb2b26d9-25c4-4328-802b-068c674c8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "loader = test_loader\n",
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47e1a54f-e56b-4650-a9c1-498ad5893824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time took: 0:00:27\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict_ratings = list()\n",
    "real_ratings = list()\n",
    "\n",
    "# Evaluate RMSE\n",
    "model.eval()\n",
    "mse = 0.\n",
    "for batch in loader:\n",
    "    with th.no_grad():\n",
    "        preds = (model(batch[0].to(device)) + 1)/ 2\n",
    "    labels = (batch[1].to(device) + 1)/ 2\n",
    "    mse += ((preds - labels) ** 2).sum().item()\n",
    "    \n",
    "    real_ratings.append(labels)\n",
    "    predict_ratings.append(preds)\n",
    "    \n",
    "mse /= len(loader.dataset)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a533c878-4f4f-4d70-b1ab-1f930ab636b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9968, 3.1041, 2.8940, 3.9403, 4.1405, 3.1857, 3.4408, 4.0894, 2.6228,\n",
       "        3.2692, 2.8797, 2.1028, 2.8179, 3.5234, 3.3022, 4.0670, 4.0670, 2.9974,\n",
       "        2.1890, 2.4611, 1.2208, 2.3978, 3.7354, 2.5466, 3.1223, 3.4322, 2.1431,\n",
       "        2.5878, 2.5878, 3.6192], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3292c796-c71b-4078-8fd9-a07f58be62b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5000, 3.5000, 3.5000, 5.0000, 4.0000, 4.5000, 4.5000, 4.0000, 4.0000,\n",
       "        3.5000, 4.5000, 1.0000, 3.0000, 2.5000, 4.0000, 2.0000, 2.0000, 4.0000,\n",
       "        2.5000, 2.5000, 2.5000, 2.5000, 5.0000, 3.0000, 3.5000, 5.0000, 3.5000,\n",
       "        3.0000, 3.0000, 4.5000], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54927b7e-515f-481e-b8ed-d746e8de230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.838736481576567"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dca19d71-2874-4586-a7a6-5547ed60a2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7650, 2.8793, 2.5193, 2.8136, 3.7364, 2.8414, 2.8343, 3.5618, 3.6456,\n",
       "        3.5358], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ratings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a41bd92d-e324-4a86-9656-da4c8c516a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 3.0000, 3.0000, 2.5000, 3.0000, 3.0000, 3.0000, 4.5000, 3.0000,\n",
       "        2.5000], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_ratings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f0465-ef4c-424f-8a7d-1bd31800fc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae685cc-df32-47d9-ab80-320e40749f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda367ca-52b8-4455-87ec-c8cc7b71562b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
