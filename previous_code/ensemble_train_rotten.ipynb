{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9808d08-eb26-4f02-bc5f-364f9aa033f3",
   "metadata": {},
   "source": [
    "# Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee754ff-2a3d-4760-9dde-f35b5079e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training epoch took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5af6c94-0780-4733-88b7-286a4a08728a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training IGMC model on the MovieLens dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "from shutil import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import IGMC\n",
    "from explicit_data_rotten import RottenTomato\n",
    "from dataset_rotten import RottenTomatoDataset, collate_rotten_tomato\n",
    "from utils import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c1bb83-260d-40b8-900b-6c27d7da5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(label_type, model, loader, device):\n",
    "    predict_list = list()\n",
    "    label_list = list()\n",
    "\n",
    "    # Evaluate RMSE\n",
    "    model.eval()\n",
    "    mse = 0.\n",
    "    for batch in loader:\n",
    "        with th.no_grad():\n",
    "            preds = model(batch[0].to(device))\n",
    "        labels = batch[1].to(device)\n",
    "\n",
    "        if label_type == 'rating':\n",
    "            preds  = (preds + 1)/2\n",
    "            labels = (labels + 1)/2\n",
    "        else:\n",
    "            preds  = preds + 1\n",
    "            labels = labels + 1\n",
    "        mse += ((preds - labels) ** 2).sum().item()\n",
    "\n",
    "        predict_list.append(preds.tolist()) # 예측값 저장\n",
    "        label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "    # 2차원 -> 1차원 리스트 변형\n",
    "    predict_list = [element for array in predict_list for element in array]\n",
    "    label_list = [element for array in label_list for element in array]    \n",
    "\n",
    "    mse /= len(loader.dataset)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse, predict_list, label_list\n",
    "\n",
    "\n",
    "def adj_rating_reg(model):\n",
    "    arr_loss = 0\n",
    "    for conv in model.convs:\n",
    "        weight = conv.weight.view(conv.num_bases, conv.in_feat * conv.out_feat)\n",
    "        weight = th.matmul(conv.w_comp, weight).view(conv.num_rels, conv.in_feat, conv.out_feat)\n",
    "        arr_loss += th.sum((weight[1:, :, :] - weight[:-1, :, :])**2)\n",
    "    return arr_loss\n",
    "\n",
    "# @profile\n",
    "def train_epoch(label_type, model, loss_fn, optimizer, arr_lambda, loader, device, log_interval):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.\n",
    "    iter_loss = 0.\n",
    "    iter_mse = 0.\n",
    "    iter_cnt = 0\n",
    "    iter_dur = []\n",
    "\n",
    "    # 저장 리스트(예측, 정답)\n",
    "    predict_list = list()\n",
    "    label_list = list()\n",
    "\n",
    "    # 서브그래프 단위로 학습\n",
    "    for iter_idx, batch in enumerate(loader, start=1):\n",
    "        t_start = time.time()\n",
    "\n",
    "        inputs = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "        preds = model(inputs)\n",
    "\n",
    "        if label_type == 'rating':\n",
    "            preds  = (preds + 1)/2\n",
    "            labels = (labels + 1)/2\n",
    "        else:\n",
    "            preds  = preds + 1\n",
    "            labels = labels + 1\n",
    "        \n",
    "        if label_type == 'emotion':\n",
    "            loss = loss_fn(preds, labels).mean()\n",
    "        else:\n",
    "            loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * preds.shape[0]\n",
    "        iter_loss += loss.item() * preds.shape[0]\n",
    "        iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "        iter_cnt += preds.shape[0]\n",
    "        iter_dur.append(time.time() - t_start)\n",
    "\n",
    "        predict_list.append(preds.tolist()) # 예측값 저장\n",
    "        label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "        if iter_idx % log_interval == 0:\n",
    "            print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "                iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "            iter_loss = 0.\n",
    "            iter_mse = 0.\n",
    "            iter_cnt = 0\n",
    "\n",
    "    # 2차원 -> 1차원 리스트 변형\n",
    "    predict_list = [element for array in predict_list for element in array]\n",
    "    label_list = [element for array in label_list for element in array]\n",
    "\n",
    "    train_epoch_loss = epoch_loss / len(loader.dataset)  \n",
    "    return train_epoch_loss, predict_list, label_list\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    movielens = MovieLens(args.data_name, testing=args.testing,\n",
    "                            test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "    if args.testing:\n",
    "        test_dataset = RottenTomatoDataset(\n",
    "            movielens.test_rating_pairs, movielens.test_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "    else:\n",
    "        test_dataset = RottenTomatoDataset(\n",
    "            movielens.valid_rating_pairs, movielens.valid_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "    train_dataset = RottenTomatoDataset(\n",
    "        movielens.train_rating_pairs, movielens.train_rating_values, movielens.train_graph, \n",
    "        args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "    train_loader = th.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "    test_loader = th.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "\n",
    "    in_feats = (args.hop+1)*2 #+ movielens.train_graph.ndata['refex'].shape[1]\n",
    "    model = IGMC(in_feats=in_feats, \n",
    "                 latent_dim=[32, 32, 32, 32],\n",
    "                 num_relations=5, # movielens.num_rating, \n",
    "                 num_bases=4, \n",
    "                 regression=True, \n",
    "                 edge_dropout=args.edge_dropout,\n",
    "                #  side_features=args.use_features,\n",
    "                #  n_side_features=n_features,\n",
    "                #  multiply_by=args.multiply_by\n",
    "            ).to(args.device)\n",
    "    loss_fn = nn.MSELoss().to(args.device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "    print(\"Loading network finished ...\\n\")\n",
    "\n",
    "    ### prepare the logger\n",
    "    logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "    \n",
    "    best_epoch = 0\n",
    "    best_rmse = np.inf\n",
    "    ### declare the loss information\n",
    "    print(\"Start training ...\")\n",
    "    for epoch_idx in range(1, args.train_epochs+1):\n",
    "        print ('Epoch', epoch_idx)\n",
    "    \n",
    "        train_loss = train_epoch(model, loss_fn, optimizer, args.arr_lambda, \n",
    "                                train_loader, args.device, args.train_log_interval)\n",
    "        test_rmse = evaluate(model, test_loader, args.device)\n",
    "        eval_info = {\n",
    "            'epoch': epoch_idx,\n",
    "            'train_loss': train_loss,\n",
    "            'test_rmse': test_rmse,\n",
    "        }\n",
    "        print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "        if epoch_idx % args.train_lr_decay_step == 0:\n",
    "            for param in optimizer.param_groups:\n",
    "                param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "        logger.log(eval_info, model, optimizer)\n",
    "        if best_rmse > test_rmse:\n",
    "            best_rmse = test_rmse\n",
    "            best_epoch = epoch_idx\n",
    "    eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "    print(eval_info)\n",
    "    with open(os.path.join(args.save_dir, 'log.txt'), 'a') as f:\n",
    "        f.write(eval_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fbabcc-6d45-4d08-8d5e-f9f483e56aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def config():\n",
    "    parser = argparse.ArgumentParser(description='IGMC')\n",
    "    # general settings\n",
    "    parser.add_argument('--testing', action='store_true', default=False,\n",
    "                        help='if set, use testing mode which splits all ratings into train/test;\\\n",
    "                        otherwise, use validation model which splits all ratings into \\\n",
    "                        train/val/test and evaluate on val only')\n",
    "    parser.add_argument('--device', default='0', type=int,\n",
    "                        help='Running device. E.g `--device 0`, if using cpu, set `--device -1`')\n",
    "    parser.add_argument('--seed', type=int, default=1234, metavar='S',\n",
    "                        help='random seed (default: 1234)')\n",
    "    parser.add_argument('--data_name', default='ml-100k', type=str,\n",
    "                        help='The dataset name: ml-100k, ml-1m')\n",
    "    parser.add_argument('--data_test_ratio', type=float, default=0.1) # for ml-100k the test ration is 0.2\n",
    "    parser.add_argument('--num_workers', type=int, default=8)\n",
    "    parser.add_argument('--data_valid_ratio', type=float, default=0.2)\n",
    "    # parser.add_argument('--ensemble', action='store_true', default=False,\n",
    "    #                     help='if True, load a series of model checkpoints and ensemble the results')               \n",
    "    parser.add_argument('--train_log_interval', type=int, default=100)\n",
    "    parser.add_argument('--valid_log_interval', type=int, default=10)\n",
    "    parser.add_argument('--save_appendix', type=str, default='debug', \n",
    "                        help='what to append to save-names when saving results')\n",
    "    # subgraph extraction settings\n",
    "    parser.add_argument('--hop', default=1, metavar='S', \n",
    "                        help='enclosing subgraph hop number')\n",
    "    parser.add_argument('--sample_ratio', type=float, default=1.0, \n",
    "                        help='if < 1, subsample nodes per hop according to the ratio')\n",
    "    parser.add_argument('--max_nodes_per_hop', type=int, default=200, \n",
    "                        help='if > 0, upper bound the # nodes per hop by another subsampling')\n",
    "    # parser.add_argument('--use_features', action='store_true', default=False,\n",
    "    #                     help='whether to use node features (side information)')\n",
    "    # edge dropout settings\n",
    "    parser.add_argument('--edge_dropout', type=float, default=0.2, \n",
    "                        help='if not 0, random drops edges from adjacency matrix with this prob')\n",
    "    parser.add_argument('--force_undirected', action='store_true', default=False, \n",
    "                        help='in edge dropout, force (x, y) and (y, x) to be dropped together')\n",
    "    # optimization settings\n",
    "    parser.add_argument('--train_lr', type=float, default=1e-3)\n",
    "    parser.add_argument('--train_min_lr', type=float, default=1e-6)\n",
    "    parser.add_argument('--train_lr_decay_factor', type=float, default=0.1)\n",
    "    parser.add_argument('--train_lr_decay_step', type=int, default=50)\n",
    "    parser.add_argument('--train_epochs', type=int, default=80)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--arr_lambda', type=float, default=0.001)\n",
    "    parser.add_argument('--num_rgcn_bases', type=int, default=4)\n",
    "                \n",
    "    args = parser.parse_args()\n",
    "    args.device = th.device(args.device) if args.device >= 0 and th.cuda.is_available() else th.device('cpu')\n",
    "    \n",
    "    ### set save_dir according to localtime and test mode\n",
    "    file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "    val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "    local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "    args.save_dir = os.path.join(\n",
    "        file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "            args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "        )\n",
    "    )\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir) \n",
    "    print(args)\n",
    "\n",
    "    # backup current .py files\n",
    "    for f in glob.glob(r\"*.py\"):\n",
    "        copy(f, args.save_dir)\n",
    "\n",
    "    # save command line input\n",
    "    cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "    with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "        f.write(cmd_input)\n",
    "        f.write(\"\\n\")\n",
    "    print('Command line input: ' + cmd_input + ' is saved.')\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff187c-d0a5-44d6-bf40-12a1c7927a3b",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0218e93a-7bb0-4007-a0d4-194dfbf0fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({ \n",
    "    'data_name':            'rotten',\n",
    "    'testing':     \t        True,\n",
    "    'device':      \t        0,\n",
    "    'seed':        \t        1234,\n",
    "    'data_test_ratio':      0.1,\n",
    "    'num_workers':   \t    8,\n",
    "    'data_valid_ratio':     0.2,\n",
    "    'train_log_interval':   200,\n",
    "    'valid_log_interval':   10,\n",
    "    'save_appendix':   \t    'debug',\n",
    "    'hop':   \t            1,\n",
    "    'sample_ratio':    \t    1.0,\n",
    "    'max_nodes_per_hop':    100,\n",
    "    'edge_dropout':   \t    0.2,\n",
    "    'force_undirected':     False,\n",
    "    'train_lr':   \t        1e-3,\n",
    "    'train_min_lr':   \t    1e-6,\n",
    "    'train_lr_decay_factor':0.1,\n",
    "    'train_lr_decay_step':  50,\n",
    "    'train_epochs':   \t    10,\n",
    "    'batch_size':   \t    32,\n",
    "    'arr_lambda':   \t    0.001,\n",
    "    'num_rgcn_bases':   \t4,\n",
    "    'train_epochs':   \t    1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eefc4e0-e1a6-47fa-af1b-3f79a748f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_name': 'rotten', 'testing': True, 'device': 0, 'seed': 1234, 'data_test_ratio': 0.1, 'num_workers': 8, 'data_valid_ratio': 0.2, 'train_log_interval': 200, 'valid_log_interval': 10, 'save_appendix': 'debug', 'hop': 1, 'sample_ratio': 1.0, 'max_nodes_per_hop': 100, 'edge_dropout': 0.2, 'force_undirected': False, 'train_lr': 0.001, 'train_min_lr': 1e-06, 'train_lr_decay_factor': 0.1, 'train_lr_decay_step': 50, 'train_epochs': 1, 'batch_size': 32, 'arr_lambda': 0.001, 'num_rgcn_bases': 4, 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\IGMC_CX\\\\log/rotten_debug_testmode_2112012305'}\n",
      "Command line input: python3 C:\\Users\\user\\anaconda3\\envs\\graph\\lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\user\\AppData\\Roaming\\jupyter\\runtime\\kernel-b4a7fef6-92e7-4265-ba11-11f25e20ee96.json is saved.\n"
     ]
    }
   ],
   "source": [
    "### set save_dir according to localtime and test mode\n",
    "file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "args.save_dir = os.path.join(\n",
    "    file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "        args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "    )\n",
    ")\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir) \n",
    "print(args)\n",
    "\n",
    "# backup current .py files\n",
    "for f in glob.glob(r\"*.py\"):\n",
    "    copy(f, args.save_dir)\n",
    "\n",
    "# save command line input\n",
    "cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "    f.write(cmd_input)\n",
    "    f.write(\"\\n\")\n",
    "print('Command line input: ' + cmd_input + ' is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e5af39-9646-43f8-87d2-8d9c498b7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "th.manual_seed(args.seed)\n",
    "if th.cuda.is_available():\n",
    "    th.cuda.manual_seed_all(args.seed)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd9d7e-1617-4c32-a8bc-006d4a49ca35",
   "metadata": {},
   "source": [
    "## 2. Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c44d14-7115-4e81-9c99-99f370f93129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label_type: rating\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n",
      "Label_type: sentiment\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n",
      "Label_type: emotion\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n"
     ]
    }
   ],
   "source": [
    "### prepare data and set model\n",
    "path = './raw_data/rotten_tomato/'\n",
    "rotten_tomato_r = RottenTomato('rating',    path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "rotten_tomato_s = RottenTomato('sentiment', path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "rotten_tomato_e = RottenTomato('emotion',   path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ff8769-41d9-4fe5-938f-51c370d372cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "valid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('testing')\n",
    "test_dataset_r = RottenTomatoDataset(\n",
    "    rotten_tomato_r.test_rating_pairs, rotten_tomato_r.test_rating_values, rotten_tomato_r.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "test_dataset_s = RottenTomatoDataset(\n",
    "    rotten_tomato_s.test_rating_pairs, rotten_tomato_s.test_rating_values, rotten_tomato_s.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "test_dataset_e = RottenTomatoDataset(\n",
    "    rotten_tomato_e.test_rating_pairs, rotten_tomato_e.test_rating_values, rotten_tomato_e.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "\n",
    "print('valid')\n",
    "valid_dataset_r = RottenTomatoDataset(\n",
    "    rotten_tomato_r.valid_rating_pairs, rotten_tomato_r.valid_rating_values, rotten_tomato_r.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "valid_dataset_s = RottenTomatoDataset(\n",
    "    rotten_tomato_s.valid_rating_pairs, rotten_tomato_s.valid_rating_values, rotten_tomato_s.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "valid_dataset_e = RottenTomatoDataset(\n",
    "    rotten_tomato_e.valid_rating_pairs, rotten_tomato_e.valid_rating_values, rotten_tomato_e.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af5734e1-bc3a-422f-8050-da7ad09bfe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43266\n",
      "28766\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_dataset_r))\n",
    "print(len(test_dataset_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e9ce45-2ab8-4a5a-bae3-17a9871aad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_r = RottenTomatoDataset(\n",
    "    rotten_tomato_r.train_rating_pairs, rotten_tomato_r.train_rating_values, rotten_tomato_r.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "train_dataset_s = RottenTomatoDataset(\n",
    "    rotten_tomato_s.train_rating_pairs, rotten_tomato_s.train_rating_values, rotten_tomato_s.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "train_dataset_e = RottenTomatoDataset(\n",
    "    rotten_tomato_e.train_rating_pairs, rotten_tomato_e.train_rating_values, rotten_tomato_e.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "621bf1ca-2328-439c-bfe9-fd51f892552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_r = th.utils.data.DataLoader(train_dataset_r, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "valid_loader_r = th.utils.data.DataLoader(valid_dataset_r, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "test_loader_r = th.utils.data.DataLoader(test_dataset_r, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "\n",
    "train_loader_s = th.utils.data.DataLoader(train_dataset_s, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "valid_loader_s = th.utils.data.DataLoader(valid_dataset_s, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "test_loader_s = th.utils.data.DataLoader(test_dataset_s, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "\n",
    "train_loader_e = th.utils.data.DataLoader(train_dataset_e, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "valid_loader_e = th.utils.data.DataLoader(valid_dataset_e, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "test_loader_e = th.utils.data.DataLoader(test_dataset_e, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c679b72-a7a2-4abb-9c4d-efdebf97dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feats = (args.hop+1)*2 #+ rotten_tomato.train_graph.ndata['refex'].shape[1]\n",
    "\n",
    "# rating\n",
    "model_r = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=10, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "\n",
    "# sentiment\n",
    "model_s = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=5, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "\n",
    "# emotion\n",
    "model_e = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=6, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss().to(args.device)\n",
    "optimizer_r = optim.Adam(model_r.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "optimizer_s = optim.Adam(model_s.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "optimizer_e = optim.Adam(model_e.parameters(), lr=args.train_lr, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a70cc4-cd48-4c52-8e31-4cb7c27d1205",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326886b9-35e6-41e0-96a1-f5ce214a1a53",
   "metadata": {},
   "source": [
    "### 3-1. rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b1fbeff-7f20-4c16-a521-7e7a5f041e16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=200, loss=1.1869, mse=1.1819, time=0.0445\n",
      "Iter=400, loss=0.7766, mse=0.7725, time=0.0428\n",
      "Iter=600, loss=0.7556, mse=0.7521, time=0.0422\n",
      "Iter=800, loss=0.7689, mse=0.7659, time=0.0421\n",
      "Iter=1000, loss=0.7524, mse=0.7498, time=0.0418\n",
      "Iter=1200, loss=0.7504, mse=0.7481, time=0.0417\n",
      "Iter=1400, loss=0.7240, mse=0.7219, time=0.0415\n",
      "Iter=1600, loss=0.7512, mse=0.7492, time=0.0413\n",
      "Iter=1800, loss=0.7286, mse=0.7268, time=0.0413\n",
      "Iter=2000, loss=0.7389, mse=0.7373, time=0.0411\n",
      "Iter=2200, loss=0.7241, mse=0.7226, time=0.0411\n",
      "Iter=2400, loss=0.7441, mse=0.7427, time=0.0411\n",
      "Iter=2600, loss=0.7720, mse=0.7707, time=0.0410\n",
      "Iter=2800, loss=0.7387, mse=0.7374, time=0.0410\n",
      "Iter=3000, loss=0.7290, mse=0.7278, time=0.0410\n",
      "Iter=3200, loss=0.7178, mse=0.7166, time=0.0409\n",
      "Iter=3400, loss=0.7387, mse=0.7375, time=0.0409\n",
      "Iter=3600, loss=0.6966, mse=0.6954, time=0.0409\n",
      "Iter=3800, loss=0.7288, mse=0.7276, time=0.0409\n",
      "Iter=4000, loss=0.7220, mse=0.7208, time=0.0408\n",
      "Iter=4200, loss=0.7177, mse=0.7165, time=0.0408\n",
      "Iter=4400, loss=0.6928, mse=0.6916, time=0.0408\n",
      "Iter=4600, loss=0.6968, mse=0.6957, time=0.0408\n",
      "Iter=4800, loss=0.7209, mse=0.7197, time=0.0408\n",
      "Iter=5000, loss=0.6783, mse=0.6771, time=0.0407\n",
      "Iter=5200, loss=0.7127, mse=0.7115, time=0.0407\n",
      "Iter=5400, loss=0.6981, mse=0.6969, time=0.0407\n",
      "Iter=5600, loss=0.6879, mse=0.6868, time=0.0407\n",
      "Iter=5800, loss=0.6843, mse=0.6831, time=0.0407\n",
      "Iter=6000, loss=0.7054, mse=0.7042, time=0.0407\n",
      "Iter=6200, loss=0.7213, mse=0.7201, time=0.0407\n",
      "Iter=6400, loss=0.7102, mse=0.7090, time=0.0406\n",
      "Iter=6600, loss=0.6718, mse=0.6705, time=0.0407\n",
      "=== Epoch 1, train loss 0.736951, test rmse 0.809963 ===\n",
      "Epoch 2\n",
      "Iter=200, loss=0.6796, mse=0.6783, time=0.0421\n",
      "Iter=400, loss=0.6820, mse=0.6807, time=0.0414\n",
      "Iter=600, loss=0.6946, mse=0.6932, time=0.0418\n",
      "Iter=800, loss=0.6691, mse=0.6676, time=0.0417\n",
      "Iter=1000, loss=0.6584, mse=0.6569, time=0.0415\n",
      "Iter=1200, loss=0.6783, mse=0.6768, time=0.0414\n",
      "Iter=1400, loss=0.6680, mse=0.6664, time=0.0413\n",
      "Iter=1600, loss=0.6785, mse=0.6769, time=0.0413\n",
      "Iter=1800, loss=0.6592, mse=0.6577, time=0.0412\n",
      "Iter=2000, loss=0.6751, mse=0.6736, time=0.0412\n",
      "Iter=2200, loss=0.6825, mse=0.6810, time=0.0412\n",
      "Iter=2400, loss=0.6988, mse=0.6972, time=0.0412\n",
      "Iter=2600, loss=0.7071, mse=0.7056, time=0.0411\n",
      "Iter=2800, loss=0.6650, mse=0.6634, time=0.0411\n",
      "Iter=3000, loss=0.6893, mse=0.6877, time=0.0411\n",
      "Iter=3200, loss=0.6752, mse=0.6736, time=0.0411\n",
      "Iter=3400, loss=0.6972, mse=0.6956, time=0.0411\n",
      "Iter=3600, loss=0.6525, mse=0.6508, time=0.0411\n",
      "Iter=3800, loss=0.6615, mse=0.6598, time=0.0411\n",
      "Iter=4000, loss=0.6580, mse=0.6564, time=0.0411\n",
      "Iter=4200, loss=0.6571, mse=0.6554, time=0.0411\n",
      "Iter=4400, loss=0.6543, mse=0.6526, time=0.0411\n",
      "Iter=4600, loss=0.6660, mse=0.6644, time=0.0411\n",
      "Iter=4800, loss=0.6654, mse=0.6638, time=0.0410\n",
      "Iter=5000, loss=0.6610, mse=0.6594, time=0.0410\n",
      "Iter=5200, loss=0.6488, mse=0.6471, time=0.0410\n",
      "Iter=5400, loss=0.6421, mse=0.6405, time=0.0410\n",
      "Iter=5600, loss=0.6531, mse=0.6514, time=0.0410\n",
      "Iter=5800, loss=0.6426, mse=0.6409, time=0.0410\n",
      "Iter=6000, loss=0.6592, mse=0.6574, time=0.0411\n",
      "Iter=6200, loss=0.6636, mse=0.6618, time=0.0411\n",
      "Iter=6400, loss=0.6410, mse=0.6392, time=0.0411\n",
      "Iter=6600, loss=0.6699, mse=0.6680, time=0.0411\n",
      "=== Epoch 2, train loss 0.668211, test rmse 0.802493 ===\n",
      "Epoch 3\n",
      "Iter=200, loss=0.6651, mse=0.6633, time=0.0421\n",
      "Iter=400, loss=0.6639, mse=0.6622, time=0.0410\n",
      "Iter=600, loss=0.6536, mse=0.6518, time=0.0409\n",
      "Iter=800, loss=0.6457, mse=0.6439, time=0.0411\n",
      "Iter=1000, loss=0.6368, mse=0.6350, time=0.0410\n",
      "Iter=1200, loss=0.6412, mse=0.6392, time=0.0410\n",
      "Iter=1400, loss=0.6431, mse=0.6412, time=0.0410\n",
      "Iter=1600, loss=0.6423, mse=0.6406, time=0.0411\n",
      "Iter=1800, loss=0.6314, mse=0.6297, time=0.0411\n",
      "Iter=2000, loss=0.6649, mse=0.6631, time=0.0411\n",
      "Iter=2200, loss=0.6467, mse=0.6449, time=0.0411\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35356/2434929853.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_r, loss_fn, optimizer_r, args.arr_lambda, \n\u001b[0m\u001b[0;32m     30\u001b[0m                                                                    train_loader_r, args.device, args.train_log_interval)\n\u001b[0;32m     31\u001b[0m     \u001b[0mvalid_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_valid_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_valid_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35356/2527849762.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(label_type, model, loss_fn, optimizer, arr_lambda, loader, device, log_interval)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rating'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter_project\\keejun\\IGMC_CX\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# edge mask zero denotes the edge dropped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             x = th.tanh(conv(block, x, block.edata['etype'], \n\u001b[0m\u001b[0;32m     66\u001b[0m                              norm=block.edata['edge_mask'].unsqueeze(1)))\n\u001b[0;32m     67\u001b[0m             \u001b[0mconcat_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\relgraphconv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, feat, etypes, norm)\u001b[0m\n\u001b[0;32m    359\u001b[0m                                                          self.loop_weight)\n\u001b[0;32m    360\u001b[0m             \u001b[1;31m# message passing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m             g.update_all(functools.partial(self.message_func, etypes=etypes),\n\u001b[0m\u001b[0;32m    362\u001b[0m                          fn.sum(msg='msg', out='h'))\n\u001b[0;32m    363\u001b[0m             \u001b[1;31m# apply bias and activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[1;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[0;32m   4847\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_edge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4848\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4849\u001b[1;33m             \u001b[0mndata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage_passing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_node_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4850\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_n_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mALL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4851\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# heterogeneous graph with number of relation types > 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\core.py\u001b[0m in \u001b[0;36mmessage_passing\u001b[1;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_builtin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg_field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             \u001b[0mndata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minvoke_gspmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsgdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[0morig_nid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdstdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\core.py\u001b[0m in \u001b[0;36minvoke_gspmm\u001b[1;34m(graph, mfunc, rfunc, srcdata, dstdata, edata)\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mrhs_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_etypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_dict_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlhs_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mrfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_field\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\ops\\spmm.py\u001b[0m in \u001b[0;36mfunc\u001b[1;34m(g, x)\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgspmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'copy_lhs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mgspmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'copy_rhs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\ops\\spmm.py\u001b[0m in \u001b[0;36mgspmm\u001b[1;34m(g, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mlhs_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreshape_lhs_rhs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# With max and min reducers infinity will be returned for zero degree nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         ret = gspmm_internal(g._graph, op,\n\u001b[0m\u001b[0;32m     76\u001b[0m                              \u001b[1;34m'sum'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreduce_op\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'mean'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                              lhs_data, rhs_data)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\backend\\pytorch\\sparse.py\u001b[0m in \u001b[0;36mgspmm\u001b[1;34m(gidx, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgspmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgidx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlhs_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mGSpMM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgidx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlhs_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgsddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgidx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlhs_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlhs_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'u'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\cuda\\amp\\autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_fwd\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0m_cast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcast_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0m_cast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcast_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_fwd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\backend\\pytorch\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, gidx, op, reduce_op, X, Y)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcustom_fwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgidx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_gspmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgidx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgidx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\sparse.py\u001b[0m in \u001b[0;36m_gspmm\u001b[1;34m(gidx, op, reduce_op, u, e)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0marg_e_nd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_dgl_nd_for_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_e\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgidx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         _CAPI_DGLKernelSpMM(gidx, op, reduce_op,\n\u001b[0m\u001b[0;32m    158\u001b[0m                             \u001b[0mto_dgl_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_u\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                             \u001b[0mto_dgl_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_e\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mret_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDGLValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mret_tcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         check_call(_LIB.DGLFuncCall(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "label_type = 'rating'\n",
    "\n",
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch_idx in range(1, 5):\n",
    "    print ('Epoch', epoch_idx)\n",
    "    \n",
    "    train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_r, loss_fn, optimizer_r, args.arr_lambda, \n",
    "                                                                   train_loader_r, args.device, args.train_log_interval)\n",
    "    valid_rmse, predict_valid_list, label_valid_list = evaluate(label_type, model_r, valid_loader_r, args.device)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(label_type, model_r, test_loader_r, args.device)\n",
    "    \n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model_r, optimizer_r)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_valid_list = predict_valid_list \n",
    "        best_label_valid_list = label_valid_list\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "\n",
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a501375-be50-45f9-870b-337d7ff63863",
   "metadata": {},
   "source": [
    "- 결과 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "273dda48-ab5e-4aa5-a6c8-8252a7dc0c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216328\n",
      "216328\n"
     ]
    }
   ],
   "source": [
    "print(len(predict_train_list))\n",
    "print(len(label_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c3f7529a-6739-4498-a5ca-d64246448b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43266\n",
      "43266\n"
     ]
    }
   ],
   "source": [
    "print(len(best_predict_valid_list))\n",
    "print(len(best_label_valid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "904ae17b-4e10-4a15-b259-0e234c061981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28766\n",
      "28766\n"
     ]
    }
   ],
   "source": [
    "print(len(best_predict_test_list))\n",
    "print(len(best_label_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ca4add52-d517-43e0-9139-87c1793852b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_rating_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "valid_rating_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "valid_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_rating_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_rating_df2 = pd.DataFrame([x for x in zip(predict_test_list, label_test_list)])\n",
    "test_rating_df2.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "89aae242-13fc-47a3-aad4-d3e06ebb371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/rotten_tomato/ensemble/'\n",
    "train_rating_df.to_csv(path + 'train_rating.csv', index=False)\n",
    "valid_rating_df.to_csv(path + 'valid_rating.csv', index=False)\n",
    "test_rating_df.to_csv(path + 'test_rating.csv', index=False)\n",
    "test_rating_df2.to_csv(path + 'test_rating2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acc35c-e77b-4764-bdb3-47977a789154",
   "metadata": {},
   "source": [
    "### 3-2. sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0884d5c0-8804-4b99-ad4d-02275629f742",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=200, loss=1.5511, mse=1.5494, time=0.0424\n",
      "Iter=400, loss=1.5360, mse=1.5345, time=0.0423\n",
      "Iter=600, loss=1.5444, mse=1.5430, time=0.0434\n",
      "Iter=800, loss=1.4904, mse=1.4891, time=0.0444\n",
      "Iter=1000, loss=1.4986, mse=1.4973, time=0.0460\n",
      "Iter=1200, loss=1.4771, mse=1.4759, time=0.0461\n",
      "Iter=1400, loss=1.4886, mse=1.4875, time=0.0457\n",
      "Iter=1600, loss=1.4702, mse=1.4692, time=0.0453\n",
      "Iter=1800, loss=1.4903, mse=1.4893, time=0.0449\n",
      "Iter=2000, loss=1.4588, mse=1.4578, time=0.0447\n",
      "Iter=2200, loss=1.4533, mse=1.4523, time=0.0446\n",
      "Iter=2400, loss=1.4961, mse=1.4951, time=0.0447\n",
      "Iter=2600, loss=1.4613, mse=1.4604, time=0.0445\n",
      "Iter=2800, loss=1.4696, mse=1.4688, time=0.0443\n",
      "Iter=3000, loss=1.4235, mse=1.4227, time=0.0442\n",
      "Iter=3200, loss=1.4581, mse=1.4573, time=0.0439\n",
      "Iter=3400, loss=1.4327, mse=1.4319, time=0.0443\n",
      "Iter=3600, loss=1.4304, mse=1.4296, time=0.0441\n",
      "Iter=3800, loss=1.4488, mse=1.4481, time=0.0440\n",
      "Iter=4000, loss=1.4846, mse=1.4839, time=0.0438\n",
      "Iter=4200, loss=1.4146, mse=1.4139, time=0.0437\n",
      "Iter=4400, loss=1.4421, mse=1.4415, time=0.0435\n",
      "Iter=4600, loss=1.4221, mse=1.4215, time=0.0434\n",
      "Iter=4800, loss=1.4264, mse=1.4258, time=0.0433\n",
      "Iter=5000, loss=1.4522, mse=1.4516, time=0.0432\n",
      "Iter=5200, loss=1.4285, mse=1.4279, time=0.0431\n",
      "Iter=5400, loss=1.4216, mse=1.4210, time=0.0430\n",
      "Iter=5600, loss=1.4420, mse=1.4414, time=0.0429\n",
      "Iter=5800, loss=1.4583, mse=1.4577, time=0.0428\n",
      "Iter=6000, loss=1.4502, mse=1.4496, time=0.0428\n",
      "Iter=6200, loss=1.4124, mse=1.4118, time=0.0426\n",
      "Iter=6400, loss=1.4064, mse=1.4058, time=0.0426\n",
      "Iter=6600, loss=1.4194, mse=1.4189, time=0.0425\n",
      "=== Epoch 1, train loss 1.458404, test rmse 1.181308 ===\n",
      "Epoch 2\n",
      "Iter=200, loss=1.4036, mse=1.4030, time=0.0425\n",
      "Iter=400, loss=1.4357, mse=1.4351, time=0.0414\n",
      "Iter=600, loss=1.3981, mse=1.3976, time=0.0413\n",
      "Iter=800, loss=1.4193, mse=1.4187, time=0.0411\n",
      "Iter=1000, loss=1.4015, mse=1.4010, time=0.0409\n",
      "Iter=1200, loss=1.4283, mse=1.4278, time=0.0410\n",
      "Iter=1400, loss=1.4207, mse=1.4202, time=0.0409\n",
      "Iter=1600, loss=1.4021, mse=1.4016, time=0.0409\n",
      "Iter=1800, loss=1.4478, mse=1.4473, time=0.0408\n",
      "Iter=2000, loss=1.3985, mse=1.3980, time=0.0408\n",
      "Iter=2200, loss=1.4129, mse=1.4124, time=0.0408\n",
      "Iter=2400, loss=1.4018, mse=1.4012, time=0.0409\n",
      "Iter=2600, loss=1.4266, mse=1.4261, time=0.0408\n",
      "Iter=2800, loss=1.4356, mse=1.4351, time=0.0409\n",
      "Iter=3000, loss=1.4076, mse=1.4070, time=0.0409\n",
      "Iter=3200, loss=1.4033, mse=1.4028, time=0.0409\n",
      "Iter=3400, loss=1.4352, mse=1.4347, time=0.0408\n",
      "Iter=3600, loss=1.4159, mse=1.4153, time=0.0408\n",
      "Iter=3800, loss=1.3699, mse=1.3694, time=0.0408\n",
      "Iter=4000, loss=1.4090, mse=1.4085, time=0.0408\n",
      "Iter=4200, loss=1.3856, mse=1.3851, time=0.0408\n",
      "Iter=4400, loss=1.3858, mse=1.3853, time=0.0408\n",
      "Iter=4600, loss=1.4029, mse=1.4024, time=0.0408\n",
      "Iter=4800, loss=1.3607, mse=1.3602, time=0.0408\n",
      "Iter=5000, loss=1.4081, mse=1.4076, time=0.0408\n",
      "Iter=5200, loss=1.3815, mse=1.3811, time=0.0408\n",
      "Iter=5400, loss=1.4202, mse=1.4198, time=0.0407\n",
      "Iter=5600, loss=1.4340, mse=1.4335, time=0.0407\n",
      "Iter=5800, loss=1.4380, mse=1.4375, time=0.0406\n",
      "Iter=6000, loss=1.4037, mse=1.4032, time=0.0406\n",
      "Iter=6200, loss=1.3816, mse=1.3811, time=0.0406\n",
      "Iter=6400, loss=1.3800, mse=1.3795, time=0.0406\n",
      "Iter=6600, loss=1.4047, mse=1.4042, time=0.0406\n",
      "=== Epoch 2, train loss 1.407492, test rmse 1.178304 ===\n",
      "Epoch 3\n",
      "Iter=200, loss=1.4095, mse=1.4090, time=0.0419\n",
      "Iter=400, loss=1.4465, mse=1.4460, time=0.0411\n",
      "Iter=600, loss=1.3996, mse=1.3991, time=0.0409\n",
      "Iter=800, loss=1.4115, mse=1.4109, time=0.0408\n",
      "Iter=1000, loss=1.3918, mse=1.3912, time=0.0409\n",
      "Iter=1200, loss=1.4003, mse=1.3998, time=0.0409\n",
      "Iter=1400, loss=1.3531, mse=1.3526, time=0.0409\n",
      "Iter=1600, loss=1.3859, mse=1.3855, time=0.0409\n",
      "Iter=1800, loss=1.3899, mse=1.3894, time=0.0410\n",
      "Iter=2000, loss=1.3685, mse=1.3681, time=0.0409\n",
      "Iter=2200, loss=1.3722, mse=1.3717, time=0.0409\n",
      "Iter=2400, loss=1.4320, mse=1.4316, time=0.0409\n",
      "Iter=2600, loss=1.4006, mse=1.4002, time=0.0409\n",
      "Iter=2800, loss=1.4137, mse=1.4132, time=0.0409\n",
      "Iter=3000, loss=1.4104, mse=1.4099, time=0.0409\n",
      "Iter=3200, loss=1.3972, mse=1.3967, time=0.0409\n",
      "Iter=3400, loss=1.4105, mse=1.4100, time=0.0408\n",
      "Iter=3600, loss=1.3699, mse=1.3694, time=0.0408\n",
      "Iter=3800, loss=1.3744, mse=1.3739, time=0.0408\n",
      "Iter=4000, loss=1.4040, mse=1.4035, time=0.0408\n",
      "Iter=4200, loss=1.3641, mse=1.3637, time=0.0408\n",
      "Iter=4400, loss=1.4164, mse=1.4159, time=0.0408\n",
      "Iter=4600, loss=1.3934, mse=1.3929, time=0.0408\n",
      "Iter=4800, loss=1.4072, mse=1.4067, time=0.0408\n",
      "Iter=5000, loss=1.3983, mse=1.3979, time=0.0408\n",
      "Iter=5200, loss=1.4096, mse=1.4092, time=0.0409\n",
      "Iter=5400, loss=1.4076, mse=1.4071, time=0.0409\n",
      "Iter=5600, loss=1.3919, mse=1.3914, time=0.0409\n",
      "Iter=5800, loss=1.3987, mse=1.3982, time=0.0410\n",
      "Iter=6000, loss=1.4191, mse=1.4186, time=0.0411\n",
      "Iter=6200, loss=1.3924, mse=1.3919, time=0.0411\n",
      "Iter=6400, loss=1.4060, mse=1.4056, time=0.0411\n",
      "Iter=6600, loss=1.3821, mse=1.3817, time=0.0411\n",
      "=== Epoch 3, train loss 1.398482, test rmse 1.170668 ===\n",
      "Epoch 4\n",
      "Iter=200, loss=1.3924, mse=1.3920, time=0.0415\n",
      "Iter=400, loss=1.3966, mse=1.3961, time=0.0412\n",
      "Iter=600, loss=1.3704, mse=1.3700, time=0.0409\n",
      "Iter=800, loss=1.4060, mse=1.4055, time=0.0411\n",
      "Iter=1000, loss=1.4207, mse=1.4202, time=0.0409\n",
      "Iter=1200, loss=1.3925, mse=1.3920, time=0.0408\n",
      "Iter=1400, loss=1.3923, mse=1.3918, time=0.0409\n",
      "Iter=1600, loss=1.4049, mse=1.4045, time=0.0408\n",
      "Iter=1800, loss=1.3559, mse=1.3554, time=0.0408\n",
      "Iter=2000, loss=1.4200, mse=1.4196, time=0.0408\n",
      "Iter=2200, loss=1.3866, mse=1.3862, time=0.0407\n",
      "Iter=2400, loss=1.3822, mse=1.3817, time=0.0407\n",
      "Iter=2600, loss=1.3745, mse=1.3741, time=0.0407\n",
      "Iter=2800, loss=1.3841, mse=1.3836, time=0.0407\n",
      "Iter=3000, loss=1.3666, mse=1.3662, time=0.0407\n",
      "Iter=3200, loss=1.4257, mse=1.4253, time=0.0407\n",
      "Iter=3400, loss=1.3989, mse=1.3984, time=0.0407\n",
      "Iter=3600, loss=1.3760, mse=1.3755, time=0.0406\n",
      "Iter=3800, loss=1.4052, mse=1.4047, time=0.0406\n",
      "Iter=4000, loss=1.3835, mse=1.3831, time=0.0405\n",
      "Iter=4200, loss=1.4048, mse=1.4044, time=0.0405\n",
      "Iter=4400, loss=1.4011, mse=1.4007, time=0.0405\n",
      "Iter=4600, loss=1.3796, mse=1.3792, time=0.0406\n",
      "Iter=4800, loss=1.3835, mse=1.3830, time=0.0406\n",
      "Iter=5000, loss=1.3658, mse=1.3653, time=0.0406\n",
      "Iter=5200, loss=1.3711, mse=1.3706, time=0.0406\n",
      "Iter=5400, loss=1.3945, mse=1.3940, time=0.0406\n",
      "Iter=5600, loss=1.4276, mse=1.4272, time=0.0407\n",
      "Iter=5800, loss=1.4227, mse=1.4223, time=0.0406\n",
      "Iter=6000, loss=1.4118, mse=1.4114, time=0.0407\n",
      "Iter=6200, loss=1.4138, mse=1.4133, time=0.0407\n",
      "Iter=6400, loss=1.4039, mse=1.4035, time=0.0407\n",
      "Iter=6600, loss=1.3959, mse=1.3955, time=0.0407\n",
      "=== Epoch 4, train loss 1.394145, test rmse 1.165756 ===\n",
      "Epoch 5\n",
      "Iter=200, loss=1.3766, mse=1.3761, time=0.0418\n",
      "Iter=400, loss=1.3504, mse=1.3499, time=0.0412\n",
      "Iter=600, loss=1.3673, mse=1.3669, time=0.0411\n",
      "Iter=800, loss=1.3690, mse=1.3685, time=0.0409\n",
      "Iter=1000, loss=1.3829, mse=1.3824, time=0.0408\n",
      "Iter=1200, loss=1.3960, mse=1.3955, time=0.0407\n",
      "Iter=1400, loss=1.3643, mse=1.3638, time=0.0406\n",
      "Iter=1600, loss=1.4167, mse=1.4163, time=0.0406\n",
      "Iter=1800, loss=1.3832, mse=1.3827, time=0.0406\n",
      "Iter=2000, loss=1.4047, mse=1.4043, time=0.0407\n",
      "Iter=2200, loss=1.4038, mse=1.4034, time=0.0406\n",
      "Iter=2400, loss=1.3977, mse=1.3973, time=0.0407\n",
      "Iter=2600, loss=1.3851, mse=1.3847, time=0.0406\n",
      "Iter=2800, loss=1.4023, mse=1.4019, time=0.0405\n",
      "Iter=3000, loss=1.3757, mse=1.3753, time=0.0404\n",
      "Iter=3200, loss=1.4477, mse=1.4473, time=0.0404\n",
      "Iter=3400, loss=1.3960, mse=1.3956, time=0.0404\n",
      "Iter=3600, loss=1.3930, mse=1.3926, time=0.0405\n",
      "Iter=3800, loss=1.3844, mse=1.3840, time=0.0405\n",
      "Iter=4000, loss=1.4317, mse=1.4313, time=0.0405\n",
      "Iter=4200, loss=1.3771, mse=1.3767, time=0.0405\n",
      "Iter=4400, loss=1.3948, mse=1.3944, time=0.0405\n",
      "Iter=4600, loss=1.3795, mse=1.3791, time=0.0406\n",
      "Iter=4800, loss=1.4297, mse=1.4292, time=0.0406\n",
      "Iter=5000, loss=1.4156, mse=1.4152, time=0.0406\n",
      "Iter=5200, loss=1.3932, mse=1.3928, time=0.0406\n",
      "Iter=5400, loss=1.3994, mse=1.3989, time=0.0406\n",
      "Iter=5600, loss=1.3601, mse=1.3597, time=0.0406\n",
      "Iter=5800, loss=1.4011, mse=1.4006, time=0.0406\n",
      "Iter=6000, loss=1.3621, mse=1.3617, time=0.0406\n",
      "Iter=6200, loss=1.3813, mse=1.3809, time=0.0406\n",
      "Iter=6400, loss=1.3974, mse=1.3969, time=0.0406\n",
      "Iter=6600, loss=1.3772, mse=1.3768, time=0.0406\n",
      "=== Epoch 5, train loss 1.390404, test rmse 1.169243 ===\n",
      "Epoch 6\n",
      "Iter=200, loss=1.3727, mse=1.3723, time=0.0424\n",
      "Iter=400, loss=1.3880, mse=1.3876, time=0.0414\n",
      "Iter=600, loss=1.3709, mse=1.3704, time=0.0413\n",
      "Iter=800, loss=1.3772, mse=1.3768, time=0.0413\n",
      "Iter=1000, loss=1.3524, mse=1.3520, time=0.0412\n",
      "Iter=1200, loss=1.3882, mse=1.3878, time=0.0410\n",
      "Iter=1400, loss=1.3481, mse=1.3476, time=0.0409\n",
      "Iter=1600, loss=1.3945, mse=1.3941, time=0.0408\n",
      "Iter=1800, loss=1.4204, mse=1.4199, time=0.0407\n",
      "Iter=2000, loss=1.4100, mse=1.4096, time=0.0405\n",
      "Iter=2200, loss=1.4208, mse=1.4204, time=0.0404\n",
      "Iter=2400, loss=1.4009, mse=1.4005, time=0.0404\n",
      "Iter=2600, loss=1.3850, mse=1.3846, time=0.0404\n",
      "Iter=2800, loss=1.4088, mse=1.4084, time=0.0404\n",
      "Iter=3000, loss=1.4076, mse=1.4072, time=0.0405\n",
      "Iter=3200, loss=1.3798, mse=1.3794, time=0.0405\n",
      "Iter=3400, loss=1.3994, mse=1.3990, time=0.0405\n",
      "Iter=3600, loss=1.4081, mse=1.4077, time=0.0406\n",
      "Iter=3800, loss=1.3737, mse=1.3732, time=0.0406\n",
      "Iter=4000, loss=1.4062, mse=1.4058, time=0.0407\n",
      "Iter=4200, loss=1.4015, mse=1.4011, time=0.0407\n",
      "Iter=4400, loss=1.3673, mse=1.3669, time=0.0407\n",
      "Iter=4600, loss=1.3709, mse=1.3705, time=0.0407\n",
      "Iter=4800, loss=1.3856, mse=1.3852, time=0.0407\n",
      "Iter=5000, loss=1.4189, mse=1.4184, time=0.0406\n",
      "Iter=5200, loss=1.3788, mse=1.3783, time=0.0407\n",
      "Iter=5400, loss=1.3427, mse=1.3422, time=0.0407\n",
      "Iter=5600, loss=1.3684, mse=1.3680, time=0.0407\n",
      "Iter=5800, loss=1.3930, mse=1.3926, time=0.0407\n",
      "Iter=6000, loss=1.3943, mse=1.3939, time=0.0407\n",
      "Iter=6200, loss=1.4126, mse=1.4122, time=0.0407\n",
      "Iter=6400, loss=1.4162, mse=1.4158, time=0.0407\n",
      "Iter=6600, loss=1.4407, mse=1.4403, time=0.0407\n",
      "=== Epoch 6, train loss 1.390525, test rmse 1.163907 ===\n",
      "Epoch 7\n",
      "Iter=200, loss=1.3478, mse=1.3474, time=0.0435\n",
      "Iter=400, loss=1.3454, mse=1.3450, time=0.0426\n",
      "Iter=600, loss=1.3985, mse=1.3982, time=0.0417\n",
      "Iter=800, loss=1.3820, mse=1.3816, time=0.0413\n",
      "Iter=1000, loss=1.3532, mse=1.3528, time=0.0407\n",
      "Iter=1200, loss=1.4079, mse=1.4075, time=0.0406\n",
      "Iter=1400, loss=1.3943, mse=1.3939, time=0.0403\n",
      "Iter=1600, loss=1.3633, mse=1.3629, time=0.0403\n",
      "Iter=1800, loss=1.4483, mse=1.4479, time=0.0404\n",
      "Iter=2000, loss=1.3935, mse=1.3931, time=0.0405\n",
      "Iter=2200, loss=1.4054, mse=1.4050, time=0.0405\n",
      "Iter=2400, loss=1.4368, mse=1.4364, time=0.0406\n",
      "Iter=2600, loss=1.3942, mse=1.3938, time=0.0406\n",
      "Iter=2800, loss=1.3832, mse=1.3828, time=0.0406\n",
      "Iter=3000, loss=1.3723, mse=1.3719, time=0.0407\n",
      "Iter=3200, loss=1.4152, mse=1.4148, time=0.0408\n",
      "Iter=3400, loss=1.3971, mse=1.3967, time=0.0408\n",
      "Iter=3600, loss=1.3866, mse=1.3862, time=0.0408\n",
      "Iter=3800, loss=1.3956, mse=1.3952, time=0.0408\n",
      "Iter=4000, loss=1.3960, mse=1.3957, time=0.0407\n",
      "Iter=4200, loss=1.4053, mse=1.4050, time=0.0407\n",
      "Iter=4400, loss=1.4046, mse=1.4042, time=0.0407\n",
      "Iter=4600, loss=1.4049, mse=1.4045, time=0.0407\n",
      "Iter=4800, loss=1.4008, mse=1.4004, time=0.0407\n",
      "Iter=5000, loss=1.3735, mse=1.3731, time=0.0407\n",
      "Iter=5200, loss=1.4032, mse=1.4028, time=0.0407\n",
      "Iter=5400, loss=1.3912, mse=1.3908, time=0.0407\n",
      "Iter=5600, loss=1.4010, mse=1.4006, time=0.0407\n",
      "Iter=5800, loss=1.3835, mse=1.3831, time=0.0407\n",
      "Iter=6000, loss=1.3852, mse=1.3848, time=0.0407\n",
      "Iter=6200, loss=1.3947, mse=1.3943, time=0.0407\n",
      "Iter=6400, loss=1.3629, mse=1.3625, time=0.0407\n",
      "Iter=6600, loss=1.3804, mse=1.3800, time=0.0407\n",
      "=== Epoch 7, train loss 1.391296, test rmse 1.164311 ===\n",
      "Epoch 8\n",
      "Iter=200, loss=1.4002, mse=1.3999, time=0.0406\n",
      "Iter=400, loss=1.3982, mse=1.3978, time=0.0397\n",
      "Iter=600, loss=1.3593, mse=1.3589, time=0.0399\n",
      "Iter=800, loss=1.3816, mse=1.3812, time=0.0401\n",
      "Iter=1000, loss=1.3820, mse=1.3816, time=0.0403\n",
      "Iter=1200, loss=1.4214, mse=1.4210, time=0.0402\n",
      "Iter=1400, loss=1.3926, mse=1.3922, time=0.0404\n",
      "Iter=1600, loss=1.3793, mse=1.3789, time=0.0404\n",
      "Iter=1800, loss=1.3761, mse=1.3757, time=0.0405\n",
      "Iter=2000, loss=1.3658, mse=1.3654, time=0.0405\n",
      "Iter=2200, loss=1.4112, mse=1.4109, time=0.0405\n",
      "Iter=2400, loss=1.4266, mse=1.4262, time=0.0406\n",
      "Iter=2600, loss=1.3723, mse=1.3719, time=0.0406\n",
      "Iter=2800, loss=1.4064, mse=1.4060, time=0.0406\n",
      "Iter=3000, loss=1.3471, mse=1.3467, time=0.0406\n",
      "Iter=3200, loss=1.4040, mse=1.4036, time=0.0406\n",
      "Iter=3400, loss=1.3851, mse=1.3846, time=0.0406\n",
      "Iter=3600, loss=1.3810, mse=1.3806, time=0.0406\n",
      "Iter=3800, loss=1.3845, mse=1.3840, time=0.0407\n",
      "Iter=4000, loss=1.4078, mse=1.4074, time=0.0407\n",
      "Iter=4200, loss=1.3675, mse=1.3671, time=0.0407\n",
      "Iter=4400, loss=1.3896, mse=1.3892, time=0.0407\n",
      "Iter=4600, loss=1.4203, mse=1.4199, time=0.0407\n",
      "Iter=4800, loss=1.4029, mse=1.4025, time=0.0407\n",
      "Iter=5000, loss=1.4116, mse=1.4112, time=0.0407\n",
      "Iter=5200, loss=1.3696, mse=1.3692, time=0.0407\n",
      "Iter=5400, loss=1.3561, mse=1.3557, time=0.0407\n",
      "Iter=5600, loss=1.3700, mse=1.3696, time=0.0407\n",
      "Iter=5800, loss=1.4104, mse=1.4100, time=0.0407\n",
      "Iter=6000, loss=1.4157, mse=1.4153, time=0.0407\n",
      "Iter=6200, loss=1.4033, mse=1.4029, time=0.0407\n",
      "Iter=6400, loss=1.3809, mse=1.3805, time=0.0407\n",
      "Iter=6600, loss=1.3992, mse=1.3988, time=0.0407\n",
      "=== Epoch 8, train loss 1.390189, test rmse 1.165701 ===\n",
      "Epoch 9\n",
      "Iter=200, loss=1.3671, mse=1.3668, time=0.0413\n",
      "Iter=400, loss=1.3847, mse=1.3843, time=0.0412\n",
      "Iter=600, loss=1.3844, mse=1.3840, time=0.0410\n",
      "Iter=800, loss=1.4098, mse=1.4094, time=0.0410\n",
      "Iter=1000, loss=1.4163, mse=1.4159, time=0.0411\n",
      "Iter=1200, loss=1.4146, mse=1.4142, time=0.0411\n",
      "Iter=1400, loss=1.3773, mse=1.3769, time=0.0410\n",
      "Iter=1600, loss=1.3913, mse=1.3909, time=0.0410\n",
      "Iter=1800, loss=1.4044, mse=1.4040, time=0.0410\n",
      "Iter=2000, loss=1.3760, mse=1.3757, time=0.0410\n",
      "Iter=2200, loss=1.4012, mse=1.4008, time=0.0410\n",
      "Iter=2400, loss=1.4050, mse=1.4047, time=0.0409\n",
      "Iter=2600, loss=1.3848, mse=1.3845, time=0.0409\n",
      "Iter=2800, loss=1.4121, mse=1.4117, time=0.0409\n",
      "Iter=3000, loss=1.3629, mse=1.3625, time=0.0409\n",
      "Iter=3200, loss=1.3961, mse=1.3957, time=0.0408\n",
      "Iter=3400, loss=1.3967, mse=1.3963, time=0.0408\n",
      "Iter=3600, loss=1.3697, mse=1.3693, time=0.0408\n",
      "Iter=3800, loss=1.4103, mse=1.4099, time=0.0408\n",
      "Iter=4000, loss=1.3899, mse=1.3896, time=0.0408\n",
      "Iter=4200, loss=1.4072, mse=1.4068, time=0.0408\n",
      "Iter=4400, loss=1.3631, mse=1.3627, time=0.0409\n",
      "Iter=4600, loss=1.4052, mse=1.4048, time=0.0408\n",
      "Iter=4800, loss=1.3607, mse=1.3604, time=0.0408\n",
      "Iter=5000, loss=1.4053, mse=1.4049, time=0.0408\n",
      "Iter=5200, loss=1.3871, mse=1.3867, time=0.0408\n",
      "Iter=5400, loss=1.3688, mse=1.3684, time=0.0408\n",
      "Iter=5600, loss=1.3566, mse=1.3563, time=0.0408\n",
      "Iter=5800, loss=1.3717, mse=1.3713, time=0.0408\n",
      "Iter=6000, loss=1.3779, mse=1.3776, time=0.0408\n",
      "Iter=6200, loss=1.3941, mse=1.3937, time=0.0408\n",
      "Iter=6400, loss=1.3641, mse=1.3637, time=0.0408\n",
      "Iter=6600, loss=1.3775, mse=1.3771, time=0.0407\n",
      "=== Epoch 9, train loss 1.388560, test rmse 1.169393 ===\n",
      "Epoch 10\n",
      "Iter=200, loss=1.3764, mse=1.3760, time=0.0431\n",
      "Iter=400, loss=1.3746, mse=1.3742, time=0.0415\n",
      "Iter=600, loss=1.4447, mse=1.4444, time=0.0412\n",
      "Iter=800, loss=1.4223, mse=1.4219, time=0.0410\n",
      "Iter=1000, loss=1.3726, mse=1.3722, time=0.0410\n",
      "Iter=1200, loss=1.3816, mse=1.3812, time=0.0409\n",
      "Iter=1400, loss=1.4058, mse=1.4054, time=0.0411\n",
      "Iter=1600, loss=1.3838, mse=1.3834, time=0.0410\n",
      "Iter=1800, loss=1.3923, mse=1.3919, time=0.0410\n",
      "Iter=2000, loss=1.3987, mse=1.3983, time=0.0409\n",
      "Iter=2200, loss=1.3865, mse=1.3862, time=0.0409\n",
      "Iter=2400, loss=1.3904, mse=1.3900, time=0.0409\n",
      "Iter=2600, loss=1.3910, mse=1.3906, time=0.0409\n",
      "Iter=2800, loss=1.4126, mse=1.4122, time=0.0409\n",
      "Iter=3000, loss=1.3872, mse=1.3868, time=0.0408\n",
      "Iter=3200, loss=1.3635, mse=1.3631, time=0.0408\n",
      "Iter=3400, loss=1.3959, mse=1.3955, time=0.0408\n",
      "Iter=3600, loss=1.4110, mse=1.4107, time=0.0408\n",
      "Iter=3800, loss=1.3797, mse=1.3793, time=0.0408\n",
      "Iter=4000, loss=1.3691, mse=1.3687, time=0.0408\n",
      "Iter=4200, loss=1.4269, mse=1.4265, time=0.0408\n",
      "Iter=4400, loss=1.3677, mse=1.3673, time=0.0408\n",
      "Iter=4600, loss=1.3715, mse=1.3711, time=0.0408\n",
      "Iter=4800, loss=1.3804, mse=1.3800, time=0.0408\n",
      "Iter=5000, loss=1.3950, mse=1.3945, time=0.0408\n",
      "Iter=5200, loss=1.3998, mse=1.3994, time=0.0408\n",
      "Iter=5400, loss=1.4275, mse=1.4271, time=0.0407\n",
      "Iter=5600, loss=1.3529, mse=1.3526, time=0.0407\n",
      "Iter=5800, loss=1.4167, mse=1.4164, time=0.0407\n",
      "Iter=6000, loss=1.3903, mse=1.3899, time=0.0406\n",
      "Iter=6200, loss=1.3756, mse=1.3752, time=0.0406\n",
      "Iter=6400, loss=1.3802, mse=1.3798, time=0.0406\n",
      "Iter=6600, loss=1.3884, mse=1.3880, time=0.0406\n",
      "=== Epoch 10, train loss 1.390589, test rmse 1.168470 ===\n",
      "Epoch 11\n",
      "Iter=200, loss=1.4047, mse=1.4043, time=0.0416\n",
      "Iter=400, loss=1.3930, mse=1.3926, time=0.0413\n",
      "Iter=600, loss=1.3785, mse=1.3781, time=0.0410\n",
      "Iter=800, loss=1.4089, mse=1.4085, time=0.0410\n",
      "Iter=1000, loss=1.3489, mse=1.3485, time=0.0410\n",
      "Iter=1200, loss=1.4140, mse=1.4136, time=0.0409\n",
      "Iter=1400, loss=1.4101, mse=1.4098, time=0.0409\n",
      "Iter=1600, loss=1.4049, mse=1.4046, time=0.0410\n",
      "Iter=1800, loss=1.4059, mse=1.4056, time=0.0410\n",
      "Iter=2000, loss=1.4172, mse=1.4169, time=0.0409\n",
      "Iter=2200, loss=1.4206, mse=1.4203, time=0.0409\n",
      "Iter=2400, loss=1.3844, mse=1.3841, time=0.0408\n",
      "Iter=2600, loss=1.4014, mse=1.4011, time=0.0408\n",
      "Iter=2800, loss=1.3659, mse=1.3655, time=0.0408\n",
      "Iter=3000, loss=1.3972, mse=1.3968, time=0.0408\n",
      "Iter=3200, loss=1.3850, mse=1.3846, time=0.0408\n",
      "Iter=3400, loss=1.3723, mse=1.3719, time=0.0408\n",
      "Iter=3600, loss=1.4092, mse=1.4089, time=0.0408\n",
      "Iter=3800, loss=1.3442, mse=1.3438, time=0.0408\n",
      "Iter=4000, loss=1.3715, mse=1.3711, time=0.0408\n",
      "Iter=4200, loss=1.3625, mse=1.3621, time=0.0407\n",
      "Iter=4400, loss=1.3492, mse=1.3488, time=0.0407\n",
      "Iter=4600, loss=1.4089, mse=1.4085, time=0.0407\n",
      "Iter=4800, loss=1.4012, mse=1.4008, time=0.0406\n",
      "Iter=5000, loss=1.4104, mse=1.4100, time=0.0406\n",
      "Iter=5200, loss=1.4213, mse=1.4210, time=0.0406\n",
      "Iter=5400, loss=1.3644, mse=1.3640, time=0.0406\n",
      "Iter=5600, loss=1.3419, mse=1.3415, time=0.0406\n",
      "Iter=5800, loss=1.4026, mse=1.4023, time=0.0406\n",
      "Iter=6000, loss=1.3816, mse=1.3812, time=0.0406\n",
      "Iter=6200, loss=1.3923, mse=1.3919, time=0.0406\n",
      "Iter=6400, loss=1.3831, mse=1.3828, time=0.0407\n",
      "Iter=6600, loss=1.3990, mse=1.3987, time=0.0407\n",
      "=== Epoch 11, train loss 1.390163, test rmse 1.163835 ===\n",
      "Epoch 12\n",
      "Iter=200, loss=1.3803, mse=1.3799, time=0.0423\n",
      "Iter=400, loss=1.4289, mse=1.4285, time=0.0414\n",
      "Iter=600, loss=1.3872, mse=1.3869, time=0.0414\n",
      "Iter=800, loss=1.4070, mse=1.4066, time=0.0411\n",
      "Iter=1000, loss=1.3994, mse=1.3990, time=0.0411\n",
      "Iter=1200, loss=1.3829, mse=1.3826, time=0.0411\n",
      "Iter=1400, loss=1.3760, mse=1.3756, time=0.0410\n",
      "Iter=1600, loss=1.3717, mse=1.3713, time=0.0410\n",
      "Iter=1800, loss=1.3670, mse=1.3667, time=0.0410\n",
      "Iter=2000, loss=1.3568, mse=1.3564, time=0.0410\n",
      "Iter=2200, loss=1.3963, mse=1.3959, time=0.0409\n",
      "Iter=2400, loss=1.3913, mse=1.3909, time=0.0409\n",
      "Iter=2600, loss=1.4062, mse=1.4058, time=0.0409\n",
      "Iter=2800, loss=1.3808, mse=1.3805, time=0.0409\n",
      "Iter=3000, loss=1.3949, mse=1.3946, time=0.0409\n",
      "Iter=3200, loss=1.3963, mse=1.3960, time=0.0408\n",
      "Iter=3400, loss=1.4185, mse=1.4181, time=0.0408\n",
      "Iter=3600, loss=1.4099, mse=1.4096, time=0.0407\n",
      "Iter=3800, loss=1.3842, mse=1.3838, time=0.0406\n",
      "Iter=4000, loss=1.3870, mse=1.3866, time=0.0406\n",
      "Iter=4200, loss=1.3926, mse=1.3923, time=0.0406\n",
      "Iter=4400, loss=1.4126, mse=1.4123, time=0.0406\n",
      "Iter=4600, loss=1.3749, mse=1.3746, time=0.0406\n",
      "Iter=4800, loss=1.3870, mse=1.3867, time=0.0406\n",
      "Iter=5000, loss=1.3772, mse=1.3768, time=0.0406\n",
      "Iter=5200, loss=1.3927, mse=1.3923, time=0.0406\n",
      "Iter=5400, loss=1.3856, mse=1.3853, time=0.0406\n",
      "Iter=5600, loss=1.3965, mse=1.3961, time=0.0406\n",
      "Iter=5800, loss=1.3653, mse=1.3649, time=0.0407\n",
      "Iter=6000, loss=1.3874, mse=1.3870, time=0.0406\n",
      "Iter=6200, loss=1.4206, mse=1.4203, time=0.0406\n",
      "Iter=6400, loss=1.3773, mse=1.3769, time=0.0406\n",
      "Iter=6600, loss=1.3775, mse=1.3771, time=0.0406\n",
      "=== Epoch 12, train loss 1.390117, test rmse 1.168544 ===\n",
      "Epoch 13\n",
      "Iter=200, loss=1.3629, mse=1.3626, time=0.0424\n",
      "Iter=400, loss=1.3860, mse=1.3857, time=0.0414\n",
      "Iter=600, loss=1.3995, mse=1.3992, time=0.0411\n",
      "Iter=800, loss=1.4023, mse=1.4020, time=0.0409\n",
      "Iter=1000, loss=1.3734, mse=1.3731, time=0.0411\n",
      "Iter=1200, loss=1.3753, mse=1.3750, time=0.0409\n",
      "Iter=1400, loss=1.3737, mse=1.3734, time=0.0410\n",
      "Iter=1600, loss=1.4308, mse=1.4305, time=0.0409\n",
      "Iter=1800, loss=1.3708, mse=1.3704, time=0.0409\n",
      "Iter=2000, loss=1.3874, mse=1.3870, time=0.0408\n",
      "Iter=2200, loss=1.3894, mse=1.3891, time=0.0408\n",
      "Iter=2400, loss=1.3948, mse=1.3944, time=0.0408\n",
      "Iter=2600, loss=1.4206, mse=1.4202, time=0.0408\n",
      "Iter=2800, loss=1.3743, mse=1.3739, time=0.0407\n",
      "Iter=3000, loss=1.3812, mse=1.3809, time=0.0406\n",
      "Iter=3200, loss=1.3849, mse=1.3846, time=0.0405\n",
      "Iter=3400, loss=1.3733, mse=1.3730, time=0.0405\n",
      "Iter=3600, loss=1.4024, mse=1.4021, time=0.0405\n",
      "Iter=3800, loss=1.3929, mse=1.3926, time=0.0405\n",
      "Iter=4000, loss=1.3861, mse=1.3858, time=0.0406\n",
      "Iter=4200, loss=1.3579, mse=1.3575, time=0.0406\n",
      "Iter=4400, loss=1.4019, mse=1.4016, time=0.0406\n",
      "Iter=4600, loss=1.3739, mse=1.3736, time=0.0407\n",
      "Iter=4800, loss=1.3964, mse=1.3961, time=0.0407\n",
      "Iter=5000, loss=1.3996, mse=1.3993, time=0.0406\n",
      "Iter=5200, loss=1.3899, mse=1.3895, time=0.0406\n",
      "Iter=5400, loss=1.3672, mse=1.3669, time=0.0406\n",
      "Iter=5600, loss=1.4034, mse=1.4031, time=0.0406\n",
      "Iter=5800, loss=1.4070, mse=1.4066, time=0.0406\n",
      "Iter=6000, loss=1.3870, mse=1.3866, time=0.0406\n",
      "Iter=6200, loss=1.3794, mse=1.3791, time=0.0406\n",
      "Iter=6400, loss=1.4220, mse=1.4217, time=0.0406\n",
      "Iter=6600, loss=1.3961, mse=1.3958, time=0.0406\n",
      "=== Epoch 13, train loss 1.389266, test rmse 1.169462 ===\n",
      "Epoch 14\n",
      "Iter=200, loss=1.3677, mse=1.3674, time=0.0419\n",
      "Iter=400, loss=1.3699, mse=1.3695, time=0.0411\n",
      "Iter=600, loss=1.3727, mse=1.3723, time=0.0410\n",
      "Iter=800, loss=1.3888, mse=1.3884, time=0.0410\n",
      "Iter=1000, loss=1.3763, mse=1.3760, time=0.0408\n",
      "Iter=1200, loss=1.4003, mse=1.4000, time=0.0408\n",
      "Iter=1400, loss=1.4079, mse=1.4076, time=0.0408\n",
      "Iter=1600, loss=1.3998, mse=1.3995, time=0.0407\n",
      "Iter=1800, loss=1.3646, mse=1.3643, time=0.0406\n",
      "Iter=2000, loss=1.4097, mse=1.4094, time=0.0405\n",
      "Iter=2200, loss=1.4059, mse=1.4056, time=0.0405\n",
      "Iter=2400, loss=1.3736, mse=1.3733, time=0.0406\n",
      "Iter=2600, loss=1.3838, mse=1.3834, time=0.0406\n",
      "Iter=2800, loss=1.3873, mse=1.3869, time=0.0406\n",
      "Iter=3000, loss=1.3734, mse=1.3731, time=0.0407\n",
      "Iter=3200, loss=1.3818, mse=1.3815, time=0.0407\n",
      "Iter=3400, loss=1.3910, mse=1.3907, time=0.0407\n",
      "Iter=3600, loss=1.3946, mse=1.3943, time=0.0407\n",
      "Iter=3800, loss=1.4097, mse=1.4094, time=0.0408\n",
      "Iter=4000, loss=1.3692, mse=1.3689, time=0.0407\n",
      "Iter=4200, loss=1.4132, mse=1.4129, time=0.0408\n",
      "Iter=4400, loss=1.3793, mse=1.3790, time=0.0407\n",
      "Iter=4600, loss=1.4011, mse=1.4008, time=0.0408\n",
      "Iter=4800, loss=1.3669, mse=1.3666, time=0.0407\n",
      "Iter=5000, loss=1.3722, mse=1.3719, time=0.0407\n",
      "Iter=5200, loss=1.3715, mse=1.3712, time=0.0407\n",
      "Iter=5400, loss=1.3973, mse=1.3970, time=0.0407\n",
      "Iter=5600, loss=1.3731, mse=1.3727, time=0.0407\n",
      "Iter=5800, loss=1.3912, mse=1.3909, time=0.0407\n",
      "Iter=6000, loss=1.4045, mse=1.4042, time=0.0407\n",
      "Iter=6200, loss=1.3828, mse=1.3825, time=0.0407\n",
      "Iter=6400, loss=1.4143, mse=1.4139, time=0.0407\n",
      "Iter=6600, loss=1.4096, mse=1.4093, time=0.0407\n",
      "=== Epoch 14, train loss 1.388760, test rmse 1.164884 ===\n",
      "Epoch 15\n",
      "Iter=200, loss=1.3767, mse=1.3763, time=0.0419\n",
      "Iter=400, loss=1.4024, mse=1.4021, time=0.0413\n",
      "Iter=600, loss=1.3838, mse=1.3835, time=0.0410\n",
      "Iter=800, loss=1.3895, mse=1.3892, time=0.0406\n",
      "Iter=1000, loss=1.3917, mse=1.3913, time=0.0404\n",
      "Iter=1200, loss=1.3853, mse=1.3850, time=0.0403\n",
      "Iter=1400, loss=1.3714, mse=1.3710, time=0.0404\n",
      "Iter=1600, loss=1.3712, mse=1.3708, time=0.0404\n",
      "Iter=1800, loss=1.3910, mse=1.3906, time=0.0405\n",
      "Iter=2000, loss=1.3955, mse=1.3951, time=0.0405\n",
      "Iter=2200, loss=1.3835, mse=1.3831, time=0.0405\n",
      "Iter=2400, loss=1.3792, mse=1.3789, time=0.0406\n",
      "Iter=2600, loss=1.3626, mse=1.3622, time=0.0406\n",
      "Iter=2800, loss=1.4080, mse=1.4077, time=0.0407\n",
      "Iter=3000, loss=1.4086, mse=1.4083, time=0.0407\n",
      "Iter=3200, loss=1.3560, mse=1.3556, time=0.0406\n",
      "Iter=3400, loss=1.3791, mse=1.3788, time=0.0407\n",
      "Iter=3600, loss=1.4100, mse=1.4097, time=0.0407\n",
      "Iter=3800, loss=1.4287, mse=1.4284, time=0.0407\n",
      "Iter=4000, loss=1.3754, mse=1.3751, time=0.0407\n",
      "Iter=4200, loss=1.4064, mse=1.4061, time=0.0407\n",
      "Iter=4400, loss=1.3793, mse=1.3790, time=0.0407\n",
      "Iter=4600, loss=1.4079, mse=1.4076, time=0.0407\n",
      "Iter=4800, loss=1.3841, mse=1.3838, time=0.0407\n",
      "Iter=5000, loss=1.4158, mse=1.4155, time=0.0407\n",
      "Iter=5200, loss=1.3756, mse=1.3753, time=0.0407\n",
      "Iter=5400, loss=1.3895, mse=1.3891, time=0.0407\n",
      "Iter=5600, loss=1.3844, mse=1.3841, time=0.0407\n",
      "Iter=5800, loss=1.4025, mse=1.4021, time=0.0407\n",
      "Iter=6000, loss=1.4068, mse=1.4065, time=0.0407\n",
      "Iter=6200, loss=1.3951, mse=1.3948, time=0.0407\n",
      "Iter=6400, loss=1.3599, mse=1.3596, time=0.0408\n",
      "Iter=6600, loss=1.4003, mse=1.4000, time=0.0409\n",
      "=== Epoch 15, train loss 1.389058, test rmse 1.163720 ===\n",
      "Epoch 16\n",
      "Iter=200, loss=1.3747, mse=1.3743, time=0.0413\n",
      "Iter=400, loss=1.3713, mse=1.3710, time=0.0410\n",
      "Iter=600, loss=1.3864, mse=1.3861, time=0.0408\n",
      "Iter=800, loss=1.3988, mse=1.3984, time=0.0410\n",
      "Iter=1000, loss=1.4321, mse=1.4318, time=0.0409\n",
      "Iter=1200, loss=1.4058, mse=1.4055, time=0.0408\n",
      "Iter=1400, loss=1.3628, mse=1.3625, time=0.0408\n",
      "Iter=1600, loss=1.4180, mse=1.4176, time=0.0408\n",
      "Iter=1800, loss=1.3626, mse=1.3622, time=0.0408\n",
      "Iter=2000, loss=1.3916, mse=1.3912, time=0.0407\n",
      "Iter=2200, loss=1.3922, mse=1.3918, time=0.0407\n",
      "Iter=2400, loss=1.3940, mse=1.3936, time=0.0407\n",
      "Iter=2600, loss=1.4286, mse=1.4283, time=0.0406\n",
      "Iter=2800, loss=1.3473, mse=1.3470, time=0.0406\n",
      "Iter=3000, loss=1.3595, mse=1.3592, time=0.0407\n",
      "Iter=3200, loss=1.3820, mse=1.3817, time=0.0407\n",
      "Iter=3400, loss=1.4052, mse=1.4049, time=0.0407\n",
      "Iter=3600, loss=1.3936, mse=1.3933, time=0.0407\n",
      "Iter=3800, loss=1.4117, mse=1.4113, time=0.0407\n",
      "Iter=4000, loss=1.4000, mse=1.3997, time=0.0408\n",
      "Iter=4200, loss=1.3866, mse=1.3863, time=0.0408\n",
      "Iter=4400, loss=1.3957, mse=1.3954, time=0.0408\n",
      "Iter=4600, loss=1.3583, mse=1.3580, time=0.0409\n",
      "Iter=4800, loss=1.4133, mse=1.4130, time=0.0410\n",
      "Iter=5000, loss=1.3908, mse=1.3905, time=0.0410\n",
      "Iter=5200, loss=1.3753, mse=1.3750, time=0.0410\n",
      "Iter=5400, loss=1.3794, mse=1.3791, time=0.0410\n",
      "Iter=5600, loss=1.3727, mse=1.3724, time=0.0410\n",
      "Iter=5800, loss=1.3887, mse=1.3884, time=0.0410\n",
      "Iter=6000, loss=1.4016, mse=1.4012, time=0.0410\n",
      "Iter=6200, loss=1.3642, mse=1.3638, time=0.0410\n",
      "Iter=6400, loss=1.3873, mse=1.3869, time=0.0409\n",
      "Iter=6600, loss=1.4296, mse=1.4292, time=0.0409\n",
      "=== Epoch 16, train loss 1.389296, test rmse 1.171993 ===\n",
      "Epoch 17\n",
      "Iter=200, loss=1.3919, mse=1.3915, time=0.0419\n",
      "Iter=400, loss=1.3950, mse=1.3946, time=0.0413\n",
      "Iter=600, loss=1.3814, mse=1.3810, time=0.0413\n",
      "Iter=800, loss=1.3974, mse=1.3971, time=0.0413\n",
      "Iter=1000, loss=1.3664, mse=1.3661, time=0.0411\n",
      "Iter=1200, loss=1.4085, mse=1.4082, time=0.0411\n",
      "Iter=1400, loss=1.3937, mse=1.3934, time=0.0409\n",
      "Iter=1600, loss=1.3728, mse=1.3725, time=0.0409\n",
      "Iter=1800, loss=1.3653, mse=1.3650, time=0.0409\n",
      "Iter=2000, loss=1.3817, mse=1.3814, time=0.0409\n",
      "Iter=2200, loss=1.3714, mse=1.3711, time=0.0409\n",
      "Iter=2400, loss=1.3884, mse=1.3881, time=0.0409\n",
      "Iter=2600, loss=1.3871, mse=1.3867, time=0.0409\n",
      "Iter=2800, loss=1.4277, mse=1.4273, time=0.0409\n",
      "Iter=3000, loss=1.3844, mse=1.3840, time=0.0409\n",
      "Iter=3200, loss=1.4150, mse=1.4146, time=0.0409\n",
      "Iter=3400, loss=1.4025, mse=1.4021, time=0.0409\n",
      "Iter=3600, loss=1.4040, mse=1.4037, time=0.0409\n",
      "Iter=3800, loss=1.4058, mse=1.4054, time=0.0408\n",
      "Iter=4000, loss=1.3998, mse=1.3995, time=0.0408\n",
      "Iter=4200, loss=1.3673, mse=1.3669, time=0.0408\n",
      "Iter=4400, loss=1.3653, mse=1.3650, time=0.0408\n",
      "Iter=4600, loss=1.4340, mse=1.4337, time=0.0408\n",
      "Iter=4800, loss=1.4089, mse=1.4086, time=0.0408\n",
      "Iter=5000, loss=1.4024, mse=1.4021, time=0.0408\n",
      "Iter=5200, loss=1.3806, mse=1.3803, time=0.0408\n",
      "Iter=5400, loss=1.3981, mse=1.3977, time=0.0408\n",
      "Iter=5600, loss=1.3879, mse=1.3875, time=0.0408\n",
      "Iter=5800, loss=1.3626, mse=1.3623, time=0.0408\n",
      "Iter=6000, loss=1.3974, mse=1.3971, time=0.0408\n",
      "Iter=6200, loss=1.3278, mse=1.3275, time=0.0407\n",
      "Iter=6400, loss=1.3748, mse=1.3745, time=0.0407\n",
      "Iter=6600, loss=1.3927, mse=1.3924, time=0.0406\n",
      "=== Epoch 17, train loss 1.389014, test rmse 1.166167 ===\n",
      "Epoch 18\n",
      "Iter=200, loss=1.3530, mse=1.3527, time=0.0421\n",
      "Iter=400, loss=1.3521, mse=1.3518, time=0.0410\n",
      "Iter=600, loss=1.3938, mse=1.3934, time=0.0409\n",
      "Iter=800, loss=1.4267, mse=1.4263, time=0.0408\n",
      "Iter=1000, loss=1.3829, mse=1.3826, time=0.0408\n",
      "Iter=1200, loss=1.3632, mse=1.3629, time=0.0408\n",
      "Iter=1400, loss=1.3840, mse=1.3837, time=0.0408\n",
      "Iter=1600, loss=1.3658, mse=1.3654, time=0.0408\n",
      "Iter=1800, loss=1.4033, mse=1.4029, time=0.0409\n",
      "Iter=2000, loss=1.3709, mse=1.3706, time=0.0408\n",
      "Iter=2200, loss=1.3790, mse=1.3787, time=0.0408\n",
      "Iter=2400, loss=1.3842, mse=1.3839, time=0.0408\n",
      "Iter=2600, loss=1.3630, mse=1.3627, time=0.0408\n",
      "Iter=2800, loss=1.3687, mse=1.3684, time=0.0408\n",
      "Iter=3000, loss=1.3998, mse=1.3995, time=0.0408\n",
      "Iter=3200, loss=1.3987, mse=1.3984, time=0.0408\n",
      "Iter=3400, loss=1.4062, mse=1.4059, time=0.0408\n",
      "Iter=3600, loss=1.4136, mse=1.4133, time=0.0408\n",
      "Iter=3800, loss=1.3797, mse=1.3794, time=0.0408\n",
      "Iter=4000, loss=1.3953, mse=1.3950, time=0.0408\n",
      "Iter=4200, loss=1.3625, mse=1.3622, time=0.0408\n",
      "Iter=4400, loss=1.4129, mse=1.4125, time=0.0408\n",
      "Iter=4600, loss=1.3919, mse=1.3916, time=0.0408\n",
      "Iter=4800, loss=1.4138, mse=1.4135, time=0.0408\n",
      "Iter=5000, loss=1.4037, mse=1.4034, time=0.0408\n",
      "Iter=5200, loss=1.3722, mse=1.3719, time=0.0407\n",
      "Iter=5400, loss=1.4337, mse=1.4334, time=0.0407\n",
      "Iter=5600, loss=1.3797, mse=1.3794, time=0.0406\n",
      "Iter=5800, loss=1.3947, mse=1.3943, time=0.0407\n",
      "Iter=6000, loss=1.3583, mse=1.3579, time=0.0407\n",
      "Iter=6200, loss=1.4011, mse=1.4007, time=0.0407\n",
      "Iter=6400, loss=1.4013, mse=1.4009, time=0.0407\n",
      "Iter=6600, loss=1.3649, mse=1.3646, time=0.0407\n",
      "=== Epoch 18, train loss 1.387804, test rmse 1.165306 ===\n",
      "Epoch 19\n",
      "Iter=200, loss=1.4168, mse=1.4165, time=0.0415\n",
      "Iter=400, loss=1.4275, mse=1.4271, time=0.0415\n",
      "Iter=600, loss=1.3843, mse=1.3839, time=0.0412\n",
      "Iter=800, loss=1.3988, mse=1.3984, time=0.0411\n",
      "Iter=1000, loss=1.4029, mse=1.4025, time=0.0410\n",
      "Iter=1200, loss=1.3643, mse=1.3639, time=0.0410\n",
      "Iter=1400, loss=1.3711, mse=1.3707, time=0.0410\n",
      "Iter=1600, loss=1.3560, mse=1.3556, time=0.0409\n",
      "Iter=1800, loss=1.3923, mse=1.3919, time=0.0409\n",
      "Iter=2000, loss=1.4322, mse=1.4319, time=0.0408\n",
      "Iter=2200, loss=1.3940, mse=1.3936, time=0.0409\n",
      "Iter=2400, loss=1.4045, mse=1.4041, time=0.0409\n",
      "Iter=2600, loss=1.3921, mse=1.3917, time=0.0408\n",
      "Iter=2800, loss=1.4048, mse=1.4044, time=0.0408\n",
      "Iter=3000, loss=1.3893, mse=1.3890, time=0.0408\n",
      "Iter=3200, loss=1.3772, mse=1.3769, time=0.0408\n",
      "Iter=3400, loss=1.3902, mse=1.3898, time=0.0408\n",
      "Iter=3600, loss=1.3802, mse=1.3798, time=0.0408\n",
      "Iter=3800, loss=1.3847, mse=1.3843, time=0.0408\n",
      "Iter=4000, loss=1.3401, mse=1.3398, time=0.0408\n",
      "Iter=4200, loss=1.3865, mse=1.3861, time=0.0407\n",
      "Iter=4400, loss=1.3681, mse=1.3677, time=0.0407\n",
      "Iter=4600, loss=1.3667, mse=1.3663, time=0.0407\n",
      "Iter=4800, loss=1.4032, mse=1.4029, time=0.0407\n",
      "Iter=5000, loss=1.3996, mse=1.3993, time=0.0407\n",
      "Iter=5200, loss=1.3771, mse=1.3768, time=0.0407\n",
      "Iter=5400, loss=1.3562, mse=1.3559, time=0.0407\n",
      "Iter=5600, loss=1.4021, mse=1.4017, time=0.0407\n",
      "Iter=5800, loss=1.4118, mse=1.4114, time=0.0407\n",
      "Iter=6000, loss=1.3705, mse=1.3701, time=0.0407\n",
      "Iter=6200, loss=1.3802, mse=1.3799, time=0.0407\n",
      "Iter=6400, loss=1.4029, mse=1.4025, time=0.0407\n",
      "Iter=6600, loss=1.3610, mse=1.3606, time=0.0407\n",
      "=== Epoch 19, train loss 1.388022, test rmse 1.164883 ===\n",
      "Epoch 20\n",
      "Iter=200, loss=1.3978, mse=1.3975, time=0.0423\n",
      "Iter=400, loss=1.3937, mse=1.3934, time=0.0414\n",
      "Iter=600, loss=1.4031, mse=1.4027, time=0.0410\n",
      "Iter=800, loss=1.3991, mse=1.3987, time=0.0409\n",
      "Iter=1000, loss=1.3656, mse=1.3653, time=0.0409\n",
      "Iter=1200, loss=1.3739, mse=1.3735, time=0.0409\n",
      "Iter=1400, loss=1.3787, mse=1.3783, time=0.0408\n",
      "Iter=1600, loss=1.3806, mse=1.3803, time=0.0408\n",
      "Iter=1800, loss=1.4098, mse=1.4094, time=0.0407\n",
      "Iter=2000, loss=1.3850, mse=1.3847, time=0.0408\n",
      "Iter=2200, loss=1.3615, mse=1.3611, time=0.0407\n",
      "Iter=2400, loss=1.3914, mse=1.3911, time=0.0408\n",
      "Iter=2600, loss=1.4167, mse=1.4164, time=0.0408\n",
      "Iter=2800, loss=1.3819, mse=1.3816, time=0.0408\n",
      "Iter=3000, loss=1.3667, mse=1.3663, time=0.0406\n",
      "Iter=3200, loss=1.4049, mse=1.4046, time=0.0406\n",
      "Iter=3400, loss=1.4157, mse=1.4154, time=0.0405\n",
      "Iter=3600, loss=1.3807, mse=1.3803, time=0.0405\n",
      "Iter=3800, loss=1.3348, mse=1.3345, time=0.0405\n",
      "Iter=4000, loss=1.3903, mse=1.3899, time=0.0405\n",
      "Iter=4200, loss=1.3591, mse=1.3587, time=0.0405\n",
      "Iter=4400, loss=1.4010, mse=1.4006, time=0.0406\n",
      "Iter=4600, loss=1.3963, mse=1.3959, time=0.0406\n",
      "Iter=4800, loss=1.3783, mse=1.3779, time=0.0406\n",
      "Iter=5000, loss=1.4103, mse=1.4099, time=0.0406\n",
      "Iter=5200, loss=1.4073, mse=1.4069, time=0.0406\n",
      "Iter=5400, loss=1.4022, mse=1.4018, time=0.0406\n",
      "Iter=5600, loss=1.3799, mse=1.3795, time=0.0406\n",
      "Iter=5800, loss=1.3819, mse=1.3815, time=0.0406\n",
      "Iter=6000, loss=1.3930, mse=1.3927, time=0.0406\n",
      "Iter=6200, loss=1.4008, mse=1.4005, time=0.0406\n",
      "Iter=6400, loss=1.3823, mse=1.3820, time=0.0406\n",
      "Iter=6600, loss=1.3588, mse=1.3584, time=0.0406\n",
      "=== Epoch 20, train loss 1.386195, test rmse 1.166451 ===\n",
      "Epoch 21\n",
      "Iter=200, loss=1.3945, mse=1.3942, time=0.0425\n",
      "Iter=400, loss=1.3765, mse=1.3762, time=0.0414\n",
      "Iter=600, loss=1.4071, mse=1.4068, time=0.0414\n",
      "Iter=800, loss=1.3717, mse=1.3714, time=0.0411\n",
      "Iter=1000, loss=1.3756, mse=1.3752, time=0.0410\n",
      "Iter=1200, loss=1.4090, mse=1.4087, time=0.0409\n",
      "Iter=1400, loss=1.4141, mse=1.4137, time=0.0409\n",
      "Iter=1600, loss=1.4093, mse=1.4090, time=0.0409\n",
      "Iter=1800, loss=1.4081, mse=1.4078, time=0.0409\n",
      "Iter=2000, loss=1.3769, mse=1.3766, time=0.0408\n",
      "Iter=2200, loss=1.3938, mse=1.3935, time=0.0407\n",
      "Iter=2400, loss=1.3773, mse=1.3770, time=0.0406\n",
      "Iter=2600, loss=1.3916, mse=1.3912, time=0.0405\n",
      "Iter=2800, loss=1.3857, mse=1.3853, time=0.0405\n",
      "Iter=3000, loss=1.3848, mse=1.3845, time=0.0405\n",
      "Iter=3200, loss=1.3647, mse=1.3644, time=0.0405\n",
      "Iter=3400, loss=1.3813, mse=1.3810, time=0.0405\n",
      "Iter=3600, loss=1.3873, mse=1.3869, time=0.0406\n",
      "Iter=3800, loss=1.4052, mse=1.4049, time=0.0406\n",
      "Iter=4000, loss=1.3964, mse=1.3961, time=0.0406\n",
      "Iter=4200, loss=1.3911, mse=1.3907, time=0.0407\n",
      "Iter=4400, loss=1.3696, mse=1.3693, time=0.0407\n",
      "Iter=4600, loss=1.4072, mse=1.4068, time=0.0407\n",
      "Iter=4800, loss=1.3365, mse=1.3362, time=0.0407\n",
      "Iter=5000, loss=1.3917, mse=1.3914, time=0.0407\n",
      "Iter=5200, loss=1.3796, mse=1.3793, time=0.0407\n",
      "Iter=5400, loss=1.3760, mse=1.3756, time=0.0407\n",
      "Iter=5600, loss=1.3768, mse=1.3765, time=0.0407\n",
      "Iter=5800, loss=1.3810, mse=1.3807, time=0.0407\n",
      "Iter=6000, loss=1.3770, mse=1.3767, time=0.0407\n",
      "Iter=6200, loss=1.3929, mse=1.3926, time=0.0407\n",
      "Iter=6400, loss=1.3953, mse=1.3950, time=0.0407\n",
      "Iter=6600, loss=1.4005, mse=1.4002, time=0.0407\n",
      "=== Epoch 21, train loss 1.387417, test rmse 1.171544 ===\n",
      "Epoch 22\n",
      "Iter=200, loss=1.4039, mse=1.4035, time=0.0417\n",
      "Iter=400, loss=1.3658, mse=1.3654, time=0.0410\n",
      "Iter=600, loss=1.3935, mse=1.3932, time=0.0407\n",
      "Iter=800, loss=1.3939, mse=1.3935, time=0.0407\n",
      "Iter=1000, loss=1.3637, mse=1.3634, time=0.0406\n",
      "Iter=1200, loss=1.3947, mse=1.3944, time=0.0405\n",
      "Iter=1400, loss=1.3931, mse=1.3928, time=0.0402\n",
      "Iter=1600, loss=1.4005, mse=1.4002, time=0.0402\n",
      "Iter=1800, loss=1.4014, mse=1.4011, time=0.0402\n",
      "Iter=2000, loss=1.3962, mse=1.3959, time=0.0404\n",
      "Iter=2200, loss=1.3892, mse=1.3889, time=0.0405\n",
      "Iter=2400, loss=1.4023, mse=1.4019, time=0.0406\n",
      "Iter=2600, loss=1.3828, mse=1.3825, time=0.0413\n",
      "Iter=2800, loss=1.3814, mse=1.3811, time=0.0417\n",
      "Iter=3000, loss=1.3841, mse=1.3838, time=0.0419\n",
      "Iter=3200, loss=1.3772, mse=1.3769, time=0.0420\n",
      "Iter=3400, loss=1.3590, mse=1.3586, time=0.0421\n",
      "Iter=3600, loss=1.3510, mse=1.3506, time=0.0421\n",
      "Iter=3800, loss=1.3836, mse=1.3832, time=0.0421\n",
      "Iter=4000, loss=1.3868, mse=1.3864, time=0.0422\n",
      "Iter=4200, loss=1.4092, mse=1.4088, time=0.0422\n",
      "Iter=4400, loss=1.4176, mse=1.4172, time=0.0422\n",
      "Iter=4600, loss=1.3904, mse=1.3900, time=0.0423\n",
      "Iter=4800, loss=1.3561, mse=1.3557, time=0.0423\n",
      "Iter=5000, loss=1.4105, mse=1.4101, time=0.0424\n",
      "Iter=5200, loss=1.3851, mse=1.3847, time=0.0425\n",
      "Iter=5400, loss=1.4082, mse=1.4078, time=0.0426\n",
      "Iter=5600, loss=1.3839, mse=1.3836, time=0.0427\n",
      "Iter=5800, loss=1.3919, mse=1.3915, time=0.0428\n",
      "Iter=6000, loss=1.4125, mse=1.4121, time=0.0428\n",
      "Iter=6200, loss=1.3974, mse=1.3970, time=0.0428\n",
      "Iter=6400, loss=1.3866, mse=1.3863, time=0.0429\n",
      "Iter=6600, loss=1.4117, mse=1.4114, time=0.0430\n",
      "=== Epoch 22, train loss 1.389839, test rmse 1.168159 ===\n",
      "Epoch 23\n",
      "Iter=200, loss=1.4036, mse=1.4033, time=0.0421\n",
      "Iter=400, loss=1.3887, mse=1.3884, time=0.0425\n",
      "Iter=600, loss=1.3739, mse=1.3735, time=0.0428\n",
      "Iter=800, loss=1.3914, mse=1.3910, time=0.0428\n",
      "Iter=1000, loss=1.3585, mse=1.3582, time=0.0430\n",
      "Iter=1200, loss=1.4039, mse=1.4036, time=0.0430\n",
      "Iter=1400, loss=1.3948, mse=1.3945, time=0.0430\n",
      "Iter=1600, loss=1.3520, mse=1.3516, time=0.0430\n",
      "Iter=1800, loss=1.4237, mse=1.4234, time=0.0432\n",
      "Iter=2000, loss=1.3775, mse=1.3772, time=0.0432\n",
      "Iter=2200, loss=1.3972, mse=1.3969, time=0.0432\n",
      "Iter=2400, loss=1.3859, mse=1.3856, time=0.0433\n",
      "Iter=2600, loss=1.4035, mse=1.4032, time=0.0432\n",
      "Iter=2800, loss=1.3788, mse=1.3785, time=0.0432\n",
      "Iter=3000, loss=1.3782, mse=1.3779, time=0.0432\n",
      "Iter=3200, loss=1.4072, mse=1.4069, time=0.0432\n",
      "Iter=3400, loss=1.4098, mse=1.4095, time=0.0432\n",
      "Iter=3600, loss=1.3751, mse=1.3747, time=0.0432\n",
      "Iter=3800, loss=1.3769, mse=1.3765, time=0.0432\n",
      "Iter=4000, loss=1.3840, mse=1.3836, time=0.0433\n",
      "Iter=4200, loss=1.3917, mse=1.3914, time=0.0435\n",
      "Iter=4400, loss=1.3806, mse=1.3803, time=0.0439\n",
      "Iter=4600, loss=1.4059, mse=1.4056, time=0.0437\n",
      "Iter=4800, loss=1.3956, mse=1.3953, time=0.0437\n",
      "Iter=5000, loss=1.3694, mse=1.3691, time=0.0435\n",
      "Iter=5200, loss=1.3810, mse=1.3807, time=0.0435\n",
      "Iter=5400, loss=1.3545, mse=1.3542, time=0.0433\n",
      "Iter=5600, loss=1.3960, mse=1.3957, time=0.0433\n",
      "Iter=5800, loss=1.3932, mse=1.3929, time=0.0432\n",
      "Iter=6000, loss=1.3847, mse=1.3843, time=0.0431\n",
      "Iter=6200, loss=1.4013, mse=1.4010, time=0.0430\n",
      "Iter=6400, loss=1.3734, mse=1.3731, time=0.0430\n",
      "Iter=6600, loss=1.3877, mse=1.3874, time=0.0429\n",
      "=== Epoch 23, train loss 1.388014, test rmse 1.165498 ===\n",
      "Epoch 24\n",
      "Iter=200, loss=1.3919, mse=1.3916, time=0.0423\n",
      "Iter=400, loss=1.4026, mse=1.4022, time=0.0416\n",
      "Iter=600, loss=1.3929, mse=1.3926, time=0.0414\n",
      "Iter=800, loss=1.4101, mse=1.4097, time=0.0413\n",
      "Iter=1000, loss=1.3750, mse=1.3747, time=0.0413\n",
      "Iter=1200, loss=1.3778, mse=1.3775, time=0.0413\n",
      "Iter=1400, loss=1.3909, mse=1.3906, time=0.0411\n",
      "Iter=1600, loss=1.3861, mse=1.3858, time=0.0411\n",
      "Iter=1800, loss=1.4033, mse=1.4030, time=0.0410\n",
      "Iter=2000, loss=1.3665, mse=1.3662, time=0.0411\n",
      "Iter=2200, loss=1.3599, mse=1.3596, time=0.0410\n",
      "Iter=2400, loss=1.3798, mse=1.3794, time=0.0410\n",
      "Iter=2600, loss=1.3716, mse=1.3712, time=0.0410\n",
      "Iter=2800, loss=1.3936, mse=1.3932, time=0.0409\n",
      "Iter=3000, loss=1.3744, mse=1.3741, time=0.0409\n",
      "Iter=3200, loss=1.3924, mse=1.3921, time=0.0409\n",
      "Iter=3400, loss=1.3747, mse=1.3744, time=0.0409\n",
      "Iter=3600, loss=1.3561, mse=1.3558, time=0.0409\n",
      "Iter=3800, loss=1.3871, mse=1.3868, time=0.0409\n",
      "Iter=4000, loss=1.4078, mse=1.4075, time=0.0409\n",
      "Iter=4200, loss=1.3888, mse=1.3885, time=0.0409\n",
      "Iter=4400, loss=1.3878, mse=1.3875, time=0.0408\n",
      "Iter=4600, loss=1.4078, mse=1.4075, time=0.0408\n",
      "Iter=4800, loss=1.3682, mse=1.3679, time=0.0408\n",
      "Iter=5000, loss=1.3910, mse=1.3907, time=0.0408\n",
      "Iter=5200, loss=1.4308, mse=1.4305, time=0.0407\n",
      "Iter=5400, loss=1.4104, mse=1.4101, time=0.0407\n",
      "Iter=5600, loss=1.4019, mse=1.4016, time=0.0407\n",
      "Iter=5800, loss=1.3776, mse=1.3773, time=0.0407\n",
      "Iter=6000, loss=1.3877, mse=1.3874, time=0.0407\n",
      "Iter=6200, loss=1.3625, mse=1.3622, time=0.0407\n",
      "Iter=6400, loss=1.3890, mse=1.3887, time=0.0407\n",
      "Iter=6600, loss=1.3939, mse=1.3936, time=0.0406\n",
      "=== Epoch 24, train loss 1.387807, test rmse 1.162945 ===\n",
      "Epoch 25\n",
      "Iter=200, loss=1.3806, mse=1.3803, time=0.0416\n",
      "Iter=400, loss=1.3638, mse=1.3635, time=0.0411\n",
      "Iter=600, loss=1.4091, mse=1.4088, time=0.0408\n",
      "Iter=800, loss=1.4068, mse=1.4065, time=0.0407\n",
      "Iter=1000, loss=1.4035, mse=1.4032, time=0.0407\n",
      "Iter=1200, loss=1.3405, mse=1.3402, time=0.0405\n",
      "Iter=1400, loss=1.4200, mse=1.4197, time=0.0407\n",
      "Iter=1600, loss=1.3728, mse=1.3724, time=0.0407\n",
      "Iter=1800, loss=1.3583, mse=1.3580, time=0.0407\n",
      "Iter=2000, loss=1.3806, mse=1.3803, time=0.0406\n",
      "Iter=2200, loss=1.4309, mse=1.4306, time=0.0407\n",
      "Iter=2400, loss=1.3462, mse=1.3459, time=0.0407\n",
      "Iter=2600, loss=1.4137, mse=1.4134, time=0.0407\n",
      "Iter=2800, loss=1.3938, mse=1.3935, time=0.0407\n",
      "Iter=3000, loss=1.4277, mse=1.4274, time=0.0407\n",
      "Iter=3200, loss=1.3649, mse=1.3646, time=0.0407\n",
      "Iter=3400, loss=1.3533, mse=1.3530, time=0.0407\n",
      "Iter=3600, loss=1.4036, mse=1.4032, time=0.0407\n",
      "Iter=3800, loss=1.4056, mse=1.4052, time=0.0406\n",
      "Iter=4000, loss=1.3995, mse=1.3992, time=0.0407\n",
      "Iter=4200, loss=1.3617, mse=1.3614, time=0.0407\n",
      "Iter=4400, loss=1.3959, mse=1.3955, time=0.0407\n",
      "Iter=4600, loss=1.3672, mse=1.3668, time=0.0407\n",
      "Iter=4800, loss=1.3999, mse=1.3996, time=0.0407\n",
      "Iter=5000, loss=1.3901, mse=1.3898, time=0.0406\n",
      "Iter=5200, loss=1.3768, mse=1.3765, time=0.0407\n",
      "Iter=5400, loss=1.4176, mse=1.4173, time=0.0406\n",
      "Iter=5600, loss=1.3731, mse=1.3728, time=0.0405\n",
      "Iter=5800, loss=1.3944, mse=1.3941, time=0.0405\n",
      "Iter=6000, loss=1.3958, mse=1.3954, time=0.0404\n",
      "Iter=6200, loss=1.3762, mse=1.3759, time=0.0404\n",
      "Iter=6400, loss=1.3707, mse=1.3704, time=0.0405\n",
      "Iter=6600, loss=1.4063, mse=1.4060, time=0.0404\n",
      "=== Epoch 25, train loss 1.389592, test rmse 1.163553 ===\n",
      "Epoch 26\n",
      "Iter=200, loss=1.3947, mse=1.3944, time=0.0414\n",
      "Iter=400, loss=1.4097, mse=1.4094, time=0.0414\n",
      "Iter=600, loss=1.4023, mse=1.4020, time=0.0412\n",
      "Iter=800, loss=1.4006, mse=1.4003, time=0.0412\n",
      "Iter=1000, loss=1.3902, mse=1.3898, time=0.0410\n",
      "Iter=1200, loss=1.4016, mse=1.4013, time=0.0410\n",
      "Iter=1400, loss=1.3596, mse=1.3593, time=0.0410\n",
      "Iter=1600, loss=1.3911, mse=1.3908, time=0.0410\n",
      "Iter=1800, loss=1.3885, mse=1.3882, time=0.0409\n",
      "Iter=2000, loss=1.3875, mse=1.3872, time=0.0409\n",
      "Iter=2200, loss=1.3767, mse=1.3763, time=0.0409\n",
      "Iter=2400, loss=1.3679, mse=1.3676, time=0.0409\n",
      "Iter=2600, loss=1.4190, mse=1.4187, time=0.0409\n",
      "Iter=2800, loss=1.3581, mse=1.3577, time=0.0409\n",
      "Iter=3000, loss=1.4265, mse=1.4262, time=0.0409\n",
      "Iter=3200, loss=1.3445, mse=1.3442, time=0.0408\n",
      "Iter=3400, loss=1.4055, mse=1.4052, time=0.0409\n",
      "Iter=3600, loss=1.3959, mse=1.3956, time=0.0408\n",
      "Iter=3800, loss=1.4011, mse=1.4008, time=0.0408\n",
      "Iter=4000, loss=1.3600, mse=1.3596, time=0.0408\n",
      "Iter=4200, loss=1.3857, mse=1.3854, time=0.0408\n",
      "Iter=4400, loss=1.3607, mse=1.3604, time=0.0408\n",
      "Iter=4600, loss=1.4199, mse=1.4196, time=0.0408\n",
      "Iter=4800, loss=1.3932, mse=1.3929, time=0.0407\n",
      "Iter=5000, loss=1.3629, mse=1.3626, time=0.0406\n",
      "Iter=5200, loss=1.3439, mse=1.3436, time=0.0406\n",
      "Iter=5400, loss=1.4000, mse=1.3997, time=0.0406\n",
      "Iter=5600, loss=1.3780, mse=1.3777, time=0.0406\n",
      "Iter=5800, loss=1.4269, mse=1.4266, time=0.0406\n",
      "Iter=6000, loss=1.3919, mse=1.3916, time=0.0407\n",
      "Iter=6200, loss=1.4140, mse=1.4137, time=0.0406\n",
      "Iter=6400, loss=1.3772, mse=1.3769, time=0.0407\n",
      "Iter=6600, loss=1.3800, mse=1.3797, time=0.0407\n",
      "=== Epoch 26, train loss 1.388297, test rmse 1.164143 ===\n",
      "Epoch 27\n",
      "Iter=200, loss=1.3852, mse=1.3849, time=0.0426\n",
      "Iter=400, loss=1.3856, mse=1.3853, time=0.0415\n",
      "Iter=600, loss=1.4002, mse=1.3999, time=0.0413\n",
      "Iter=800, loss=1.3766, mse=1.3763, time=0.0413\n",
      "Iter=1000, loss=1.3994, mse=1.3991, time=0.0413\n",
      "Iter=1200, loss=1.3631, mse=1.3628, time=0.0412\n",
      "Iter=1400, loss=1.3936, mse=1.3933, time=0.0412\n",
      "Iter=1600, loss=1.3961, mse=1.3958, time=0.0411\n",
      "Iter=1800, loss=1.3860, mse=1.3857, time=0.0411\n",
      "Iter=2000, loss=1.3840, mse=1.3837, time=0.0410\n",
      "Iter=2200, loss=1.3825, mse=1.3822, time=0.0409\n",
      "Iter=2400, loss=1.3767, mse=1.3764, time=0.0410\n",
      "Iter=2600, loss=1.3582, mse=1.3578, time=0.0409\n",
      "Iter=2800, loss=1.3960, mse=1.3957, time=0.0409\n",
      "Iter=3000, loss=1.3545, mse=1.3542, time=0.0409\n",
      "Iter=3200, loss=1.3893, mse=1.3890, time=0.0409\n",
      "Iter=3400, loss=1.4159, mse=1.4155, time=0.0408\n",
      "Iter=3600, loss=1.3922, mse=1.3918, time=0.0408\n",
      "Iter=3800, loss=1.4026, mse=1.4022, time=0.0407\n",
      "Iter=4000, loss=1.3671, mse=1.3668, time=0.0407\n",
      "Iter=4200, loss=1.3547, mse=1.3544, time=0.0407\n",
      "Iter=4400, loss=1.4243, mse=1.4240, time=0.0407\n",
      "Iter=4600, loss=1.3922, mse=1.3919, time=0.0407\n",
      "Iter=4800, loss=1.4029, mse=1.4026, time=0.0407\n",
      "Iter=5000, loss=1.3815, mse=1.3812, time=0.0407\n",
      "Iter=5200, loss=1.3884, mse=1.3881, time=0.0407\n",
      "Iter=5400, loss=1.3877, mse=1.3874, time=0.0407\n",
      "Iter=5600, loss=1.4119, mse=1.4116, time=0.0407\n",
      "Iter=5800, loss=1.3705, mse=1.3702, time=0.0407\n",
      "Iter=6000, loss=1.3726, mse=1.3723, time=0.0407\n",
      "Iter=6200, loss=1.4116, mse=1.4112, time=0.0407\n",
      "Iter=6400, loss=1.3827, mse=1.3824, time=0.0407\n",
      "Iter=6600, loss=1.3828, mse=1.3826, time=0.0407\n",
      "=== Epoch 27, train loss 1.386776, test rmse 1.164348 ===\n",
      "Epoch 28\n",
      "Iter=200, loss=1.3829, mse=1.3826, time=0.0413\n",
      "Iter=400, loss=1.4197, mse=1.4194, time=0.0411\n",
      "Iter=600, loss=1.3660, mse=1.3656, time=0.0410\n",
      "Iter=800, loss=1.4218, mse=1.4215, time=0.0409\n",
      "Iter=1000, loss=1.4094, mse=1.4091, time=0.0407\n",
      "Iter=1200, loss=1.3605, mse=1.3602, time=0.0406\n",
      "Iter=1400, loss=1.3563, mse=1.3561, time=0.0407\n",
      "Iter=1600, loss=1.3536, mse=1.3534, time=0.0407\n",
      "Iter=1800, loss=1.3889, mse=1.3887, time=0.0407\n",
      "Iter=2000, loss=1.3997, mse=1.3994, time=0.0407\n",
      "Iter=2200, loss=1.3906, mse=1.3903, time=0.0408\n",
      "Iter=2400, loss=1.3705, mse=1.3702, time=0.0407\n",
      "Iter=2600, loss=1.3738, mse=1.3735, time=0.0407\n",
      "Iter=2800, loss=1.4277, mse=1.4274, time=0.0405\n",
      "Iter=3000, loss=1.3899, mse=1.3897, time=0.0405\n",
      "Iter=3200, loss=1.3944, mse=1.3942, time=0.0404\n",
      "Iter=3400, loss=1.3931, mse=1.3928, time=0.0404\n",
      "Iter=3600, loss=1.3671, mse=1.3668, time=0.0404\n",
      "Iter=3800, loss=1.3919, mse=1.3916, time=0.0405\n",
      "Iter=4000, loss=1.4111, mse=1.4108, time=0.0405\n",
      "Iter=4200, loss=1.4124, mse=1.4121, time=0.0406\n",
      "Iter=4400, loss=1.3472, mse=1.3469, time=0.0406\n",
      "Iter=4600, loss=1.3901, mse=1.3897, time=0.0406\n",
      "Iter=4800, loss=1.4133, mse=1.4130, time=0.0406\n",
      "Iter=5000, loss=1.4053, mse=1.4049, time=0.0406\n",
      "Iter=5200, loss=1.3901, mse=1.3898, time=0.0406\n",
      "Iter=5400, loss=1.3646, mse=1.3642, time=0.0406\n",
      "Iter=5600, loss=1.3927, mse=1.3924, time=0.0406\n",
      "Iter=5800, loss=1.3726, mse=1.3722, time=0.0406\n",
      "Iter=6000, loss=1.3577, mse=1.3574, time=0.0406\n",
      "Iter=6200, loss=1.4092, mse=1.4089, time=0.0406\n",
      "Iter=6400, loss=1.3700, mse=1.3696, time=0.0406\n",
      "Iter=6600, loss=1.3625, mse=1.3622, time=0.0406\n",
      "=== Epoch 28, train loss 1.386913, test rmse 1.169290 ===\n",
      "Epoch 29\n",
      "Iter=200, loss=1.4057, mse=1.4053, time=0.0420\n",
      "Iter=400, loss=1.3931, mse=1.3928, time=0.0409\n",
      "Iter=600, loss=1.3838, mse=1.3835, time=0.0408\n",
      "Iter=800, loss=1.3955, mse=1.3951, time=0.0407\n",
      "Iter=1000, loss=1.3722, mse=1.3719, time=0.0406\n",
      "Iter=1200, loss=1.3881, mse=1.3877, time=0.0406\n",
      "Iter=1400, loss=1.4030, mse=1.4026, time=0.0405\n",
      "Iter=1600, loss=1.3864, mse=1.3860, time=0.0404\n",
      "Iter=1800, loss=1.3949, mse=1.3946, time=0.0404\n",
      "Iter=2000, loss=1.4087, mse=1.4083, time=0.0403\n",
      "Iter=2200, loss=1.4067, mse=1.4064, time=0.0402\n",
      "Iter=2400, loss=1.3871, mse=1.3867, time=0.0403\n",
      "Iter=2600, loss=1.3922, mse=1.3919, time=0.0403\n",
      "Iter=2800, loss=1.4070, mse=1.4067, time=0.0403\n",
      "Iter=3000, loss=1.3808, mse=1.3804, time=0.0404\n",
      "Iter=3200, loss=1.3979, mse=1.3975, time=0.0405\n",
      "Iter=3400, loss=1.3745, mse=1.3742, time=0.0405\n",
      "Iter=3600, loss=1.3790, mse=1.3787, time=0.0405\n",
      "Iter=3800, loss=1.3696, mse=1.3693, time=0.0406\n",
      "Iter=4000, loss=1.3590, mse=1.3587, time=0.0406\n",
      "Iter=4200, loss=1.3878, mse=1.3875, time=0.0406\n",
      "Iter=4400, loss=1.4104, mse=1.4101, time=0.0406\n",
      "Iter=4600, loss=1.4079, mse=1.4076, time=0.0406\n",
      "Iter=4800, loss=1.3897, mse=1.3894, time=0.0406\n",
      "Iter=5000, loss=1.3736, mse=1.3733, time=0.0406\n",
      "Iter=5200, loss=1.3573, mse=1.3570, time=0.0406\n",
      "Iter=5400, loss=1.4290, mse=1.4287, time=0.0406\n",
      "Iter=5600, loss=1.3732, mse=1.3728, time=0.0406\n",
      "Iter=5800, loss=1.4011, mse=1.4008, time=0.0406\n",
      "Iter=6000, loss=1.3908, mse=1.3905, time=0.0406\n",
      "Iter=6200, loss=1.3797, mse=1.3794, time=0.0406\n",
      "Iter=6400, loss=1.4116, mse=1.4112, time=0.0406\n",
      "Iter=6600, loss=1.3772, mse=1.3768, time=0.0406\n",
      "=== Epoch 29, train loss 1.388984, test rmse 1.164896 ===\n",
      "Epoch 30\n",
      "Iter=200, loss=1.3877, mse=1.3874, time=0.0417\n",
      "Iter=400, loss=1.3505, mse=1.3502, time=0.0415\n",
      "Iter=600, loss=1.3993, mse=1.3990, time=0.0413\n",
      "Iter=800, loss=1.3801, mse=1.3798, time=0.0407\n",
      "Iter=1000, loss=1.3711, mse=1.3707, time=0.0404\n",
      "Iter=1200, loss=1.3885, mse=1.3881, time=0.0400\n",
      "Iter=1400, loss=1.4215, mse=1.4212, time=0.0400\n",
      "Iter=1600, loss=1.3692, mse=1.3689, time=0.0401\n",
      "Iter=1800, loss=1.3927, mse=1.3924, time=0.0402\n",
      "Iter=2000, loss=1.3714, mse=1.3711, time=0.0402\n",
      "Iter=2200, loss=1.4009, mse=1.4006, time=0.0403\n",
      "Iter=2400, loss=1.4000, mse=1.3997, time=0.0404\n",
      "Iter=2600, loss=1.3975, mse=1.3972, time=0.0404\n",
      "Iter=2800, loss=1.4231, mse=1.4227, time=0.0405\n",
      "Iter=3000, loss=1.3675, mse=1.3672, time=0.0406\n",
      "Iter=3200, loss=1.3787, mse=1.3784, time=0.0406\n",
      "Iter=3400, loss=1.4143, mse=1.4139, time=0.0405\n",
      "Iter=3600, loss=1.3444, mse=1.3440, time=0.0406\n",
      "Iter=3800, loss=1.3811, mse=1.3807, time=0.0406\n",
      "Iter=4000, loss=1.3571, mse=1.3568, time=0.0406\n",
      "Iter=4200, loss=1.4053, mse=1.4050, time=0.0406\n",
      "Iter=4400, loss=1.3706, mse=1.3702, time=0.0406\n",
      "Iter=4600, loss=1.3978, mse=1.3975, time=0.0405\n",
      "Iter=4800, loss=1.4119, mse=1.4116, time=0.0406\n",
      "Iter=5000, loss=1.3913, mse=1.3910, time=0.0405\n",
      "Iter=5200, loss=1.3947, mse=1.3943, time=0.0406\n",
      "Iter=5400, loss=1.3818, mse=1.3815, time=0.0406\n",
      "Iter=5600, loss=1.3741, mse=1.3737, time=0.0406\n",
      "Iter=5800, loss=1.3783, mse=1.3780, time=0.0406\n",
      "Iter=6000, loss=1.4420, mse=1.4417, time=0.0406\n",
      "Iter=6200, loss=1.3510, mse=1.3507, time=0.0406\n",
      "Iter=6400, loss=1.4068, mse=1.4065, time=0.0406\n",
      "Iter=6600, loss=1.3937, mse=1.3934, time=0.0406\n",
      "=== Epoch 30, train loss 1.387963, test rmse 1.161992 ===\n",
      "Epoch 31\n",
      "Iter=200, loss=1.4012, mse=1.4008, time=0.0412\n",
      "Iter=400, loss=1.4191, mse=1.4187, time=0.0408\n",
      "Iter=600, loss=1.3648, mse=1.3644, time=0.0409\n",
      "Iter=800, loss=1.3820, mse=1.3816, time=0.0407\n",
      "Iter=1000, loss=1.4129, mse=1.4125, time=0.0407\n",
      "Iter=1200, loss=1.4105, mse=1.4102, time=0.0409\n",
      "Iter=1400, loss=1.3538, mse=1.3534, time=0.0408\n",
      "Iter=1600, loss=1.3809, mse=1.3806, time=0.0408\n",
      "Iter=1800, loss=1.4153, mse=1.4150, time=0.0408\n",
      "Iter=2000, loss=1.3778, mse=1.3774, time=0.0409\n",
      "Iter=2200, loss=1.3642, mse=1.3638, time=0.0408\n",
      "Iter=2400, loss=1.4004, mse=1.4001, time=0.0408\n",
      "Iter=2600, loss=1.4229, mse=1.4226, time=0.0409\n",
      "Iter=2800, loss=1.3868, mse=1.3864, time=0.0409\n",
      "Iter=3000, loss=1.3477, mse=1.3474, time=0.0409\n",
      "Iter=3200, loss=1.3872, mse=1.3869, time=0.0408\n",
      "Iter=3400, loss=1.3963, mse=1.3960, time=0.0408\n",
      "Iter=3600, loss=1.3843, mse=1.3840, time=0.0409\n",
      "Iter=3800, loss=1.3946, mse=1.3943, time=0.0409\n",
      "Iter=4000, loss=1.3817, mse=1.3814, time=0.0408\n",
      "Iter=4200, loss=1.4007, mse=1.4004, time=0.0408\n",
      "Iter=4400, loss=1.4072, mse=1.4068, time=0.0408\n",
      "Iter=4600, loss=1.4228, mse=1.4225, time=0.0408\n",
      "Iter=4800, loss=1.4126, mse=1.4123, time=0.0408\n",
      "Iter=5000, loss=1.3749, mse=1.3745, time=0.0408\n",
      "Iter=5200, loss=1.3847, mse=1.3844, time=0.0408\n",
      "Iter=5400, loss=1.3550, mse=1.3547, time=0.0408\n",
      "Iter=5600, loss=1.3401, mse=1.3398, time=0.0408\n",
      "Iter=5800, loss=1.3658, mse=1.3654, time=0.0408\n",
      "Iter=6000, loss=1.3966, mse=1.3963, time=0.0408\n",
      "Iter=6200, loss=1.3716, mse=1.3713, time=0.0408\n",
      "Iter=6400, loss=1.3828, mse=1.3825, time=0.0408\n",
      "Iter=6600, loss=1.3883, mse=1.3880, time=0.0408\n",
      "=== Epoch 31, train loss 1.387786, test rmse 1.165469 ===\n",
      "Epoch 32\n",
      "Iter=200, loss=1.3991, mse=1.3988, time=0.0401\n",
      "Iter=400, loss=1.3587, mse=1.3583, time=0.0392\n",
      "Iter=600, loss=1.3521, mse=1.3518, time=0.0390\n",
      "Iter=800, loss=1.3770, mse=1.3766, time=0.0389\n",
      "Iter=1000, loss=1.4182, mse=1.4179, time=0.0390\n",
      "Iter=1200, loss=1.3652, mse=1.3648, time=0.0394\n",
      "Iter=1400, loss=1.4056, mse=1.4052, time=0.0395\n",
      "Iter=1600, loss=1.3948, mse=1.3944, time=0.0397\n",
      "Iter=1800, loss=1.3877, mse=1.3874, time=0.0399\n",
      "Iter=2000, loss=1.3829, mse=1.3826, time=0.0399\n",
      "Iter=2200, loss=1.3929, mse=1.3925, time=0.0400\n",
      "Iter=2400, loss=1.3926, mse=1.3923, time=0.0401\n",
      "Iter=2600, loss=1.4073, mse=1.4070, time=0.0402\n",
      "Iter=2800, loss=1.4060, mse=1.4057, time=0.0402\n",
      "Iter=3000, loss=1.4014, mse=1.4010, time=0.0403\n",
      "Iter=3200, loss=1.3601, mse=1.3598, time=0.0402\n",
      "Iter=3400, loss=1.4039, mse=1.4036, time=0.0403\n",
      "Iter=3600, loss=1.3694, mse=1.3691, time=0.0403\n",
      "Iter=3800, loss=1.3773, mse=1.3770, time=0.0403\n",
      "Iter=4000, loss=1.4012, mse=1.4008, time=0.0403\n",
      "Iter=4200, loss=1.3753, mse=1.3749, time=0.0403\n",
      "Iter=4400, loss=1.3815, mse=1.3811, time=0.0403\n",
      "Iter=4600, loss=1.4001, mse=1.3998, time=0.0403\n",
      "Iter=4800, loss=1.3821, mse=1.3818, time=0.0403\n",
      "Iter=5000, loss=1.3809, mse=1.3806, time=0.0404\n",
      "Iter=5200, loss=1.4036, mse=1.4033, time=0.0404\n",
      "Iter=5400, loss=1.3627, mse=1.3624, time=0.0404\n",
      "Iter=5600, loss=1.3716, mse=1.3713, time=0.0404\n",
      "Iter=5800, loss=1.4147, mse=1.4144, time=0.0404\n",
      "Iter=6000, loss=1.3889, mse=1.3886, time=0.0404\n",
      "Iter=6200, loss=1.4294, mse=1.4291, time=0.0404\n",
      "Iter=6400, loss=1.3594, mse=1.3591, time=0.0404\n",
      "Iter=6600, loss=1.3926, mse=1.3923, time=0.0404\n",
      "=== Epoch 32, train loss 1.387842, test rmse 1.168886 ===\n",
      "Epoch 33\n",
      "Iter=200, loss=1.4185, mse=1.4182, time=0.0421\n",
      "Iter=400, loss=1.4053, mse=1.4050, time=0.0413\n",
      "Iter=600, loss=1.3505, mse=1.3502, time=0.0411\n",
      "Iter=800, loss=1.3938, mse=1.3935, time=0.0410\n",
      "Iter=1000, loss=1.3840, mse=1.3837, time=0.0411\n",
      "Iter=1200, loss=1.4235, mse=1.4232, time=0.0410\n",
      "Iter=1400, loss=1.3580, mse=1.3577, time=0.0410\n",
      "Iter=1600, loss=1.3738, mse=1.3735, time=0.0411\n",
      "Iter=1800, loss=1.3783, mse=1.3780, time=0.0410\n",
      "Iter=2000, loss=1.4067, mse=1.4064, time=0.0410\n",
      "Iter=2200, loss=1.3753, mse=1.3750, time=0.0410\n",
      "Iter=2400, loss=1.4070, mse=1.4067, time=0.0410\n",
      "Iter=2600, loss=1.3730, mse=1.3727, time=0.0409\n",
      "Iter=2800, loss=1.3802, mse=1.3799, time=0.0409\n",
      "Iter=3000, loss=1.4011, mse=1.4008, time=0.0409\n",
      "Iter=3200, loss=1.4124, mse=1.4121, time=0.0409\n",
      "Iter=3400, loss=1.3939, mse=1.3936, time=0.0409\n",
      "Iter=3600, loss=1.4301, mse=1.4298, time=0.0409\n",
      "Iter=3800, loss=1.3715, mse=1.3712, time=0.0410\n",
      "Iter=4000, loss=1.3631, mse=1.3628, time=0.0409\n",
      "Iter=4200, loss=1.3772, mse=1.3769, time=0.0409\n",
      "Iter=4400, loss=1.3727, mse=1.3723, time=0.0409\n",
      "Iter=4600, loss=1.4007, mse=1.4004, time=0.0409\n",
      "Iter=4800, loss=1.3951, mse=1.3947, time=0.0409\n",
      "Iter=5000, loss=1.3744, mse=1.3741, time=0.0409\n",
      "Iter=5200, loss=1.4549, mse=1.4546, time=0.0409\n",
      "Iter=5400, loss=1.3772, mse=1.3769, time=0.0409\n",
      "Iter=5600, loss=1.3706, mse=1.3702, time=0.0409\n",
      "Iter=5800, loss=1.3818, mse=1.3815, time=0.0408\n",
      "Iter=6000, loss=1.3786, mse=1.3783, time=0.0408\n",
      "Iter=6200, loss=1.3835, mse=1.3832, time=0.0408\n",
      "Iter=6400, loss=1.3545, mse=1.3542, time=0.0408\n",
      "Iter=6600, loss=1.4025, mse=1.4022, time=0.0408\n",
      "=== Epoch 33, train loss 1.388302, test rmse 1.166135 ===\n",
      "Epoch 34\n",
      "Iter=200, loss=1.3620, mse=1.3617, time=0.0412\n",
      "Iter=400, loss=1.3675, mse=1.3671, time=0.0410\n",
      "Iter=600, loss=1.3831, mse=1.3827, time=0.0411\n",
      "Iter=800, loss=1.3672, mse=1.3669, time=0.0410\n",
      "Iter=1000, loss=1.4054, mse=1.4051, time=0.0408\n",
      "Iter=1200, loss=1.3881, mse=1.3878, time=0.0408\n",
      "Iter=1400, loss=1.4066, mse=1.4063, time=0.0408\n",
      "Iter=1600, loss=1.3970, mse=1.3967, time=0.0407\n",
      "Iter=1800, loss=1.3991, mse=1.3988, time=0.0408\n",
      "Iter=2000, loss=1.3788, mse=1.3785, time=0.0407\n",
      "Iter=2200, loss=1.3470, mse=1.3467, time=0.0407\n",
      "Iter=2400, loss=1.4183, mse=1.4180, time=0.0407\n",
      "Iter=2600, loss=1.4263, mse=1.4260, time=0.0407\n",
      "Iter=2800, loss=1.4128, mse=1.4124, time=0.0407\n",
      "Iter=3000, loss=1.3967, mse=1.3964, time=0.0407\n",
      "Iter=3200, loss=1.3967, mse=1.3963, time=0.0407\n",
      "Iter=3400, loss=1.3452, mse=1.3448, time=0.0407\n",
      "Iter=3600, loss=1.4248, mse=1.4245, time=0.0407\n",
      "Iter=3800, loss=1.3872, mse=1.3869, time=0.0407\n",
      "Iter=4000, loss=1.3907, mse=1.3904, time=0.0407\n",
      "Iter=4200, loss=1.3922, mse=1.3919, time=0.0407\n",
      "Iter=4400, loss=1.3261, mse=1.3259, time=0.0407\n",
      "Iter=4600, loss=1.3985, mse=1.3982, time=0.0407\n",
      "Iter=4800, loss=1.3971, mse=1.3968, time=0.0407\n",
      "Iter=5000, loss=1.3926, mse=1.3923, time=0.0407\n",
      "Iter=5200, loss=1.4013, mse=1.4010, time=0.0407\n",
      "Iter=5400, loss=1.3822, mse=1.3819, time=0.0406\n",
      "Iter=5600, loss=1.3705, mse=1.3702, time=0.0406\n",
      "Iter=5800, loss=1.4041, mse=1.4039, time=0.0406\n",
      "Iter=6000, loss=1.3723, mse=1.3720, time=0.0407\n",
      "Iter=6200, loss=1.3745, mse=1.3742, time=0.0406\n",
      "Iter=6400, loss=1.3714, mse=1.3711, time=0.0405\n",
      "Iter=6600, loss=1.3944, mse=1.3941, time=0.0405\n",
      "=== Epoch 34, train loss 1.386816, test rmse 1.167668 ===\n",
      "Epoch 35\n",
      "Iter=200, loss=1.3438, mse=1.3435, time=0.0422\n",
      "Iter=400, loss=1.3828, mse=1.3825, time=0.0413\n",
      "Iter=600, loss=1.3765, mse=1.3762, time=0.0409\n",
      "Iter=800, loss=1.4099, mse=1.4095, time=0.0409\n",
      "Iter=1000, loss=1.3801, mse=1.3798, time=0.0409\n",
      "Iter=1200, loss=1.3998, mse=1.3994, time=0.0409\n",
      "Iter=1400, loss=1.3751, mse=1.3748, time=0.0408\n",
      "Iter=1600, loss=1.3977, mse=1.3974, time=0.0408\n",
      "Iter=1800, loss=1.3548, mse=1.3545, time=0.0408\n",
      "Iter=2000, loss=1.3834, mse=1.3831, time=0.0408\n",
      "Iter=2200, loss=1.3941, mse=1.3938, time=0.0408\n",
      "Iter=2400, loss=1.3885, mse=1.3881, time=0.0409\n",
      "Iter=2600, loss=1.3976, mse=1.3973, time=0.0409\n",
      "Iter=2800, loss=1.4110, mse=1.4106, time=0.0409\n",
      "Iter=3000, loss=1.4520, mse=1.4517, time=0.0409\n",
      "Iter=3200, loss=1.3903, mse=1.3900, time=0.0409\n",
      "Iter=3400, loss=1.3920, mse=1.3917, time=0.0409\n",
      "Iter=3600, loss=1.4106, mse=1.4103, time=0.0408\n",
      "Iter=3800, loss=1.3592, mse=1.3589, time=0.0408\n",
      "Iter=4000, loss=1.3752, mse=1.3749, time=0.0408\n",
      "Iter=4200, loss=1.3663, mse=1.3660, time=0.0409\n",
      "Iter=4400, loss=1.3830, mse=1.3827, time=0.0410\n",
      "Iter=4600, loss=1.4467, mse=1.4465, time=0.0410\n",
      "Iter=4800, loss=1.3999, mse=1.3996, time=0.0410\n",
      "Iter=5000, loss=1.3822, mse=1.3819, time=0.0410\n",
      "Iter=5200, loss=1.3711, mse=1.3708, time=0.0409\n",
      "Iter=5400, loss=1.3692, mse=1.3689, time=0.0408\n",
      "Iter=5600, loss=1.3932, mse=1.3929, time=0.0408\n",
      "Iter=5800, loss=1.3578, mse=1.3575, time=0.0408\n",
      "Iter=6000, loss=1.3700, mse=1.3697, time=0.0408\n",
      "Iter=6200, loss=1.4004, mse=1.4001, time=0.0408\n",
      "Iter=6400, loss=1.4145, mse=1.4142, time=0.0408\n",
      "Iter=6600, loss=1.4047, mse=1.4044, time=0.0408\n",
      "=== Epoch 35, train loss 1.388913, test rmse 1.167388 ===\n",
      "Epoch 36\n",
      "Iter=200, loss=1.3734, mse=1.3731, time=0.0421\n",
      "Iter=400, loss=1.3984, mse=1.3981, time=0.0414\n",
      "Iter=600, loss=1.3884, mse=1.3880, time=0.0412\n",
      "Iter=800, loss=1.3735, mse=1.3732, time=0.0410\n",
      "Iter=1000, loss=1.3937, mse=1.3935, time=0.0409\n",
      "Iter=1200, loss=1.4098, mse=1.4095, time=0.0409\n",
      "Iter=1400, loss=1.3923, mse=1.3920, time=0.0409\n",
      "Iter=1600, loss=1.3909, mse=1.3906, time=0.0408\n",
      "Iter=1800, loss=1.3794, mse=1.3791, time=0.0409\n",
      "Iter=2000, loss=1.4019, mse=1.4016, time=0.0409\n",
      "Iter=2200, loss=1.3606, mse=1.3603, time=0.0408\n",
      "Iter=2400, loss=1.3806, mse=1.3803, time=0.0408\n",
      "Iter=2600, loss=1.3498, mse=1.3494, time=0.0407\n",
      "Iter=2800, loss=1.4234, mse=1.4231, time=0.0407\n",
      "Iter=3000, loss=1.3866, mse=1.3863, time=0.0407\n",
      "Iter=3200, loss=1.3628, mse=1.3625, time=0.0407\n",
      "Iter=3400, loss=1.3876, mse=1.3873, time=0.0407\n",
      "Iter=3600, loss=1.3686, mse=1.3683, time=0.0407\n",
      "Iter=3800, loss=1.4280, mse=1.4277, time=0.0407\n",
      "Iter=4000, loss=1.3939, mse=1.3936, time=0.0407\n",
      "Iter=4200, loss=1.3900, mse=1.3897, time=0.0406\n",
      "Iter=4400, loss=1.3873, mse=1.3870, time=0.0406\n",
      "Iter=4600, loss=1.4003, mse=1.4000, time=0.0405\n",
      "Iter=4800, loss=1.3506, mse=1.3503, time=0.0405\n",
      "Iter=5000, loss=1.4262, mse=1.4259, time=0.0406\n",
      "Iter=5200, loss=1.3805, mse=1.3802, time=0.0405\n",
      "Iter=5400, loss=1.3992, mse=1.3989, time=0.0406\n",
      "Iter=5600, loss=1.4023, mse=1.4020, time=0.0406\n",
      "Iter=5800, loss=1.4149, mse=1.4145, time=0.0406\n",
      "Iter=6000, loss=1.3908, mse=1.3905, time=0.0406\n",
      "Iter=6200, loss=1.3988, mse=1.3985, time=0.0406\n",
      "Iter=6400, loss=1.3882, mse=1.3879, time=0.0406\n",
      "Iter=6600, loss=1.3646, mse=1.3643, time=0.0406\n",
      "=== Epoch 36, train loss 1.388244, test rmse 1.168025 ===\n",
      "Epoch 37\n",
      "Iter=200, loss=1.3665, mse=1.3662, time=0.0416\n",
      "Iter=400, loss=1.3999, mse=1.3996, time=0.0414\n",
      "Iter=600, loss=1.4153, mse=1.4150, time=0.0411\n",
      "Iter=800, loss=1.3718, mse=1.3715, time=0.0415\n",
      "Iter=1000, loss=1.4024, mse=1.4022, time=0.0413\n",
      "Iter=1200, loss=1.3716, mse=1.3713, time=0.0412\n",
      "Iter=1400, loss=1.4516, mse=1.4513, time=0.0411\n",
      "Iter=1600, loss=1.3946, mse=1.3943, time=0.0410\n",
      "Iter=1800, loss=1.3420, mse=1.3417, time=0.0410\n",
      "Iter=2000, loss=1.3623, mse=1.3620, time=0.0409\n",
      "Iter=2200, loss=1.3959, mse=1.3956, time=0.0409\n",
      "Iter=2400, loss=1.3828, mse=1.3825, time=0.0409\n",
      "Iter=2600, loss=1.3718, mse=1.3715, time=0.0408\n",
      "Iter=2800, loss=1.4046, mse=1.4043, time=0.0408\n",
      "Iter=3000, loss=1.3885, mse=1.3882, time=0.0408\n",
      "Iter=3200, loss=1.3955, mse=1.3952, time=0.0407\n",
      "Iter=3400, loss=1.4067, mse=1.4063, time=0.0407\n",
      "Iter=3600, loss=1.4128, mse=1.4125, time=0.0405\n",
      "Iter=3800, loss=1.3602, mse=1.3599, time=0.0405\n",
      "Iter=4000, loss=1.3986, mse=1.3983, time=0.0405\n",
      "Iter=4200, loss=1.3406, mse=1.3403, time=0.0405\n",
      "Iter=4400, loss=1.3822, mse=1.3819, time=0.0406\n",
      "Iter=4600, loss=1.3984, mse=1.3981, time=0.0406\n",
      "Iter=4800, loss=1.4093, mse=1.4090, time=0.0406\n",
      "Iter=5000, loss=1.3947, mse=1.3944, time=0.0406\n",
      "Iter=5200, loss=1.3828, mse=1.3825, time=0.0406\n",
      "Iter=5400, loss=1.3872, mse=1.3869, time=0.0406\n",
      "Iter=5600, loss=1.3908, mse=1.3905, time=0.0406\n",
      "Iter=5800, loss=1.3821, mse=1.3818, time=0.0406\n",
      "Iter=6000, loss=1.3938, mse=1.3935, time=0.0406\n",
      "Iter=6200, loss=1.4017, mse=1.4014, time=0.0406\n",
      "Iter=6400, loss=1.3979, mse=1.3976, time=0.0406\n",
      "Iter=6600, loss=1.3822, mse=1.3819, time=0.0406\n",
      "=== Epoch 37, train loss 1.389375, test rmse 1.164503 ===\n",
      "Epoch 38\n",
      "Iter=200, loss=1.4085, mse=1.4082, time=0.0425\n",
      "Iter=400, loss=1.3764, mse=1.3761, time=0.0411\n",
      "Iter=600, loss=1.3827, mse=1.3824, time=0.0410\n",
      "Iter=800, loss=1.3792, mse=1.3789, time=0.0410\n",
      "Iter=1000, loss=1.3934, mse=1.3931, time=0.0408\n",
      "Iter=1200, loss=1.4058, mse=1.4055, time=0.0410\n",
      "Iter=1400, loss=1.3732, mse=1.3729, time=0.0409\n",
      "Iter=1600, loss=1.3875, mse=1.3872, time=0.0409\n",
      "Iter=1800, loss=1.3915, mse=1.3912, time=0.0408\n",
      "Iter=2000, loss=1.3903, mse=1.3900, time=0.0408\n",
      "Iter=2200, loss=1.3982, mse=1.3979, time=0.0408\n",
      "Iter=2400, loss=1.4059, mse=1.4056, time=0.0407\n",
      "Iter=2600, loss=1.3735, mse=1.3732, time=0.0406\n",
      "Iter=2800, loss=1.3724, mse=1.3721, time=0.0406\n",
      "Iter=3000, loss=1.4130, mse=1.4127, time=0.0406\n",
      "Iter=3200, loss=1.3905, mse=1.3902, time=0.0406\n",
      "Iter=3400, loss=1.3938, mse=1.3935, time=0.0406\n",
      "Iter=3600, loss=1.3920, mse=1.3917, time=0.0406\n",
      "Iter=3800, loss=1.4278, mse=1.4275, time=0.0406\n",
      "Iter=4000, loss=1.4190, mse=1.4186, time=0.0406\n",
      "Iter=4200, loss=1.3573, mse=1.3570, time=0.0407\n",
      "Iter=4400, loss=1.3799, mse=1.3796, time=0.0407\n",
      "Iter=4600, loss=1.3707, mse=1.3704, time=0.0407\n",
      "Iter=4800, loss=1.3780, mse=1.3777, time=0.0407\n",
      "Iter=5000, loss=1.3753, mse=1.3750, time=0.0407\n",
      "Iter=5200, loss=1.3845, mse=1.3842, time=0.0406\n",
      "Iter=5400, loss=1.4075, mse=1.4072, time=0.0407\n",
      "Iter=5600, loss=1.3922, mse=1.3919, time=0.0406\n",
      "Iter=5800, loss=1.3979, mse=1.3976, time=0.0407\n",
      "Iter=6000, loss=1.3885, mse=1.3882, time=0.0407\n",
      "Iter=6200, loss=1.3903, mse=1.3900, time=0.0407\n",
      "Iter=6400, loss=1.3551, mse=1.3548, time=0.0407\n",
      "Iter=6600, loss=1.3598, mse=1.3596, time=0.0406\n",
      "=== Epoch 38, train loss 1.387352, test rmse 1.166078 ===\n",
      "Epoch 39\n",
      "Iter=200, loss=1.3670, mse=1.3667, time=0.0413\n",
      "Iter=400, loss=1.3983, mse=1.3980, time=0.0409\n",
      "Iter=600, loss=1.3749, mse=1.3746, time=0.0408\n",
      "Iter=800, loss=1.3671, mse=1.3668, time=0.0406\n",
      "Iter=1000, loss=1.3937, mse=1.3934, time=0.0405\n",
      "Iter=1200, loss=1.4202, mse=1.4199, time=0.0404\n",
      "Iter=1400, loss=1.3843, mse=1.3840, time=0.0402\n",
      "Iter=1600, loss=1.3775, mse=1.3772, time=0.0400\n",
      "Iter=1800, loss=1.3921, mse=1.3918, time=0.0400\n",
      "Iter=2000, loss=1.3625, mse=1.3622, time=0.0401\n",
      "Iter=2200, loss=1.4170, mse=1.4167, time=0.0402\n",
      "Iter=2400, loss=1.3569, mse=1.3566, time=0.0402\n",
      "Iter=2600, loss=1.3530, mse=1.3527, time=0.0403\n",
      "Iter=2800, loss=1.3913, mse=1.3911, time=0.0404\n",
      "Iter=3000, loss=1.3929, mse=1.3927, time=0.0405\n",
      "Iter=3200, loss=1.3805, mse=1.3803, time=0.0405\n",
      "Iter=3400, loss=1.3839, mse=1.3836, time=0.0406\n",
      "Iter=3600, loss=1.3847, mse=1.3844, time=0.0406\n",
      "Iter=3800, loss=1.3870, mse=1.3867, time=0.0406\n",
      "Iter=4000, loss=1.4023, mse=1.4020, time=0.0406\n",
      "Iter=4200, loss=1.3998, mse=1.3995, time=0.0406\n",
      "Iter=4400, loss=1.4139, mse=1.4136, time=0.0406\n",
      "Iter=4600, loss=1.4268, mse=1.4265, time=0.0406\n",
      "Iter=4800, loss=1.4039, mse=1.4036, time=0.0406\n",
      "Iter=5000, loss=1.4095, mse=1.4092, time=0.0406\n",
      "Iter=5200, loss=1.3884, mse=1.3880, time=0.0406\n",
      "Iter=5400, loss=1.3670, mse=1.3667, time=0.0406\n",
      "Iter=5600, loss=1.3654, mse=1.3651, time=0.0406\n",
      "Iter=5800, loss=1.3470, mse=1.3467, time=0.0406\n",
      "Iter=6000, loss=1.3895, mse=1.3891, time=0.0406\n",
      "Iter=6200, loss=1.3879, mse=1.3876, time=0.0406\n",
      "Iter=6400, loss=1.4119, mse=1.4116, time=0.0406\n",
      "Iter=6600, loss=1.4080, mse=1.4077, time=0.0406\n",
      "=== Epoch 39, train loss 1.389387, test rmse 1.164018 ===\n",
      "Epoch 40\n",
      "Iter=200, loss=1.4257, mse=1.4254, time=0.0422\n",
      "Iter=400, loss=1.3828, mse=1.3824, time=0.0409\n",
      "Iter=600, loss=1.3810, mse=1.3807, time=0.0403\n",
      "Iter=800, loss=1.3920, mse=1.3917, time=0.0399\n",
      "Iter=1000, loss=1.3798, mse=1.3795, time=0.0398\n",
      "Iter=1200, loss=1.4044, mse=1.4041, time=0.0399\n",
      "Iter=1400, loss=1.3686, mse=1.3683, time=0.0400\n",
      "Iter=1600, loss=1.3436, mse=1.3433, time=0.0401\n",
      "Iter=1800, loss=1.4114, mse=1.4112, time=0.0402\n",
      "Iter=2000, loss=1.4185, mse=1.4182, time=0.0403\n",
      "Iter=2200, loss=1.3848, mse=1.3845, time=0.0403\n",
      "Iter=2400, loss=1.3583, mse=1.3580, time=0.0404\n",
      "Iter=2600, loss=1.4090, mse=1.4088, time=0.0405\n",
      "Iter=2800, loss=1.3868, mse=1.3865, time=0.0405\n",
      "Iter=3000, loss=1.3588, mse=1.3585, time=0.0405\n",
      "Iter=3200, loss=1.3606, mse=1.3603, time=0.0405\n",
      "Iter=3400, loss=1.3537, mse=1.3534, time=0.0405\n",
      "Iter=3600, loss=1.4324, mse=1.4321, time=0.0405\n",
      "Iter=3800, loss=1.3966, mse=1.3963, time=0.0405\n",
      "Iter=4000, loss=1.3578, mse=1.3575, time=0.0405\n",
      "Iter=4200, loss=1.3938, mse=1.3935, time=0.0405\n",
      "Iter=4400, loss=1.3830, mse=1.3827, time=0.0405\n",
      "Iter=4600, loss=1.4307, mse=1.4304, time=0.0405\n",
      "Iter=4800, loss=1.4114, mse=1.4111, time=0.0405\n",
      "Iter=5000, loss=1.3759, mse=1.3756, time=0.0405\n",
      "Iter=5200, loss=1.4032, mse=1.4029, time=0.0405\n",
      "Iter=5400, loss=1.3946, mse=1.3943, time=0.0406\n",
      "Iter=5600, loss=1.3533, mse=1.3531, time=0.0406\n",
      "Iter=5800, loss=1.3916, mse=1.3914, time=0.0406\n",
      "Iter=6000, loss=1.3655, mse=1.3652, time=0.0406\n",
      "Iter=6200, loss=1.4020, mse=1.4017, time=0.0406\n",
      "Iter=6400, loss=1.3883, mse=1.3880, time=0.0406\n",
      "Iter=6600, loss=1.4092, mse=1.4089, time=0.0406\n",
      "=== Epoch 40, train loss 1.388251, test rmse 1.166653 ===\n",
      "Epoch 41\n",
      "Iter=200, loss=1.3714, mse=1.3711, time=0.0422\n",
      "Iter=400, loss=1.3973, mse=1.3970, time=0.0415\n",
      "Iter=600, loss=1.4076, mse=1.4073, time=0.0415\n",
      "Iter=800, loss=1.4297, mse=1.4294, time=0.0414\n",
      "Iter=1000, loss=1.4033, mse=1.4030, time=0.0413\n",
      "Iter=1200, loss=1.4054, mse=1.4051, time=0.0412\n",
      "Iter=1400, loss=1.3892, mse=1.3889, time=0.0413\n",
      "Iter=1600, loss=1.3644, mse=1.3641, time=0.0413\n",
      "Iter=1800, loss=1.3712, mse=1.3709, time=0.0412\n",
      "Iter=2000, loss=1.4080, mse=1.4077, time=0.0412\n",
      "Iter=2200, loss=1.3872, mse=1.3869, time=0.0412\n",
      "Iter=2400, loss=1.3771, mse=1.3768, time=0.0411\n",
      "Iter=2600, loss=1.3729, mse=1.3726, time=0.0411\n",
      "Iter=2800, loss=1.3854, mse=1.3851, time=0.0410\n",
      "Iter=3000, loss=1.3723, mse=1.3720, time=0.0410\n",
      "Iter=3200, loss=1.3857, mse=1.3854, time=0.0410\n",
      "Iter=3400, loss=1.3965, mse=1.3962, time=0.0410\n",
      "Iter=3600, loss=1.3512, mse=1.3509, time=0.0412\n",
      "Iter=3800, loss=1.3881, mse=1.3878, time=0.0411\n",
      "Iter=4000, loss=1.3532, mse=1.3529, time=0.0411\n",
      "Iter=4200, loss=1.3696, mse=1.3693, time=0.0411\n",
      "Iter=4400, loss=1.3733, mse=1.3730, time=0.0411\n",
      "Iter=4600, loss=1.3941, mse=1.3938, time=0.0411\n",
      "Iter=4800, loss=1.3718, mse=1.3715, time=0.0411\n",
      "Iter=5000, loss=1.3929, mse=1.3926, time=0.0411\n",
      "Iter=5200, loss=1.3903, mse=1.3900, time=0.0410\n",
      "Iter=5400, loss=1.3851, mse=1.3848, time=0.0410\n",
      "Iter=5600, loss=1.3827, mse=1.3823, time=0.0410\n",
      "Iter=5800, loss=1.4110, mse=1.4107, time=0.0410\n",
      "Iter=6000, loss=1.3960, mse=1.3957, time=0.0410\n",
      "Iter=6200, loss=1.4262, mse=1.4259, time=0.0410\n",
      "Iter=6400, loss=1.3547, mse=1.3544, time=0.0410\n",
      "Iter=6600, loss=1.3895, mse=1.3892, time=0.0410\n",
      "=== Epoch 41, train loss 1.386287, test rmse 1.165340 ===\n",
      "Epoch 42\n",
      "Iter=200, loss=1.3714, mse=1.3711, time=0.0418\n",
      "Iter=400, loss=1.4361, mse=1.4358, time=0.0416\n",
      "Iter=600, loss=1.3586, mse=1.3582, time=0.0412\n",
      "Iter=800, loss=1.3842, mse=1.3839, time=0.0411\n",
      "Iter=1000, loss=1.4235, mse=1.4232, time=0.0411\n",
      "Iter=1200, loss=1.3913, mse=1.3910, time=0.0411\n",
      "Iter=1400, loss=1.4070, mse=1.4067, time=0.0410\n",
      "Iter=1600, loss=1.3726, mse=1.3723, time=0.0409\n",
      "Iter=1800, loss=1.3584, mse=1.3581, time=0.0409\n",
      "Iter=2000, loss=1.4129, mse=1.4126, time=0.0409\n",
      "Iter=2200, loss=1.4039, mse=1.4036, time=0.0409\n",
      "Iter=2400, loss=1.3516, mse=1.3513, time=0.0409\n",
      "Iter=2600, loss=1.3757, mse=1.3754, time=0.0408\n",
      "Iter=2800, loss=1.4230, mse=1.4227, time=0.0408\n",
      "Iter=3000, loss=1.4120, mse=1.4117, time=0.0410\n",
      "Iter=3200, loss=1.3770, mse=1.3767, time=0.0413\n",
      "Iter=3400, loss=1.4070, mse=1.4067, time=0.0414\n",
      "Iter=3600, loss=1.4043, mse=1.4040, time=0.0413\n",
      "Iter=3800, loss=1.3863, mse=1.3860, time=0.0413\n",
      "Iter=4000, loss=1.3730, mse=1.3727, time=0.0413\n",
      "Iter=4200, loss=1.3769, mse=1.3766, time=0.0413\n",
      "Iter=4400, loss=1.3896, mse=1.3893, time=0.0412\n",
      "Iter=4600, loss=1.4016, mse=1.4013, time=0.0412\n",
      "Iter=4800, loss=1.3863, mse=1.3860, time=0.0412\n",
      "Iter=5000, loss=1.3763, mse=1.3760, time=0.0412\n",
      "Iter=5200, loss=1.3637, mse=1.3634, time=0.0412\n",
      "Iter=5400, loss=1.3815, mse=1.3812, time=0.0411\n",
      "Iter=5600, loss=1.3754, mse=1.3751, time=0.0411\n",
      "Iter=5800, loss=1.3808, mse=1.3805, time=0.0411\n",
      "Iter=6000, loss=1.4036, mse=1.4033, time=0.0410\n",
      "Iter=6200, loss=1.3901, mse=1.3898, time=0.0409\n",
      "Iter=6400, loss=1.3588, mse=1.3585, time=0.0409\n",
      "Iter=6600, loss=1.3824, mse=1.3820, time=0.0409\n",
      "=== Epoch 42, train loss 1.388018, test rmse 1.174273 ===\n",
      "Epoch 43\n",
      "Iter=200, loss=1.4149, mse=1.4146, time=0.0416\n",
      "Iter=400, loss=1.4030, mse=1.4027, time=0.0408\n",
      "Iter=600, loss=1.3979, mse=1.3976, time=0.0408\n",
      "Iter=800, loss=1.4061, mse=1.4058, time=0.0408\n",
      "Iter=1000, loss=1.4055, mse=1.4051, time=0.0406\n",
      "Iter=1200, loss=1.4154, mse=1.4151, time=0.0409\n",
      "Iter=1400, loss=1.3701, mse=1.3697, time=0.0408\n",
      "Iter=1600, loss=1.3780, mse=1.3777, time=0.0408\n",
      "Iter=1800, loss=1.4002, mse=1.3998, time=0.0407\n",
      "Iter=2000, loss=1.3845, mse=1.3842, time=0.0407\n",
      "Iter=2200, loss=1.3862, mse=1.3859, time=0.0407\n",
      "Iter=2400, loss=1.3793, mse=1.3790, time=0.0407\n",
      "Iter=2600, loss=1.3528, mse=1.3524, time=0.0406\n",
      "Iter=2800, loss=1.3657, mse=1.3653, time=0.0407\n",
      "Iter=3000, loss=1.3962, mse=1.3958, time=0.0407\n",
      "Iter=3200, loss=1.3726, mse=1.3723, time=0.0407\n",
      "Iter=3400, loss=1.3943, mse=1.3939, time=0.0407\n",
      "Iter=3600, loss=1.3704, mse=1.3700, time=0.0407\n",
      "Iter=3800, loss=1.3540, mse=1.3536, time=0.0407\n",
      "Iter=4000, loss=1.3916, mse=1.3912, time=0.0407\n",
      "Iter=4200, loss=1.3924, mse=1.3920, time=0.0407\n",
      "Iter=4400, loss=1.3723, mse=1.3720, time=0.0406\n",
      "Iter=4600, loss=1.4088, mse=1.4084, time=0.0406\n",
      "Iter=4800, loss=1.3761, mse=1.3758, time=0.0406\n",
      "Iter=5000, loss=1.3886, mse=1.3883, time=0.0406\n",
      "Iter=5200, loss=1.3838, mse=1.3835, time=0.0405\n",
      "Iter=5400, loss=1.3948, mse=1.3945, time=0.0405\n",
      "Iter=5600, loss=1.3868, mse=1.3865, time=0.0405\n",
      "Iter=5800, loss=1.3430, mse=1.3426, time=0.0405\n",
      "Iter=6000, loss=1.4213, mse=1.4209, time=0.0405\n",
      "Iter=6200, loss=1.4041, mse=1.4038, time=0.0405\n",
      "Iter=6400, loss=1.3646, mse=1.3642, time=0.0405\n",
      "Iter=6600, loss=1.4115, mse=1.4112, time=0.0405\n",
      "=== Epoch 43, train loss 1.387266, test rmse 1.166730 ===\n",
      "Epoch 44\n",
      "Iter=200, loss=1.4239, mse=1.4235, time=0.0413\n",
      "Iter=400, loss=1.3755, mse=1.3752, time=0.0413\n",
      "Iter=600, loss=1.4078, mse=1.4075, time=0.0411\n",
      "Iter=800, loss=1.4098, mse=1.4095, time=0.0409\n",
      "Iter=1000, loss=1.3870, mse=1.3867, time=0.0409\n",
      "Iter=1200, loss=1.3780, mse=1.3777, time=0.0408\n",
      "Iter=1400, loss=1.4138, mse=1.4135, time=0.0408\n",
      "Iter=1600, loss=1.3835, mse=1.3832, time=0.0407\n",
      "Iter=1800, loss=1.3798, mse=1.3795, time=0.0408\n",
      "Iter=2000, loss=1.3630, mse=1.3627, time=0.0408\n",
      "Iter=2200, loss=1.3790, mse=1.3787, time=0.0408\n",
      "Iter=2400, loss=1.4035, mse=1.4032, time=0.0408\n",
      "Iter=2600, loss=1.3983, mse=1.3979, time=0.0408\n",
      "Iter=2800, loss=1.3818, mse=1.3815, time=0.0407\n",
      "Iter=3000, loss=1.3888, mse=1.3885, time=0.0407\n",
      "Iter=3200, loss=1.3755, mse=1.3752, time=0.0407\n",
      "Iter=3400, loss=1.3758, mse=1.3755, time=0.0408\n",
      "Iter=3600, loss=1.3706, mse=1.3703, time=0.0408\n",
      "Iter=3800, loss=1.3888, mse=1.3884, time=0.0408\n",
      "Iter=4000, loss=1.4049, mse=1.4045, time=0.0407\n",
      "Iter=4200, loss=1.3921, mse=1.3918, time=0.0406\n",
      "Iter=4400, loss=1.3996, mse=1.3993, time=0.0405\n",
      "Iter=4600, loss=1.3761, mse=1.3758, time=0.0405\n",
      "Iter=4800, loss=1.4107, mse=1.4104, time=0.0405\n",
      "Iter=5000, loss=1.3844, mse=1.3841, time=0.0405\n",
      "Iter=5200, loss=1.3980, mse=1.3977, time=0.0406\n",
      "Iter=5400, loss=1.3817, mse=1.3814, time=0.0406\n",
      "Iter=5600, loss=1.4070, mse=1.4067, time=0.0406\n",
      "Iter=5800, loss=1.3446, mse=1.3443, time=0.0406\n",
      "Iter=6000, loss=1.4099, mse=1.4096, time=0.0406\n",
      "Iter=6200, loss=1.4142, mse=1.4138, time=0.0406\n",
      "Iter=6400, loss=1.3674, mse=1.3671, time=0.0406\n",
      "Iter=6600, loss=1.3730, mse=1.3726, time=0.0406\n",
      "=== Epoch 44, train loss 1.389566, test rmse 1.163687 ===\n",
      "Epoch 45\n",
      "Iter=200, loss=1.4080, mse=1.4077, time=0.0461\n",
      "Iter=400, loss=1.3896, mse=1.3893, time=0.0442\n",
      "Iter=600, loss=1.3537, mse=1.3534, time=0.0436\n",
      "Iter=800, loss=1.4232, mse=1.4229, time=0.0431\n",
      "Iter=1000, loss=1.3888, mse=1.3885, time=0.0425\n",
      "Iter=1200, loss=1.3960, mse=1.3957, time=0.0423\n",
      "Iter=1400, loss=1.3764, mse=1.3761, time=0.0421\n",
      "Iter=1600, loss=1.3642, mse=1.3639, time=0.0420\n",
      "Iter=1800, loss=1.4144, mse=1.4141, time=0.0418\n",
      "Iter=2000, loss=1.3980, mse=1.3977, time=0.0416\n",
      "Iter=2200, loss=1.3827, mse=1.3824, time=0.0416\n",
      "Iter=2400, loss=1.3949, mse=1.3946, time=0.0415\n",
      "Iter=2600, loss=1.3989, mse=1.3986, time=0.0414\n",
      "Iter=2800, loss=1.3829, mse=1.3826, time=0.0413\n",
      "Iter=3000, loss=1.3707, mse=1.3703, time=0.0413\n",
      "Iter=3200, loss=1.3604, mse=1.3601, time=0.0411\n",
      "Iter=3400, loss=1.3667, mse=1.3664, time=0.0411\n",
      "Iter=3600, loss=1.4167, mse=1.4164, time=0.0410\n",
      "Iter=3800, loss=1.3796, mse=1.3793, time=0.0410\n",
      "Iter=4000, loss=1.3967, mse=1.3964, time=0.0410\n",
      "Iter=4200, loss=1.3959, mse=1.3956, time=0.0410\n",
      "Iter=4400, loss=1.3995, mse=1.3992, time=0.0410\n",
      "Iter=4600, loss=1.3910, mse=1.3907, time=0.0410\n",
      "Iter=4800, loss=1.3522, mse=1.3518, time=0.0410\n",
      "Iter=5000, loss=1.3675, mse=1.3671, time=0.0410\n",
      "Iter=5200, loss=1.4160, mse=1.4156, time=0.0410\n",
      "Iter=5400, loss=1.3518, mse=1.3515, time=0.0410\n",
      "Iter=5600, loss=1.4031, mse=1.4027, time=0.0410\n",
      "Iter=5800, loss=1.3752, mse=1.3749, time=0.0410\n",
      "Iter=6000, loss=1.3663, mse=1.3660, time=0.0410\n",
      "Iter=6200, loss=1.4214, mse=1.4211, time=0.0410\n",
      "Iter=6400, loss=1.4085, mse=1.4081, time=0.0410\n",
      "Iter=6600, loss=1.3922, mse=1.3919, time=0.0409\n",
      "=== Epoch 45, train loss 1.388323, test rmse 1.171120 ===\n",
      "Epoch 46\n",
      "Iter=200, loss=1.3985, mse=1.3982, time=0.0420\n",
      "Iter=400, loss=1.3601, mse=1.3598, time=0.0414\n",
      "Iter=600, loss=1.3866, mse=1.3863, time=0.0413\n",
      "Iter=800, loss=1.3899, mse=1.3895, time=0.0411\n",
      "Iter=1000, loss=1.3836, mse=1.3833, time=0.0410\n",
      "Iter=1200, loss=1.3611, mse=1.3608, time=0.0409\n",
      "Iter=1400, loss=1.3764, mse=1.3760, time=0.0409\n",
      "Iter=1600, loss=1.3938, mse=1.3935, time=0.0408\n",
      "Iter=1800, loss=1.4065, mse=1.4061, time=0.0408\n",
      "Iter=2000, loss=1.3863, mse=1.3860, time=0.0408\n",
      "Iter=2200, loss=1.3903, mse=1.3899, time=0.0408\n",
      "Iter=2400, loss=1.3838, mse=1.3835, time=0.0406\n",
      "Iter=2600, loss=1.3848, mse=1.3845, time=0.0406\n",
      "Iter=2800, loss=1.4269, mse=1.4265, time=0.0406\n",
      "Iter=3000, loss=1.3879, mse=1.3876, time=0.0407\n",
      "Iter=3200, loss=1.3769, mse=1.3765, time=0.0407\n",
      "Iter=3400, loss=1.3731, mse=1.3727, time=0.0407\n",
      "Iter=3600, loss=1.3577, mse=1.3574, time=0.0407\n",
      "Iter=3800, loss=1.3945, mse=1.3941, time=0.0407\n",
      "Iter=4000, loss=1.4037, mse=1.4034, time=0.0407\n",
      "Iter=4200, loss=1.3860, mse=1.3856, time=0.0407\n",
      "Iter=4400, loss=1.3776, mse=1.3773, time=0.0407\n",
      "Iter=4600, loss=1.3993, mse=1.3990, time=0.0407\n",
      "Iter=4800, loss=1.4043, mse=1.4039, time=0.0407\n",
      "Iter=5000, loss=1.4368, mse=1.4365, time=0.0407\n",
      "Iter=5200, loss=1.3843, mse=1.3839, time=0.0407\n",
      "Iter=5400, loss=1.3891, mse=1.3887, time=0.0407\n",
      "Iter=5600, loss=1.3994, mse=1.3991, time=0.0407\n",
      "Iter=5800, loss=1.4073, mse=1.4069, time=0.0407\n",
      "Iter=6000, loss=1.3817, mse=1.3814, time=0.0407\n",
      "Iter=6200, loss=1.3613, mse=1.3610, time=0.0408\n",
      "Iter=6400, loss=1.4125, mse=1.4122, time=0.0407\n",
      "Iter=6600, loss=1.3832, mse=1.3829, time=0.0407\n",
      "=== Epoch 46, train loss 1.388210, test rmse 1.164152 ===\n",
      "Epoch 47\n",
      "Iter=200, loss=1.3411, mse=1.3408, time=0.0413\n",
      "Iter=400, loss=1.3677, mse=1.3674, time=0.0412\n",
      "Iter=600, loss=1.3892, mse=1.3889, time=0.0409\n",
      "Iter=800, loss=1.4051, mse=1.4048, time=0.0408\n",
      "Iter=1000, loss=1.3735, mse=1.3732, time=0.0408\n",
      "Iter=1200, loss=1.3778, mse=1.3775, time=0.0406\n",
      "Iter=1400, loss=1.3788, mse=1.3785, time=0.0403\n",
      "Iter=1600, loss=1.3659, mse=1.3656, time=0.0401\n",
      "Iter=1800, loss=1.4096, mse=1.4093, time=0.0403\n",
      "Iter=2000, loss=1.3864, mse=1.3861, time=0.0403\n",
      "Iter=2200, loss=1.3975, mse=1.3972, time=0.0403\n",
      "Iter=2400, loss=1.3834, mse=1.3831, time=0.0405\n",
      "Iter=2600, loss=1.3774, mse=1.3771, time=0.0407\n",
      "Iter=2800, loss=1.3848, mse=1.3845, time=0.0407\n",
      "Iter=3000, loss=1.4114, mse=1.4110, time=0.0408\n",
      "Iter=3200, loss=1.3788, mse=1.3784, time=0.0410\n",
      "Iter=3400, loss=1.3553, mse=1.3550, time=0.0410\n",
      "Iter=3600, loss=1.3944, mse=1.3941, time=0.0410\n",
      "Iter=3800, loss=1.4125, mse=1.4121, time=0.0410\n",
      "Iter=4000, loss=1.3683, mse=1.3679, time=0.0409\n",
      "Iter=4200, loss=1.3694, mse=1.3691, time=0.0409\n",
      "Iter=4400, loss=1.3918, mse=1.3915, time=0.0409\n",
      "Iter=4600, loss=1.4023, mse=1.4020, time=0.0409\n",
      "Iter=4800, loss=1.4050, mse=1.4047, time=0.0409\n",
      "Iter=5000, loss=1.4070, mse=1.4067, time=0.0409\n",
      "Iter=5200, loss=1.4215, mse=1.4212, time=0.0409\n",
      "Iter=5400, loss=1.3879, mse=1.3876, time=0.0409\n",
      "Iter=5600, loss=1.3820, mse=1.3817, time=0.0409\n",
      "Iter=5800, loss=1.3803, mse=1.3800, time=0.0409\n",
      "Iter=6000, loss=1.4278, mse=1.4275, time=0.0409\n",
      "Iter=6200, loss=1.3909, mse=1.3906, time=0.0409\n",
      "Iter=6400, loss=1.3812, mse=1.3809, time=0.0409\n",
      "Iter=6600, loss=1.3945, mse=1.3941, time=0.0408\n",
      "=== Epoch 47, train loss 1.388119, test rmse 1.166285 ===\n",
      "Epoch 48\n",
      "Iter=200, loss=1.3873, mse=1.3870, time=0.0413\n",
      "Iter=400, loss=1.3981, mse=1.3978, time=0.0399\n",
      "Iter=600, loss=1.4106, mse=1.4103, time=0.0397\n",
      "Iter=800, loss=1.3831, mse=1.3828, time=0.0395\n",
      "Iter=1000, loss=1.3853, mse=1.3850, time=0.0396\n",
      "Iter=1200, loss=1.3815, mse=1.3812, time=0.0399\n",
      "Iter=1400, loss=1.3724, mse=1.3721, time=0.0401\n",
      "Iter=1600, loss=1.3940, mse=1.3936, time=0.0402\n",
      "Iter=1800, loss=1.4054, mse=1.4050, time=0.0403\n",
      "Iter=2000, loss=1.3840, mse=1.3837, time=0.0403\n",
      "Iter=2200, loss=1.3801, mse=1.3797, time=0.0404\n",
      "Iter=2400, loss=1.4029, mse=1.4025, time=0.0405\n",
      "Iter=2600, loss=1.3903, mse=1.3900, time=0.0406\n",
      "Iter=2800, loss=1.4141, mse=1.4138, time=0.0406\n",
      "Iter=3000, loss=1.3927, mse=1.3924, time=0.0406\n",
      "Iter=3200, loss=1.3909, mse=1.3906, time=0.0406\n",
      "Iter=3400, loss=1.3919, mse=1.3916, time=0.0406\n",
      "Iter=3600, loss=1.3701, mse=1.3698, time=0.0406\n",
      "Iter=3800, loss=1.3932, mse=1.3928, time=0.0406\n",
      "Iter=4000, loss=1.3880, mse=1.3877, time=0.0406\n",
      "Iter=4200, loss=1.3623, mse=1.3619, time=0.0406\n",
      "Iter=4400, loss=1.4049, mse=1.4045, time=0.0406\n",
      "Iter=4600, loss=1.3684, mse=1.3680, time=0.0407\n",
      "Iter=4800, loss=1.3659, mse=1.3655, time=0.0406\n",
      "Iter=5000, loss=1.3870, mse=1.3867, time=0.0406\n",
      "Iter=5200, loss=1.3671, mse=1.3668, time=0.0407\n",
      "Iter=5400, loss=1.3624, mse=1.3620, time=0.0407\n",
      "Iter=5600, loss=1.3791, mse=1.3788, time=0.0407\n",
      "Iter=5800, loss=1.3596, mse=1.3593, time=0.0407\n",
      "Iter=6000, loss=1.3824, mse=1.3821, time=0.0407\n",
      "Iter=6200, loss=1.3710, mse=1.3706, time=0.0406\n",
      "Iter=6400, loss=1.4051, mse=1.4048, time=0.0406\n",
      "Iter=6600, loss=1.4447, mse=1.4443, time=0.0406\n",
      "=== Epoch 48, train loss 1.387361, test rmse 1.165508 ===\n",
      "Epoch 49\n",
      "Iter=200, loss=1.4082, mse=1.4078, time=0.0422\n",
      "Iter=400, loss=1.3841, mse=1.3837, time=0.0414\n",
      "Iter=600, loss=1.3857, mse=1.3854, time=0.0413\n",
      "Iter=800, loss=1.3856, mse=1.3853, time=0.0411\n",
      "Iter=1000, loss=1.3501, mse=1.3497, time=0.0410\n",
      "Iter=1200, loss=1.3869, mse=1.3866, time=0.0410\n",
      "Iter=1400, loss=1.4101, mse=1.4098, time=0.0411\n",
      "Iter=1600, loss=1.3859, mse=1.3855, time=0.0410\n",
      "Iter=1800, loss=1.3878, mse=1.3875, time=0.0410\n",
      "Iter=2000, loss=1.3797, mse=1.3794, time=0.0410\n",
      "Iter=2200, loss=1.4051, mse=1.4048, time=0.0410\n",
      "Iter=2400, loss=1.3874, mse=1.3871, time=0.0410\n",
      "Iter=2600, loss=1.4083, mse=1.4080, time=0.0409\n",
      "Iter=2800, loss=1.3745, mse=1.3742, time=0.0409\n",
      "Iter=3000, loss=1.3821, mse=1.3818, time=0.0409\n",
      "Iter=3200, loss=1.3979, mse=1.3976, time=0.0409\n",
      "Iter=3400, loss=1.3661, mse=1.3657, time=0.0409\n",
      "Iter=3600, loss=1.3813, mse=1.3810, time=0.0409\n",
      "Iter=3800, loss=1.3939, mse=1.3935, time=0.0409\n",
      "Iter=4000, loss=1.3868, mse=1.3865, time=0.0409\n",
      "Iter=4200, loss=1.3589, mse=1.3586, time=0.0409\n",
      "Iter=4400, loss=1.4319, mse=1.4316, time=0.0409\n",
      "Iter=4600, loss=1.3915, mse=1.3912, time=0.0409\n",
      "Iter=4800, loss=1.4007, mse=1.4003, time=0.0409\n",
      "Iter=5000, loss=1.3870, mse=1.3866, time=0.0409\n",
      "Iter=5200, loss=1.4282, mse=1.4279, time=0.0409\n",
      "Iter=5400, loss=1.3615, mse=1.3612, time=0.0409\n",
      "Iter=5600, loss=1.3773, mse=1.3770, time=0.0409\n",
      "Iter=5800, loss=1.3393, mse=1.3390, time=0.0409\n",
      "Iter=6000, loss=1.3997, mse=1.3994, time=0.0408\n",
      "Iter=6200, loss=1.3908, mse=1.3904, time=0.0409\n",
      "Iter=6400, loss=1.3975, mse=1.3972, time=0.0409\n",
      "Iter=6600, loss=1.3862, mse=1.3859, time=0.0409\n",
      "=== Epoch 49, train loss 1.388542, test rmse 1.165987 ===\n",
      "Epoch 50\n",
      "Iter=200, loss=1.3985, mse=1.3981, time=0.0425\n",
      "Iter=400, loss=1.4111, mse=1.4107, time=0.0421\n",
      "Iter=600, loss=1.3759, mse=1.3755, time=0.0416\n",
      "Iter=800, loss=1.3841, mse=1.3837, time=0.0415\n",
      "Iter=1000, loss=1.3485, mse=1.3481, time=0.0413\n",
      "Iter=1200, loss=1.3805, mse=1.3801, time=0.0414\n",
      "Iter=1400, loss=1.3755, mse=1.3752, time=0.0413\n",
      "Iter=1600, loss=1.3766, mse=1.3762, time=0.0413\n",
      "Iter=1800, loss=1.3957, mse=1.3953, time=0.0413\n",
      "Iter=2000, loss=1.4294, mse=1.4290, time=0.0412\n",
      "Iter=2200, loss=1.4089, mse=1.4086, time=0.0412\n",
      "Iter=2400, loss=1.4073, mse=1.4070, time=0.0411\n",
      "Iter=2600, loss=1.3698, mse=1.3694, time=0.0411\n",
      "Iter=2800, loss=1.3800, mse=1.3797, time=0.0410\n",
      "Iter=3000, loss=1.3735, mse=1.3732, time=0.0410\n",
      "Iter=3200, loss=1.3942, mse=1.3939, time=0.0410\n",
      "Iter=3400, loss=1.3629, mse=1.3626, time=0.0410\n",
      "Iter=3600, loss=1.3690, mse=1.3687, time=0.0410\n",
      "Iter=3800, loss=1.3780, mse=1.3777, time=0.0409\n",
      "Iter=4000, loss=1.3567, mse=1.3564, time=0.0409\n",
      "Iter=4200, loss=1.4043, mse=1.4039, time=0.0409\n",
      "Iter=4400, loss=1.3635, mse=1.3631, time=0.0409\n",
      "Iter=4600, loss=1.3927, mse=1.3924, time=0.0409\n",
      "Iter=4800, loss=1.4165, mse=1.4162, time=0.0409\n",
      "Iter=5000, loss=1.3753, mse=1.3749, time=0.0408\n",
      "Iter=5200, loss=1.4250, mse=1.4247, time=0.0408\n",
      "Iter=5400, loss=1.3739, mse=1.3735, time=0.0408\n",
      "Iter=5600, loss=1.3708, mse=1.3704, time=0.0408\n",
      "Iter=5800, loss=1.3981, mse=1.3977, time=0.0408\n",
      "Iter=6000, loss=1.4017, mse=1.4013, time=0.0407\n",
      "Iter=6200, loss=1.3883, mse=1.3880, time=0.0407\n",
      "Iter=6400, loss=1.3763, mse=1.3760, time=0.0407\n",
      "Iter=6600, loss=1.4002, mse=1.3998, time=0.0406\n",
      "=== Epoch 50, train loss 1.386687, test rmse 1.164353 ===\n",
      "Epoch 51\n",
      "Iter=200, loss=1.3805, mse=1.3802, time=0.0421\n",
      "Iter=400, loss=1.3628, mse=1.3625, time=0.0413\n",
      "Iter=600, loss=1.3884, mse=1.3881, time=0.0413\n",
      "Iter=800, loss=1.4016, mse=1.4013, time=0.0410\n",
      "Iter=1000, loss=1.4183, mse=1.4179, time=0.0409\n",
      "Iter=1200, loss=1.4256, mse=1.4253, time=0.0410\n",
      "Iter=1400, loss=1.4076, mse=1.4073, time=0.0409\n",
      "Iter=1600, loss=1.3755, mse=1.3752, time=0.0409\n",
      "Iter=1800, loss=1.3928, mse=1.3925, time=0.0408\n",
      "Iter=2000, loss=1.3643, mse=1.3640, time=0.0409\n",
      "Iter=2200, loss=1.3795, mse=1.3791, time=0.0408\n",
      "Iter=2400, loss=1.3962, mse=1.3958, time=0.0409\n",
      "Iter=2600, loss=1.3679, mse=1.3676, time=0.0408\n",
      "Iter=2800, loss=1.3659, mse=1.3656, time=0.0408\n",
      "Iter=3000, loss=1.3813, mse=1.3810, time=0.0408\n",
      "Iter=3200, loss=1.3818, mse=1.3815, time=0.0408\n",
      "Iter=3400, loss=1.4190, mse=1.4187, time=0.0407\n",
      "Iter=3600, loss=1.3869, mse=1.3866, time=0.0407\n",
      "Iter=3800, loss=1.3916, mse=1.3913, time=0.0407\n",
      "Iter=4000, loss=1.3787, mse=1.3784, time=0.0407\n",
      "Iter=4200, loss=1.3830, mse=1.3826, time=0.0408\n",
      "Iter=4400, loss=1.3709, mse=1.3706, time=0.0407\n",
      "Iter=4600, loss=1.3683, mse=1.3680, time=0.0407\n",
      "Iter=4800, loss=1.4004, mse=1.4001, time=0.0407\n",
      "Iter=5000, loss=1.3923, mse=1.3920, time=0.0406\n",
      "Iter=5200, loss=1.3672, mse=1.3668, time=0.0406\n",
      "Iter=5400, loss=1.3725, mse=1.3722, time=0.0406\n",
      "Iter=5600, loss=1.3941, mse=1.3938, time=0.0406\n",
      "Iter=5800, loss=1.4085, mse=1.4082, time=0.0406\n",
      "Iter=6000, loss=1.3605, mse=1.3602, time=0.0406\n",
      "Iter=6200, loss=1.3708, mse=1.3705, time=0.0406\n",
      "Iter=6400, loss=1.4265, mse=1.4262, time=0.0406\n",
      "Iter=6600, loss=1.4017, mse=1.4013, time=0.0406\n",
      "=== Epoch 51, train loss 1.388168, test rmse 1.164867 ===\n",
      "Epoch 52\n",
      "Iter=200, loss=1.4169, mse=1.4166, time=0.0416\n",
      "Iter=400, loss=1.3781, mse=1.3779, time=0.0411\n",
      "Iter=600, loss=1.3648, mse=1.3645, time=0.0408\n",
      "Iter=800, loss=1.4016, mse=1.4013, time=0.0407\n",
      "Iter=1000, loss=1.3927, mse=1.3924, time=0.0409\n",
      "Iter=1200, loss=1.3917, mse=1.3914, time=0.0408\n",
      "Iter=1400, loss=1.4309, mse=1.4306, time=0.0408\n",
      "Iter=1600, loss=1.3832, mse=1.3829, time=0.0408\n",
      "Iter=1800, loss=1.3804, mse=1.3801, time=0.0408\n",
      "Iter=2000, loss=1.3878, mse=1.3875, time=0.0408\n",
      "Iter=2200, loss=1.3675, mse=1.3672, time=0.0408\n",
      "Iter=2400, loss=1.4054, mse=1.4051, time=0.0408\n",
      "Iter=2600, loss=1.3868, mse=1.3865, time=0.0408\n",
      "Iter=2800, loss=1.3546, mse=1.3543, time=0.0408\n",
      "Iter=3000, loss=1.4015, mse=1.4012, time=0.0408\n",
      "Iter=3200, loss=1.3734, mse=1.3731, time=0.0408\n",
      "Iter=3400, loss=1.3797, mse=1.3794, time=0.0408\n",
      "Iter=3600, loss=1.4033, mse=1.4029, time=0.0408\n",
      "Iter=3800, loss=1.3588, mse=1.3584, time=0.0408\n",
      "Iter=4000, loss=1.4014, mse=1.4011, time=0.0408\n",
      "Iter=4200, loss=1.4078, mse=1.4075, time=0.0407\n",
      "Iter=4400, loss=1.4022, mse=1.4019, time=0.0407\n",
      "Iter=4600, loss=1.3993, mse=1.3990, time=0.0406\n",
      "Iter=4800, loss=1.3943, mse=1.3940, time=0.0406\n",
      "Iter=5000, loss=1.3593, mse=1.3590, time=0.0406\n",
      "Iter=5200, loss=1.3520, mse=1.3516, time=0.0406\n",
      "Iter=5400, loss=1.3686, mse=1.3682, time=0.0406\n",
      "Iter=5600, loss=1.4024, mse=1.4020, time=0.0406\n",
      "Iter=5800, loss=1.3993, mse=1.3990, time=0.0406\n",
      "Iter=6000, loss=1.3764, mse=1.3761, time=0.0407\n",
      "Iter=6200, loss=1.3899, mse=1.3895, time=0.0407\n",
      "Iter=6400, loss=1.3615, mse=1.3611, time=0.0407\n",
      "Iter=6600, loss=1.4070, mse=1.4067, time=0.0407\n",
      "=== Epoch 52, train loss 1.387437, test rmse 1.167923 ===\n",
      "Epoch 53\n",
      "Iter=200, loss=1.3826, mse=1.3822, time=0.0418\n",
      "Iter=400, loss=1.3728, mse=1.3724, time=0.0413\n",
      "Iter=600, loss=1.3949, mse=1.3946, time=0.0412\n",
      "Iter=800, loss=1.3916, mse=1.3912, time=0.0411\n",
      "Iter=1000, loss=1.3678, mse=1.3674, time=0.0410\n",
      "Iter=1200, loss=1.3972, mse=1.3969, time=0.0409\n",
      "Iter=1400, loss=1.4080, mse=1.4077, time=0.0409\n",
      "Iter=1600, loss=1.4150, mse=1.4147, time=0.0409\n",
      "Iter=1800, loss=1.3849, mse=1.3846, time=0.0407\n",
      "Iter=2000, loss=1.3953, mse=1.3950, time=0.0407\n",
      "Iter=2200, loss=1.3781, mse=1.3777, time=0.0407\n",
      "Iter=2400, loss=1.3672, mse=1.3669, time=0.0407\n",
      "Iter=2600, loss=1.3584, mse=1.3580, time=0.0407\n",
      "Iter=2800, loss=1.3959, mse=1.3955, time=0.0407\n",
      "Iter=3000, loss=1.3675, mse=1.3672, time=0.0408\n",
      "Iter=3200, loss=1.4067, mse=1.4063, time=0.0407\n",
      "Iter=3400, loss=1.3684, mse=1.3681, time=0.0406\n",
      "Iter=3600, loss=1.3925, mse=1.3921, time=0.0405\n",
      "Iter=3800, loss=1.4127, mse=1.4124, time=0.0405\n",
      "Iter=4000, loss=1.3846, mse=1.3843, time=0.0405\n",
      "Iter=4200, loss=1.4032, mse=1.4029, time=0.0405\n",
      "Iter=4400, loss=1.3640, mse=1.3637, time=0.0405\n",
      "Iter=4600, loss=1.3828, mse=1.3825, time=0.0405\n",
      "Iter=4800, loss=1.3711, mse=1.3707, time=0.0405\n",
      "Iter=5000, loss=1.3831, mse=1.3828, time=0.0406\n",
      "Iter=5200, loss=1.3327, mse=1.3323, time=0.0406\n",
      "Iter=5400, loss=1.3926, mse=1.3923, time=0.0406\n",
      "Iter=5600, loss=1.3828, mse=1.3825, time=0.0406\n",
      "Iter=5800, loss=1.3963, mse=1.3959, time=0.0406\n",
      "Iter=6000, loss=1.3873, mse=1.3869, time=0.0406\n",
      "Iter=6200, loss=1.4107, mse=1.4103, time=0.0406\n",
      "Iter=6400, loss=1.3910, mse=1.3907, time=0.0406\n",
      "Iter=6600, loss=1.4082, mse=1.4079, time=0.0407\n",
      "=== Epoch 53, train loss 1.387371, test rmse 1.162446 ===\n",
      "Epoch 54\n",
      "Iter=200, loss=1.3700, mse=1.3697, time=0.0429\n",
      "Iter=400, loss=1.3993, mse=1.3990, time=0.0416\n",
      "Iter=600, loss=1.3419, mse=1.3416, time=0.0413\n",
      "Iter=800, loss=1.4205, mse=1.4202, time=0.0412\n",
      "Iter=1000, loss=1.3713, mse=1.3710, time=0.0410\n",
      "Iter=1200, loss=1.3955, mse=1.3952, time=0.0408\n",
      "Iter=1400, loss=1.3701, mse=1.3698, time=0.0408\n",
      "Iter=1600, loss=1.3767, mse=1.3764, time=0.0408\n",
      "Iter=1800, loss=1.4193, mse=1.4190, time=0.0408\n",
      "Iter=2000, loss=1.4137, mse=1.4133, time=0.0408\n",
      "Iter=2200, loss=1.3641, mse=1.3638, time=0.0407\n",
      "Iter=2400, loss=1.3811, mse=1.3808, time=0.0406\n",
      "Iter=2600, loss=1.4234, mse=1.4231, time=0.0405\n",
      "Iter=2800, loss=1.3851, mse=1.3848, time=0.0404\n",
      "Iter=3000, loss=1.3721, mse=1.3718, time=0.0404\n",
      "Iter=3200, loss=1.3697, mse=1.3694, time=0.0404\n",
      "Iter=3400, loss=1.3823, mse=1.3820, time=0.0404\n",
      "Iter=3600, loss=1.3698, mse=1.3695, time=0.0405\n",
      "Iter=3800, loss=1.3637, mse=1.3633, time=0.0405\n",
      "Iter=4000, loss=1.3882, mse=1.3879, time=0.0406\n",
      "Iter=4200, loss=1.3846, mse=1.3843, time=0.0406\n",
      "Iter=4400, loss=1.3826, mse=1.3823, time=0.0406\n",
      "Iter=4600, loss=1.3953, mse=1.3950, time=0.0406\n",
      "Iter=4800, loss=1.3731, mse=1.3728, time=0.0407\n",
      "Iter=5000, loss=1.3717, mse=1.3713, time=0.0408\n",
      "Iter=5200, loss=1.3802, mse=1.3799, time=0.0408\n",
      "Iter=5400, loss=1.4050, mse=1.4046, time=0.0408\n",
      "Iter=5600, loss=1.4055, mse=1.4051, time=0.0408\n",
      "Iter=5800, loss=1.3565, mse=1.3561, time=0.0408\n",
      "Iter=6000, loss=1.3866, mse=1.3862, time=0.0408\n",
      "Iter=6200, loss=1.4038, mse=1.4034, time=0.0408\n",
      "Iter=6400, loss=1.4049, mse=1.4045, time=0.0409\n",
      "Iter=6600, loss=1.4226, mse=1.4222, time=0.0408\n",
      "=== Epoch 54, train loss 1.385826, test rmse 1.167027 ===\n",
      "Epoch 55\n",
      "Iter=200, loss=1.3858, mse=1.3854, time=0.0410\n",
      "Iter=400, loss=1.3661, mse=1.3657, time=0.0407\n",
      "Iter=600, loss=1.4135, mse=1.4131, time=0.0407\n",
      "Iter=800, loss=1.3974, mse=1.3970, time=0.0407\n",
      "Iter=1000, loss=1.3883, mse=1.3880, time=0.0407\n",
      "Iter=1200, loss=1.3616, mse=1.3612, time=0.0406\n",
      "Iter=1400, loss=1.3984, mse=1.3980, time=0.0406\n",
      "Iter=1600, loss=1.3861, mse=1.3857, time=0.0403\n",
      "Iter=1800, loss=1.4117, mse=1.4113, time=0.0402\n",
      "Iter=2000, loss=1.3697, mse=1.3694, time=0.0401\n",
      "Iter=2200, loss=1.3731, mse=1.3728, time=0.0401\n",
      "Iter=2400, loss=1.3812, mse=1.3808, time=0.0402\n",
      "Iter=2600, loss=1.3676, mse=1.3673, time=0.0403\n",
      "Iter=2800, loss=1.3893, mse=1.3889, time=0.0403\n",
      "Iter=3000, loss=1.3692, mse=1.3689, time=0.0404\n",
      "Iter=3200, loss=1.3667, mse=1.3663, time=0.0404\n",
      "Iter=3400, loss=1.3933, mse=1.3930, time=0.0404\n",
      "Iter=3600, loss=1.4271, mse=1.4267, time=0.0404\n",
      "Iter=3800, loss=1.3708, mse=1.3704, time=0.0405\n",
      "Iter=4000, loss=1.3710, mse=1.3706, time=0.0405\n",
      "Iter=4200, loss=1.4126, mse=1.4123, time=0.0405\n",
      "Iter=4400, loss=1.3652, mse=1.3649, time=0.0405\n",
      "Iter=4600, loss=1.3866, mse=1.3862, time=0.0405\n",
      "Iter=4800, loss=1.3946, mse=1.3943, time=0.0405\n",
      "Iter=5000, loss=1.4132, mse=1.4129, time=0.0405\n",
      "Iter=5200, loss=1.3973, mse=1.3970, time=0.0405\n",
      "Iter=5400, loss=1.3870, mse=1.3867, time=0.0405\n",
      "Iter=5600, loss=1.3573, mse=1.3569, time=0.0405\n",
      "Iter=5800, loss=1.4208, mse=1.4205, time=0.0405\n",
      "Iter=6000, loss=1.3995, mse=1.3992, time=0.0405\n",
      "Iter=6200, loss=1.3520, mse=1.3517, time=0.0405\n",
      "Iter=6400, loss=1.3908, mse=1.3905, time=0.0405\n",
      "Iter=6600, loss=1.4377, mse=1.4374, time=0.0405\n",
      "=== Epoch 55, train loss 1.387796, test rmse 1.164706 ===\n",
      "Epoch 56\n",
      "Iter=200, loss=1.4017, mse=1.4013, time=0.0419\n",
      "Iter=400, loss=1.3853, mse=1.3849, time=0.0412\n",
      "Iter=600, loss=1.4060, mse=1.4057, time=0.0407\n",
      "Iter=800, loss=1.3900, mse=1.3897, time=0.0402\n",
      "Iter=1000, loss=1.3842, mse=1.3839, time=0.0399\n",
      "Iter=1200, loss=1.4072, mse=1.4068, time=0.0400\n",
      "Iter=1400, loss=1.3888, mse=1.3885, time=0.0401\n",
      "Iter=1600, loss=1.3870, mse=1.3867, time=0.0402\n",
      "Iter=1800, loss=1.3612, mse=1.3609, time=0.0402\n",
      "Iter=2000, loss=1.3901, mse=1.3898, time=0.0403\n",
      "Iter=2200, loss=1.3939, mse=1.3936, time=0.0403\n",
      "Iter=2400, loss=1.3640, mse=1.3637, time=0.0404\n",
      "Iter=2600, loss=1.3617, mse=1.3614, time=0.0404\n",
      "Iter=2800, loss=1.3722, mse=1.3719, time=0.0405\n",
      "Iter=3000, loss=1.4185, mse=1.4181, time=0.0405\n",
      "Iter=3200, loss=1.3766, mse=1.3762, time=0.0405\n",
      "Iter=3400, loss=1.3914, mse=1.3910, time=0.0405\n",
      "Iter=3600, loss=1.3954, mse=1.3951, time=0.0406\n",
      "Iter=3800, loss=1.3734, mse=1.3731, time=0.0406\n",
      "Iter=4000, loss=1.3821, mse=1.3818, time=0.0406\n",
      "Iter=4200, loss=1.3774, mse=1.3771, time=0.0406\n",
      "Iter=4400, loss=1.3829, mse=1.3825, time=0.0406\n",
      "Iter=4600, loss=1.3764, mse=1.3760, time=0.0406\n",
      "Iter=4800, loss=1.4090, mse=1.4086, time=0.0406\n",
      "Iter=5000, loss=1.4024, mse=1.4021, time=0.0406\n",
      "Iter=5200, loss=1.4027, mse=1.4024, time=0.0406\n",
      "Iter=5400, loss=1.4028, mse=1.4024, time=0.0407\n",
      "Iter=5600, loss=1.3771, mse=1.3767, time=0.0406\n",
      "Iter=5800, loss=1.3835, mse=1.3831, time=0.0407\n",
      "Iter=6000, loss=1.4052, mse=1.4048, time=0.0407\n",
      "Iter=6200, loss=1.3815, mse=1.3812, time=0.0407\n",
      "Iter=6400, loss=1.3755, mse=1.3752, time=0.0407\n",
      "Iter=6600, loss=1.4110, mse=1.4107, time=0.0407\n",
      "=== Epoch 56, train loss 1.388479, test rmse 1.166208 ===\n",
      "Epoch 57\n",
      "Iter=200, loss=1.3803, mse=1.3799, time=0.0418\n",
      "Iter=400, loss=1.3736, mse=1.3733, time=0.0408\n",
      "Iter=600, loss=1.3856, mse=1.3853, time=0.0409\n",
      "Iter=800, loss=1.3614, mse=1.3610, time=0.0409\n",
      "Iter=1000, loss=1.4001, mse=1.3997, time=0.0408\n",
      "Iter=1200, loss=1.3748, mse=1.3744, time=0.0408\n",
      "Iter=1400, loss=1.3778, mse=1.3775, time=0.0408\n",
      "Iter=1600, loss=1.3769, mse=1.3765, time=0.0408\n",
      "Iter=1800, loss=1.3904, mse=1.3901, time=0.0409\n",
      "Iter=2000, loss=1.3587, mse=1.3584, time=0.0409\n",
      "Iter=2200, loss=1.3930, mse=1.3927, time=0.0409\n",
      "Iter=2400, loss=1.3828, mse=1.3825, time=0.0408\n",
      "Iter=2600, loss=1.3952, mse=1.3949, time=0.0408\n",
      "Iter=2800, loss=1.3945, mse=1.3942, time=0.0408\n",
      "Iter=3000, loss=1.4097, mse=1.4093, time=0.0408\n",
      "Iter=3200, loss=1.4058, mse=1.4054, time=0.0408\n",
      "Iter=3400, loss=1.4051, mse=1.4047, time=0.0408\n",
      "Iter=3600, loss=1.4057, mse=1.4054, time=0.0408\n",
      "Iter=3800, loss=1.4149, mse=1.4146, time=0.0408\n",
      "Iter=4000, loss=1.3952, mse=1.3948, time=0.0409\n",
      "Iter=4200, loss=1.3886, mse=1.3883, time=0.0408\n",
      "Iter=4400, loss=1.3960, mse=1.3956, time=0.0409\n",
      "Iter=4600, loss=1.3707, mse=1.3703, time=0.0408\n",
      "Iter=4800, loss=1.3724, mse=1.3720, time=0.0409\n",
      "Iter=5000, loss=1.3704, mse=1.3701, time=0.0409\n",
      "Iter=5200, loss=1.4046, mse=1.4043, time=0.0409\n",
      "Iter=5400, loss=1.3782, mse=1.3778, time=0.0409\n",
      "Iter=5600, loss=1.3794, mse=1.3790, time=0.0408\n",
      "Iter=5800, loss=1.3883, mse=1.3879, time=0.0408\n",
      "Iter=6000, loss=1.4239, mse=1.4236, time=0.0408\n",
      "Iter=6200, loss=1.3880, mse=1.3877, time=0.0408\n",
      "Iter=6400, loss=1.3798, mse=1.3794, time=0.0408\n",
      "Iter=6600, loss=1.3845, mse=1.3841, time=0.0408\n",
      "=== Epoch 57, train loss 1.388001, test rmse 1.161787 ===\n",
      "Epoch 58\n",
      "Iter=200, loss=1.3686, mse=1.3683, time=0.0417\n",
      "Iter=400, loss=1.3668, mse=1.3665, time=0.0412\n",
      "Iter=600, loss=1.4204, mse=1.4200, time=0.0411\n",
      "Iter=800, loss=1.3907, mse=1.3904, time=0.0412\n",
      "Iter=1000, loss=1.3663, mse=1.3660, time=0.0410\n",
      "Iter=1200, loss=1.3861, mse=1.3857, time=0.0411\n",
      "Iter=1400, loss=1.4012, mse=1.4009, time=0.0410\n",
      "Iter=1600, loss=1.3623, mse=1.3620, time=0.0409\n",
      "Iter=1800, loss=1.3669, mse=1.3666, time=0.0409\n",
      "Iter=2000, loss=1.3628, mse=1.3624, time=0.0408\n",
      "Iter=2200, loss=1.3993, mse=1.3989, time=0.0408\n",
      "Iter=2400, loss=1.3945, mse=1.3942, time=0.0408\n",
      "Iter=2600, loss=1.4049, mse=1.4046, time=0.0408\n",
      "Iter=2800, loss=1.3986, mse=1.3982, time=0.0408\n",
      "Iter=3000, loss=1.3846, mse=1.3842, time=0.0408\n",
      "Iter=3200, loss=1.3859, mse=1.3855, time=0.0408\n",
      "Iter=3400, loss=1.3793, mse=1.3790, time=0.0408\n",
      "Iter=3600, loss=1.3740, mse=1.3737, time=0.0408\n",
      "Iter=3800, loss=1.4073, mse=1.4069, time=0.0408\n",
      "Iter=4000, loss=1.3682, mse=1.3678, time=0.0408\n",
      "Iter=4200, loss=1.3812, mse=1.3808, time=0.0408\n",
      "Iter=4400, loss=1.3529, mse=1.3525, time=0.0408\n",
      "Iter=4600, loss=1.4081, mse=1.4078, time=0.0408\n",
      "Iter=4800, loss=1.3995, mse=1.3992, time=0.0408\n",
      "Iter=5000, loss=1.3766, mse=1.3763, time=0.0407\n",
      "Iter=5200, loss=1.3794, mse=1.3791, time=0.0408\n",
      "Iter=5400, loss=1.4082, mse=1.4079, time=0.0407\n",
      "Iter=5600, loss=1.4147, mse=1.4144, time=0.0407\n",
      "Iter=5800, loss=1.4010, mse=1.4007, time=0.0407\n",
      "Iter=6000, loss=1.3944, mse=1.3941, time=0.0407\n",
      "Iter=6200, loss=1.3854, mse=1.3850, time=0.0407\n",
      "Iter=6400, loss=1.4036, mse=1.4033, time=0.0406\n",
      "Iter=6600, loss=1.3763, mse=1.3760, time=0.0406\n",
      "=== Epoch 58, train loss 1.386497, test rmse 1.162519 ===\n",
      "Epoch 59\n",
      "Iter=200, loss=1.3554, mse=1.3551, time=0.0424\n",
      "Iter=400, loss=1.3587, mse=1.3584, time=0.0411\n",
      "Iter=600, loss=1.3690, mse=1.3687, time=0.0411\n",
      "Iter=800, loss=1.3860, mse=1.3857, time=0.0409\n",
      "Iter=1000, loss=1.4379, mse=1.4376, time=0.0409\n",
      "Iter=1200, loss=1.4089, mse=1.4086, time=0.0409\n",
      "Iter=1400, loss=1.3848, mse=1.3845, time=0.0409\n",
      "Iter=1600, loss=1.3795, mse=1.3792, time=0.0409\n",
      "Iter=1800, loss=1.3711, mse=1.3707, time=0.0409\n",
      "Iter=2000, loss=1.3770, mse=1.3766, time=0.0409\n",
      "Iter=2200, loss=1.3711, mse=1.3708, time=0.0409\n",
      "Iter=2400, loss=1.3977, mse=1.3974, time=0.0409\n",
      "Iter=2600, loss=1.4132, mse=1.4129, time=0.0408\n",
      "Iter=2800, loss=1.3832, mse=1.3828, time=0.0408\n",
      "Iter=3000, loss=1.3612, mse=1.3609, time=0.0408\n",
      "Iter=3200, loss=1.3950, mse=1.3946, time=0.0408\n",
      "Iter=3400, loss=1.3643, mse=1.3639, time=0.0408\n",
      "Iter=3600, loss=1.4181, mse=1.4177, time=0.0408\n",
      "Iter=3800, loss=1.3891, mse=1.3888, time=0.0408\n",
      "Iter=4000, loss=1.3993, mse=1.3989, time=0.0408\n",
      "Iter=4200, loss=1.4208, mse=1.4205, time=0.0408\n",
      "Iter=4400, loss=1.3913, mse=1.3909, time=0.0408\n",
      "Iter=4600, loss=1.3845, mse=1.3842, time=0.0408\n",
      "Iter=4800, loss=1.3437, mse=1.3434, time=0.0408\n",
      "Iter=5000, loss=1.3871, mse=1.3868, time=0.0408\n",
      "Iter=5200, loss=1.3697, mse=1.3693, time=0.0408\n",
      "Iter=5400, loss=1.4357, mse=1.4353, time=0.0407\n",
      "Iter=5600, loss=1.3910, mse=1.3907, time=0.0407\n",
      "Iter=5800, loss=1.3914, mse=1.3910, time=0.0406\n",
      "Iter=6000, loss=1.3779, mse=1.3776, time=0.0406\n",
      "Iter=6200, loss=1.4066, mse=1.4063, time=0.0406\n",
      "Iter=6400, loss=1.3864, mse=1.3860, time=0.0406\n",
      "Iter=6600, loss=1.3893, mse=1.3889, time=0.0406\n",
      "=== Epoch 59, train loss 1.387196, test rmse 1.167903 ===\n",
      "Epoch 60\n",
      "Iter=200, loss=1.3925, mse=1.3921, time=0.0419\n",
      "Iter=400, loss=1.3481, mse=1.3477, time=0.0412\n",
      "Iter=600, loss=1.4165, mse=1.4162, time=0.0409\n",
      "Iter=800, loss=1.3891, mse=1.3887, time=0.0410\n",
      "Iter=1000, loss=1.3902, mse=1.3899, time=0.0410\n",
      "Iter=1200, loss=1.3902, mse=1.3898, time=0.0409\n",
      "Iter=1400, loss=1.3758, mse=1.3755, time=0.0409\n",
      "Iter=1600, loss=1.3906, mse=1.3902, time=0.0409\n",
      "Iter=1800, loss=1.3505, mse=1.3502, time=0.0408\n",
      "Iter=2000, loss=1.3782, mse=1.3778, time=0.0409\n",
      "Iter=2200, loss=1.4088, mse=1.4085, time=0.0408\n",
      "Iter=2400, loss=1.3813, mse=1.3810, time=0.0408\n",
      "Iter=2600, loss=1.4173, mse=1.4170, time=0.0408\n",
      "Iter=2800, loss=1.3893, mse=1.3890, time=0.0407\n",
      "Iter=3000, loss=1.4014, mse=1.4011, time=0.0408\n",
      "Iter=3200, loss=1.3873, mse=1.3870, time=0.0407\n",
      "Iter=3400, loss=1.3938, mse=1.3934, time=0.0407\n",
      "Iter=3600, loss=1.3864, mse=1.3861, time=0.0408\n",
      "Iter=3800, loss=1.4285, mse=1.4281, time=0.0407\n",
      "Iter=4000, loss=1.3843, mse=1.3839, time=0.0407\n",
      "Iter=4200, loss=1.3772, mse=1.3769, time=0.0407\n",
      "Iter=4400, loss=1.3806, mse=1.3803, time=0.0407\n",
      "Iter=4600, loss=1.3690, mse=1.3687, time=0.0406\n",
      "Iter=4800, loss=1.3631, mse=1.3628, time=0.0406\n",
      "Iter=5000, loss=1.3528, mse=1.3524, time=0.0405\n",
      "Iter=5200, loss=1.4190, mse=1.4187, time=0.0405\n",
      "Iter=5400, loss=1.3983, mse=1.3980, time=0.0405\n",
      "Iter=5600, loss=1.3676, mse=1.3673, time=0.0405\n",
      "Iter=5800, loss=1.4169, mse=1.4166, time=0.0405\n",
      "Iter=6000, loss=1.4009, mse=1.4005, time=0.0405\n",
      "Iter=6200, loss=1.3705, mse=1.3702, time=0.0406\n",
      "Iter=6400, loss=1.3963, mse=1.3959, time=0.0406\n",
      "Iter=6600, loss=1.3935, mse=1.3931, time=0.0406\n",
      "=== Epoch 60, train loss 1.388277, test rmse 1.169016 ===\n",
      "Epoch 61\n",
      "Iter=200, loss=1.3857, mse=1.3853, time=0.0415\n",
      "Iter=400, loss=1.4011, mse=1.4007, time=0.0411\n",
      "Iter=600, loss=1.3819, mse=1.3815, time=0.0412\n",
      "Iter=800, loss=1.4059, mse=1.4055, time=0.0411\n",
      "Iter=1000, loss=1.3766, mse=1.3762, time=0.0409\n",
      "Iter=1200, loss=1.3763, mse=1.3759, time=0.0410\n",
      "Iter=1400, loss=1.3941, mse=1.3938, time=0.0408\n",
      "Iter=1600, loss=1.4015, mse=1.4012, time=0.0408\n",
      "Iter=1800, loss=1.4162, mse=1.4159, time=0.0407\n",
      "Iter=2000, loss=1.4033, mse=1.4030, time=0.0407\n",
      "Iter=2200, loss=1.3963, mse=1.3959, time=0.0406\n",
      "Iter=2400, loss=1.3963, mse=1.3960, time=0.0406\n",
      "Iter=2600, loss=1.3691, mse=1.3688, time=0.0406\n",
      "Iter=2800, loss=1.3581, mse=1.3578, time=0.0406\n",
      "Iter=3000, loss=1.3823, mse=1.3820, time=0.0406\n",
      "Iter=3200, loss=1.3878, mse=1.3875, time=0.0407\n",
      "Iter=3400, loss=1.3706, mse=1.3703, time=0.0406\n",
      "Iter=3600, loss=1.4196, mse=1.4193, time=0.0407\n",
      "Iter=3800, loss=1.3958, mse=1.3954, time=0.0405\n",
      "Iter=4000, loss=1.3612, mse=1.3609, time=0.0404\n",
      "Iter=4200, loss=1.4054, mse=1.4050, time=0.0404\n",
      "Iter=4400, loss=1.3791, mse=1.3787, time=0.0404\n",
      "Iter=4600, loss=1.3691, mse=1.3688, time=0.0404\n",
      "Iter=4800, loss=1.3887, mse=1.3884, time=0.0404\n",
      "Iter=5000, loss=1.3810, mse=1.3807, time=0.0404\n",
      "Iter=5200, loss=1.3550, mse=1.3546, time=0.0405\n",
      "Iter=5400, loss=1.3966, mse=1.3963, time=0.0405\n",
      "Iter=5600, loss=1.4089, mse=1.4086, time=0.0405\n",
      "Iter=5800, loss=1.4053, mse=1.4049, time=0.0405\n",
      "Iter=6000, loss=1.3751, mse=1.3747, time=0.0405\n",
      "Iter=6200, loss=1.3311, mse=1.3307, time=0.0405\n",
      "Iter=6400, loss=1.3915, mse=1.3911, time=0.0405\n",
      "Iter=6600, loss=1.3970, mse=1.3967, time=0.0405\n",
      "=== Epoch 61, train loss 1.387002, test rmse 1.166763 ===\n",
      "Epoch 62\n",
      "Iter=200, loss=1.3976, mse=1.3973, time=0.0415\n",
      "Iter=400, loss=1.3817, mse=1.3813, time=0.0415\n",
      "Iter=600, loss=1.4111, mse=1.4107, time=0.0413\n",
      "Iter=800, loss=1.3692, mse=1.3689, time=0.0410\n",
      "Iter=1000, loss=1.3905, mse=1.3902, time=0.0410\n",
      "Iter=1200, loss=1.3812, mse=1.3808, time=0.0409\n",
      "Iter=1400, loss=1.3854, mse=1.3850, time=0.0410\n",
      "Iter=1600, loss=1.3812, mse=1.3808, time=0.0409\n",
      "Iter=1800, loss=1.3993, mse=1.3989, time=0.0409\n",
      "Iter=2000, loss=1.4068, mse=1.4065, time=0.0409\n",
      "Iter=2200, loss=1.3678, mse=1.3675, time=0.0409\n",
      "Iter=2400, loss=1.3521, mse=1.3518, time=0.0409\n",
      "Iter=2600, loss=1.3704, mse=1.3701, time=0.0410\n",
      "Iter=2800, loss=1.3631, mse=1.3627, time=0.0409\n",
      "Iter=3000, loss=1.3944, mse=1.3941, time=0.0408\n",
      "Iter=3200, loss=1.3779, mse=1.3775, time=0.0407\n",
      "Iter=3400, loss=1.4041, mse=1.4037, time=0.0407\n",
      "Iter=3600, loss=1.4103, mse=1.4099, time=0.0407\n",
      "Iter=3800, loss=1.3971, mse=1.3967, time=0.0406\n",
      "Iter=4000, loss=1.3655, mse=1.3651, time=0.0407\n",
      "Iter=4200, loss=1.4185, mse=1.4182, time=0.0407\n",
      "Iter=4400, loss=1.3823, mse=1.3819, time=0.0407\n",
      "Iter=4600, loss=1.3847, mse=1.3843, time=0.0407\n",
      "Iter=4800, loss=1.3969, mse=1.3966, time=0.0407\n",
      "Iter=5000, loss=1.3839, mse=1.3836, time=0.0407\n",
      "Iter=5200, loss=1.3799, mse=1.3795, time=0.0407\n",
      "Iter=5400, loss=1.3747, mse=1.3744, time=0.0407\n",
      "Iter=5600, loss=1.3725, mse=1.3722, time=0.0407\n",
      "Iter=5800, loss=1.3827, mse=1.3824, time=0.0407\n",
      "Iter=6000, loss=1.3814, mse=1.3810, time=0.0407\n",
      "Iter=6200, loss=1.3658, mse=1.3655, time=0.0407\n",
      "Iter=6400, loss=1.3825, mse=1.3821, time=0.0407\n",
      "Iter=6600, loss=1.4130, mse=1.4126, time=0.0407\n",
      "=== Epoch 62, train loss 1.385764, test rmse 1.164202 ===\n",
      "Epoch 63\n",
      "Iter=200, loss=1.4123, mse=1.4119, time=0.0422\n",
      "Iter=400, loss=1.4235, mse=1.4231, time=0.0414\n",
      "Iter=600, loss=1.3868, mse=1.3864, time=0.0410\n",
      "Iter=800, loss=1.3640, mse=1.3636, time=0.0410\n",
      "Iter=1000, loss=1.3508, mse=1.3504, time=0.0409\n",
      "Iter=1200, loss=1.3771, mse=1.3767, time=0.0409\n",
      "Iter=1400, loss=1.3826, mse=1.3822, time=0.0409\n",
      "Iter=1600, loss=1.3801, mse=1.3798, time=0.0409\n",
      "Iter=1800, loss=1.4077, mse=1.4074, time=0.0408\n",
      "Iter=2000, loss=1.4027, mse=1.4024, time=0.0407\n",
      "Iter=2200, loss=1.3650, mse=1.3646, time=0.0405\n",
      "Iter=2400, loss=1.3882, mse=1.3878, time=0.0405\n",
      "Iter=2600, loss=1.3971, mse=1.3968, time=0.0404\n",
      "Iter=2800, loss=1.3753, mse=1.3750, time=0.0405\n",
      "Iter=3000, loss=1.3932, mse=1.3929, time=0.0405\n",
      "Iter=3200, loss=1.3762, mse=1.3759, time=0.0405\n",
      "Iter=3400, loss=1.3740, mse=1.3736, time=0.0406\n",
      "Iter=3600, loss=1.3680, mse=1.3676, time=0.0406\n",
      "Iter=3800, loss=1.3970, mse=1.3966, time=0.0406\n",
      "Iter=4000, loss=1.4126, mse=1.4122, time=0.0406\n",
      "Iter=4200, loss=1.3714, mse=1.3710, time=0.0407\n",
      "Iter=4400, loss=1.4061, mse=1.4057, time=0.0407\n",
      "Iter=4600, loss=1.3751, mse=1.3748, time=0.0407\n",
      "Iter=4800, loss=1.4137, mse=1.4134, time=0.0407\n",
      "Iter=5000, loss=1.4321, mse=1.4318, time=0.0407\n",
      "Iter=5200, loss=1.4282, mse=1.4278, time=0.0407\n",
      "Iter=5400, loss=1.3647, mse=1.3643, time=0.0407\n",
      "Iter=5600, loss=1.3528, mse=1.3524, time=0.0407\n",
      "Iter=5800, loss=1.3580, mse=1.3577, time=0.0407\n",
      "Iter=6000, loss=1.4196, mse=1.4192, time=0.0407\n",
      "Iter=6200, loss=1.3836, mse=1.3833, time=0.0407\n",
      "Iter=6400, loss=1.3931, mse=1.3928, time=0.0407\n",
      "Iter=6600, loss=1.3775, mse=1.3772, time=0.0407\n",
      "=== Epoch 63, train loss 1.387644, test rmse 1.163498 ===\n",
      "Epoch 64\n",
      "Iter=200, loss=1.3763, mse=1.3759, time=0.0420\n",
      "Iter=400, loss=1.3969, mse=1.3966, time=0.0411\n",
      "Iter=600, loss=1.4003, mse=1.3999, time=0.0414\n",
      "Iter=800, loss=1.3937, mse=1.3933, time=0.0419\n",
      "Iter=1000, loss=1.3804, mse=1.3801, time=0.0420\n",
      "Iter=1200, loss=1.3765, mse=1.3762, time=0.0414\n",
      "Iter=1400, loss=1.4088, mse=1.4084, time=0.0411\n",
      "Iter=1600, loss=1.3445, mse=1.3442, time=0.0409\n",
      "Iter=1800, loss=1.3584, mse=1.3581, time=0.0410\n",
      "Iter=2000, loss=1.3791, mse=1.3788, time=0.0410\n",
      "Iter=2200, loss=1.4276, mse=1.4273, time=0.0409\n",
      "Iter=2400, loss=1.3505, mse=1.3501, time=0.0410\n",
      "Iter=2600, loss=1.3598, mse=1.3595, time=0.0410\n",
      "Iter=2800, loss=1.3846, mse=1.3843, time=0.0410\n",
      "Iter=3000, loss=1.3939, mse=1.3936, time=0.0409\n",
      "Iter=3200, loss=1.4067, mse=1.4064, time=0.0410\n",
      "Iter=3400, loss=1.3959, mse=1.3955, time=0.0410\n",
      "Iter=3600, loss=1.3937, mse=1.3934, time=0.0410\n",
      "Iter=3800, loss=1.3744, mse=1.3741, time=0.0410\n",
      "Iter=4000, loss=1.4090, mse=1.4087, time=0.0410\n",
      "Iter=4200, loss=1.3838, mse=1.3835, time=0.0411\n",
      "Iter=4400, loss=1.3709, mse=1.3706, time=0.0411\n",
      "Iter=4600, loss=1.4113, mse=1.4110, time=0.0410\n",
      "Iter=4800, loss=1.3931, mse=1.3927, time=0.0410\n",
      "Iter=5000, loss=1.3672, mse=1.3668, time=0.0410\n",
      "Iter=5200, loss=1.3689, mse=1.3685, time=0.0410\n",
      "Iter=5400, loss=1.3846, mse=1.3843, time=0.0410\n",
      "Iter=5600, loss=1.4067, mse=1.4064, time=0.0410\n",
      "Iter=5800, loss=1.4098, mse=1.4095, time=0.0410\n",
      "Iter=6000, loss=1.4191, mse=1.4188, time=0.0410\n",
      "Iter=6200, loss=1.4096, mse=1.4092, time=0.0410\n",
      "Iter=6400, loss=1.3584, mse=1.3580, time=0.0410\n",
      "Iter=6600, loss=1.3860, mse=1.3857, time=0.0410\n",
      "=== Epoch 64, train loss 1.387228, test rmse 1.163702 ===\n",
      "Epoch 65\n",
      "Iter=200, loss=1.3559, mse=1.3556, time=0.0403\n",
      "Iter=400, loss=1.3559, mse=1.3556, time=0.0397\n",
      "Iter=600, loss=1.4003, mse=1.3999, time=0.0392\n",
      "Iter=800, loss=1.4033, mse=1.4029, time=0.0394\n",
      "Iter=1000, loss=1.4197, mse=1.4194, time=0.0395\n",
      "Iter=1200, loss=1.3743, mse=1.3740, time=0.0397\n",
      "Iter=1400, loss=1.4017, mse=1.4014, time=0.0399\n",
      "Iter=1600, loss=1.3752, mse=1.3749, time=0.0399\n",
      "Iter=1800, loss=1.3950, mse=1.3947, time=0.0401\n",
      "Iter=2000, loss=1.3597, mse=1.3594, time=0.0401\n",
      "Iter=2200, loss=1.4247, mse=1.4244, time=0.0402\n",
      "Iter=2400, loss=1.3263, mse=1.3260, time=0.0403\n",
      "Iter=2600, loss=1.3824, mse=1.3821, time=0.0403\n",
      "Iter=2800, loss=1.3775, mse=1.3772, time=0.0404\n",
      "Iter=3000, loss=1.3651, mse=1.3647, time=0.0404\n",
      "Iter=3200, loss=1.3703, mse=1.3699, time=0.0404\n",
      "Iter=3400, loss=1.3660, mse=1.3656, time=0.0404\n",
      "Iter=3600, loss=1.4251, mse=1.4248, time=0.0403\n",
      "Iter=3800, loss=1.3838, mse=1.3834, time=0.0404\n",
      "Iter=4000, loss=1.4220, mse=1.4217, time=0.0404\n",
      "Iter=4200, loss=1.4257, mse=1.4253, time=0.0404\n",
      "Iter=4400, loss=1.3763, mse=1.3760, time=0.0404\n",
      "Iter=4600, loss=1.4194, mse=1.4191, time=0.0404\n",
      "Iter=4800, loss=1.3709, mse=1.3705, time=0.0404\n",
      "Iter=5000, loss=1.3690, mse=1.3686, time=0.0404\n",
      "Iter=5200, loss=1.3586, mse=1.3583, time=0.0404\n",
      "Iter=5400, loss=1.4323, mse=1.4319, time=0.0404\n",
      "Iter=5600, loss=1.4094, mse=1.4091, time=0.0404\n",
      "Iter=5800, loss=1.3754, mse=1.3750, time=0.0404\n",
      "Iter=6000, loss=1.3916, mse=1.3913, time=0.0404\n",
      "Iter=6200, loss=1.3801, mse=1.3798, time=0.0404\n",
      "Iter=6400, loss=1.4135, mse=1.4132, time=0.0404\n",
      "Iter=6600, loss=1.3986, mse=1.3982, time=0.0403\n",
      "=== Epoch 65, train loss 1.387645, test rmse 1.167081 ===\n",
      "Epoch 66\n",
      "Iter=200, loss=1.3878, mse=1.3875, time=0.0421\n",
      "Iter=400, loss=1.4330, mse=1.4327, time=0.0413\n",
      "Iter=600, loss=1.3644, mse=1.3641, time=0.0409\n",
      "Iter=800, loss=1.4063, mse=1.4060, time=0.0409\n",
      "Iter=1000, loss=1.3600, mse=1.3596, time=0.0408\n",
      "Iter=1200, loss=1.4216, mse=1.4213, time=0.0409\n",
      "Iter=1400, loss=1.3777, mse=1.3774, time=0.0409\n",
      "Iter=1600, loss=1.3874, mse=1.3870, time=0.0409\n",
      "Iter=1800, loss=1.3759, mse=1.3755, time=0.0409\n",
      "Iter=2000, loss=1.3849, mse=1.3845, time=0.0408\n",
      "Iter=2200, loss=1.4066, mse=1.4063, time=0.0408\n",
      "Iter=2400, loss=1.3741, mse=1.3737, time=0.0408\n",
      "Iter=2600, loss=1.4003, mse=1.4000, time=0.0407\n",
      "Iter=2800, loss=1.3925, mse=1.3922, time=0.0407\n",
      "Iter=3000, loss=1.3999, mse=1.3995, time=0.0407\n",
      "Iter=3200, loss=1.3897, mse=1.3894, time=0.0408\n",
      "Iter=3400, loss=1.3918, mse=1.3914, time=0.0407\n",
      "Iter=3600, loss=1.4009, mse=1.4005, time=0.0408\n",
      "Iter=3800, loss=1.3765, mse=1.3762, time=0.0407\n",
      "Iter=4000, loss=1.3978, mse=1.3974, time=0.0407\n",
      "Iter=4200, loss=1.3737, mse=1.3733, time=0.0407\n",
      "Iter=4400, loss=1.3788, mse=1.3784, time=0.0407\n",
      "Iter=4600, loss=1.3756, mse=1.3752, time=0.0408\n",
      "Iter=4800, loss=1.4108, mse=1.4104, time=0.0407\n",
      "Iter=5000, loss=1.3703, mse=1.3699, time=0.0408\n",
      "Iter=5200, loss=1.3756, mse=1.3752, time=0.0408\n",
      "Iter=5400, loss=1.3823, mse=1.3819, time=0.0408\n",
      "Iter=5600, loss=1.3689, mse=1.3685, time=0.0408\n",
      "Iter=5800, loss=1.3851, mse=1.3847, time=0.0408\n",
      "Iter=6000, loss=1.3864, mse=1.3860, time=0.0408\n",
      "Iter=6200, loss=1.4008, mse=1.4004, time=0.0408\n",
      "Iter=6400, loss=1.3599, mse=1.3595, time=0.0408\n",
      "Iter=6600, loss=1.3835, mse=1.3831, time=0.0408\n",
      "=== Epoch 66, train loss 1.387388, test rmse 1.165684 ===\n",
      "Epoch 67\n",
      "Iter=200, loss=1.3928, mse=1.3924, time=0.0414\n",
      "Iter=400, loss=1.3711, mse=1.3707, time=0.0415\n",
      "Iter=600, loss=1.3906, mse=1.3902, time=0.0413\n",
      "Iter=800, loss=1.3404, mse=1.3400, time=0.0412\n",
      "Iter=1000, loss=1.3741, mse=1.3737, time=0.0410\n",
      "Iter=1200, loss=1.4095, mse=1.4091, time=0.0409\n",
      "Iter=1400, loss=1.3708, mse=1.3705, time=0.0409\n",
      "Iter=1600, loss=1.3771, mse=1.3767, time=0.0408\n",
      "Iter=1800, loss=1.4195, mse=1.4192, time=0.0409\n",
      "Iter=2000, loss=1.4211, mse=1.4207, time=0.0408\n",
      "Iter=2200, loss=1.3855, mse=1.3852, time=0.0408\n",
      "Iter=2400, loss=1.3727, mse=1.3723, time=0.0408\n",
      "Iter=2600, loss=1.4026, mse=1.4022, time=0.0408\n",
      "Iter=2800, loss=1.3870, mse=1.3866, time=0.0408\n",
      "Iter=3000, loss=1.3941, mse=1.3937, time=0.0408\n",
      "Iter=3200, loss=1.3929, mse=1.3926, time=0.0408\n",
      "Iter=3400, loss=1.3805, mse=1.3801, time=0.0408\n",
      "Iter=3600, loss=1.4128, mse=1.4124, time=0.0408\n",
      "Iter=3800, loss=1.3710, mse=1.3707, time=0.0408\n",
      "Iter=4000, loss=1.4006, mse=1.4003, time=0.0408\n",
      "Iter=4200, loss=1.3940, mse=1.3936, time=0.0408\n",
      "Iter=4400, loss=1.4144, mse=1.4140, time=0.0408\n",
      "Iter=4600, loss=1.3892, mse=1.3889, time=0.0408\n",
      "Iter=4800, loss=1.3691, mse=1.3687, time=0.0408\n",
      "Iter=5000, loss=1.4042, mse=1.4038, time=0.0407\n",
      "Iter=5200, loss=1.3664, mse=1.3660, time=0.0408\n",
      "Iter=5400, loss=1.3881, mse=1.3877, time=0.0407\n",
      "Iter=5600, loss=1.3905, mse=1.3901, time=0.0407\n",
      "Iter=5800, loss=1.3526, mse=1.3522, time=0.0407\n",
      "Iter=6000, loss=1.4114, mse=1.4110, time=0.0407\n",
      "Iter=6200, loss=1.4011, mse=1.4008, time=0.0406\n",
      "Iter=6400, loss=1.3639, mse=1.3635, time=0.0406\n",
      "Iter=6600, loss=1.3750, mse=1.3747, time=0.0406\n",
      "=== Epoch 67, train loss 1.386679, test rmse 1.165530 ===\n",
      "Epoch 68\n",
      "Iter=200, loss=1.3543, mse=1.3540, time=0.0417\n",
      "Iter=400, loss=1.3874, mse=1.3870, time=0.0408\n",
      "Iter=600, loss=1.3792, mse=1.3789, time=0.0407\n",
      "Iter=800, loss=1.4074, mse=1.4071, time=0.0407\n",
      "Iter=1000, loss=1.3704, mse=1.3700, time=0.0406\n",
      "Iter=1200, loss=1.3952, mse=1.3949, time=0.0407\n",
      "Iter=1400, loss=1.4081, mse=1.4078, time=0.0407\n",
      "Iter=1600, loss=1.4101, mse=1.4097, time=0.0407\n",
      "Iter=1800, loss=1.3758, mse=1.3755, time=0.0407\n",
      "Iter=2000, loss=1.3956, mse=1.3953, time=0.0407\n",
      "Iter=2200, loss=1.3917, mse=1.3913, time=0.0408\n",
      "Iter=2400, loss=1.3805, mse=1.3802, time=0.0408\n",
      "Iter=2600, loss=1.3640, mse=1.3636, time=0.0407\n",
      "Iter=2800, loss=1.3573, mse=1.3570, time=0.0407\n",
      "Iter=3000, loss=1.4168, mse=1.4165, time=0.0407\n",
      "Iter=3200, loss=1.3737, mse=1.3734, time=0.0407\n",
      "Iter=3400, loss=1.3789, mse=1.3786, time=0.0407\n",
      "Iter=3600, loss=1.3849, mse=1.3846, time=0.0408\n",
      "Iter=3800, loss=1.3879, mse=1.3875, time=0.0408\n",
      "Iter=4000, loss=1.4137, mse=1.4134, time=0.0408\n",
      "Iter=4200, loss=1.4003, mse=1.3999, time=0.0408\n",
      "Iter=4400, loss=1.3751, mse=1.3748, time=0.0407\n",
      "Iter=4600, loss=1.3657, mse=1.3654, time=0.0408\n",
      "Iter=4800, loss=1.3664, mse=1.3660, time=0.0407\n",
      "Iter=5000, loss=1.3891, mse=1.3887, time=0.0407\n",
      "Iter=5200, loss=1.4219, mse=1.4215, time=0.0406\n",
      "Iter=5400, loss=1.3657, mse=1.3653, time=0.0406\n",
      "Iter=5600, loss=1.4124, mse=1.4120, time=0.0406\n",
      "Iter=5800, loss=1.3907, mse=1.3903, time=0.0406\n",
      "Iter=6000, loss=1.3606, mse=1.3603, time=0.0406\n",
      "Iter=6200, loss=1.4086, mse=1.4083, time=0.0406\n",
      "Iter=6400, loss=1.3930, mse=1.3926, time=0.0406\n",
      "Iter=6600, loss=1.3682, mse=1.3679, time=0.0406\n",
      "=== Epoch 68, train loss 1.386893, test rmse 1.165476 ===\n",
      "Epoch 69\n",
      "Iter=200, loss=1.3701, mse=1.3697, time=0.0426\n",
      "Iter=400, loss=1.4040, mse=1.4037, time=0.0413\n",
      "Iter=600, loss=1.3707, mse=1.3704, time=0.0409\n",
      "Iter=800, loss=1.3965, mse=1.3962, time=0.0408\n",
      "Iter=1000, loss=1.3793, mse=1.3789, time=0.0409\n",
      "Iter=1200, loss=1.3883, mse=1.3880, time=0.0408\n",
      "Iter=1400, loss=1.3756, mse=1.3753, time=0.0408\n",
      "Iter=1600, loss=1.3963, mse=1.3960, time=0.0407\n",
      "Iter=1800, loss=1.3794, mse=1.3790, time=0.0408\n",
      "Iter=2000, loss=1.4092, mse=1.4089, time=0.0408\n",
      "Iter=2200, loss=1.3728, mse=1.3725, time=0.0408\n",
      "Iter=2400, loss=1.3852, mse=1.3849, time=0.0407\n",
      "Iter=2600, loss=1.3432, mse=1.3428, time=0.0408\n",
      "Iter=2800, loss=1.3841, mse=1.3837, time=0.0407\n",
      "Iter=3000, loss=1.3993, mse=1.3990, time=0.0407\n",
      "Iter=3200, loss=1.3747, mse=1.3744, time=0.0407\n",
      "Iter=3400, loss=1.3639, mse=1.3636, time=0.0407\n",
      "Iter=3600, loss=1.3733, mse=1.3729, time=0.0407\n",
      "Iter=3800, loss=1.3762, mse=1.3758, time=0.0407\n",
      "Iter=4000, loss=1.3874, mse=1.3870, time=0.0406\n",
      "Iter=4200, loss=1.4115, mse=1.4112, time=0.0406\n",
      "Iter=4400, loss=1.3904, mse=1.3901, time=0.0405\n",
      "Iter=4600, loss=1.3937, mse=1.3934, time=0.0405\n",
      "Iter=4800, loss=1.3871, mse=1.3868, time=0.0405\n",
      "Iter=5000, loss=1.4318, mse=1.4314, time=0.0405\n",
      "Iter=5200, loss=1.3905, mse=1.3902, time=0.0406\n",
      "Iter=5400, loss=1.3842, mse=1.3838, time=0.0405\n",
      "Iter=5600, loss=1.3904, mse=1.3901, time=0.0406\n",
      "Iter=5800, loss=1.3752, mse=1.3749, time=0.0406\n",
      "Iter=6000, loss=1.3807, mse=1.3804, time=0.0406\n",
      "Iter=6200, loss=1.4092, mse=1.4089, time=0.0406\n",
      "Iter=6400, loss=1.4024, mse=1.4020, time=0.0406\n",
      "Iter=6600, loss=1.3903, mse=1.3900, time=0.0406\n",
      "=== Epoch 69, train loss 1.387487, test rmse 1.169550 ===\n",
      "Epoch 70\n",
      "Iter=200, loss=1.3650, mse=1.3647, time=0.0434\n",
      "Iter=400, loss=1.3882, mse=1.3879, time=0.0439\n",
      "Iter=600, loss=1.4060, mse=1.4056, time=0.0437\n",
      "Iter=800, loss=1.3989, mse=1.3986, time=0.0430\n",
      "Iter=1000, loss=1.4037, mse=1.4033, time=0.0424\n",
      "Iter=1200, loss=1.4243, mse=1.4239, time=0.0422\n",
      "Iter=1400, loss=1.3943, mse=1.3939, time=0.0420\n",
      "Iter=1600, loss=1.3554, mse=1.3550, time=0.0419\n",
      "Iter=1800, loss=1.4184, mse=1.4181, time=0.0418\n",
      "Iter=2000, loss=1.3837, mse=1.3834, time=0.0417\n",
      "Iter=2200, loss=1.4048, mse=1.4045, time=0.0416\n",
      "Iter=2400, loss=1.3862, mse=1.3858, time=0.0415\n",
      "Iter=2600, loss=1.3800, mse=1.3796, time=0.0415\n",
      "Iter=2800, loss=1.3998, mse=1.3994, time=0.0414\n",
      "Iter=3000, loss=1.4111, mse=1.4107, time=0.0414\n",
      "Iter=3200, loss=1.3631, mse=1.3628, time=0.0412\n",
      "Iter=3400, loss=1.3629, mse=1.3626, time=0.0411\n",
      "Iter=3600, loss=1.4073, mse=1.4070, time=0.0411\n",
      "Iter=3800, loss=1.3708, mse=1.3705, time=0.0411\n",
      "Iter=4000, loss=1.4015, mse=1.4012, time=0.0410\n",
      "Iter=4200, loss=1.4077, mse=1.4074, time=0.0411\n",
      "Iter=4400, loss=1.3870, mse=1.3867, time=0.0410\n",
      "Iter=4600, loss=1.3601, mse=1.3598, time=0.0411\n",
      "Iter=4800, loss=1.3671, mse=1.3668, time=0.0411\n",
      "Iter=5000, loss=1.3900, mse=1.3897, time=0.0411\n",
      "Iter=5200, loss=1.4007, mse=1.4003, time=0.0411\n",
      "Iter=5400, loss=1.3745, mse=1.3741, time=0.0411\n",
      "Iter=5600, loss=1.3699, mse=1.3696, time=0.0410\n",
      "Iter=5800, loss=1.4038, mse=1.4033, time=0.0410\n",
      "Iter=6000, loss=1.3771, mse=1.3767, time=0.0410\n",
      "Iter=6200, loss=1.3689, mse=1.3685, time=0.0410\n",
      "Iter=6400, loss=1.3718, mse=1.3715, time=0.0410\n",
      "Iter=6600, loss=1.4046, mse=1.4042, time=0.0410\n",
      "=== Epoch 70, train loss 1.388240, test rmse 1.165187 ===\n",
      "Epoch 71\n",
      "Iter=200, loss=1.3767, mse=1.3764, time=0.0425\n",
      "Iter=400, loss=1.3766, mse=1.3763, time=0.0415\n",
      "Iter=600, loss=1.3747, mse=1.3744, time=0.0413\n",
      "Iter=800, loss=1.3654, mse=1.3650, time=0.0411\n",
      "Iter=1000, loss=1.3520, mse=1.3517, time=0.0409\n",
      "Iter=1200, loss=1.4255, mse=1.4252, time=0.0407\n",
      "Iter=1400, loss=1.3755, mse=1.3751, time=0.0408\n",
      "Iter=1600, loss=1.3898, mse=1.3895, time=0.0407\n",
      "Iter=1800, loss=1.4041, mse=1.4037, time=0.0406\n",
      "Iter=2000, loss=1.4061, mse=1.4058, time=0.0407\n",
      "Iter=2200, loss=1.4083, mse=1.4079, time=0.0407\n",
      "Iter=2400, loss=1.3592, mse=1.3588, time=0.0407\n",
      "Iter=2600, loss=1.3886, mse=1.3882, time=0.0407\n",
      "Iter=2800, loss=1.4180, mse=1.4176, time=0.0407\n",
      "Iter=3000, loss=1.4042, mse=1.4039, time=0.0407\n",
      "Iter=3200, loss=1.4017, mse=1.4014, time=0.0407\n",
      "Iter=3400, loss=1.3843, mse=1.3840, time=0.0406\n",
      "Iter=3600, loss=1.3986, mse=1.3982, time=0.0406\n",
      "Iter=3800, loss=1.3988, mse=1.3984, time=0.0405\n",
      "Iter=4000, loss=1.4121, mse=1.4118, time=0.0406\n",
      "Iter=4200, loss=1.4100, mse=1.4097, time=0.0405\n",
      "Iter=4400, loss=1.3941, mse=1.3938, time=0.0405\n",
      "Iter=4600, loss=1.4042, mse=1.4038, time=0.0405\n",
      "Iter=4800, loss=1.4029, mse=1.4025, time=0.0405\n",
      "Iter=5000, loss=1.3763, mse=1.3759, time=0.0405\n",
      "Iter=5200, loss=1.3578, mse=1.3574, time=0.0404\n",
      "Iter=5400, loss=1.3858, mse=1.3854, time=0.0405\n",
      "Iter=5600, loss=1.3925, mse=1.3922, time=0.0404\n",
      "Iter=5800, loss=1.4130, mse=1.4127, time=0.0403\n",
      "Iter=6000, loss=1.3346, mse=1.3343, time=0.0403\n",
      "Iter=6200, loss=1.4053, mse=1.4049, time=0.0403\n",
      "Iter=6400, loss=1.3618, mse=1.3614, time=0.0402\n",
      "Iter=6600, loss=1.3751, mse=1.3747, time=0.0402\n",
      "=== Epoch 71, train loss 1.388206, test rmse 1.162274 ===\n",
      "Epoch 72\n",
      "Iter=200, loss=1.3900, mse=1.3896, time=0.0416\n",
      "Iter=400, loss=1.3793, mse=1.3789, time=0.0409\n",
      "Iter=600, loss=1.3974, mse=1.3971, time=0.0404\n",
      "Iter=800, loss=1.3858, mse=1.3855, time=0.0411\n",
      "Iter=1000, loss=1.4415, mse=1.4412, time=0.0410\n",
      "Iter=1200, loss=1.4084, mse=1.4080, time=0.0407\n",
      "Iter=1400, loss=1.3607, mse=1.3604, time=0.0405\n",
      "Iter=1600, loss=1.3770, mse=1.3766, time=0.0405\n",
      "Iter=1800, loss=1.4252, mse=1.4248, time=0.0404\n",
      "Iter=2000, loss=1.3692, mse=1.3688, time=0.0404\n",
      "Iter=2200, loss=1.3964, mse=1.3960, time=0.0403\n",
      "Iter=2400, loss=1.3834, mse=1.3830, time=0.0404\n",
      "Iter=2600, loss=1.3520, mse=1.3516, time=0.0404\n",
      "Iter=2800, loss=1.4062, mse=1.4058, time=0.0404\n",
      "Iter=3000, loss=1.3841, mse=1.3837, time=0.0403\n",
      "Iter=3200, loss=1.4201, mse=1.4198, time=0.0402\n",
      "Iter=3400, loss=1.3753, mse=1.3749, time=0.0402\n",
      "Iter=3600, loss=1.4275, mse=1.4271, time=0.0402\n",
      "Iter=3800, loss=1.3957, mse=1.3954, time=0.0401\n",
      "Iter=4000, loss=1.3894, mse=1.3891, time=0.0402\n",
      "Iter=4200, loss=1.3780, mse=1.3776, time=0.0402\n",
      "Iter=4400, loss=1.4055, mse=1.4051, time=0.0401\n",
      "Iter=4600, loss=1.3729, mse=1.3726, time=0.0401\n",
      "Iter=4800, loss=1.3561, mse=1.3557, time=0.0401\n",
      "Iter=5000, loss=1.3681, mse=1.3678, time=0.0402\n",
      "Iter=5200, loss=1.3859, mse=1.3856, time=0.0403\n",
      "Iter=5400, loss=1.3649, mse=1.3646, time=0.0404\n",
      "Iter=5600, loss=1.3860, mse=1.3856, time=0.0404\n",
      "Iter=5800, loss=1.3917, mse=1.3914, time=0.0403\n",
      "Iter=6000, loss=1.4238, mse=1.4235, time=0.0403\n",
      "Iter=6200, loss=1.3641, mse=1.3637, time=0.0403\n",
      "Iter=6400, loss=1.3909, mse=1.3905, time=0.0403\n",
      "Iter=6600, loss=1.3720, mse=1.3717, time=0.0403\n",
      "=== Epoch 72, train loss 1.387693, test rmse 1.170200 ===\n",
      "Epoch 73\n",
      "Iter=200, loss=1.3786, mse=1.3782, time=0.0425\n",
      "Iter=400, loss=1.3699, mse=1.3696, time=0.0417\n",
      "Iter=600, loss=1.3973, mse=1.3970, time=0.0409\n",
      "Iter=800, loss=1.3666, mse=1.3663, time=0.0406\n",
      "Iter=1000, loss=1.4064, mse=1.4060, time=0.0401\n",
      "Iter=1200, loss=1.3586, mse=1.3582, time=0.0399\n",
      "Iter=1400, loss=1.3791, mse=1.3787, time=0.0399\n",
      "Iter=1600, loss=1.3611, mse=1.3608, time=0.0400\n",
      "Iter=1800, loss=1.3834, mse=1.3830, time=0.0401\n",
      "Iter=2000, loss=1.4198, mse=1.4194, time=0.0401\n",
      "Iter=2200, loss=1.3934, mse=1.3930, time=0.0402\n",
      "Iter=2400, loss=1.3779, mse=1.3775, time=0.0402\n",
      "Iter=2600, loss=1.3996, mse=1.3992, time=0.0402\n",
      "Iter=2800, loss=1.3965, mse=1.3961, time=0.0402\n",
      "Iter=3000, loss=1.4149, mse=1.4146, time=0.0402\n",
      "Iter=3200, loss=1.4019, mse=1.4015, time=0.0401\n",
      "Iter=3400, loss=1.4039, mse=1.4035, time=0.0401\n",
      "Iter=3600, loss=1.3540, mse=1.3536, time=0.0401\n",
      "Iter=3800, loss=1.4037, mse=1.4034, time=0.0401\n",
      "Iter=4000, loss=1.3820, mse=1.3817, time=0.0401\n",
      "Iter=4200, loss=1.3959, mse=1.3955, time=0.0401\n",
      "Iter=4400, loss=1.4197, mse=1.4194, time=0.0401\n",
      "Iter=4600, loss=1.3637, mse=1.3634, time=0.0401\n",
      "Iter=4800, loss=1.3640, mse=1.3637, time=0.0401\n",
      "Iter=5000, loss=1.4198, mse=1.4194, time=0.0400\n",
      "Iter=5200, loss=1.3777, mse=1.3774, time=0.0400\n",
      "Iter=5400, loss=1.3798, mse=1.3794, time=0.0400\n",
      "Iter=5600, loss=1.3782, mse=1.3778, time=0.0399\n",
      "Iter=5800, loss=1.4162, mse=1.4159, time=0.0399\n",
      "Iter=6000, loss=1.3983, mse=1.3980, time=0.0400\n",
      "Iter=6200, loss=1.3918, mse=1.3915, time=0.0399\n",
      "Iter=6400, loss=1.3573, mse=1.3570, time=0.0400\n",
      "Iter=6600, loss=1.3776, mse=1.3772, time=0.0400\n",
      "=== Epoch 73, train loss 1.387670, test rmse 1.164174 ===\n",
      "Epoch 74\n",
      "Iter=200, loss=1.4034, mse=1.4031, time=0.0416\n",
      "Iter=400, loss=1.4040, mse=1.4036, time=0.0411\n",
      "Iter=600, loss=1.3766, mse=1.3763, time=0.0413\n",
      "Iter=800, loss=1.3809, mse=1.3806, time=0.0409\n",
      "Iter=1000, loss=1.3802, mse=1.3798, time=0.0405\n",
      "Iter=1200, loss=1.3732, mse=1.3729, time=0.0405\n",
      "Iter=1400, loss=1.3875, mse=1.3872, time=0.0405\n",
      "Iter=1600, loss=1.3966, mse=1.3963, time=0.0404\n",
      "Iter=1800, loss=1.4020, mse=1.4016, time=0.0404\n",
      "Iter=2000, loss=1.3706, mse=1.3702, time=0.0404\n",
      "Iter=2200, loss=1.3961, mse=1.3957, time=0.0403\n",
      "Iter=2400, loss=1.3946, mse=1.3942, time=0.0404\n",
      "Iter=2600, loss=1.3886, mse=1.3882, time=0.0403\n",
      "Iter=2800, loss=1.3946, mse=1.3942, time=0.0402\n",
      "Iter=3000, loss=1.3634, mse=1.3631, time=0.0401\n",
      "Iter=3200, loss=1.3800, mse=1.3797, time=0.0401\n",
      "Iter=3400, loss=1.3991, mse=1.3988, time=0.0401\n",
      "Iter=3600, loss=1.3873, mse=1.3869, time=0.0400\n",
      "Iter=3800, loss=1.4157, mse=1.4154, time=0.0400\n",
      "Iter=4000, loss=1.4124, mse=1.4120, time=0.0400\n",
      "Iter=4200, loss=1.3569, mse=1.3566, time=0.0399\n",
      "Iter=4400, loss=1.3842, mse=1.3838, time=0.0399\n",
      "Iter=4600, loss=1.3682, mse=1.3678, time=0.0399\n",
      "Iter=4800, loss=1.3841, mse=1.3838, time=0.0399\n",
      "Iter=5000, loss=1.4030, mse=1.4027, time=0.0399\n",
      "Iter=5200, loss=1.3665, mse=1.3662, time=0.0398\n",
      "Iter=5400, loss=1.3849, mse=1.3846, time=0.0398\n",
      "Iter=5600, loss=1.3893, mse=1.3890, time=0.0398\n",
      "Iter=5800, loss=1.3614, mse=1.3611, time=0.0398\n",
      "Iter=6000, loss=1.4069, mse=1.4065, time=0.0398\n",
      "Iter=6200, loss=1.3796, mse=1.3792, time=0.0399\n",
      "Iter=6400, loss=1.3899, mse=1.3895, time=0.0399\n",
      "Iter=6600, loss=1.3877, mse=1.3873, time=0.0399\n",
      "=== Epoch 74, train loss 1.387169, test rmse 1.165391 ===\n",
      "Epoch 75\n",
      "Iter=200, loss=1.3676, mse=1.3672, time=0.0421\n",
      "Iter=400, loss=1.3936, mse=1.3932, time=0.0412\n",
      "Iter=600, loss=1.3919, mse=1.3915, time=0.0404\n",
      "Iter=800, loss=1.4026, mse=1.4023, time=0.0400\n",
      "Iter=1000, loss=1.3831, mse=1.3827, time=0.0406\n",
      "Iter=1200, loss=1.3655, mse=1.3651, time=0.0406\n",
      "Iter=1400, loss=1.4489, mse=1.4486, time=0.0407\n",
      "Iter=1600, loss=1.3837, mse=1.3833, time=0.0406\n",
      "Iter=1800, loss=1.3800, mse=1.3797, time=0.0407\n",
      "Iter=2000, loss=1.3937, mse=1.3933, time=0.0407\n",
      "Iter=2200, loss=1.3864, mse=1.3860, time=0.0406\n",
      "Iter=2400, loss=1.4003, mse=1.3999, time=0.0406\n",
      "Iter=2600, loss=1.4065, mse=1.4061, time=0.0406\n",
      "Iter=2800, loss=1.3900, mse=1.3897, time=0.0406\n",
      "Iter=3000, loss=1.3485, mse=1.3481, time=0.0405\n",
      "Iter=3200, loss=1.3983, mse=1.3980, time=0.0405\n",
      "Iter=3400, loss=1.4072, mse=1.4068, time=0.0406\n",
      "Iter=3600, loss=1.3779, mse=1.3775, time=0.0405\n",
      "Iter=3800, loss=1.4061, mse=1.4057, time=0.0405\n",
      "Iter=4000, loss=1.3912, mse=1.3909, time=0.0405\n",
      "Iter=4200, loss=1.4031, mse=1.4027, time=0.0405\n",
      "Iter=4400, loss=1.3604, mse=1.3601, time=0.0405\n",
      "Iter=4600, loss=1.3534, mse=1.3530, time=0.0404\n",
      "Iter=4800, loss=1.3582, mse=1.3578, time=0.0404\n",
      "Iter=5000, loss=1.3995, mse=1.3992, time=0.0404\n",
      "Iter=5200, loss=1.3675, mse=1.3671, time=0.0402\n",
      "Iter=5400, loss=1.3719, mse=1.3715, time=0.0402\n",
      "Iter=5600, loss=1.3971, mse=1.3967, time=0.0403\n",
      "Iter=5800, loss=1.3778, mse=1.3774, time=0.0403\n",
      "Iter=6000, loss=1.3929, mse=1.3926, time=0.0403\n",
      "Iter=6200, loss=1.3909, mse=1.3906, time=0.0404\n",
      "Iter=6400, loss=1.4066, mse=1.4062, time=0.0404\n",
      "Iter=6600, loss=1.3614, mse=1.3611, time=0.0403\n",
      "=== Epoch 75, train loss 1.387379, test rmse 1.166696 ===\n",
      "Epoch 76\n",
      "Iter=200, loss=1.4307, mse=1.4303, time=0.0429\n",
      "Iter=400, loss=1.3845, mse=1.3841, time=0.0413\n",
      "Iter=600, loss=1.4230, mse=1.4226, time=0.0409\n",
      "Iter=800, loss=1.3754, mse=1.3750, time=0.0404\n",
      "Iter=1000, loss=1.4146, mse=1.4142, time=0.0403\n",
      "Iter=1200, loss=1.3320, mse=1.3316, time=0.0403\n",
      "Iter=1400, loss=1.3639, mse=1.3635, time=0.0404\n",
      "Iter=1600, loss=1.4050, mse=1.4047, time=0.0403\n",
      "Iter=1800, loss=1.3938, mse=1.3934, time=0.0403\n",
      "Iter=2000, loss=1.4200, mse=1.4197, time=0.0402\n",
      "Iter=2200, loss=1.3619, mse=1.3616, time=0.0403\n",
      "Iter=2400, loss=1.4110, mse=1.4107, time=0.0403\n",
      "Iter=2600, loss=1.3849, mse=1.3846, time=0.0403\n",
      "Iter=2800, loss=1.3937, mse=1.3934, time=0.0403\n",
      "Iter=3000, loss=1.3935, mse=1.3932, time=0.0402\n",
      "Iter=3200, loss=1.3844, mse=1.3841, time=0.0401\n",
      "Iter=3400, loss=1.3896, mse=1.3893, time=0.0400\n",
      "Iter=3600, loss=1.3899, mse=1.3896, time=0.0399\n",
      "Iter=3800, loss=1.3953, mse=1.3950, time=0.0399\n",
      "Iter=4000, loss=1.4045, mse=1.4042, time=0.0399\n",
      "Iter=4200, loss=1.4070, mse=1.4067, time=0.0399\n",
      "Iter=4400, loss=1.3846, mse=1.3843, time=0.0399\n",
      "Iter=4600, loss=1.3704, mse=1.3700, time=0.0398\n",
      "Iter=4800, loss=1.3867, mse=1.3864, time=0.0398\n",
      "Iter=5000, loss=1.4042, mse=1.4039, time=0.0397\n",
      "Iter=5200, loss=1.3714, mse=1.3711, time=0.0397\n",
      "Iter=5400, loss=1.4089, mse=1.4086, time=0.0397\n",
      "Iter=5600, loss=1.3867, mse=1.3863, time=0.0397\n",
      "Iter=5800, loss=1.3550, mse=1.3546, time=0.0397\n",
      "Iter=6000, loss=1.3864, mse=1.3860, time=0.0397\n",
      "Iter=6200, loss=1.3714, mse=1.3711, time=0.0397\n",
      "Iter=6400, loss=1.3844, mse=1.3840, time=0.0397\n",
      "Iter=6600, loss=1.3626, mse=1.3623, time=0.0397\n",
      "=== Epoch 76, train loss 1.388023, test rmse 1.177480 ===\n",
      "Epoch 77\n",
      "Iter=200, loss=1.3670, mse=1.3666, time=0.0404\n",
      "Iter=400, loss=1.3802, mse=1.3798, time=0.0402\n",
      "Iter=600, loss=1.3759, mse=1.3755, time=0.0401\n",
      "Iter=800, loss=1.3988, mse=1.3985, time=0.0402\n",
      "Iter=1000, loss=1.3880, mse=1.3876, time=0.0402\n",
      "Iter=1200, loss=1.3852, mse=1.3849, time=0.0404\n",
      "Iter=1400, loss=1.3715, mse=1.3712, time=0.0403\n",
      "Iter=1600, loss=1.3852, mse=1.3848, time=0.0403\n",
      "Iter=1800, loss=1.3760, mse=1.3757, time=0.0403\n",
      "Iter=2000, loss=1.3918, mse=1.3915, time=0.0402\n",
      "Iter=2200, loss=1.4172, mse=1.4169, time=0.0403\n",
      "Iter=2400, loss=1.3990, mse=1.3987, time=0.0402\n",
      "Iter=2600, loss=1.3843, mse=1.3839, time=0.0402\n",
      "Iter=2800, loss=1.3874, mse=1.3870, time=0.0402\n",
      "Iter=3000, loss=1.3766, mse=1.3762, time=0.0402\n",
      "Iter=3200, loss=1.4087, mse=1.4084, time=0.0402\n",
      "Iter=3400, loss=1.4035, mse=1.4031, time=0.0401\n",
      "Iter=3600, loss=1.4038, mse=1.4035, time=0.0402\n",
      "Iter=3800, loss=1.3954, mse=1.3950, time=0.0401\n",
      "Iter=4000, loss=1.3434, mse=1.3430, time=0.0401\n",
      "Iter=4200, loss=1.4046, mse=1.4042, time=0.0401\n",
      "Iter=4400, loss=1.3520, mse=1.3517, time=0.0402\n",
      "Iter=4600, loss=1.3899, mse=1.3896, time=0.0401\n",
      "Iter=4800, loss=1.3803, mse=1.3799, time=0.0401\n",
      "Iter=5000, loss=1.3605, mse=1.3602, time=0.0401\n",
      "Iter=5200, loss=1.3532, mse=1.3528, time=0.0401\n",
      "Iter=5400, loss=1.3956, mse=1.3952, time=0.0401\n",
      "Iter=5600, loss=1.3847, mse=1.3844, time=0.0402\n",
      "Iter=5800, loss=1.4090, mse=1.4087, time=0.0402\n",
      "Iter=6000, loss=1.3586, mse=1.3582, time=0.0402\n",
      "Iter=6200, loss=1.3781, mse=1.3778, time=0.0402\n",
      "Iter=6400, loss=1.3999, mse=1.3996, time=0.0402\n",
      "Iter=6600, loss=1.4359, mse=1.4355, time=0.0402\n",
      "=== Epoch 77, train loss 1.385705, test rmse 1.164676 ===\n",
      "Epoch 78\n",
      "Iter=200, loss=1.3752, mse=1.3748, time=0.0433\n",
      "Iter=400, loss=1.4314, mse=1.4310, time=0.0417\n",
      "Iter=600, loss=1.3841, mse=1.3838, time=0.0410\n",
      "Iter=800, loss=1.3774, mse=1.3771, time=0.0410\n",
      "Iter=1000, loss=1.4035, mse=1.4032, time=0.0410\n",
      "Iter=1200, loss=1.3541, mse=1.3538, time=0.0409\n",
      "Iter=1400, loss=1.3990, mse=1.3986, time=0.0409\n",
      "Iter=1600, loss=1.3668, mse=1.3665, time=0.0409\n",
      "Iter=1800, loss=1.3846, mse=1.3843, time=0.0408\n",
      "Iter=2000, loss=1.3952, mse=1.3949, time=0.0409\n",
      "Iter=2200, loss=1.4160, mse=1.4156, time=0.0410\n",
      "Iter=2400, loss=1.4133, mse=1.4129, time=0.0410\n",
      "Iter=2600, loss=1.3715, mse=1.3711, time=0.0410\n",
      "Iter=2800, loss=1.3747, mse=1.3743, time=0.0409\n",
      "Iter=3000, loss=1.3727, mse=1.3723, time=0.0408\n",
      "Iter=3200, loss=1.3801, mse=1.3798, time=0.0407\n",
      "Iter=3400, loss=1.3802, mse=1.3798, time=0.0406\n",
      "Iter=3600, loss=1.3717, mse=1.3713, time=0.0405\n",
      "Iter=3800, loss=1.3676, mse=1.3672, time=0.0405\n",
      "Iter=4000, loss=1.3667, mse=1.3663, time=0.0404\n",
      "Iter=4200, loss=1.4219, mse=1.4215, time=0.0404\n",
      "Iter=4400, loss=1.3995, mse=1.3991, time=0.0403\n",
      "Iter=4600, loss=1.3828, mse=1.3824, time=0.0403\n",
      "Iter=4800, loss=1.3773, mse=1.3769, time=0.0403\n",
      "Iter=5000, loss=1.3793, mse=1.3789, time=0.0404\n",
      "Iter=5200, loss=1.3955, mse=1.3951, time=0.0404\n",
      "Iter=5400, loss=1.3797, mse=1.3793, time=0.0404\n",
      "Iter=5600, loss=1.4017, mse=1.4013, time=0.0404\n",
      "Iter=5800, loss=1.3892, mse=1.3888, time=0.0404\n",
      "Iter=6000, loss=1.3859, mse=1.3856, time=0.0404\n",
      "Iter=6200, loss=1.3779, mse=1.3776, time=0.0404\n",
      "Iter=6400, loss=1.3927, mse=1.3923, time=0.0404\n",
      "Iter=6600, loss=1.3886, mse=1.3883, time=0.0404\n",
      "=== Epoch 78, train loss 1.386915, test rmse 1.165367 ===\n",
      "Epoch 79\n",
      "Iter=200, loss=1.3681, mse=1.3678, time=0.0421\n",
      "Iter=400, loss=1.3742, mse=1.3739, time=0.0422\n",
      "Iter=600, loss=1.4164, mse=1.4160, time=0.0418\n",
      "Iter=800, loss=1.3517, mse=1.3514, time=0.0412\n",
      "Iter=1000, loss=1.4123, mse=1.4120, time=0.0413\n",
      "Iter=1200, loss=1.4297, mse=1.4293, time=0.0412\n",
      "Iter=1400, loss=1.4119, mse=1.4115, time=0.0412\n",
      "Iter=1600, loss=1.4041, mse=1.4037, time=0.0411\n",
      "Iter=1800, loss=1.3664, mse=1.3660, time=0.0411\n",
      "Iter=2000, loss=1.4125, mse=1.4122, time=0.0410\n",
      "Iter=2200, loss=1.3977, mse=1.3973, time=0.0409\n",
      "Iter=2400, loss=1.3956, mse=1.3953, time=0.0408\n",
      "Iter=2600, loss=1.4073, mse=1.4070, time=0.0407\n",
      "Iter=2800, loss=1.4326, mse=1.4323, time=0.0407\n",
      "Iter=3000, loss=1.3381, mse=1.3377, time=0.0406\n",
      "Iter=3200, loss=1.3936, mse=1.3933, time=0.0407\n",
      "Iter=3400, loss=1.4299, mse=1.4295, time=0.0405\n",
      "Iter=3600, loss=1.3721, mse=1.3718, time=0.0405\n",
      "Iter=3800, loss=1.3541, mse=1.3538, time=0.0404\n",
      "Iter=4000, loss=1.3946, mse=1.3943, time=0.0404\n",
      "Iter=4200, loss=1.3506, mse=1.3503, time=0.0403\n",
      "Iter=4400, loss=1.3804, mse=1.3800, time=0.0403\n",
      "Iter=4600, loss=1.3633, mse=1.3629, time=0.0402\n",
      "Iter=4800, loss=1.4054, mse=1.4050, time=0.0402\n",
      "Iter=5000, loss=1.3907, mse=1.3903, time=0.0402\n",
      "Iter=5200, loss=1.3910, mse=1.3906, time=0.0401\n",
      "Iter=5400, loss=1.3874, mse=1.3871, time=0.0401\n",
      "Iter=5600, loss=1.3714, mse=1.3710, time=0.0400\n",
      "Iter=5800, loss=1.3714, mse=1.3711, time=0.0400\n",
      "Iter=6000, loss=1.3767, mse=1.3764, time=0.0400\n",
      "Iter=6200, loss=1.3868, mse=1.3864, time=0.0400\n",
      "Iter=6400, loss=1.3488, mse=1.3484, time=0.0400\n",
      "Iter=6600, loss=1.4070, mse=1.4066, time=0.0401\n",
      "=== Epoch 79, train loss 1.387586, test rmse 1.166059 ===\n",
      "Training ends. The best testing rmse is 1.161787 at epoch 57\n",
      "  Training epoch took: 8:56:49\n"
     ]
    }
   ],
   "source": [
    "label_type = 'sentiment'\n",
    "\n",
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch_idx in range(1, 80):\n",
    "    print ('Epoch', epoch_idx)\n",
    "    \n",
    "    train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_s, loss_fn, optimizer_s, args.arr_lambda, \n",
    "                                                                   train_loader_s, args.device, args.train_log_interval)\n",
    "    valid_rmse, predict_valid_list, label_valid_list = evaluate(label_type, model_s, valid_loader_s, args.device)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(label_type, model_s, test_loader_s, args.device)\n",
    "    \n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model_s, optimizer_s)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_valid_list = predict_valid_list \n",
    "        best_label_valid_list = label_valid_list\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "\n",
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "35d01f21-2fb5-4361-86ef-ae9cbe7c1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_sentiment_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_sentiment_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "valid_sentiment_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "valid_sentiment_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_sentiment_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_sentiment_df.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2ae60ad8-2da2-4c0a-a74d-37d2d60a19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/rotten_tomato/ensemble/'\n",
    "train_sentiment_df.to_csv(path + 'train_sentiment.csv', index=False)\n",
    "valid_sentiment_df.to_csv(path + 'valid_sentiment.csv', index=False)\n",
    "test_sentiment_df.to_csv(path + 'test_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d6b0c-3aab-4512-8402-77a174a23725",
   "metadata": {},
   "source": [
    "### 3-3. emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d6c37c27-d219-465b-bec2-bc8796d483d8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=200, loss=1.1998, mse=1.1998, time=0.0424\n",
      "Iter=400, loss=1.2266, mse=1.2266, time=0.0413\n",
      "Iter=600, loss=1.2013, mse=1.2013, time=0.0411\n",
      "Iter=800, loss=1.2216, mse=1.2216, time=0.0410\n",
      "Iter=1000, loss=1.2213, mse=1.2213, time=0.0407\n",
      "Iter=1200, loss=1.2352, mse=1.2352, time=0.0402\n",
      "Iter=1400, loss=1.2343, mse=1.2343, time=0.0401\n",
      "Iter=1600, loss=1.2495, mse=1.2495, time=0.0397\n",
      "Iter=1800, loss=1.2810, mse=1.2810, time=0.0394\n",
      "Iter=2000, loss=1.2238, mse=1.2238, time=0.0392\n",
      "Iter=2200, loss=1.1690, mse=1.1690, time=0.0392\n",
      "Iter=2400, loss=1.2587, mse=1.2587, time=0.0391\n",
      "Iter=2600, loss=1.2564, mse=1.2564, time=0.0391\n",
      "Iter=2800, loss=1.2007, mse=1.2007, time=0.0390\n",
      "Iter=3000, loss=1.2310, mse=1.2310, time=0.0389\n",
      "Iter=3200, loss=1.2483, mse=1.2483, time=0.0389\n",
      "Iter=3400, loss=1.2365, mse=1.2365, time=0.0388\n",
      "Iter=3600, loss=1.2541, mse=1.2541, time=0.0388\n",
      "Iter=3800, loss=1.2518, mse=1.2518, time=0.0387\n",
      "Iter=4000, loss=1.2654, mse=1.2654, time=0.0386\n",
      "Iter=4200, loss=1.2160, mse=1.2160, time=0.0385\n",
      "Iter=4400, loss=1.2327, mse=1.2327, time=0.0385\n",
      "Iter=4600, loss=1.1849, mse=1.1849, time=0.0385\n",
      "Iter=4800, loss=1.2725, mse=1.2725, time=0.0384\n",
      "Iter=5000, loss=1.2463, mse=1.2463, time=0.0384\n",
      "Iter=5200, loss=1.2758, mse=1.2758, time=0.0384\n",
      "Iter=5400, loss=1.2662, mse=1.2662, time=0.0384\n",
      "Iter=5600, loss=1.2235, mse=1.2235, time=0.0383\n",
      "Iter=5800, loss=1.2466, mse=1.2466, time=0.0383\n",
      "Iter=6000, loss=1.2327, mse=1.2327, time=0.0384\n",
      "Iter=6200, loss=1.2026, mse=1.2026, time=0.0384\n",
      "Iter=6400, loss=1.2150, mse=1.2150, time=0.0384\n",
      "Iter=6600, loss=1.2533, mse=1.2533, time=0.0384\n",
      "=== Epoch 1, train loss 1.233737, test rmse 1.066802 ===\n",
      "Epoch 2\n",
      "Iter=200, loss=1.2225, mse=1.2225, time=0.0413\n",
      "Iter=400, loss=1.2182, mse=1.2182, time=0.0404\n",
      "Iter=600, loss=1.2750, mse=1.2750, time=0.0399\n",
      "Iter=800, loss=1.2659, mse=1.2659, time=0.0395\n",
      "Iter=1000, loss=1.2307, mse=1.2307, time=0.0394\n",
      "Iter=1200, loss=1.2090, mse=1.2090, time=0.0393\n",
      "Iter=1400, loss=1.2545, mse=1.2545, time=0.0392\n",
      "Iter=1600, loss=1.2266, mse=1.2266, time=0.0391\n",
      "Iter=1800, loss=1.2397, mse=1.2397, time=0.0391\n",
      "Iter=2000, loss=1.2553, mse=1.2553, time=0.0391\n",
      "Iter=2200, loss=1.2670, mse=1.2670, time=0.0391\n",
      "Iter=2400, loss=1.2271, mse=1.2271, time=0.0391\n",
      "Iter=2600, loss=1.2561, mse=1.2561, time=0.0391\n",
      "Iter=2800, loss=1.2494, mse=1.2494, time=0.0390\n",
      "Iter=3000, loss=1.2339, mse=1.2339, time=0.0390\n",
      "Iter=3200, loss=1.1840, mse=1.1840, time=0.0390\n",
      "Iter=3400, loss=1.1907, mse=1.1907, time=0.0390\n",
      "Iter=3600, loss=1.2611, mse=1.2611, time=0.0389\n",
      "Iter=3800, loss=1.2641, mse=1.2641, time=0.0388\n",
      "Iter=4000, loss=1.2682, mse=1.2682, time=0.0387\n",
      "Iter=4200, loss=1.2357, mse=1.2357, time=0.0387\n",
      "Iter=4400, loss=1.2236, mse=1.2236, time=0.0388\n",
      "Iter=4600, loss=1.1814, mse=1.1814, time=0.0388\n",
      "Iter=4800, loss=1.1801, mse=1.1801, time=0.0388\n",
      "Iter=5000, loss=1.2557, mse=1.2557, time=0.0387\n",
      "Iter=5200, loss=1.2122, mse=1.2122, time=0.0387\n",
      "Iter=5400, loss=1.2094, mse=1.2094, time=0.0387\n",
      "Iter=5600, loss=1.2575, mse=1.2575, time=0.0387\n",
      "Iter=5800, loss=1.2280, mse=1.2280, time=0.0387\n",
      "Iter=6000, loss=1.2446, mse=1.2446, time=0.0387\n",
      "Iter=6200, loss=1.2624, mse=1.2624, time=0.0387\n",
      "Iter=6400, loss=1.1938, mse=1.1938, time=0.0387\n",
      "Iter=6600, loss=1.2232, mse=1.2232, time=0.0387\n",
      "=== Epoch 2, train loss 1.233953, test rmse 1.066634 ===\n",
      "Epoch 3\n",
      "Iter=200, loss=1.2377, mse=1.2377, time=0.0416\n",
      "Iter=400, loss=1.2230, mse=1.2230, time=0.0401\n",
      "Iter=600, loss=1.2515, mse=1.2515, time=0.0392\n",
      "Iter=800, loss=1.2391, mse=1.2391, time=0.0388\n",
      "Iter=1000, loss=1.2008, mse=1.2008, time=0.0386\n",
      "Iter=1200, loss=1.2048, mse=1.2048, time=0.0387\n",
      "Iter=1400, loss=1.2259, mse=1.2259, time=0.0386\n",
      "Iter=1600, loss=1.2205, mse=1.2205, time=0.0385\n",
      "Iter=1800, loss=1.2473, mse=1.2473, time=0.0384\n",
      "Iter=2000, loss=1.2538, mse=1.2538, time=0.0384\n",
      "Iter=2200, loss=1.2624, mse=1.2624, time=0.0385\n",
      "Iter=2400, loss=1.2640, mse=1.2640, time=0.0384\n",
      "Iter=2600, loss=1.1738, mse=1.1738, time=0.0385\n",
      "Iter=2800, loss=1.2052, mse=1.2052, time=0.0385\n",
      "Iter=3000, loss=1.2347, mse=1.2347, time=0.0386\n",
      "Iter=3200, loss=1.2625, mse=1.2625, time=0.0386\n",
      "Iter=3400, loss=1.2671, mse=1.2671, time=0.0385\n",
      "Iter=3600, loss=1.2497, mse=1.2497, time=0.0385\n",
      "Iter=3800, loss=1.2183, mse=1.2183, time=0.0385\n",
      "Iter=4000, loss=1.2386, mse=1.2386, time=0.0385\n",
      "Iter=4200, loss=1.2306, mse=1.2306, time=0.0385\n",
      "Iter=4400, loss=1.2481, mse=1.2481, time=0.0385\n",
      "Iter=4600, loss=1.2062, mse=1.2062, time=0.0386\n",
      "Iter=4800, loss=1.2313, mse=1.2313, time=0.0387\n",
      "Iter=5000, loss=1.1964, mse=1.1964, time=0.0386\n",
      "Iter=5200, loss=1.2032, mse=1.2032, time=0.0386\n",
      "Iter=5400, loss=1.2509, mse=1.2509, time=0.0386\n",
      "Iter=5600, loss=1.2289, mse=1.2289, time=0.0386\n",
      "Iter=5800, loss=1.2431, mse=1.2431, time=0.0386\n",
      "Iter=6000, loss=1.2051, mse=1.2051, time=0.0386\n",
      "Iter=6200, loss=1.2439, mse=1.2439, time=0.0386\n",
      "Iter=6400, loss=1.2683, mse=1.2683, time=0.0386\n",
      "Iter=6600, loss=1.2871, mse=1.2871, time=0.0387\n",
      "=== Epoch 3, train loss 1.234537, test rmse 1.067858 ===\n",
      "Epoch 4\n",
      "Iter=200, loss=1.2305, mse=1.2305, time=0.0404\n",
      "Iter=400, loss=1.2615, mse=1.2615, time=0.0391\n",
      "Iter=600, loss=1.2189, mse=1.2189, time=0.0389\n",
      "Iter=800, loss=1.1795, mse=1.1795, time=0.0391\n",
      "Iter=1000, loss=1.1995, mse=1.1995, time=0.0391\n",
      "Iter=1200, loss=1.2432, mse=1.2432, time=0.0390\n",
      "Iter=1400, loss=1.2340, mse=1.2340, time=0.0390\n",
      "Iter=1600, loss=1.2780, mse=1.2780, time=0.0390\n",
      "Iter=1800, loss=1.2233, mse=1.2233, time=0.0390\n",
      "Iter=2000, loss=1.2704, mse=1.2704, time=0.0389\n",
      "Iter=2200, loss=1.2022, mse=1.2022, time=0.0389\n",
      "Iter=2400, loss=1.2027, mse=1.2027, time=0.0389\n",
      "Iter=2600, loss=1.2323, mse=1.2323, time=0.0388\n",
      "Iter=2800, loss=1.2487, mse=1.2487, time=0.0387\n",
      "Iter=3000, loss=1.2227, mse=1.2227, time=0.0387\n",
      "Iter=3200, loss=1.2384, mse=1.2384, time=0.0386\n",
      "Iter=3400, loss=1.2282, mse=1.2282, time=0.0385\n",
      "Iter=3600, loss=1.2404, mse=1.2404, time=0.0385\n",
      "Iter=3800, loss=1.2842, mse=1.2842, time=0.0385\n",
      "Iter=4000, loss=1.3000, mse=1.3000, time=0.0386\n",
      "Iter=4200, loss=1.1779, mse=1.1779, time=0.0385\n",
      "Iter=4400, loss=1.2617, mse=1.2617, time=0.0385\n",
      "Iter=4600, loss=1.2059, mse=1.2059, time=0.0385\n",
      "Iter=4800, loss=1.2544, mse=1.2544, time=0.0385\n",
      "Iter=5000, loss=1.2423, mse=1.2423, time=0.0384\n",
      "Iter=5200, loss=1.2519, mse=1.2519, time=0.0384\n",
      "Iter=5400, loss=1.2355, mse=1.2355, time=0.0384\n",
      "Iter=5600, loss=1.1940, mse=1.1940, time=0.0384\n",
      "Iter=5800, loss=1.2333, mse=1.2333, time=0.0384\n",
      "Iter=6000, loss=1.1981, mse=1.1981, time=0.0384\n",
      "Iter=6200, loss=1.2727, mse=1.2727, time=0.0384\n",
      "Iter=6400, loss=1.1850, mse=1.1850, time=0.0384\n",
      "Iter=6600, loss=1.2516, mse=1.2516, time=0.0384\n",
      "=== Epoch 4, train loss 1.234093, test rmse 1.066177 ===\n",
      "Epoch 5\n",
      "Iter=200, loss=1.2187, mse=1.2187, time=0.0399\n",
      "Iter=400, loss=1.2362, mse=1.2362, time=0.0389\n",
      "Iter=600, loss=1.2257, mse=1.2257, time=0.0389\n",
      "Iter=800, loss=1.2226, mse=1.2226, time=0.0391\n",
      "Iter=1000, loss=1.2332, mse=1.2332, time=0.0390\n",
      "Iter=1200, loss=1.2037, mse=1.2037, time=0.0388\n",
      "Iter=1400, loss=1.2243, mse=1.2243, time=0.0388\n",
      "Iter=1600, loss=1.2246, mse=1.2246, time=0.0388\n",
      "Iter=1800, loss=1.2450, mse=1.2450, time=0.0388\n",
      "Iter=2000, loss=1.2636, mse=1.2636, time=0.0388\n",
      "Iter=2200, loss=1.2457, mse=1.2457, time=0.0386\n",
      "Iter=2400, loss=1.2463, mse=1.2463, time=0.0387\n",
      "Iter=2600, loss=1.2376, mse=1.2376, time=0.0386\n",
      "Iter=2800, loss=1.2461, mse=1.2461, time=0.0387\n",
      "Iter=3000, loss=1.2336, mse=1.2336, time=0.0385\n",
      "Iter=3200, loss=1.1768, mse=1.1768, time=0.0384\n",
      "Iter=3400, loss=1.2217, mse=1.2217, time=0.0384\n",
      "Iter=3600, loss=1.2641, mse=1.2641, time=0.0385\n",
      "Iter=3800, loss=1.2163, mse=1.2163, time=0.0384\n",
      "Iter=4000, loss=1.2542, mse=1.2542, time=0.0383\n",
      "Iter=4200, loss=1.2321, mse=1.2321, time=0.0383\n",
      "Iter=4400, loss=1.2312, mse=1.2312, time=0.0383\n",
      "Iter=4600, loss=1.2524, mse=1.2524, time=0.0383\n",
      "Iter=4800, loss=1.2638, mse=1.2638, time=0.0384\n",
      "Iter=5000, loss=1.2449, mse=1.2449, time=0.0384\n",
      "Iter=5200, loss=1.2130, mse=1.2130, time=0.0384\n",
      "Iter=5400, loss=1.2468, mse=1.2468, time=0.0384\n",
      "Iter=5600, loss=1.2169, mse=1.2169, time=0.0384\n",
      "Iter=5800, loss=1.2657, mse=1.2657, time=0.0385\n",
      "Iter=6000, loss=1.2441, mse=1.2441, time=0.0385\n",
      "Iter=6200, loss=1.2482, mse=1.2482, time=0.0385\n",
      "Iter=6400, loss=1.1956, mse=1.1956, time=0.0385\n",
      "Iter=6600, loss=1.2204, mse=1.2204, time=0.0386\n",
      "=== Epoch 5, train loss 1.234405, test rmse 1.066224 ===\n",
      "Epoch 6\n",
      "Iter=200, loss=1.2287, mse=1.2287, time=0.0406\n",
      "Iter=400, loss=1.2737, mse=1.2737, time=0.0400\n",
      "Iter=600, loss=1.2511, mse=1.2511, time=0.0397\n",
      "Iter=800, loss=1.2398, mse=1.2398, time=0.0396\n",
      "Iter=1000, loss=1.2481, mse=1.2481, time=0.0396\n",
      "Iter=1200, loss=1.2244, mse=1.2244, time=0.0395\n",
      "Iter=1400, loss=1.2381, mse=1.2381, time=0.0393\n",
      "Iter=1600, loss=1.2362, mse=1.2362, time=0.0392\n",
      "Iter=1800, loss=1.2098, mse=1.2098, time=0.0390\n",
      "Iter=2000, loss=1.2009, mse=1.2009, time=0.0389\n",
      "Iter=2200, loss=1.2188, mse=1.2188, time=0.0389\n",
      "Iter=2400, loss=1.2296, mse=1.2296, time=0.0389\n",
      "Iter=2600, loss=1.2552, mse=1.2552, time=0.0388\n",
      "Iter=2800, loss=1.2398, mse=1.2398, time=0.0386\n",
      "Iter=3000, loss=1.2725, mse=1.2725, time=0.0385\n",
      "Iter=3200, loss=1.2669, mse=1.2669, time=0.0384\n",
      "Iter=3400, loss=1.2618, mse=1.2618, time=0.0384\n",
      "Iter=3600, loss=1.2331, mse=1.2331, time=0.0383\n",
      "Iter=3800, loss=1.2230, mse=1.2230, time=0.0382\n",
      "Iter=4000, loss=1.2227, mse=1.2227, time=0.0382\n",
      "Iter=4200, loss=1.2103, mse=1.2103, time=0.0382\n",
      "Iter=4400, loss=1.2343, mse=1.2343, time=0.0382\n",
      "Iter=4600, loss=1.2722, mse=1.2722, time=0.0382\n",
      "Iter=4800, loss=1.2425, mse=1.2425, time=0.0382\n",
      "Iter=5000, loss=1.2064, mse=1.2064, time=0.0382\n",
      "Iter=5200, loss=1.2405, mse=1.2405, time=0.0382\n",
      "Iter=5400, loss=1.2157, mse=1.2157, time=0.0382\n",
      "Iter=5600, loss=1.2129, mse=1.2129, time=0.0382\n",
      "Iter=5800, loss=1.2225, mse=1.2225, time=0.0382\n",
      "Iter=6000, loss=1.2298, mse=1.2298, time=0.0382\n",
      "Iter=6200, loss=1.2662, mse=1.2662, time=0.0382\n",
      "Iter=6400, loss=1.1926, mse=1.1926, time=0.0382\n",
      "Iter=6600, loss=1.2216, mse=1.2216, time=0.0382\n",
      "=== Epoch 6, train loss 1.234200, test rmse 1.066407 ===\n",
      "Epoch 7\n",
      "Iter=200, loss=1.2023, mse=1.2023, time=0.0411\n",
      "Iter=400, loss=1.2298, mse=1.2298, time=0.0400\n",
      "Iter=600, loss=1.1999, mse=1.1999, time=0.0396\n",
      "Iter=800, loss=1.2699, mse=1.2699, time=0.0395\n",
      "Iter=1000, loss=1.1830, mse=1.1830, time=0.0392\n",
      "Iter=1200, loss=1.1884, mse=1.1884, time=0.0391\n",
      "Iter=1400, loss=1.2307, mse=1.2307, time=0.0391\n",
      "Iter=1600, loss=1.2150, mse=1.2150, time=0.0392\n",
      "Iter=1800, loss=1.2055, mse=1.2055, time=0.0392\n",
      "Iter=2000, loss=1.1801, mse=1.1801, time=0.0390\n",
      "Iter=2200, loss=1.2424, mse=1.2424, time=0.0390\n",
      "Iter=2400, loss=1.2258, mse=1.2258, time=0.0389\n",
      "Iter=2600, loss=1.2540, mse=1.2540, time=0.0388\n",
      "Iter=2800, loss=1.2992, mse=1.2992, time=0.0387\n",
      "Iter=3000, loss=1.2966, mse=1.2966, time=0.0387\n",
      "Iter=3200, loss=1.2457, mse=1.2457, time=0.0387\n",
      "Iter=3400, loss=1.2724, mse=1.2724, time=0.0387\n",
      "Iter=3600, loss=1.2502, mse=1.2502, time=0.0388\n",
      "Iter=3800, loss=1.2628, mse=1.2628, time=0.0388\n",
      "Iter=4000, loss=1.1903, mse=1.1903, time=0.0388\n",
      "Iter=4200, loss=1.2188, mse=1.2188, time=0.0388\n",
      "Iter=4400, loss=1.2463, mse=1.2463, time=0.0389\n",
      "Iter=4600, loss=1.2732, mse=1.2732, time=0.0390\n",
      "Iter=4800, loss=1.2602, mse=1.2602, time=0.0390\n",
      "Iter=5000, loss=1.2607, mse=1.2607, time=0.0390\n",
      "Iter=5200, loss=1.2364, mse=1.2364, time=0.0389\n",
      "Iter=5400, loss=1.2475, mse=1.2475, time=0.0389\n",
      "Iter=5600, loss=1.2422, mse=1.2422, time=0.0389\n",
      "Iter=5800, loss=1.2415, mse=1.2415, time=0.0389\n",
      "Iter=6000, loss=1.1776, mse=1.1776, time=0.0389\n",
      "Iter=6200, loss=1.2321, mse=1.2321, time=0.0389\n",
      "Iter=6400, loss=1.2265, mse=1.2265, time=0.0389\n",
      "Iter=6600, loss=1.2401, mse=1.2401, time=0.0389\n",
      "=== Epoch 7, train loss 1.234044, test rmse 1.066081 ===\n",
      "Epoch 8\n",
      "Iter=200, loss=1.2488, mse=1.2488, time=0.0412\n",
      "Iter=400, loss=1.2212, mse=1.2212, time=0.0402\n",
      "Iter=600, loss=1.2634, mse=1.2634, time=0.0399\n",
      "Iter=800, loss=1.2392, mse=1.2392, time=0.0397\n",
      "Iter=1000, loss=1.2720, mse=1.2720, time=0.0395\n",
      "Iter=1200, loss=1.2007, mse=1.2007, time=0.0392\n",
      "Iter=1400, loss=1.1835, mse=1.1835, time=0.0391\n",
      "Iter=1600, loss=1.2186, mse=1.2186, time=0.0392\n",
      "Iter=1800, loss=1.1980, mse=1.1980, time=0.0390\n",
      "Iter=2000, loss=1.2822, mse=1.2822, time=0.0390\n",
      "Iter=2200, loss=1.2609, mse=1.2609, time=0.0389\n",
      "Iter=2400, loss=1.1926, mse=1.1926, time=0.0387\n",
      "Iter=2600, loss=1.2274, mse=1.2274, time=0.0387\n",
      "Iter=2800, loss=1.2694, mse=1.2694, time=0.0387\n",
      "Iter=3000, loss=1.2434, mse=1.2434, time=0.0387\n",
      "Iter=3200, loss=1.1622, mse=1.1622, time=0.0386\n",
      "Iter=3400, loss=1.2057, mse=1.2057, time=0.0386\n",
      "Iter=3600, loss=1.2385, mse=1.2385, time=0.0386\n",
      "Iter=3800, loss=1.2532, mse=1.2532, time=0.0386\n",
      "Iter=4000, loss=1.2332, mse=1.2332, time=0.0386\n",
      "Iter=4200, loss=1.2432, mse=1.2432, time=0.0385\n",
      "Iter=4400, loss=1.2335, mse=1.2335, time=0.0385\n",
      "Iter=4600, loss=1.2803, mse=1.2803, time=0.0385\n",
      "Iter=4800, loss=1.2183, mse=1.2183, time=0.0386\n",
      "Iter=5000, loss=1.1934, mse=1.1934, time=0.0386\n",
      "Iter=5200, loss=1.2477, mse=1.2477, time=0.0387\n",
      "Iter=5400, loss=1.2283, mse=1.2283, time=0.0387\n",
      "Iter=5600, loss=1.1932, mse=1.1932, time=0.0387\n",
      "Iter=5800, loss=1.2559, mse=1.2559, time=0.0386\n",
      "Iter=6000, loss=1.2336, mse=1.2336, time=0.0386\n",
      "Iter=6200, loss=1.2531, mse=1.2531, time=0.0386\n",
      "Iter=6400, loss=1.2547, mse=1.2547, time=0.0386\n",
      "Iter=6600, loss=1.2556, mse=1.2556, time=0.0386\n",
      "=== Epoch 8, train loss 1.234227, test rmse 1.067471 ===\n",
      "Epoch 9\n",
      "Iter=200, loss=1.2397, mse=1.2397, time=0.0407\n",
      "Iter=400, loss=1.2079, mse=1.2079, time=0.0394\n",
      "Iter=600, loss=1.1939, mse=1.1939, time=0.0389\n",
      "Iter=800, loss=1.1910, mse=1.1910, time=0.0386\n",
      "Iter=1000, loss=1.2322, mse=1.2322, time=0.0385\n",
      "Iter=1200, loss=1.2604, mse=1.2604, time=0.0384\n",
      "Iter=1400, loss=1.2313, mse=1.2313, time=0.0387\n",
      "Iter=1600, loss=1.2424, mse=1.2424, time=0.0387\n",
      "Iter=1800, loss=1.2384, mse=1.2384, time=0.0386\n",
      "Iter=2000, loss=1.2507, mse=1.2507, time=0.0385\n",
      "Iter=2200, loss=1.2499, mse=1.2499, time=0.0384\n",
      "Iter=2400, loss=1.2079, mse=1.2079, time=0.0385\n",
      "Iter=2600, loss=1.2309, mse=1.2309, time=0.0386\n",
      "Iter=2800, loss=1.2295, mse=1.2295, time=0.0385\n",
      "Iter=3000, loss=1.2282, mse=1.2282, time=0.0385\n",
      "Iter=3200, loss=1.2052, mse=1.2052, time=0.0386\n",
      "Iter=3400, loss=1.2586, mse=1.2586, time=0.0385\n",
      "Iter=3600, loss=1.2116, mse=1.2116, time=0.0385\n",
      "Iter=3800, loss=1.2556, mse=1.2556, time=0.0385\n",
      "Iter=4000, loss=1.1981, mse=1.1981, time=0.0385\n",
      "Iter=4200, loss=1.2528, mse=1.2528, time=0.0385\n",
      "Iter=4400, loss=1.2527, mse=1.2527, time=0.0384\n",
      "Iter=4600, loss=1.2986, mse=1.2986, time=0.0384\n",
      "Iter=4800, loss=1.2417, mse=1.2417, time=0.0383\n",
      "Iter=5000, loss=1.2075, mse=1.2075, time=0.0383\n",
      "Iter=5200, loss=1.2104, mse=1.2104, time=0.0383\n",
      "Iter=5400, loss=1.2536, mse=1.2536, time=0.0382\n",
      "Iter=5600, loss=1.2494, mse=1.2494, time=0.0382\n",
      "Iter=5800, loss=1.2347, mse=1.2347, time=0.0381\n",
      "Iter=6000, loss=1.1921, mse=1.1921, time=0.0381\n",
      "Iter=6200, loss=1.2323, mse=1.2323, time=0.0382\n",
      "Iter=6400, loss=1.2348, mse=1.2348, time=0.0381\n",
      "Iter=6600, loss=1.2599, mse=1.2599, time=0.0380\n",
      "=== Epoch 9, train loss 1.233967, test rmse 1.066616 ===\n",
      "Epoch 10\n",
      "Iter=200, loss=1.2363, mse=1.2363, time=0.0411\n",
      "Iter=400, loss=1.2356, mse=1.2356, time=0.0397\n",
      "Iter=600, loss=1.1686, mse=1.1686, time=0.0392\n",
      "Iter=800, loss=1.2510, mse=1.2510, time=0.0392\n",
      "Iter=1000, loss=1.2393, mse=1.2393, time=0.0392\n",
      "Iter=1200, loss=1.2241, mse=1.2241, time=0.0391\n",
      "Iter=1400, loss=1.2114, mse=1.2114, time=0.0390\n",
      "Iter=1600, loss=1.2125, mse=1.2125, time=0.0388\n",
      "Iter=1800, loss=1.2251, mse=1.2251, time=0.0387\n",
      "Iter=2000, loss=1.2201, mse=1.2201, time=0.0386\n",
      "Iter=2200, loss=1.2390, mse=1.2390, time=0.0386\n",
      "Iter=2400, loss=1.2486, mse=1.2486, time=0.0386\n",
      "Iter=2600, loss=1.2067, mse=1.2067, time=0.0386\n",
      "Iter=2800, loss=1.2504, mse=1.2504, time=0.0386\n",
      "Iter=3000, loss=1.2254, mse=1.2254, time=0.0385\n",
      "Iter=3200, loss=1.2428, mse=1.2428, time=0.0386\n",
      "Iter=3400, loss=1.2433, mse=1.2433, time=0.0386\n",
      "Iter=3600, loss=1.2353, mse=1.2353, time=0.0386\n",
      "Iter=3800, loss=1.2140, mse=1.2140, time=0.0385\n",
      "Iter=4000, loss=1.2637, mse=1.2637, time=0.0385\n",
      "Iter=4200, loss=1.2820, mse=1.2820, time=0.0386\n",
      "Iter=4400, loss=1.2420, mse=1.2420, time=0.0386\n",
      "Iter=4600, loss=1.2333, mse=1.2333, time=0.0386\n",
      "Iter=4800, loss=1.1795, mse=1.1795, time=0.0386\n",
      "Iter=5000, loss=1.2249, mse=1.2249, time=0.0386\n",
      "Iter=5200, loss=1.2149, mse=1.2149, time=0.0386\n",
      "Iter=5400, loss=1.2686, mse=1.2686, time=0.0386\n",
      "Iter=5600, loss=1.2550, mse=1.2550, time=0.0386\n",
      "Iter=5800, loss=1.2839, mse=1.2839, time=0.0386\n",
      "Iter=6000, loss=1.2015, mse=1.2015, time=0.0386\n",
      "Iter=6200, loss=1.2151, mse=1.2151, time=0.0385\n",
      "Iter=6400, loss=1.2089, mse=1.2089, time=0.0385\n",
      "Iter=6600, loss=1.2733, mse=1.2733, time=0.0385\n",
      "=== Epoch 10, train loss 1.234002, test rmse 1.066484 ===\n",
      "Epoch 11\n",
      "Iter=200, loss=1.2014, mse=1.2014, time=0.0416\n",
      "Iter=400, loss=1.2825, mse=1.2825, time=0.0401\n",
      "Iter=600, loss=1.2126, mse=1.2126, time=0.0393\n",
      "Iter=800, loss=1.2615, mse=1.2615, time=0.0391\n",
      "Iter=1000, loss=1.2657, mse=1.2657, time=0.0390\n",
      "Iter=1200, loss=1.1955, mse=1.1955, time=0.0390\n",
      "Iter=1400, loss=1.2303, mse=1.2303, time=0.0388\n",
      "Iter=1600, loss=1.2289, mse=1.2289, time=0.0386\n",
      "Iter=1800, loss=1.2827, mse=1.2827, time=0.0386\n",
      "Iter=2000, loss=1.2405, mse=1.2405, time=0.0387\n",
      "Iter=2200, loss=1.2556, mse=1.2556, time=0.0388\n",
      "Iter=2400, loss=1.2050, mse=1.2050, time=0.0387\n",
      "Iter=2600, loss=1.2423, mse=1.2423, time=0.0387\n",
      "Iter=2800, loss=1.2702, mse=1.2702, time=0.0387\n",
      "Iter=3000, loss=1.2246, mse=1.2246, time=0.0387\n",
      "Iter=3200, loss=1.1711, mse=1.1711, time=0.0387\n",
      "Iter=3400, loss=1.2249, mse=1.2249, time=0.0387\n",
      "Iter=3600, loss=1.2302, mse=1.2302, time=0.0387\n",
      "Iter=3800, loss=1.2204, mse=1.2204, time=0.0387\n",
      "Iter=4000, loss=1.1695, mse=1.1695, time=0.0388\n",
      "Iter=4200, loss=1.3055, mse=1.3055, time=0.0387\n",
      "Iter=4400, loss=1.2409, mse=1.2409, time=0.0387\n",
      "Iter=4600, loss=1.2672, mse=1.2672, time=0.0387\n",
      "Iter=4800, loss=1.2266, mse=1.2266, time=0.0387\n",
      "Iter=5000, loss=1.2211, mse=1.2211, time=0.0387\n",
      "Iter=5200, loss=1.2521, mse=1.2521, time=0.0386\n",
      "Iter=5400, loss=1.2512, mse=1.2512, time=0.0386\n",
      "Iter=5600, loss=1.2209, mse=1.2209, time=0.0386\n",
      "Iter=5800, loss=1.2000, mse=1.2000, time=0.0385\n",
      "Iter=6000, loss=1.2655, mse=1.2655, time=0.0384\n",
      "Iter=6200, loss=1.2214, mse=1.2214, time=0.0384\n",
      "Iter=6400, loss=1.2278, mse=1.2278, time=0.0385\n",
      "Iter=6600, loss=1.2146, mse=1.2146, time=0.0385\n",
      "=== Epoch 11, train loss 1.234410, test rmse 1.066739 ===\n",
      "Epoch 12\n",
      "Iter=200, loss=1.2075, mse=1.2075, time=0.0428\n",
      "Iter=400, loss=1.2504, mse=1.2504, time=0.0411\n",
      "Iter=600, loss=1.2260, mse=1.2260, time=0.0402\n",
      "Iter=800, loss=1.1962, mse=1.1962, time=0.0399\n",
      "Iter=1000, loss=1.1950, mse=1.1950, time=0.0397\n",
      "Iter=1200, loss=1.2257, mse=1.2257, time=0.0392\n",
      "Iter=1400, loss=1.2270, mse=1.2270, time=0.0388\n",
      "Iter=1600, loss=1.2660, mse=1.2660, time=0.0387\n",
      "Iter=1800, loss=1.2261, mse=1.2261, time=0.0388\n",
      "Iter=2000, loss=1.2518, mse=1.2518, time=0.0388\n",
      "Iter=2200, loss=1.2980, mse=1.2980, time=0.0389\n",
      "Iter=2400, loss=1.2589, mse=1.2589, time=0.0389\n",
      "Iter=2600, loss=1.2882, mse=1.2882, time=0.0388\n",
      "Iter=2800, loss=1.2069, mse=1.2069, time=0.0388\n",
      "Iter=3000, loss=1.1951, mse=1.1951, time=0.0389\n",
      "Iter=3200, loss=1.2167, mse=1.2167, time=0.0389\n",
      "Iter=3400, loss=1.2519, mse=1.2519, time=0.0390\n",
      "Iter=3600, loss=1.2178, mse=1.2178, time=0.0390\n",
      "Iter=3800, loss=1.1818, mse=1.1818, time=0.0390\n",
      "Iter=4000, loss=1.2234, mse=1.2234, time=0.0390\n",
      "Iter=4200, loss=1.2098, mse=1.2098, time=0.0390\n",
      "Iter=4400, loss=1.2326, mse=1.2326, time=0.0390\n",
      "Iter=4600, loss=1.2630, mse=1.2630, time=0.0389\n",
      "Iter=4800, loss=1.2537, mse=1.2537, time=0.0389\n",
      "Iter=5000, loss=1.2475, mse=1.2475, time=0.0389\n",
      "Iter=5200, loss=1.2182, mse=1.2182, time=0.0389\n",
      "Iter=5400, loss=1.2497, mse=1.2497, time=0.0389\n",
      "Iter=5600, loss=1.2162, mse=1.2162, time=0.0389\n",
      "Iter=5800, loss=1.2687, mse=1.2687, time=0.0389\n",
      "Iter=6000, loss=1.2349, mse=1.2349, time=0.0388\n",
      "Iter=6200, loss=1.2317, mse=1.2317, time=0.0388\n",
      "Iter=6400, loss=1.2722, mse=1.2722, time=0.0388\n",
      "Iter=6600, loss=1.2300, mse=1.2300, time=0.0388\n",
      "=== Epoch 12, train loss 1.234319, test rmse 1.066493 ===\n",
      "Epoch 13\n",
      "Iter=200, loss=1.2052, mse=1.2052, time=0.0398\n",
      "Iter=400, loss=1.2626, mse=1.2626, time=0.0390\n",
      "Iter=600, loss=1.2639, mse=1.2639, time=0.0393\n",
      "Iter=800, loss=1.2218, mse=1.2218, time=0.0392\n",
      "Iter=1000, loss=1.2507, mse=1.2507, time=0.0389\n",
      "Iter=1200, loss=1.2396, mse=1.2396, time=0.0388\n",
      "Iter=1400, loss=1.2574, mse=1.2574, time=0.0386\n",
      "Iter=1600, loss=1.2189, mse=1.2189, time=0.0386\n",
      "Iter=1800, loss=1.1994, mse=1.1994, time=0.0385\n",
      "Iter=2000, loss=1.2109, mse=1.2109, time=0.0386\n",
      "Iter=2200, loss=1.2448, mse=1.2448, time=0.0385\n",
      "Iter=2400, loss=1.2678, mse=1.2678, time=0.0385\n",
      "Iter=2600, loss=1.1944, mse=1.1944, time=0.0385\n",
      "Iter=2800, loss=1.2475, mse=1.2475, time=0.0385\n",
      "Iter=3000, loss=1.2236, mse=1.2236, time=0.0385\n",
      "Iter=3200, loss=1.2775, mse=1.2775, time=0.0385\n",
      "Iter=3400, loss=1.2073, mse=1.2073, time=0.0385\n",
      "Iter=3600, loss=1.2221, mse=1.2221, time=0.0385\n",
      "Iter=3800, loss=1.2017, mse=1.2017, time=0.0384\n",
      "Iter=4000, loss=1.2118, mse=1.2118, time=0.0384\n",
      "Iter=4200, loss=1.2075, mse=1.2075, time=0.0383\n",
      "Iter=4400, loss=1.2925, mse=1.2925, time=0.0383\n",
      "Iter=4600, loss=1.2168, mse=1.2168, time=0.0383\n",
      "Iter=4800, loss=1.2437, mse=1.2437, time=0.0383\n",
      "Iter=5000, loss=1.2003, mse=1.2003, time=0.0383\n",
      "Iter=5200, loss=1.2286, mse=1.2286, time=0.0383\n",
      "Iter=5400, loss=1.2516, mse=1.2516, time=0.0383\n",
      "Iter=5600, loss=1.2563, mse=1.2563, time=0.0382\n",
      "Iter=5800, loss=1.2299, mse=1.2299, time=0.0381\n",
      "Iter=6000, loss=1.2643, mse=1.2643, time=0.0381\n",
      "Iter=6200, loss=1.2396, mse=1.2396, time=0.0380\n",
      "Iter=6400, loss=1.2206, mse=1.2206, time=0.0380\n",
      "Iter=6600, loss=1.2469, mse=1.2469, time=0.0380\n",
      "=== Epoch 13, train loss 1.234168, test rmse 1.066070 ===\n",
      "Epoch 14\n",
      "Iter=200, loss=1.2535, mse=1.2535, time=0.0407\n",
      "Iter=400, loss=1.2508, mse=1.2508, time=0.0394\n",
      "Iter=600, loss=1.2179, mse=1.2179, time=0.0389\n",
      "Iter=800, loss=1.2357, mse=1.2357, time=0.0387\n",
      "Iter=1000, loss=1.2142, mse=1.2142, time=0.0382\n",
      "Iter=1200, loss=1.2462, mse=1.2462, time=0.0380\n",
      "Iter=1400, loss=1.2331, mse=1.2331, time=0.0382\n",
      "Iter=1600, loss=1.2456, mse=1.2456, time=0.0382\n",
      "Iter=1800, loss=1.2074, mse=1.2074, time=0.0383\n",
      "Iter=2000, loss=1.2040, mse=1.2040, time=0.0384\n",
      "Iter=2200, loss=1.2610, mse=1.2610, time=0.0385\n",
      "Iter=2400, loss=1.2387, mse=1.2387, time=0.0384\n",
      "Iter=2600, loss=1.2119, mse=1.2119, time=0.0384\n",
      "Iter=2800, loss=1.2335, mse=1.2335, time=0.0385\n",
      "Iter=3000, loss=1.2238, mse=1.2238, time=0.0385\n",
      "Iter=3200, loss=1.2345, mse=1.2345, time=0.0385\n",
      "Iter=3400, loss=1.1908, mse=1.1908, time=0.0385\n",
      "Iter=3600, loss=1.2183, mse=1.2183, time=0.0386\n",
      "Iter=3800, loss=1.2585, mse=1.2585, time=0.0387\n",
      "Iter=4000, loss=1.2437, mse=1.2437, time=0.0387\n",
      "Iter=4200, loss=1.2301, mse=1.2301, time=0.0387\n",
      "Iter=4400, loss=1.2586, mse=1.2586, time=0.0386\n",
      "Iter=4600, loss=1.2615, mse=1.2615, time=0.0387\n",
      "Iter=4800, loss=1.2436, mse=1.2436, time=0.0387\n",
      "Iter=5000, loss=1.2202, mse=1.2202, time=0.0387\n",
      "Iter=5200, loss=1.2610, mse=1.2610, time=0.0387\n",
      "Iter=5400, loss=1.2350, mse=1.2350, time=0.0388\n",
      "Iter=5600, loss=1.2165, mse=1.2165, time=0.0387\n",
      "Iter=5800, loss=1.2283, mse=1.2283, time=0.0387\n",
      "Iter=6000, loss=1.2558, mse=1.2558, time=0.0388\n",
      "Iter=6200, loss=1.1935, mse=1.1935, time=0.0388\n",
      "Iter=6400, loss=1.2763, mse=1.2763, time=0.0388\n",
      "Iter=6600, loss=1.2420, mse=1.2420, time=0.0388\n",
      "=== Epoch 14, train loss 1.233743, test rmse 1.066129 ===\n",
      "Epoch 15\n",
      "Iter=200, loss=1.2771, mse=1.2771, time=0.0405\n",
      "Iter=400, loss=1.2429, mse=1.2429, time=0.0396\n",
      "Iter=600, loss=1.2503, mse=1.2503, time=0.0394\n",
      "Iter=800, loss=1.2458, mse=1.2458, time=0.0391\n",
      "Iter=1000, loss=1.2367, mse=1.2367, time=0.0387\n",
      "Iter=1200, loss=1.2649, mse=1.2649, time=0.0387\n",
      "Iter=1400, loss=1.1828, mse=1.1828, time=0.0386\n",
      "Iter=1600, loss=1.2527, mse=1.2527, time=0.0386\n",
      "Iter=1800, loss=1.2425, mse=1.2425, time=0.0386\n",
      "Iter=2000, loss=1.2474, mse=1.2474, time=0.0387\n",
      "Iter=2200, loss=1.2309, mse=1.2309, time=0.0387\n",
      "Iter=2400, loss=1.2543, mse=1.2543, time=0.0387\n",
      "Iter=2600, loss=1.2288, mse=1.2288, time=0.0387\n",
      "Iter=2800, loss=1.2296, mse=1.2296, time=0.0387\n",
      "Iter=3000, loss=1.2104, mse=1.2104, time=0.0387\n",
      "Iter=3200, loss=1.2263, mse=1.2263, time=0.0387\n",
      "Iter=3400, loss=1.2405, mse=1.2405, time=0.0387\n",
      "Iter=3600, loss=1.2308, mse=1.2308, time=0.0387\n",
      "Iter=3800, loss=1.1917, mse=1.1917, time=0.0386\n",
      "Iter=4000, loss=1.2436, mse=1.2436, time=0.0387\n",
      "Iter=4200, loss=1.2569, mse=1.2569, time=0.0386\n",
      "Iter=4400, loss=1.2423, mse=1.2423, time=0.0387\n",
      "Iter=4600, loss=1.2262, mse=1.2262, time=0.0388\n",
      "Iter=4800, loss=1.2256, mse=1.2256, time=0.0388\n",
      "Iter=5000, loss=1.2255, mse=1.2255, time=0.0388\n",
      "Iter=5200, loss=1.2312, mse=1.2312, time=0.0388\n",
      "Iter=5400, loss=1.2320, mse=1.2320, time=0.0387\n",
      "Iter=5600, loss=1.2424, mse=1.2424, time=0.0387\n",
      "Iter=5800, loss=1.2095, mse=1.2095, time=0.0387\n",
      "Iter=6000, loss=1.2440, mse=1.2440, time=0.0387\n",
      "Iter=6200, loss=1.2791, mse=1.2791, time=0.0387\n",
      "Iter=6400, loss=1.2313, mse=1.2313, time=0.0387\n",
      "Iter=6600, loss=1.1937, mse=1.1937, time=0.0387\n",
      "=== Epoch 15, train loss 1.234560, test rmse 1.067449 ===\n",
      "Epoch 16\n",
      "Iter=200, loss=1.2768, mse=1.2768, time=0.0438\n",
      "Iter=400, loss=1.2172, mse=1.2172, time=0.0412\n",
      "Iter=600, loss=1.2157, mse=1.2157, time=0.0397\n",
      "Iter=800, loss=1.2831, mse=1.2831, time=0.0393\n",
      "Iter=1000, loss=1.2390, mse=1.2390, time=0.0392\n",
      "Iter=1200, loss=1.2080, mse=1.2080, time=0.0392\n",
      "Iter=1400, loss=1.2541, mse=1.2541, time=0.0394\n",
      "Iter=1600, loss=1.2889, mse=1.2889, time=0.0393\n",
      "Iter=1800, loss=1.2238, mse=1.2238, time=0.0392\n",
      "Iter=2000, loss=1.2407, mse=1.2407, time=0.0390\n",
      "Iter=2200, loss=1.2648, mse=1.2648, time=0.0390\n",
      "Iter=2400, loss=1.2139, mse=1.2139, time=0.0390\n",
      "Iter=2600, loss=1.2027, mse=1.2027, time=0.0390\n",
      "Iter=2800, loss=1.2217, mse=1.2217, time=0.0390\n",
      "Iter=3000, loss=1.2413, mse=1.2413, time=0.0391\n",
      "Iter=3200, loss=1.2660, mse=1.2660, time=0.0390\n",
      "Iter=3400, loss=1.2409, mse=1.2409, time=0.0390\n",
      "Iter=3600, loss=1.2070, mse=1.2070, time=0.0390\n",
      "Iter=3800, loss=1.2114, mse=1.2114, time=0.0390\n",
      "Iter=4000, loss=1.2414, mse=1.2414, time=0.0390\n",
      "Iter=4200, loss=1.2227, mse=1.2227, time=0.0389\n",
      "Iter=4400, loss=1.2054, mse=1.2054, time=0.0389\n",
      "Iter=4600, loss=1.2105, mse=1.2105, time=0.0388\n",
      "Iter=4800, loss=1.2146, mse=1.2146, time=0.0388\n",
      "Iter=5000, loss=1.2421, mse=1.2421, time=0.0387\n",
      "Iter=5200, loss=1.1908, mse=1.1908, time=0.0387\n",
      "Iter=5400, loss=1.2261, mse=1.2261, time=0.0387\n",
      "Iter=5600, loss=1.2830, mse=1.2830, time=0.0387\n",
      "Iter=5800, loss=1.2675, mse=1.2675, time=0.0387\n",
      "Iter=6000, loss=1.2438, mse=1.2438, time=0.0387\n",
      "Iter=6200, loss=1.2330, mse=1.2330, time=0.0388\n",
      "Iter=6400, loss=1.2244, mse=1.2244, time=0.0388\n",
      "Iter=6600, loss=1.2487, mse=1.2487, time=0.0388\n",
      "=== Epoch 16, train loss 1.234321, test rmse 1.066340 ===\n",
      "Epoch 17\n",
      "Iter=200, loss=1.2425, mse=1.2425, time=0.0400\n",
      "Iter=400, loss=1.2248, mse=1.2248, time=0.0385\n",
      "Iter=600, loss=1.2358, mse=1.2358, time=0.0385\n",
      "Iter=800, loss=1.2233, mse=1.2233, time=0.0388\n",
      "Iter=1000, loss=1.2196, mse=1.2196, time=0.0387\n",
      "Iter=1200, loss=1.2500, mse=1.2500, time=0.0385\n",
      "Iter=1400, loss=1.2040, mse=1.2040, time=0.0383\n",
      "Iter=1600, loss=1.2729, mse=1.2729, time=0.0383\n",
      "Iter=1800, loss=1.2890, mse=1.2890, time=0.0382\n",
      "Iter=2000, loss=1.2333, mse=1.2333, time=0.0382\n",
      "Iter=2200, loss=1.2564, mse=1.2564, time=0.0382\n",
      "Iter=2400, loss=1.2437, mse=1.2437, time=0.0383\n",
      "Iter=2600, loss=1.2262, mse=1.2262, time=0.0383\n",
      "Iter=2800, loss=1.2407, mse=1.2407, time=0.0384\n",
      "Iter=3000, loss=1.2357, mse=1.2357, time=0.0384\n",
      "Iter=3200, loss=1.2561, mse=1.2561, time=0.0383\n",
      "Iter=3400, loss=1.2491, mse=1.2491, time=0.0383\n",
      "Iter=3600, loss=1.2018, mse=1.2018, time=0.0382\n",
      "Iter=3800, loss=1.2269, mse=1.2269, time=0.0382\n",
      "Iter=4000, loss=1.2346, mse=1.2346, time=0.0382\n",
      "Iter=4200, loss=1.2136, mse=1.2136, time=0.0382\n",
      "Iter=4400, loss=1.1937, mse=1.1937, time=0.0383\n",
      "Iter=4600, loss=1.2592, mse=1.2592, time=0.0383\n",
      "Iter=4800, loss=1.2139, mse=1.2139, time=0.0383\n",
      "Iter=5000, loss=1.2243, mse=1.2243, time=0.0382\n",
      "Iter=5200, loss=1.2619, mse=1.2619, time=0.0382\n",
      "Iter=5400, loss=1.2377, mse=1.2377, time=0.0382\n",
      "Iter=5600, loss=1.2286, mse=1.2286, time=0.0383\n",
      "Iter=5800, loss=1.2076, mse=1.2076, time=0.0383\n",
      "Iter=6000, loss=1.2635, mse=1.2635, time=0.0383\n",
      "Iter=6200, loss=1.2192, mse=1.2192, time=0.0383\n",
      "Iter=6400, loss=1.2109, mse=1.2109, time=0.0384\n",
      "Iter=6600, loss=1.2399, mse=1.2399, time=0.0384\n",
      "=== Epoch 17, train loss 1.234449, test rmse 1.066344 ===\n",
      "Epoch 18\n",
      "Iter=200, loss=1.2775, mse=1.2775, time=0.0387\n",
      "Iter=400, loss=1.2379, mse=1.2379, time=0.0383\n",
      "Iter=600, loss=1.1984, mse=1.1984, time=0.0384\n",
      "Iter=800, loss=1.1787, mse=1.1787, time=0.0387\n",
      "Iter=1000, loss=1.2542, mse=1.2542, time=0.0389\n",
      "Iter=1200, loss=1.2451, mse=1.2451, time=0.0389\n",
      "Iter=1400, loss=1.2336, mse=1.2336, time=0.0388\n",
      "Iter=1600, loss=1.2413, mse=1.2413, time=0.0388\n",
      "Iter=1800, loss=1.1976, mse=1.1976, time=0.0388\n",
      "Iter=2000, loss=1.2597, mse=1.2597, time=0.0388\n",
      "Iter=2200, loss=1.2045, mse=1.2045, time=0.0388\n",
      "Iter=2400, loss=1.2454, mse=1.2454, time=0.0389\n",
      "Iter=2600, loss=1.2697, mse=1.2697, time=0.0388\n",
      "Iter=2800, loss=1.2323, mse=1.2323, time=0.0388\n",
      "Iter=3000, loss=1.2352, mse=1.2352, time=0.0387\n",
      "Iter=3200, loss=1.2073, mse=1.2073, time=0.0387\n",
      "Iter=3400, loss=1.2398, mse=1.2398, time=0.0386\n",
      "Iter=3600, loss=1.2706, mse=1.2706, time=0.0387\n",
      "Iter=3800, loss=1.2490, mse=1.2490, time=0.0387\n",
      "Iter=4000, loss=1.2306, mse=1.2306, time=0.0385\n",
      "Iter=4200, loss=1.2447, mse=1.2447, time=0.0385\n",
      "Iter=4400, loss=1.2080, mse=1.2080, time=0.0385\n",
      "Iter=4600, loss=1.1939, mse=1.1939, time=0.0384\n",
      "Iter=4800, loss=1.2740, mse=1.2740, time=0.0383\n",
      "Iter=5000, loss=1.2241, mse=1.2241, time=0.0383\n",
      "Iter=5200, loss=1.2090, mse=1.2090, time=0.0383\n",
      "Iter=5400, loss=1.2454, mse=1.2454, time=0.0383\n",
      "Iter=5600, loss=1.2247, mse=1.2247, time=0.0383\n",
      "Iter=5800, loss=1.2654, mse=1.2654, time=0.0383\n",
      "Iter=6000, loss=1.2284, mse=1.2284, time=0.0383\n",
      "Iter=6200, loss=1.2343, mse=1.2343, time=0.0383\n",
      "Iter=6400, loss=1.2373, mse=1.2373, time=0.0383\n",
      "Iter=6600, loss=1.2429, mse=1.2429, time=0.0384\n",
      "=== Epoch 18, train loss 1.234409, test rmse 1.066406 ===\n",
      "Epoch 19\n",
      "Iter=200, loss=1.2147, mse=1.2147, time=0.0408\n",
      "Iter=400, loss=1.2100, mse=1.2100, time=0.0411\n",
      "Iter=600, loss=1.2164, mse=1.2164, time=0.0411\n",
      "Iter=800, loss=1.2195, mse=1.2195, time=0.0410\n",
      "Iter=1000, loss=1.2454, mse=1.2454, time=0.0411\n",
      "Iter=1200, loss=1.2592, mse=1.2592, time=0.0413\n",
      "Iter=1400, loss=1.2180, mse=1.2180, time=0.0411\n",
      "Iter=1600, loss=1.2014, mse=1.2014, time=0.0411\n",
      "Iter=1800, loss=1.2112, mse=1.2112, time=0.0410\n",
      "Iter=2000, loss=1.2235, mse=1.2235, time=0.0410\n",
      "Iter=2200, loss=1.2407, mse=1.2407, time=0.0410\n",
      "Iter=2400, loss=1.2147, mse=1.2147, time=0.0410\n",
      "Iter=2600, loss=1.2150, mse=1.2150, time=0.0410\n",
      "Iter=2800, loss=1.2423, mse=1.2423, time=0.0409\n",
      "Iter=3000, loss=1.3051, mse=1.3051, time=0.0410\n",
      "Iter=3200, loss=1.2293, mse=1.2293, time=0.0410\n",
      "Iter=3400, loss=1.2077, mse=1.2077, time=0.0410\n",
      "Iter=3600, loss=1.2594, mse=1.2594, time=0.0410\n",
      "Iter=3800, loss=1.2785, mse=1.2785, time=0.0409\n",
      "Iter=4000, loss=1.2616, mse=1.2616, time=0.0407\n",
      "Iter=4200, loss=1.2211, mse=1.2211, time=0.0406\n",
      "Iter=4400, loss=1.2230, mse=1.2230, time=0.0406\n",
      "Iter=4600, loss=1.2752, mse=1.2752, time=0.0406\n",
      "Iter=4800, loss=1.2369, mse=1.2369, time=0.0407\n",
      "Iter=5000, loss=1.2247, mse=1.2247, time=0.0405\n",
      "Iter=5200, loss=1.2534, mse=1.2534, time=0.0405\n",
      "Iter=5400, loss=1.2171, mse=1.2171, time=0.0404\n",
      "Iter=5600, loss=1.2545, mse=1.2545, time=0.0404\n",
      "Iter=5800, loss=1.2178, mse=1.2178, time=0.0403\n",
      "Iter=6000, loss=1.2320, mse=1.2320, time=0.0403\n",
      "Iter=6200, loss=1.2400, mse=1.2400, time=0.0404\n",
      "Iter=6400, loss=1.2197, mse=1.2197, time=0.0403\n",
      "Iter=6600, loss=1.2418, mse=1.2418, time=0.0402\n",
      "=== Epoch 19, train loss 1.234277, test rmse 1.066751 ===\n",
      "Epoch 20\n",
      "Iter=200, loss=1.2028, mse=1.2028, time=0.0454\n",
      "Iter=400, loss=1.2129, mse=1.2129, time=0.0439\n",
      "Iter=600, loss=1.1963, mse=1.1963, time=0.0423\n",
      "Iter=800, loss=1.1978, mse=1.1978, time=0.0415\n",
      "Iter=1000, loss=1.2294, mse=1.2294, time=0.0413\n",
      "Iter=1200, loss=1.2501, mse=1.2501, time=0.0417\n",
      "Iter=1400, loss=1.2443, mse=1.2443, time=0.0415\n",
      "Iter=1600, loss=1.2620, mse=1.2620, time=0.0416\n",
      "Iter=1800, loss=1.2525, mse=1.2525, time=0.0418\n",
      "Iter=2000, loss=1.2880, mse=1.2880, time=0.0427\n",
      "Iter=2200, loss=1.2491, mse=1.2491, time=0.0430\n",
      "Iter=2400, loss=1.1664, mse=1.1664, time=0.0438\n",
      "Iter=2600, loss=1.2299, mse=1.2299, time=0.0437\n",
      "Iter=2800, loss=1.2184, mse=1.2184, time=0.0435\n",
      "Iter=3000, loss=1.2558, mse=1.2558, time=0.0437\n",
      "Iter=3200, loss=1.2015, mse=1.2015, time=0.0436\n",
      "Iter=3400, loss=1.1940, mse=1.1940, time=0.0435\n",
      "Iter=3600, loss=1.2043, mse=1.2043, time=0.0435\n",
      "Iter=3800, loss=1.2459, mse=1.2459, time=0.0434\n",
      "Iter=4000, loss=1.2270, mse=1.2270, time=0.0436\n",
      "Iter=4200, loss=1.2779, mse=1.2779, time=0.0437\n",
      "Iter=4400, loss=1.2818, mse=1.2818, time=0.0437\n",
      "Iter=4600, loss=1.2659, mse=1.2659, time=0.0436\n",
      "Iter=4800, loss=1.2924, mse=1.2924, time=0.0436\n",
      "Iter=5000, loss=1.2794, mse=1.2794, time=0.0436\n",
      "Iter=5200, loss=1.2492, mse=1.2492, time=0.0438\n",
      "Iter=5400, loss=1.2373, mse=1.2373, time=0.0438\n",
      "Iter=5600, loss=1.2515, mse=1.2515, time=0.0439\n",
      "Iter=5800, loss=1.2434, mse=1.2434, time=0.0440\n",
      "Iter=6000, loss=1.2137, mse=1.2137, time=0.0439\n",
      "Iter=6200, loss=1.2109, mse=1.2109, time=0.0440\n",
      "Iter=6400, loss=1.2010, mse=1.2010, time=0.0441\n",
      "Iter=6600, loss=1.2062, mse=1.2062, time=0.0441\n",
      "=== Epoch 20, train loss 1.234373, test rmse 1.066909 ===\n",
      "Epoch 21\n",
      "Iter=200, loss=1.2172, mse=1.2172, time=0.0450\n",
      "Iter=400, loss=1.2353, mse=1.2353, time=0.0443\n",
      "Iter=600, loss=1.2494, mse=1.2494, time=0.0456\n",
      "Iter=800, loss=1.2428, mse=1.2428, time=0.0457\n",
      "Iter=1000, loss=1.2257, mse=1.2257, time=0.0458\n",
      "Iter=1200, loss=1.2454, mse=1.2454, time=0.0457\n",
      "Iter=1400, loss=1.2324, mse=1.2324, time=0.0460\n",
      "Iter=1600, loss=1.2289, mse=1.2289, time=0.0461\n",
      "Iter=1800, loss=1.2231, mse=1.2231, time=0.0458\n",
      "Iter=2000, loss=1.2412, mse=1.2412, time=0.0454\n",
      "Iter=2200, loss=1.2231, mse=1.2231, time=0.0451\n",
      "Iter=2400, loss=1.2488, mse=1.2488, time=0.0449\n",
      "Iter=2600, loss=1.2037, mse=1.2037, time=0.0447\n",
      "Iter=2800, loss=1.2512, mse=1.2512, time=0.0444\n",
      "Iter=3000, loss=1.2367, mse=1.2367, time=0.0443\n",
      "Iter=3200, loss=1.2274, mse=1.2274, time=0.0443\n",
      "Iter=3400, loss=1.2466, mse=1.2466, time=0.0442\n",
      "Iter=3600, loss=1.2217, mse=1.2217, time=0.0440\n",
      "Iter=3800, loss=1.2398, mse=1.2398, time=0.0438\n",
      "Iter=4000, loss=1.2653, mse=1.2653, time=0.0438\n",
      "Iter=4200, loss=1.1855, mse=1.1855, time=0.0438\n",
      "Iter=4400, loss=1.2769, mse=1.2769, time=0.0439\n",
      "Iter=4600, loss=1.2624, mse=1.2624, time=0.0441\n",
      "Iter=4800, loss=1.2348, mse=1.2348, time=0.0445\n",
      "Iter=5000, loss=1.2394, mse=1.2394, time=0.0451\n",
      "Iter=5200, loss=1.1876, mse=1.1876, time=0.0456\n",
      "Iter=5400, loss=1.2447, mse=1.2447, time=0.0461\n",
      "Iter=5600, loss=1.2477, mse=1.2477, time=0.0465\n",
      "Iter=5800, loss=1.2105, mse=1.2105, time=0.0470\n",
      "Iter=6000, loss=1.2620, mse=1.2620, time=0.0473\n",
      "Iter=6200, loss=1.1912, mse=1.1912, time=0.0476\n",
      "Iter=6400, loss=1.2046, mse=1.2046, time=0.0480\n",
      "Iter=6600, loss=1.2901, mse=1.2901, time=0.0485\n",
      "=== Epoch 21, train loss 1.234387, test rmse 1.065909 ===\n",
      "Epoch 22\n",
      "Iter=200, loss=1.1990, mse=1.1990, time=0.0657\n",
      "Iter=400, loss=1.2551, mse=1.2551, time=0.0635\n",
      "Iter=600, loss=1.2428, mse=1.2428, time=0.0628\n",
      "Iter=800, loss=1.2727, mse=1.2727, time=0.0615\n",
      "Iter=1000, loss=1.2258, mse=1.2258, time=0.0611\n",
      "Iter=1200, loss=1.2562, mse=1.2562, time=0.0611\n",
      "Iter=1400, loss=1.2119, mse=1.2119, time=0.0610\n",
      "Iter=1600, loss=1.2873, mse=1.2873, time=0.0610\n",
      "Iter=1800, loss=1.2710, mse=1.2710, time=0.0613\n",
      "Iter=2000, loss=1.2419, mse=1.2419, time=0.0613\n",
      "Iter=2200, loss=1.2344, mse=1.2344, time=0.0613\n",
      "Iter=2400, loss=1.2257, mse=1.2257, time=0.0614\n",
      "Iter=2600, loss=1.2049, mse=1.2049, time=0.0639\n",
      "Iter=2800, loss=1.2576, mse=1.2576, time=0.0650\n",
      "Iter=3000, loss=1.2418, mse=1.2418, time=0.0662\n",
      "Iter=3200, loss=1.2318, mse=1.2318, time=0.0668\n",
      "Iter=3400, loss=1.2308, mse=1.2308, time=0.0668\n",
      "Iter=3600, loss=1.2242, mse=1.2242, time=0.0668\n",
      "Iter=3800, loss=1.2180, mse=1.2180, time=0.0667\n",
      "Iter=4000, loss=1.2050, mse=1.2050, time=0.0665\n",
      "Iter=4200, loss=1.2562, mse=1.2562, time=0.0667\n",
      "Iter=4400, loss=1.2336, mse=1.2336, time=0.0671\n",
      "Iter=4600, loss=1.2364, mse=1.2364, time=0.0672\n",
      "Iter=4800, loss=1.2586, mse=1.2586, time=0.0671\n",
      "Iter=5000, loss=1.2202, mse=1.2202, time=0.0669\n",
      "Iter=5200, loss=1.2406, mse=1.2406, time=0.0667\n",
      "Iter=5400, loss=1.2317, mse=1.2317, time=0.0665\n",
      "Iter=5600, loss=1.2068, mse=1.2068, time=0.0667\n",
      "Iter=5800, loss=1.2284, mse=1.2284, time=0.0667\n",
      "Iter=6000, loss=1.2499, mse=1.2499, time=0.0667\n",
      "Iter=6200, loss=1.2331, mse=1.2331, time=0.0665\n",
      "Iter=6400, loss=1.2108, mse=1.2108, time=0.0665\n",
      "Iter=6600, loss=1.2059, mse=1.2059, time=0.0664\n",
      "=== Epoch 22, train loss 1.234284, test rmse 1.067040 ===\n",
      "Epoch 23\n",
      "Iter=200, loss=1.2690, mse=1.2690, time=0.0699\n",
      "Iter=400, loss=1.2009, mse=1.2009, time=0.0711\n",
      "Iter=600, loss=1.2076, mse=1.2076, time=0.0710\n",
      "Iter=800, loss=1.2506, mse=1.2506, time=0.0696\n",
      "Iter=1000, loss=1.2648, mse=1.2648, time=0.0685\n",
      "Iter=1200, loss=1.2583, mse=1.2583, time=0.0687\n",
      "Iter=1400, loss=1.2216, mse=1.2216, time=0.0692\n",
      "Iter=1600, loss=1.2082, mse=1.2082, time=0.0692\n",
      "Iter=1800, loss=1.1967, mse=1.1967, time=0.0693\n",
      "Iter=2000, loss=1.2200, mse=1.2200, time=0.0687\n",
      "Iter=2200, loss=1.2616, mse=1.2616, time=0.0682\n",
      "Iter=2400, loss=1.2347, mse=1.2347, time=0.0696\n",
      "Iter=2600, loss=1.2625, mse=1.2625, time=0.0700\n",
      "Iter=2800, loss=1.2377, mse=1.2377, time=0.0720\n",
      "Iter=3000, loss=1.2419, mse=1.2419, time=0.0725\n",
      "Iter=3200, loss=1.2452, mse=1.2452, time=0.0724\n",
      "Iter=3400, loss=1.2489, mse=1.2489, time=0.0719\n",
      "Iter=3600, loss=1.2230, mse=1.2230, time=0.0719\n",
      "Iter=3800, loss=1.2319, mse=1.2319, time=0.0714\n",
      "Iter=4000, loss=1.2405, mse=1.2405, time=0.0710\n",
      "Iter=4200, loss=1.1967, mse=1.1967, time=0.0709\n",
      "Iter=4400, loss=1.2103, mse=1.2103, time=0.0711\n",
      "Iter=4600, loss=1.2479, mse=1.2479, time=0.0709\n",
      "Iter=4800, loss=1.2662, mse=1.2662, time=0.0707\n",
      "Iter=5000, loss=1.2306, mse=1.2306, time=0.0707\n",
      "Iter=5200, loss=1.2044, mse=1.2044, time=0.0703\n",
      "Iter=5400, loss=1.2617, mse=1.2617, time=0.0706\n",
      "Iter=5600, loss=1.2100, mse=1.2100, time=0.0701\n",
      "Iter=5800, loss=1.2290, mse=1.2290, time=0.0699\n",
      "Iter=6000, loss=1.2294, mse=1.2294, time=0.0698\n",
      "Iter=6200, loss=1.2449, mse=1.2449, time=0.0695\n",
      "Iter=6400, loss=1.2338, mse=1.2338, time=0.0692\n",
      "Iter=6600, loss=1.2743, mse=1.2743, time=0.0694\n",
      "=== Epoch 23, train loss 1.234593, test rmse 1.066220 ===\n",
      "Epoch 24\n",
      "Iter=200, loss=1.2155, mse=1.2155, time=0.0695\n",
      "Iter=400, loss=1.2119, mse=1.2119, time=0.0691\n",
      "Iter=600, loss=1.2357, mse=1.2357, time=0.0677\n",
      "Iter=800, loss=1.2658, mse=1.2658, time=0.0699\n",
      "Iter=1000, loss=1.2296, mse=1.2296, time=0.0687\n",
      "Iter=1200, loss=1.2300, mse=1.2300, time=0.0683\n",
      "Iter=1400, loss=1.2379, mse=1.2379, time=0.0677\n",
      "Iter=1600, loss=1.2657, mse=1.2657, time=0.0676\n",
      "Iter=1800, loss=1.2631, mse=1.2631, time=0.0673\n",
      "Iter=2000, loss=1.2183, mse=1.2183, time=0.0672\n",
      "Iter=2200, loss=1.2330, mse=1.2330, time=0.0665\n",
      "Iter=2400, loss=1.2440, mse=1.2440, time=0.0666\n",
      "Iter=2600, loss=1.2430, mse=1.2430, time=0.0666\n",
      "Iter=2800, loss=1.2423, mse=1.2423, time=0.0663\n",
      "Iter=3000, loss=1.2068, mse=1.2068, time=0.0662\n",
      "Iter=3200, loss=1.2037, mse=1.2037, time=0.0660\n",
      "Iter=3400, loss=1.2763, mse=1.2763, time=0.0660\n",
      "Iter=3600, loss=1.2586, mse=1.2586, time=0.0657\n",
      "Iter=3800, loss=1.2379, mse=1.2379, time=0.0654\n",
      "Iter=4000, loss=1.2524, mse=1.2524, time=0.0652\n",
      "Iter=4200, loss=1.2262, mse=1.2262, time=0.0648\n",
      "Iter=4400, loss=1.2259, mse=1.2259, time=0.0646\n",
      "Iter=4600, loss=1.2557, mse=1.2557, time=0.0646\n",
      "Iter=4800, loss=1.2518, mse=1.2518, time=0.0644\n",
      "Iter=5000, loss=1.1824, mse=1.1824, time=0.0642\n",
      "Iter=5200, loss=1.2291, mse=1.2291, time=0.0641\n",
      "Iter=5400, loss=1.2100, mse=1.2100, time=0.0639\n",
      "Iter=5600, loss=1.2321, mse=1.2321, time=0.0637\n",
      "Iter=5800, loss=1.2438, mse=1.2438, time=0.0634\n",
      "Iter=6000, loss=1.2261, mse=1.2261, time=0.0633\n",
      "Iter=6200, loss=1.2059, mse=1.2059, time=0.0633\n",
      "Iter=6400, loss=1.2249, mse=1.2249, time=0.0633\n",
      "Iter=6600, loss=1.2173, mse=1.2173, time=0.0635\n",
      "=== Epoch 24, train loss 1.234440, test rmse 1.066350 ===\n",
      "Epoch 25\n",
      "Iter=200, loss=1.2226, mse=1.2226, time=0.0637\n",
      "Iter=400, loss=1.2004, mse=1.2004, time=0.0653\n",
      "Iter=600, loss=1.2377, mse=1.2377, time=0.0700\n",
      "Iter=800, loss=1.2218, mse=1.2218, time=0.0680\n",
      "Iter=1000, loss=1.2233, mse=1.2233, time=0.0679\n",
      "Iter=1200, loss=1.2074, mse=1.2074, time=0.0706\n",
      "Iter=1400, loss=1.1849, mse=1.1849, time=0.0728\n",
      "Iter=1600, loss=1.3163, mse=1.3163, time=0.0760\n",
      "Iter=1800, loss=1.2398, mse=1.2398, time=0.0742\n",
      "Iter=2000, loss=1.2494, mse=1.2494, time=0.0724\n",
      "Iter=2200, loss=1.2559, mse=1.2559, time=0.0729\n",
      "Iter=2400, loss=1.2088, mse=1.2088, time=0.0741\n",
      "Iter=2600, loss=1.2596, mse=1.2596, time=0.0749\n",
      "Iter=2800, loss=1.2560, mse=1.2560, time=0.0765\n",
      "Iter=3000, loss=1.2238, mse=1.2238, time=0.0755\n",
      "Iter=3200, loss=1.2350, mse=1.2350, time=0.0747\n",
      "Iter=3400, loss=1.2764, mse=1.2764, time=0.0764\n",
      "Iter=3600, loss=1.2051, mse=1.2051, time=0.0772\n",
      "Iter=3800, loss=1.2312, mse=1.2312, time=0.0778\n",
      "Iter=4000, loss=1.2501, mse=1.2501, time=0.0783\n",
      "Iter=4200, loss=1.2287, mse=1.2287, time=0.0790\n",
      "Iter=4400, loss=1.2528, mse=1.2528, time=0.0796\n",
      "Iter=4600, loss=1.2233, mse=1.2233, time=0.0802\n",
      "Iter=4800, loss=1.1743, mse=1.1743, time=0.0808\n",
      "Iter=5000, loss=1.2714, mse=1.2714, time=0.0813\n",
      "Iter=5200, loss=1.2828, mse=1.2828, time=0.0819\n",
      "Iter=5400, loss=1.2357, mse=1.2357, time=0.0822\n",
      "Iter=5600, loss=1.2517, mse=1.2517, time=0.0822\n",
      "Iter=5800, loss=1.2293, mse=1.2293, time=0.0822\n",
      "Iter=6000, loss=1.1802, mse=1.1802, time=0.0825\n",
      "Iter=6200, loss=1.2322, mse=1.2322, time=0.0823\n",
      "Iter=6400, loss=1.2389, mse=1.2389, time=0.0829\n",
      "Iter=6600, loss=1.2369, mse=1.2369, time=0.0830\n",
      "=== Epoch 25, train loss 1.234494, test rmse 1.066706 ===\n",
      "Epoch 26\n",
      "Iter=200, loss=1.2660, mse=1.2660, time=0.0864\n",
      "Iter=400, loss=1.1878, mse=1.1878, time=0.0872\n",
      "Iter=600, loss=1.1957, mse=1.1957, time=0.0867\n",
      "Iter=800, loss=1.2668, mse=1.2668, time=0.0838\n",
      "Iter=1000, loss=1.1991, mse=1.1991, time=0.0835\n",
      "Iter=1200, loss=1.2664, mse=1.2664, time=0.0848\n",
      "Iter=1400, loss=1.2375, mse=1.2375, time=0.0853\n",
      "Iter=1600, loss=1.1987, mse=1.1987, time=0.0852\n",
      "Iter=1800, loss=1.2424, mse=1.2424, time=0.0856\n",
      "Iter=2000, loss=1.2416, mse=1.2416, time=0.0845\n",
      "Iter=2200, loss=1.2136, mse=1.2136, time=0.0831\n",
      "Iter=2400, loss=1.2385, mse=1.2385, time=0.0829\n",
      "Iter=2600, loss=1.2381, mse=1.2381, time=0.0833\n",
      "Iter=2800, loss=1.2383, mse=1.2383, time=0.0834\n",
      "Iter=3000, loss=1.2297, mse=1.2297, time=0.0838\n",
      "Iter=3200, loss=1.2439, mse=1.2439, time=0.0843\n",
      "Iter=3400, loss=1.2555, mse=1.2555, time=0.0841\n",
      "Iter=3600, loss=1.2546, mse=1.2546, time=0.0845\n",
      "Iter=3800, loss=1.2270, mse=1.2270, time=0.0846\n",
      "Iter=4000, loss=1.2542, mse=1.2542, time=0.0845\n",
      "Iter=4200, loss=1.2706, mse=1.2706, time=0.0845\n",
      "Iter=4400, loss=1.2249, mse=1.2249, time=0.0845\n",
      "Iter=4600, loss=1.2333, mse=1.2333, time=0.0843\n",
      "Iter=4800, loss=1.2415, mse=1.2415, time=0.0843\n",
      "Iter=5000, loss=1.2466, mse=1.2466, time=0.0843\n",
      "Iter=5200, loss=1.2806, mse=1.2806, time=0.0842\n",
      "Iter=5400, loss=1.2694, mse=1.2694, time=0.0841\n",
      "Iter=5600, loss=1.2171, mse=1.2171, time=0.0841\n",
      "Iter=5800, loss=1.1735, mse=1.1735, time=0.0842\n",
      "Iter=6000, loss=1.2395, mse=1.2395, time=0.0842\n",
      "Iter=6200, loss=1.2433, mse=1.2433, time=0.0841\n",
      "Iter=6400, loss=1.2119, mse=1.2119, time=0.0841\n",
      "Iter=6600, loss=1.1911, mse=1.1911, time=0.0843\n",
      "=== Epoch 26, train loss 1.234361, test rmse 1.066516 ===\n",
      "Epoch 27\n",
      "Iter=200, loss=1.2518, mse=1.2518, time=0.0808\n",
      "Iter=400, loss=1.2052, mse=1.2052, time=0.0842\n",
      "Iter=600, loss=1.3012, mse=1.3012, time=0.0860\n",
      "Iter=800, loss=1.2522, mse=1.2522, time=0.0834\n",
      "Iter=1000, loss=1.2806, mse=1.2806, time=0.0813\n",
      "Iter=1200, loss=1.2439, mse=1.2439, time=0.0802\n",
      "Iter=1400, loss=1.2277, mse=1.2277, time=0.0806\n",
      "Iter=1600, loss=1.1930, mse=1.1930, time=0.0797\n",
      "Iter=1800, loss=1.2085, mse=1.2085, time=0.0798\n",
      "Iter=2000, loss=1.2073, mse=1.2073, time=0.0794\n",
      "Iter=2200, loss=1.2491, mse=1.2491, time=0.0798\n",
      "Iter=2400, loss=1.1904, mse=1.1904, time=0.0804\n",
      "Iter=2600, loss=1.2409, mse=1.2409, time=0.0803\n",
      "Iter=2800, loss=1.2243, mse=1.2243, time=0.0810\n",
      "Iter=3000, loss=1.2304, mse=1.2304, time=0.0808\n",
      "Iter=3200, loss=1.1994, mse=1.1994, time=0.0808\n",
      "Iter=3400, loss=1.2031, mse=1.2031, time=0.0805\n",
      "Iter=3600, loss=1.2109, mse=1.2109, time=0.0804\n",
      "Iter=3800, loss=1.2706, mse=1.2706, time=0.0800\n",
      "Iter=4000, loss=1.2417, mse=1.2417, time=0.0798\n",
      "Iter=4200, loss=1.2556, mse=1.2556, time=0.0799\n",
      "Iter=4400, loss=1.2613, mse=1.2613, time=0.0799\n",
      "Iter=4600, loss=1.2574, mse=1.2574, time=0.0803\n",
      "Iter=4800, loss=1.2085, mse=1.2085, time=0.0806\n",
      "Iter=5000, loss=1.2338, mse=1.2338, time=0.0804\n",
      "Iter=5200, loss=1.2065, mse=1.2065, time=0.0811\n",
      "Iter=5400, loss=1.2446, mse=1.2446, time=0.0806\n",
      "Iter=5600, loss=1.2246, mse=1.2246, time=0.0808\n",
      "Iter=5800, loss=1.1843, mse=1.1843, time=0.0807\n",
      "Iter=6000, loss=1.2499, mse=1.2499, time=0.0804\n",
      "Iter=6200, loss=1.2240, mse=1.2240, time=0.0809\n",
      "Iter=6400, loss=1.2553, mse=1.2553, time=0.0814\n",
      "Iter=6600, loss=1.2882, mse=1.2882, time=0.0816\n",
      "=== Epoch 27, train loss 1.234830, test rmse 1.066077 ===\n",
      "Epoch 28\n",
      "Iter=200, loss=1.2669, mse=1.2669, time=0.0906\n",
      "Iter=400, loss=1.2684, mse=1.2684, time=0.0833\n",
      "Iter=600, loss=1.2148, mse=1.2148, time=0.0841\n",
      "Iter=800, loss=1.2504, mse=1.2504, time=0.0819\n",
      "Iter=1000, loss=1.1635, mse=1.1635, time=0.0828\n",
      "Iter=1200, loss=1.1981, mse=1.1981, time=0.0814\n",
      "Iter=1400, loss=1.2337, mse=1.2337, time=0.0806\n",
      "Iter=1600, loss=1.2516, mse=1.2516, time=0.0815\n",
      "Iter=1800, loss=1.2016, mse=1.2016, time=0.0806\n",
      "Iter=2000, loss=1.2222, mse=1.2222, time=0.0776\n",
      "Iter=2200, loss=1.2152, mse=1.2152, time=0.0748\n",
      "Iter=2400, loss=1.2198, mse=1.2198, time=0.0720\n",
      "Iter=2600, loss=1.1865, mse=1.1865, time=0.0694\n",
      "Iter=2800, loss=1.1787, mse=1.1787, time=0.0674\n",
      "Iter=3000, loss=1.2316, mse=1.2316, time=0.0657\n",
      "Iter=3200, loss=1.2272, mse=1.2272, time=0.0640\n",
      "Iter=3400, loss=1.2244, mse=1.2244, time=0.0628\n",
      "Iter=3600, loss=1.2731, mse=1.2731, time=0.0614\n",
      "Iter=3800, loss=1.2707, mse=1.2707, time=0.0601\n",
      "Iter=4000, loss=1.2445, mse=1.2445, time=0.0590\n",
      "Iter=4200, loss=1.2282, mse=1.2282, time=0.0580\n",
      "Iter=4400, loss=1.2543, mse=1.2543, time=0.0572\n",
      "Iter=4600, loss=1.2386, mse=1.2386, time=0.0563\n",
      "Iter=4800, loss=1.2283, mse=1.2283, time=0.0555\n",
      "Iter=5000, loss=1.2017, mse=1.2017, time=0.0548\n",
      "Iter=5200, loss=1.2683, mse=1.2683, time=0.0541\n",
      "Iter=5400, loss=1.2551, mse=1.2551, time=0.0535\n",
      "Iter=5600, loss=1.2322, mse=1.2322, time=0.0529\n",
      "Iter=5800, loss=1.2625, mse=1.2625, time=0.0525\n",
      "Iter=6000, loss=1.2482, mse=1.2482, time=0.0520\n",
      "Iter=6200, loss=1.2737, mse=1.2737, time=0.0516\n",
      "Iter=6400, loss=1.2585, mse=1.2585, time=0.0512\n",
      "Iter=6600, loss=1.2200, mse=1.2200, time=0.0508\n",
      "=== Epoch 28, train loss 1.234268, test rmse 1.066230 ===\n",
      "Epoch 29\n",
      "Iter=200, loss=1.1835, mse=1.1835, time=0.0414\n",
      "Iter=400, loss=1.2742, mse=1.2742, time=0.0403\n",
      "Iter=600, loss=1.2261, mse=1.2261, time=0.0399\n",
      "Iter=800, loss=1.2192, mse=1.2192, time=0.0398\n",
      "Iter=1000, loss=1.2421, mse=1.2421, time=0.0397\n",
      "Iter=1200, loss=1.2126, mse=1.2126, time=0.0396\n",
      "Iter=1400, loss=1.2687, mse=1.2687, time=0.0395\n",
      "Iter=1600, loss=1.1762, mse=1.1762, time=0.0395\n",
      "Iter=1800, loss=1.2548, mse=1.2548, time=0.0394\n",
      "Iter=2000, loss=1.2472, mse=1.2472, time=0.0393\n",
      "Iter=2200, loss=1.2612, mse=1.2612, time=0.0393\n",
      "Iter=2400, loss=1.2658, mse=1.2658, time=0.0393\n",
      "Iter=2600, loss=1.2211, mse=1.2211, time=0.0393\n",
      "Iter=2800, loss=1.2346, mse=1.2346, time=0.0393\n",
      "Iter=3000, loss=1.2008, mse=1.2008, time=0.0392\n",
      "Iter=3200, loss=1.2359, mse=1.2359, time=0.0392\n",
      "Iter=3400, loss=1.2054, mse=1.2054, time=0.0392\n",
      "Iter=3600, loss=1.2189, mse=1.2189, time=0.0390\n",
      "Iter=3800, loss=1.2997, mse=1.2997, time=0.0390\n",
      "Iter=4000, loss=1.1958, mse=1.1958, time=0.0390\n",
      "Iter=4200, loss=1.2182, mse=1.2182, time=0.0389\n",
      "Iter=4400, loss=1.2697, mse=1.2697, time=0.0389\n",
      "Iter=4600, loss=1.2238, mse=1.2238, time=0.0388\n",
      "Iter=4800, loss=1.2146, mse=1.2146, time=0.0388\n",
      "Iter=5000, loss=1.2628, mse=1.2628, time=0.0388\n",
      "Iter=5200, loss=1.2721, mse=1.2721, time=0.0388\n",
      "Iter=5400, loss=1.2080, mse=1.2080, time=0.0388\n",
      "Iter=5600, loss=1.2426, mse=1.2426, time=0.0388\n",
      "Iter=5800, loss=1.2936, mse=1.2936, time=0.0388\n",
      "Iter=6000, loss=1.2372, mse=1.2372, time=0.0388\n",
      "Iter=6200, loss=1.2202, mse=1.2202, time=0.0388\n",
      "Iter=6400, loss=1.1940, mse=1.1940, time=0.0387\n",
      "Iter=6600, loss=1.2304, mse=1.2304, time=0.0387\n",
      "=== Epoch 29, train loss 1.233970, test rmse 1.066541 ===\n",
      "Epoch 30\n",
      "Iter=200, loss=1.2589, mse=1.2589, time=0.0464\n",
      "Iter=400, loss=1.2019, mse=1.2019, time=0.0444\n",
      "Iter=600, loss=1.2070, mse=1.2070, time=0.0440\n",
      "Iter=800, loss=1.2247, mse=1.2247, time=0.0443\n",
      "Iter=1000, loss=1.2309, mse=1.2309, time=0.0442\n",
      "Iter=1200, loss=1.2323, mse=1.2323, time=0.0444\n",
      "Iter=1400, loss=1.2630, mse=1.2630, time=0.0439\n",
      "Iter=1600, loss=1.2178, mse=1.2178, time=0.0433\n",
      "Iter=1800, loss=1.2465, mse=1.2465, time=0.0432\n",
      "Iter=2000, loss=1.2410, mse=1.2410, time=0.0434\n",
      "Iter=2200, loss=1.2168, mse=1.2168, time=0.0435\n",
      "Iter=2400, loss=1.2246, mse=1.2246, time=0.0434\n",
      "Iter=2600, loss=1.2706, mse=1.2706, time=0.0436\n",
      "Iter=2800, loss=1.2130, mse=1.2130, time=0.0435\n",
      "Iter=3000, loss=1.2582, mse=1.2582, time=0.0434\n",
      "Iter=3200, loss=1.2691, mse=1.2691, time=0.0434\n",
      "Iter=3400, loss=1.2387, mse=1.2387, time=0.0434\n",
      "Iter=3600, loss=1.2174, mse=1.2174, time=0.0433\n",
      "Iter=3800, loss=1.1891, mse=1.1891, time=0.0432\n",
      "Iter=4000, loss=1.2576, mse=1.2576, time=0.0432\n",
      "Iter=4200, loss=1.2765, mse=1.2765, time=0.0432\n",
      "Iter=4400, loss=1.2288, mse=1.2288, time=0.0432\n",
      "Iter=4600, loss=1.2787, mse=1.2787, time=0.0431\n",
      "Iter=4800, loss=1.1980, mse=1.1980, time=0.0431\n",
      "Iter=5000, loss=1.2542, mse=1.2542, time=0.0432\n",
      "Iter=5200, loss=1.2066, mse=1.2066, time=0.0432\n",
      "Iter=5400, loss=1.2197, mse=1.2197, time=0.0432\n",
      "Iter=5600, loss=1.2505, mse=1.2505, time=0.0431\n",
      "Iter=5800, loss=1.2172, mse=1.2172, time=0.0432\n",
      "Iter=6000, loss=1.2532, mse=1.2532, time=0.0433\n",
      "Iter=6200, loss=1.1996, mse=1.1996, time=0.0432\n",
      "Iter=6400, loss=1.2276, mse=1.2276, time=0.0432\n",
      "Iter=6600, loss=1.2114, mse=1.2114, time=0.0431\n",
      "=== Epoch 30, train loss 1.234152, test rmse 1.066812 ===\n",
      "Epoch 31\n",
      "Iter=200, loss=1.2246, mse=1.2246, time=0.0420\n",
      "Iter=400, loss=1.1999, mse=1.1999, time=0.0416\n",
      "Iter=600, loss=1.1964, mse=1.1964, time=0.0413\n",
      "Iter=800, loss=1.2458, mse=1.2458, time=0.0410\n",
      "Iter=1000, loss=1.2528, mse=1.2528, time=0.0408\n",
      "Iter=1200, loss=1.1925, mse=1.1925, time=0.0406\n",
      "Iter=1400, loss=1.1862, mse=1.1862, time=0.0405\n",
      "Iter=1600, loss=1.2695, mse=1.2695, time=0.0404\n",
      "Iter=1800, loss=1.2756, mse=1.2756, time=0.0403\n",
      "Iter=2000, loss=1.2615, mse=1.2615, time=0.0403\n",
      "Iter=2200, loss=1.2634, mse=1.2634, time=0.0402\n",
      "Iter=2400, loss=1.1985, mse=1.1985, time=0.0402\n",
      "Iter=2600, loss=1.2086, mse=1.2086, time=0.0401\n",
      "Iter=2800, loss=1.2680, mse=1.2680, time=0.0401\n",
      "Iter=3000, loss=1.2416, mse=1.2416, time=0.0400\n",
      "Iter=3200, loss=1.2435, mse=1.2435, time=0.0399\n",
      "Iter=3400, loss=1.2170, mse=1.2170, time=0.0399\n",
      "Iter=3600, loss=1.1631, mse=1.1631, time=0.0398\n",
      "Iter=3800, loss=1.2678, mse=1.2678, time=0.0398\n",
      "Iter=4000, loss=1.2052, mse=1.2052, time=0.0398\n",
      "Iter=4200, loss=1.2663, mse=1.2663, time=0.0397\n",
      "Iter=4400, loss=1.2962, mse=1.2962, time=0.0397\n",
      "Iter=4600, loss=1.2571, mse=1.2571, time=0.0395\n",
      "Iter=4800, loss=1.2517, mse=1.2517, time=0.0395\n",
      "Iter=5000, loss=1.2464, mse=1.2464, time=0.0394\n",
      "Iter=5200, loss=1.2710, mse=1.2710, time=0.0394\n",
      "Iter=5400, loss=1.2036, mse=1.2036, time=0.0394\n",
      "Iter=5600, loss=1.2430, mse=1.2430, time=0.0394\n",
      "Iter=5800, loss=1.2263, mse=1.2263, time=0.0394\n",
      "Iter=6000, loss=1.2403, mse=1.2403, time=0.0394\n",
      "Iter=6200, loss=1.2282, mse=1.2282, time=0.0394\n",
      "Iter=6400, loss=1.2136, mse=1.2136, time=0.0393\n",
      "Iter=6600, loss=1.2101, mse=1.2101, time=0.0394\n",
      "=== Epoch 31, train loss 1.234442, test rmse 1.066504 ===\n",
      "Epoch 32\n",
      "Iter=200, loss=1.2755, mse=1.2755, time=0.0435\n",
      "Iter=400, loss=1.2233, mse=1.2233, time=0.0427\n",
      "Iter=600, loss=1.2274, mse=1.2274, time=0.0458\n",
      "Iter=800, loss=1.2516, mse=1.2516, time=0.0468\n",
      "Iter=1000, loss=1.2175, mse=1.2175, time=0.0459\n",
      "Iter=1200, loss=1.2323, mse=1.2323, time=0.0453\n",
      "Iter=1400, loss=1.2026, mse=1.2026, time=0.0445\n",
      "Iter=1600, loss=1.2229, mse=1.2229, time=0.0439\n",
      "Iter=1800, loss=1.2642, mse=1.2642, time=0.0433\n",
      "Iter=2000, loss=1.2398, mse=1.2398, time=0.0429\n",
      "Iter=2200, loss=1.2358, mse=1.2358, time=0.0436\n",
      "Iter=2400, loss=1.2499, mse=1.2499, time=0.0435\n",
      "Iter=2600, loss=1.2085, mse=1.2085, time=0.0436\n",
      "Iter=2800, loss=1.2643, mse=1.2643, time=0.0433\n",
      "Iter=3000, loss=1.2433, mse=1.2433, time=0.0431\n",
      "Iter=3200, loss=1.1870, mse=1.1870, time=0.0429\n",
      "Iter=3400, loss=1.2426, mse=1.2426, time=0.0429\n",
      "Iter=3600, loss=1.2410, mse=1.2410, time=0.0433\n",
      "Iter=3800, loss=1.2270, mse=1.2270, time=0.0442\n",
      "Iter=4000, loss=1.2422, mse=1.2422, time=0.0454\n",
      "Iter=4200, loss=1.2630, mse=1.2630, time=0.0463\n",
      "Iter=4400, loss=1.2454, mse=1.2454, time=0.0464\n",
      "Iter=4600, loss=1.2425, mse=1.2425, time=0.0462\n",
      "Iter=4800, loss=1.2295, mse=1.2295, time=0.0458\n",
      "Iter=5000, loss=1.2795, mse=1.2795, time=0.0455\n",
      "Iter=5200, loss=1.2365, mse=1.2365, time=0.0453\n",
      "Iter=5400, loss=1.1874, mse=1.1874, time=0.0450\n",
      "Iter=5600, loss=1.2718, mse=1.2718, time=0.0448\n",
      "Iter=5800, loss=1.2047, mse=1.2047, time=0.0447\n",
      "Iter=6000, loss=1.2049, mse=1.2049, time=0.0447\n",
      "Iter=6200, loss=1.1860, mse=1.1860, time=0.0448\n",
      "Iter=6400, loss=1.2540, mse=1.2540, time=0.0449\n",
      "Iter=6600, loss=1.2112, mse=1.2112, time=0.0448\n",
      "=== Epoch 32, train loss 1.234621, test rmse 1.066298 ===\n",
      "Epoch 33\n",
      "Iter=200, loss=1.2420, mse=1.2420, time=0.0402\n",
      "Iter=400, loss=1.2287, mse=1.2287, time=0.0391\n",
      "Iter=600, loss=1.2783, mse=1.2783, time=0.0390\n",
      "Iter=800, loss=1.2257, mse=1.2257, time=0.0389\n",
      "Iter=1000, loss=1.2463, mse=1.2463, time=0.0389\n",
      "Iter=1200, loss=1.2369, mse=1.2369, time=0.0388\n",
      "Iter=1400, loss=1.1965, mse=1.1965, time=0.0390\n",
      "Iter=1600, loss=1.2052, mse=1.2052, time=0.0390\n",
      "Iter=1800, loss=1.2203, mse=1.2203, time=0.0389\n",
      "Iter=2000, loss=1.2486, mse=1.2486, time=0.0388\n",
      "Iter=2200, loss=1.2507, mse=1.2507, time=0.0389\n",
      "Iter=2400, loss=1.2617, mse=1.2617, time=0.0391\n",
      "Iter=2600, loss=1.2178, mse=1.2178, time=0.0392\n",
      "Iter=2800, loss=1.2467, mse=1.2467, time=0.0394\n",
      "Iter=3000, loss=1.2456, mse=1.2456, time=0.0398\n",
      "Iter=3200, loss=1.2365, mse=1.2365, time=0.0398\n",
      "Iter=3400, loss=1.1914, mse=1.1914, time=0.0397\n",
      "Iter=3600, loss=1.3110, mse=1.3110, time=0.0396\n",
      "Iter=3800, loss=1.2814, mse=1.2814, time=0.0395\n",
      "Iter=4000, loss=1.2272, mse=1.2272, time=0.0394\n",
      "Iter=4200, loss=1.2091, mse=1.2091, time=0.0393\n",
      "Iter=4400, loss=1.2120, mse=1.2120, time=0.0392\n",
      "Iter=4600, loss=1.2134, mse=1.2134, time=0.0393\n",
      "Iter=4800, loss=1.2666, mse=1.2666, time=0.0391\n",
      "Iter=5000, loss=1.2552, mse=1.2552, time=0.0391\n",
      "Iter=5200, loss=1.2290, mse=1.2290, time=0.0392\n",
      "Iter=5400, loss=1.1978, mse=1.1978, time=0.0392\n",
      "Iter=5600, loss=1.2005, mse=1.2005, time=0.0392\n",
      "Iter=5800, loss=1.2784, mse=1.2784, time=0.0392\n",
      "Iter=6000, loss=1.2221, mse=1.2221, time=0.0392\n",
      "Iter=6200, loss=1.2055, mse=1.2055, time=0.0392\n",
      "Iter=6400, loss=1.2199, mse=1.2199, time=0.0391\n",
      "Iter=6600, loss=1.2367, mse=1.2367, time=0.0391\n",
      "=== Epoch 33, train loss 1.234434, test rmse 1.066873 ===\n",
      "Epoch 34\n",
      "Iter=200, loss=1.2637, mse=1.2637, time=0.0477\n",
      "Iter=400, loss=1.2049, mse=1.2049, time=0.0443\n",
      "Iter=600, loss=1.2216, mse=1.2216, time=0.0428\n",
      "Iter=800, loss=1.2179, mse=1.2179, time=0.0421\n",
      "Iter=1000, loss=1.2391, mse=1.2391, time=0.0416\n",
      "Iter=1200, loss=1.1703, mse=1.1703, time=0.0413\n",
      "Iter=1400, loss=1.2086, mse=1.2086, time=0.0411\n",
      "Iter=1600, loss=1.2126, mse=1.2126, time=0.0409\n",
      "Iter=1800, loss=1.2448, mse=1.2448, time=0.0407\n",
      "Iter=2000, loss=1.2393, mse=1.2393, time=0.0406\n",
      "Iter=2200, loss=1.2355, mse=1.2355, time=0.0405\n",
      "Iter=2400, loss=1.2335, mse=1.2335, time=0.0405\n",
      "Iter=2600, loss=1.2400, mse=1.2400, time=0.0405\n",
      "Iter=2800, loss=1.2453, mse=1.2453, time=0.0406\n",
      "Iter=3000, loss=1.2343, mse=1.2343, time=0.0405\n",
      "Iter=3200, loss=1.2818, mse=1.2818, time=0.0405\n",
      "Iter=3400, loss=1.2482, mse=1.2482, time=0.0404\n",
      "Iter=3600, loss=1.2549, mse=1.2549, time=0.0403\n",
      "Iter=3800, loss=1.2387, mse=1.2387, time=0.0404\n",
      "Iter=4000, loss=1.2458, mse=1.2458, time=0.0405\n",
      "Iter=4200, loss=1.2725, mse=1.2725, time=0.0404\n",
      "Iter=4400, loss=1.2649, mse=1.2649, time=0.0403\n",
      "Iter=4600, loss=1.1997, mse=1.1997, time=0.0403\n",
      "Iter=4800, loss=1.2177, mse=1.2177, time=0.0402\n",
      "Iter=5000, loss=1.2201, mse=1.2201, time=0.0401\n",
      "Iter=5200, loss=1.2058, mse=1.2058, time=0.0401\n",
      "Iter=5400, loss=1.2670, mse=1.2670, time=0.0400\n",
      "Iter=5600, loss=1.2465, mse=1.2465, time=0.0401\n",
      "Iter=5800, loss=1.2216, mse=1.2216, time=0.0402\n",
      "Iter=6000, loss=1.2087, mse=1.2087, time=0.0403\n",
      "Iter=6200, loss=1.2134, mse=1.2134, time=0.0405\n",
      "Iter=6400, loss=1.2151, mse=1.2151, time=0.0406\n",
      "Iter=6600, loss=1.2725, mse=1.2725, time=0.0406\n",
      "=== Epoch 34, train loss 1.234260, test rmse 1.066135 ===\n",
      "Epoch 35\n",
      "Iter=200, loss=1.1965, mse=1.1965, time=0.0414\n",
      "Iter=400, loss=1.2468, mse=1.2468, time=0.0415\n",
      "Iter=600, loss=1.2269, mse=1.2269, time=0.0415\n",
      "Iter=800, loss=1.1983, mse=1.1983, time=0.0428\n",
      "Iter=1000, loss=1.2104, mse=1.2104, time=0.0444\n",
      "Iter=1200, loss=1.2190, mse=1.2190, time=0.0445\n",
      "Iter=1400, loss=1.2223, mse=1.2223, time=0.0441\n",
      "Iter=1600, loss=1.2364, mse=1.2364, time=0.0436\n",
      "Iter=1800, loss=1.2273, mse=1.2273, time=0.0430\n",
      "Iter=2000, loss=1.2238, mse=1.2238, time=0.0428\n",
      "Iter=2200, loss=1.2664, mse=1.2664, time=0.0428\n",
      "Iter=2400, loss=1.3115, mse=1.3115, time=0.0430\n",
      "Iter=2600, loss=1.2326, mse=1.2326, time=0.0432\n",
      "Iter=2800, loss=1.2106, mse=1.2106, time=0.0430\n",
      "Iter=3000, loss=1.2733, mse=1.2733, time=0.0428\n",
      "Iter=3200, loss=1.2345, mse=1.2345, time=0.0426\n",
      "Iter=3400, loss=1.2404, mse=1.2404, time=0.0425\n",
      "Iter=3600, loss=1.2094, mse=1.2094, time=0.0423\n",
      "Iter=3800, loss=1.2127, mse=1.2127, time=0.0422\n",
      "Iter=4000, loss=1.2419, mse=1.2419, time=0.0420\n",
      "Iter=4200, loss=1.2487, mse=1.2487, time=0.0419\n",
      "Iter=4400, loss=1.2328, mse=1.2328, time=0.0418\n",
      "Iter=4600, loss=1.2583, mse=1.2583, time=0.0418\n",
      "Iter=4800, loss=1.2450, mse=1.2450, time=0.0417\n",
      "Iter=5000, loss=1.2047, mse=1.2047, time=0.0416\n",
      "Iter=5200, loss=1.2250, mse=1.2250, time=0.0415\n",
      "Iter=5400, loss=1.2490, mse=1.2490, time=0.0414\n",
      "Iter=5600, loss=1.2137, mse=1.2137, time=0.0415\n",
      "Iter=5800, loss=1.2378, mse=1.2378, time=0.0414\n",
      "Iter=6000, loss=1.2833, mse=1.2833, time=0.0414\n",
      "Iter=6200, loss=1.2520, mse=1.2520, time=0.0414\n",
      "Iter=6400, loss=1.2187, mse=1.2187, time=0.0414\n",
      "Iter=6600, loss=1.2199, mse=1.2199, time=0.0414\n",
      "=== Epoch 35, train loss 1.234868, test rmse 1.066456 ===\n",
      "Epoch 36\n",
      "Iter=200, loss=1.2176, mse=1.2176, time=0.0427\n",
      "Iter=400, loss=1.2472, mse=1.2472, time=0.0411\n",
      "Iter=600, loss=1.2011, mse=1.2011, time=0.0408\n",
      "Iter=800, loss=1.2169, mse=1.2169, time=0.0406\n",
      "Iter=1000, loss=1.2304, mse=1.2304, time=0.0407\n",
      "Iter=1200, loss=1.2478, mse=1.2478, time=0.0407\n",
      "Iter=1400, loss=1.2674, mse=1.2674, time=0.0406\n",
      "Iter=1600, loss=1.2514, mse=1.2514, time=0.0404\n",
      "Iter=1800, loss=1.1967, mse=1.1967, time=0.0405\n",
      "Iter=2000, loss=1.2552, mse=1.2552, time=0.0409\n",
      "Iter=2200, loss=1.1901, mse=1.1901, time=0.0407\n",
      "Iter=2400, loss=1.1712, mse=1.1712, time=0.0408\n",
      "Iter=2600, loss=1.2764, mse=1.2764, time=0.0408\n",
      "Iter=2800, loss=1.2557, mse=1.2557, time=0.0408\n",
      "Iter=3000, loss=1.2360, mse=1.2360, time=0.0408\n",
      "Iter=3200, loss=1.2470, mse=1.2470, time=0.0407\n",
      "Iter=3400, loss=1.2372, mse=1.2372, time=0.0407\n",
      "Iter=3600, loss=1.2548, mse=1.2548, time=0.0412\n",
      "Iter=3800, loss=1.2330, mse=1.2330, time=0.0415\n",
      "Iter=4000, loss=1.2219, mse=1.2219, time=0.0418\n",
      "Iter=4200, loss=1.2675, mse=1.2675, time=0.0419\n",
      "Iter=4400, loss=1.2191, mse=1.2191, time=0.0421\n",
      "Iter=4600, loss=1.2363, mse=1.2363, time=0.0422\n",
      "Iter=4800, loss=1.2347, mse=1.2347, time=0.0422\n",
      "Iter=5000, loss=1.2473, mse=1.2473, time=0.0422\n",
      "Iter=5200, loss=1.2678, mse=1.2678, time=0.0422\n",
      "Iter=5400, loss=1.2476, mse=1.2476, time=0.0422\n",
      "Iter=5600, loss=1.2421, mse=1.2421, time=0.0423\n",
      "Iter=5800, loss=1.1833, mse=1.1833, time=0.0423\n",
      "Iter=6000, loss=1.2509, mse=1.2509, time=0.0425\n",
      "Iter=6200, loss=1.2497, mse=1.2497, time=0.0425\n",
      "Iter=6400, loss=1.1866, mse=1.1866, time=0.0425\n",
      "Iter=6600, loss=1.2498, mse=1.2498, time=0.0424\n",
      "=== Epoch 36, train loss 1.234443, test rmse 1.067180 ===\n",
      "Epoch 37\n",
      "Iter=200, loss=1.2919, mse=1.2919, time=0.0399\n",
      "Iter=400, loss=1.2381, mse=1.2381, time=0.0396\n",
      "Iter=600, loss=1.1858, mse=1.1858, time=0.0397\n",
      "Iter=800, loss=1.2309, mse=1.2309, time=0.0395\n",
      "Iter=1000, loss=1.2225, mse=1.2225, time=0.0397\n",
      "Iter=1200, loss=1.2195, mse=1.2195, time=0.0398\n",
      "Iter=1400, loss=1.2324, mse=1.2324, time=0.0398\n",
      "Iter=1600, loss=1.1906, mse=1.1906, time=0.0398\n",
      "Iter=1800, loss=1.2534, mse=1.2534, time=0.0397\n",
      "Iter=2000, loss=1.2500, mse=1.2500, time=0.0401\n",
      "Iter=2200, loss=1.2750, mse=1.2750, time=0.0405\n",
      "Iter=2400, loss=1.2403, mse=1.2403, time=0.0406\n",
      "Iter=2600, loss=1.2473, mse=1.2473, time=0.0405\n",
      "Iter=2800, loss=1.2465, mse=1.2465, time=0.0406\n",
      "Iter=3000, loss=1.2014, mse=1.2014, time=0.0408\n",
      "Iter=3200, loss=1.2350, mse=1.2350, time=0.0407\n",
      "Iter=3400, loss=1.2202, mse=1.2202, time=0.0408\n",
      "Iter=3600, loss=1.2484, mse=1.2484, time=0.0407\n",
      "Iter=3800, loss=1.2227, mse=1.2227, time=0.0407\n",
      "Iter=4000, loss=1.2439, mse=1.2439, time=0.0406\n",
      "Iter=4200, loss=1.2316, mse=1.2316, time=0.0405\n",
      "Iter=4400, loss=1.2205, mse=1.2205, time=0.0404\n",
      "Iter=4600, loss=1.2479, mse=1.2479, time=0.0403\n",
      "Iter=4800, loss=1.2437, mse=1.2437, time=0.0402\n",
      "Iter=5000, loss=1.1947, mse=1.1947, time=0.0402\n",
      "Iter=5200, loss=1.2813, mse=1.2813, time=0.0403\n",
      "Iter=5400, loss=1.2425, mse=1.2425, time=0.0405\n",
      "Iter=5600, loss=1.2241, mse=1.2241, time=0.0406\n",
      "Iter=5800, loss=1.1980, mse=1.1980, time=0.0407\n",
      "Iter=6000, loss=1.2766, mse=1.2766, time=0.0408\n",
      "Iter=6200, loss=1.1867, mse=1.1867, time=0.0408\n",
      "Iter=6400, loss=1.1887, mse=1.1887, time=0.0408\n",
      "Iter=6600, loss=1.2946, mse=1.2946, time=0.0408\n",
      "=== Epoch 37, train loss 1.234432, test rmse 1.065923 ===\n",
      "Epoch 38\n",
      "Iter=200, loss=1.2213, mse=1.2213, time=0.0396\n",
      "Iter=400, loss=1.2100, mse=1.2100, time=0.0397\n",
      "Iter=600, loss=1.2372, mse=1.2372, time=0.0393\n",
      "Iter=800, loss=1.2555, mse=1.2555, time=0.0394\n",
      "Iter=1000, loss=1.2400, mse=1.2400, time=0.0393\n",
      "Iter=1200, loss=1.2272, mse=1.2272, time=0.0394\n",
      "Iter=1400, loss=1.2098, mse=1.2098, time=0.0394\n",
      "Iter=1600, loss=1.2605, mse=1.2605, time=0.0393\n",
      "Iter=1800, loss=1.2786, mse=1.2786, time=0.0392\n",
      "Iter=2000, loss=1.2775, mse=1.2775, time=0.0392\n",
      "Iter=2200, loss=1.1997, mse=1.1997, time=0.0392\n",
      "Iter=2400, loss=1.2223, mse=1.2223, time=0.0391\n",
      "Iter=2600, loss=1.2426, mse=1.2426, time=0.0390\n",
      "Iter=2800, loss=1.2133, mse=1.2133, time=0.0389\n",
      "Iter=3000, loss=1.2095, mse=1.2095, time=0.0393\n",
      "Iter=3200, loss=1.2163, mse=1.2163, time=0.0398\n",
      "Iter=3400, loss=1.2420, mse=1.2420, time=0.0401\n",
      "Iter=3600, loss=1.2430, mse=1.2430, time=0.0403\n",
      "Iter=3800, loss=1.2281, mse=1.2281, time=0.0403\n",
      "Iter=4000, loss=1.2624, mse=1.2624, time=0.0403\n",
      "Iter=4200, loss=1.2609, mse=1.2609, time=0.0403\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35260/260693645.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_e, loss_fn, optimizer_e, args.arr_lambda, \n\u001b[0m\u001b[0;32m     30\u001b[0m                                                                    train_loader_e, args.device, args.train_log_interval)\n\u001b[0;32m     31\u001b[0m     \u001b[0mvalid_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_valid_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_valid_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35260/3847565008.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(label_type, model, loss_fn, optimizer, arr_lambda, loader, device, log_interval)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'emotion'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter_project\\keejun\\IGMC_CX\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# edge mask zero denotes the edge dropped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             x = th.tanh(conv(block, x, block.edata['etype'], \n\u001b[0m\u001b[0;32m     66\u001b[0m                              norm=block.edata['edge_mask'].unsqueeze(1)))\n\u001b[0;32m     67\u001b[0m             \u001b[0mconcat_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\relgraphconv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, feat, etypes, norm)\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[1;31m# Sort the graph based on the etypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m                 \u001b[0msorted_etypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelabel_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m                 \u001b[1;31m# Create a new etypes to be an integer list of number of edges.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_searchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_etypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_rels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\subgraph.py\u001b[0m in \u001b[0;36medge_subgraph\u001b[1;34m(graph, edges, relabel_nodes, store_ids, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[0meids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcetype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0minduced_edges\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_process_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcetype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0msgi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minduced_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrelabel_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[0minduced_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minduced_nodes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrelabel_nodes\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_create_hetero_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstore_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\heterograph_index.py\u001b[0m in \u001b[0;36medge_subgraph\u001b[1;34m(self, induced_edges, preserve_nodes)\u001b[0m\n\u001b[0;32m    883\u001b[0m         \"\"\"\n\u001b[0;32m    884\u001b[0m         \u001b[0meids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dgl_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0medges\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minduced_edges\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroEdgeSubgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_unitgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mret_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDGLValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mret_tcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         check_call(_LIB.DGLFuncCall(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "label_type = 'emotion'\n",
    "\n",
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch_idx in range(1, 80):\n",
    "    print ('Epoch', epoch_idx)\n",
    "    \n",
    "    train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_e, loss_fn, optimizer_e, args.arr_lambda, \n",
    "                                                                   train_loader_e, args.device, args.train_log_interval)\n",
    "    valid_rmse, predict_valid_list, label_valid_list = evaluate(label_type, model_e, valid_loader_e, args.device)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(label_type, model_e, test_loader_e, args.device)\n",
    "    \n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model_e, optimizer_e)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_valid_list = predict_valid_list \n",
    "        best_label_valid_list = label_valid_list\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "    \n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))\n",
    "\n",
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "print(\" Total Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ad780abf-5e0a-4837-ad83-07a6b15f164a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.065909012649887"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109d317-e856-40aa-a3c4-ffe8b030fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_emotion_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "valid_emotion_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "valid_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_emotion_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ae4ab-1fef-4f42-8c1b-ab21c9b522a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/rotten_tomato/ensemble/'\n",
    "train_emotion_df.to_csv(path + 'train_emotion.csv', index=False)\n",
    "valid_emotion_df.to_csv(path + 'valid_emotion.csv', index=False)\n",
    "test_emotion_df.to_csv(path + 'test_emotion.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e8a82-6b5d-472d-a679-e85e57fc7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c728cd9-f005-491f-84dc-d63650c2700a",
   "metadata": {},
   "source": [
    "## 4. Train_epoch 함수 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1185d5-2266-46da-9245-351215a28540",
   "metadata": {},
   "source": [
    "### - Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f4bec73f-8cab-45aa-a3cb-beccdda9bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'rating'\n",
    "model = model_r\n",
    "loss_fn = loss_fn\n",
    "optimizer = optimizer_r\n",
    "arr_lambda = args.arr_lambda\n",
    "loader = train_loader_r\n",
    "device = args.device\n",
    "log_interval = args.train_log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b454620b-9795-4b72-b151-73be1461b119",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=200, loss=2.6334, mse=2.6295, time=0.0434\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35260/1789257228.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'emotion'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter_project\\keejun\\IGMC_CX\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# edge mask zero denotes the edge dropped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             x = th.tanh(conv(block, x, block.edata['etype'], \n\u001b[0m\u001b[0;32m     66\u001b[0m                              norm=block.edata['edge_mask'].unsqueeze(1)))\n\u001b[0;32m     67\u001b[0m             \u001b[0mconcat_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\relgraphconv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, feat, etypes, norm)\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[0mnode_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_repr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m                 \u001b[0mnode_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_repr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_loop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m                 \u001b[0mnode_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_repr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloop_message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.train()\n",
    "\n",
    "epoch_loss = 0.\n",
    "iter_loss = 0.\n",
    "iter_mse = 0.\n",
    "iter_cnt = 0\n",
    "iter_dur = []\n",
    "\n",
    "# 저장 리스트(예측, 정답)\n",
    "predict_list = list()\n",
    "label_list = list()\n",
    "\n",
    "# 서브그래프 단위로 학습\n",
    "for iter_idx, batch in enumerate(loader, start=1):\n",
    "    t_start = time.time()\n",
    "\n",
    "    inputs = batch[0].to(device)\n",
    "    labels = batch[1].to(device)\n",
    "    preds = model(inputs)\n",
    "    \n",
    "    if label_type == 'emotion':\n",
    "        loss = loss_fn(preds, labels).mean()\n",
    "    else:\n",
    "        loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item() * preds.shape[0]\n",
    "    iter_loss += loss.item() * preds.shape[0]\n",
    "    iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "    iter_cnt += preds.shape[0]\n",
    "    iter_dur.append(time.time() - t_start)\n",
    "\n",
    "    if label_type == 'rating':\n",
    "        preds  = (preds + 1)/2\n",
    "        labels = (labels + 1)/2\n",
    "    else:\n",
    "        preds  = preds + 1\n",
    "        labels = labels + 1\n",
    "\n",
    "    predict_list.append(preds.tolist()) # 예측값 저장\n",
    "    label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "    if iter_idx % log_interval == 0:\n",
    "        print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "            iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "        iter_loss = 0.\n",
    "        iter_mse = 0.\n",
    "        iter_cnt = 0\n",
    "\n",
    "# 2차원 -> 1차원 리스트 변형\n",
    "predict_list = [element for array in predict_list for element in array]\n",
    "label_list = [element for array in label_list for element in array]\n",
    "\n",
    "train_epoch_loss = epoch_loss / len(loader.dataset)  \n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "41de0e18-f974-42c6-9381-5c522d4271b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a6f11dc9-55c6-4490-a882-4b3bfa677093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc90f7b1-ec60-4c53-8b42-f63c06868808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.474928617477417,\n",
       " 4.432092189788818,\n",
       " 1.6393139362335205,\n",
       " 3.679456949234009,\n",
       " 2.2003211975097656,\n",
       " 3.414210081100464,\n",
       " 2.7713494300842285,\n",
       " 3.535055160522461,\n",
       " 3.712036371231079,\n",
       " 2.852395534515381]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "228b6092-4141-4df7-881c-74c1ac40727d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5, 3.0, 1.0, 3.0, 2.0, 2.5, 4.5, 3.0, 3.5, 2.0]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6bc06-0a33-414c-a73b-e409bca5e421",
   "metadata": {},
   "source": [
    "### Evaluate 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb2b26d9-25c4-4328-802b-068c674c8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'rating'\n",
    "model = model_r\n",
    "loader = test_loader_r\n",
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "47e1a54f-e56b-4650-a9c1-498ad5893824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time took: 0:00:26\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict_list = list()\n",
    "label_list = list()\n",
    "\n",
    "# Evaluate RMSE\n",
    "model.eval()\n",
    "mse = 0.\n",
    "for batch in loader:\n",
    "    with th.no_grad():\n",
    "        preds = model(batch[0].to(device))\n",
    "    labels = batch[1].to(device)\n",
    "    \n",
    "    if label_type == 'rating':\n",
    "        preds  = (preds + 1)/2\n",
    "        labels = (labels + 1)/2\n",
    "    else:\n",
    "        preds  = preds + 1\n",
    "        labels = labels + 1\n",
    "    mse += ((preds - labels) ** 2).sum().item()\n",
    "    \n",
    "    predict_list.append(preds.tolist()) # 예측값 저장\n",
    "    label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "# 2차원 -> 1차원 리스트 변형\n",
    "predict_list = [element for array in predict_list for element in array]\n",
    "label_list = [element for array in label_list for element in array]    \n",
    "    \n",
    "mse /= len(loader.dataset)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "54927b7e-515f-481e-b8ed-d746e8de230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208980129263855"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f0465-ef4c-424f-8a7d-1bd31800fc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae685cc-df32-47d9-ab80-320e40749f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda367ca-52b8-4455-87ec-c8cc7b71562b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
