{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83de891f-6a25-4da8-b421-75e9408850ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"IGMC modules\"\"\"\n",
    "\n",
    "import math \n",
    "import torch as th \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dgl.nn.pytorch import RelGraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1982873b-962b-4ae1-8d3c-9c3103fbf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(size, tensor):\n",
    "    bound = 1.0 / math.sqrt(size)\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    \n",
    "def edge_drop(graph, edge_dropout=0.2, training=True):\n",
    "    assert edge_dropout >= 0.0 and edge_dropout <= 1.0, 'Invalid dropout rate.'\n",
    "\n",
    "    if not training:\n",
    "        return graph\n",
    "\n",
    "    # set edge mask to zero in directional mode\n",
    "    src, _ = graph.edges()\n",
    "    to_drop = src.new_full((graph.number_of_edges(), ), edge_dropout, dtype=th.float)\n",
    "    to_drop = th.bernoulli(to_drop).to(th.bool)\n",
    "    graph.edata['edge_mask'][to_drop] = 0\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d9183-cc61-45e7-b108-e5498b08d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IGMC(nn.Module):\n",
    "    # The GNN model of Inductive Graph-based Matrix Completion. \n",
    "    # Use RGCN convolution + center-nodes readout.\n",
    "    \n",
    "    def __init__(self, in_feats, gconv=RelGraphConv, latent_dim=[32, 32, 32, 32], \n",
    "                num_relations=5, num_bases=2, regression=False, edge_dropout=0.2, \n",
    "                force_undirected=False, side_features=False, n_side_features=0, \n",
    "                multiply_by=1):\n",
    "        super(IGMC, self).__init__()\n",
    "\n",
    "        self.regression = regression\n",
    "        self.edge_dropout = edge_dropout\n",
    "        self.force_undirected = force_undirected\n",
    "        self.side_features = side_features\n",
    "        self.multiply_by = multiply_by\n",
    "\n",
    "        self.convs = th.nn.ModuleList()\n",
    "        self.convs.append(gconv(in_feats, latent_dim[0], num_relations, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "        for i in range(0, len(latent_dim)-1):\n",
    "            self.convs.append(gconv(latent_dim[i], latent_dim[i+1], num_relations, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "        \n",
    "        self.lin1 = nn.Linear(2 * sum(latent_dim), 128)\n",
    "        if side_features:\n",
    "            self.lin1 = nn.Linear(2 * sum(latent_dim) + n_side_features, 128)\n",
    "        if self.regression:\n",
    "            self.lin2 = nn.Linear(128, 1)\n",
    "        else:\n",
    "            assert False\n",
    "            # self.lin2 = nn.Linear(128, n_classes)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            size = conv.num_bases * conv.in_feat\n",
    "            uniform(size, conv.weight)\n",
    "            uniform(size, conv.w_comp)\n",
    "            uniform(size, conv.loop_weight)\n",
    "            uniform(size, conv.h_bias)\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    # @profile\n",
    "    def forward(self, block):\n",
    "        block = edge_drop(block, self.edge_dropout, self.training)\n",
    "\n",
    "        concat_states = []\n",
    "        x = block.ndata['x']\n",
    "        for conv in self.convs:\n",
    "            # edge mask zero denotes the edge dropped\n",
    "            x = th.tanh(conv(block, x, block.edata['etype'], \n",
    "                             norm=block.edata['edge_mask'].unsqueeze(1)))\n",
    "            concat_states.append(x)\n",
    "        concat_states = th.cat(concat_states, 1)\n",
    "        \n",
    "        users = block.ndata['nlabel'][:, 0] == 1\n",
    "        items = block.ndata['nlabel'][:, 1] == 1\n",
    "        x = th.cat([concat_states[users], concat_states[items]], 1)\n",
    "        # if self.side_features:\n",
    "        #     x = th.cat([x, data.u_feature, data.v_feature], 1)\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        if self.regression:\n",
    "            return x[:, 0] * self.multiply_by\n",
    "        else:\n",
    "            assert False\n",
    "            # return F.log_softmax(x, dim=-1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b67f13a-c920-4719-a39a-558dbc3b2292",
   "metadata": {},
   "source": [
    "## class IGMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63421be-bccb-4df0-b656-fac3dbfe32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feats = 4\n",
    "gconv=RelGraphConv\n",
    "latent_dim=[32, 32, 32, 32]\n",
    "num_relations=5\n",
    "num_bases=4\n",
    "regression=True\n",
    "edge_dropout=0.2\n",
    "force_undirected=False\n",
    "side_features=False\n",
    "n_side_features=0\n",
    "multiply_by=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad4ba3-2036-48e1-9046-6100154a1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = regression\n",
    "edge_dropout = edge_dropout\n",
    "force_undirected = force_undirected\n",
    "side_features = side_features\n",
    "multiply_by = multiply_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b26d0995-bb85-47b6-8519-fa55596876c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = th.nn.ModuleList()\n",
    "convs.append(gconv(in_feats, latent_dim[0], num_relations, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "for i in range(0, len(latent_dim)-1):\n",
    "    convs.append(gconv(latent_dim[i], latent_dim[i+1], num_relations, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "\n",
    "lin1 = nn.Linear(2 * sum(latent_dim), 128)\n",
    "if side_features:\n",
    "    lin1 = nn.Linear(2 * sum(latent_dim) + n_side_features, 128)\n",
    "if regression:\n",
    "    lin2 = nn.Linear(128, 1)\n",
    "else:\n",
    "    assert False\n",
    "    # lin2 = nn.Linear(128, n_classes)\n",
    "reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "853d0672-2d6c-4b50-8b20-e2c7647a78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_parameters():\n",
    "    for conv in convs:\n",
    "        size = conv.num_bases * conv.in_feat\n",
    "        uniform(size, conv.weight)\n",
    "        uniform(size, conv.w_comp)\n",
    "        uniform(size, conv.loop_weight)\n",
    "        uniform(size, conv.h_bias)\n",
    "    lin1.reset_parameters()\n",
    "    lin2.reset_parameters()\n",
    "\n",
    "# @profile\n",
    "def forward(block):\n",
    "    block = edge_drop(block, edge_dropout, training)\n",
    "\n",
    "    concat_states = []\n",
    "    x = block.ndata['x']\n",
    "    for conv in convs:\n",
    "        # edge mask zero denotes the edge dropped\n",
    "        x = th.tanh(conv(block, x, block.edata['etype'], \n",
    "                         norm=block.edata['edge_mask'].unsqueeze(1)))\n",
    "        concat_states.append(x)\n",
    "    concat_states = th.cat(concat_states, 1)\n",
    "\n",
    "    users = block.ndata['nlabel'][:, 0] == 1\n",
    "    items = block.ndata['nlabel'][:, 1] == 1\n",
    "    x = th.cat([concat_states[users], concat_states[items]], 1)\n",
    "    # if side_features:\n",
    "    #     x = th.cat([x, data.u_feature, data.v_feature], 1)\n",
    "\n",
    "    x = F.relu(lin1(x))\n",
    "    x = F.dropout(x, p=0.5, training=training)\n",
    "    x = lin2(x)\n",
    "    if regression:\n",
    "        return x[:, 0] * multiply_by\n",
    "    else:\n",
    "        assert False\n",
    "        # return F.log_softmax(x, dim=-1)\n",
    "\n",
    "def __repr__():\n",
    "    return __class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "704e5d3b-0dc5-477e-b101-d0c7496e87e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'block' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_54216/1008339236.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_drop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_dropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mconcat_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'block' is not defined"
     ]
    }
   ],
   "source": [
    "block = edge_drop(block, edge_dropout, training)\n",
    "\n",
    "concat_states = []\n",
    "x = block.ndata['x']\n",
    "for conv in convs:\n",
    "    # edge mask zero denotes the edge dropped\n",
    "    x = th.tanh(conv(block, x, block.edata['etype'], \n",
    "                     norm=block.edata['edge_mask'].unsqueeze(1)))\n",
    "    concat_states.append(x)\n",
    "concat_states = th.cat(concat_states, 1)\n",
    "\n",
    "users = block.ndata['nlabel'][:, 0] == 1\n",
    "items = block.ndata['nlabel'][:, 1] == 1\n",
    "x = th.cat([concat_states[users], concat_states[items]], 1)\n",
    "# if side_features:\n",
    "#     x = th.cat([x, data.u_feature, data.v_feature], 1)\n",
    "\n",
    "x = F.relu(lin1(x))\n",
    "x = F.dropout(x, p=0.5, training=training)\n",
    "x = lin2(x)\n",
    "if regression:\n",
    "    return x[:, 0] * multiply_by\n",
    "else:\n",
    "    assert False\n",
    "    # return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da938965-b911-47e4-8498-a009b1069ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
