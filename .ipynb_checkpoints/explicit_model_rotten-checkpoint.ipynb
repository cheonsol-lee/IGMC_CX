{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83de891f-6a25-4da8-b421-75e9408850ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"IGMC modules\"\"\"\n",
    "\n",
    "import math \n",
    "import torch as th \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dgl.nn.pytorch import RelGraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1982873b-962b-4ae1-8d3c-9c3103fbf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(size, tensor):\n",
    "    bound = 1.0 / math.sqrt(size)\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    \n",
    "def edge_drop(graph, edge_dropout=0.2, training=True):\n",
    "    assert edge_dropout >= 0.0 and edge_dropout <= 1.0, 'Invalid dropout rate.'\n",
    "\n",
    "    if not training:\n",
    "        return graph\n",
    "\n",
    "    # set edge mask to zero in directional mode\n",
    "    src, _ = graph.edges()\n",
    "    to_drop = src.new_full((graph.number_of_edges(), ), edge_dropout, dtype=th.float)\n",
    "    to_drop = th.bernoulli(to_drop).to(th.bool)\n",
    "    graph.edata['edge_mask'][to_drop] = 0\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d9183-cc61-45e7-b108-e5498b08d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IGMC(nn.Module):\n",
    "    # The GNN model of Inductive Graph-based Matrix Completion. \n",
    "    # Use RGCN convolution + center-nodes readout.\n",
    "    \n",
    "    def __init__(self, in_feats, gconv=RelGraphConv, latent_dim=[32, 32, 32, 32], \n",
    "                num_relations=10, num_bases=2, regression=False, edge_dropout=0.2, \n",
    "                force_undirected=False, side_features=False, n_side_features=0, \n",
    "                multiply_by=1):\n",
    "        super(IGMC, self).__init__()\n",
    "\n",
    "        self.regression = regression\n",
    "        self.edge_dropout = edge_dropout\n",
    "        self.force_undirected = force_undirected\n",
    "        self.side_features = side_features\n",
    "        self.multiply_by = multiply_by\n",
    "\n",
    "        # rating\n",
    "        self.convs_r = th.nn.ModuleList()\n",
    "        self.convs_r.append(gconv(in_feats, latent_dim[0], 10, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "        for i in range(0, len(latent_dim)-1):\n",
    "            self.convs_r.append(gconv(latent_dim[i], latent_dim[i+1], 10, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "        \n",
    "        # sentiment\n",
    "        self.convs_s = th.nn.ModuleList()\n",
    "        self.convs_s.append(gconv(in_feats, latent_dim[0], 5, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "        for i in range(0, len(latent_dim)-1):\n",
    "            self.convs_s.append(gconv(latent_dim[i], latent_dim[i+1], 5, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "        \n",
    "        # emotion\n",
    "        self.convs_e = th.nn.ModuleList()\n",
    "        self.convs_e.append(gconv(in_feats, latent_dim[0], 6, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "        for i in range(0, len(latent_dim)-1):\n",
    "            self.convs_e.append(gconv(latent_dim[i], latent_dim[i+1], 6, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "        \n",
    "        \n",
    "        self.lin1 = nn.Linear(2 * sum(latent_dim), 128)\n",
    "        if side_features:\n",
    "            self.lin1 = nn.Linear(2 * sum(latent_dim) + n_side_features, 128)\n",
    "        if self.regression:\n",
    "            self.lin2 = nn.Linear(128, 1)\n",
    "        else:\n",
    "            assert False\n",
    "            # self.lin2 = nn.Linear(128, n_classes)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            size = conv.num_bases * conv.in_feat\n",
    "            uniform(size, conv.weight)\n",
    "            uniform(size, conv.w_comp)\n",
    "            uniform(size, conv.loop_weight)\n",
    "            uniform(size, conv.h_bias)\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    # @profile\n",
    "    def forward(self, block_r, block_s, block_e):\n",
    "        block_r = edge_drop(block_r, self.edge_dropout, self.training)\n",
    "        block_s = edge_drop(block_r, self.edge_dropout, self.training)\n",
    "        block_e = edge_drop(block_r, self.edge_dropout, self.training)\n",
    "\n",
    "        # rating\n",
    "        concat_states_r = []\n",
    "        x = block_r.ndata['x']\n",
    "        # GCN 메시지 패싱 부분\n",
    "        for conv in self.convs_r:\n",
    "            # edge mask zero denotes the edge dropped\n",
    "            x = th.tanh(conv(block_r, x, block_r.edata['etype'], \n",
    "                             norm=block_r.edata['edge_mask'].unsqueeze(1)))\n",
    "            concat_states_r.append(x)\n",
    "        concat_states_r = th.cat(concat_states_r, 1)\n",
    "        \n",
    "        # sentiment\n",
    "        concat_states_s = []\n",
    "        x = block_s.ndata['x']\n",
    "        # GCN 메시지 패싱 부분\n",
    "        for conv in self.convs_s:\n",
    "            # edge mask zero denotes the edge dropped\n",
    "            x = th.tanh(conv(block_s, x, block_s.edata['etype'], \n",
    "                             norm=block_s.edata['edge_mask'].unsqueeze(1)))\n",
    "            concat_states_s.append(x)\n",
    "        concat_states_s = th.cat(concat_states_s, 1)\n",
    "        \n",
    "        # emotion\n",
    "        concat_states_e = []\n",
    "        x = block_e.ndata['x']\n",
    "        # GCN 메시지 패싱 부분\n",
    "        for conv in self.convs_e:\n",
    "            # edge mask zero denotes the edge dropped\n",
    "            x = th.tanh(conv(block_e, x, block_e.edata['etype'], \n",
    "                             norm=block_e.edata['edge_mask'].unsqueeze(1)))\n",
    "            concat_states_e.append(x)\n",
    "        concat_states_e = th.cat(concat_states_e, 1)\n",
    "\n",
    "        \n",
    "        self.users = block_r.ndata['nlabel'][:, 0] == 1\n",
    "        self.items = block_r.ndata['nlabel'][:, 1] == 1\n",
    "        x_r = th.cat([concat_states_r[self.users], concat_states_r[self.items]], 1)\n",
    "        x_s = th.cat([concat_states_s[self.users], concat_states_s[self.items]], 1)\n",
    "        x_e = th.cat([concat_states_e[self.users], concat_states_e[self.items]], 1)\n",
    "\n",
    "        x = (x_r + x_s + x_e)/3  # aggregation 부분\n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        if self.regression:\n",
    "            return x[:, 0] * self.multiply_by\n",
    "        else:\n",
    "            assert False\n",
    "            # return F.log_softmax(x, dim=-1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
