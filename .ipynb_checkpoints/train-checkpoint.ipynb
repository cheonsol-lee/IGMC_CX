{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee754ff-2a3d-4760-9dde-f35b5079e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training epoch took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5af6c94-0780-4733-88b7-286a4a08728a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training IGMC model on the MovieLens dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "from shutil import copy\n",
    "# from pyinstrument import Profiler\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import IGMC\n",
    "from data import MovieLens\n",
    "from dataset import MovieLensDataset, collate_movielens \n",
    "from utils import MetricLogger\n",
    "\n",
    "# os.environ['TZ'] = 'Asia/Shanghai'\n",
    "# time.tzset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c1bb83-260d-40b8-900b-6c27d7da5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    # Evaluate RMSE\n",
    "    model.eval()\n",
    "    mse = 0.\n",
    "    for batch in loader:\n",
    "        with th.no_grad():\n",
    "            preds = model(batch[0].to(device))\n",
    "        labels = batch[1].to(device)\n",
    "        mse += ((preds - labels) ** 2).sum().item()\n",
    "    mse /= len(loader.dataset)\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def adj_rating_reg(model):\n",
    "    arr_loss = 0\n",
    "    for conv in model.convs:\n",
    "        weight = conv.weight.view(conv.num_bases, conv.in_feat * conv.out_feat)\n",
    "        weight = th.matmul(conv.w_comp, weight).view(conv.num_rels, conv.in_feat, conv.out_feat)\n",
    "        arr_loss += th.sum((weight[1:, :, :] - weight[:-1, :, :])**2)\n",
    "    return arr_loss\n",
    "\n",
    "# @profile\n",
    "def train_epoch(model, loss_fn, optimizer, arr_lambda, loader, device, log_interval):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.\n",
    "    iter_loss = 0.\n",
    "    iter_mse = 0.\n",
    "    iter_cnt = 0\n",
    "    iter_dur = []\n",
    "\n",
    "    # profiler = Profiler()\n",
    "    # profiler.start()\n",
    "    for iter_idx, batch in enumerate(loader, start=1):\n",
    "        t_start = time.time()\n",
    "\n",
    "        inputs = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "        preds = model(inputs)\n",
    "        loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * preds.shape[0]\n",
    "        iter_loss += loss.item() * preds.shape[0]\n",
    "        iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "        iter_cnt += preds.shape[0]\n",
    "        iter_dur.append(time.time() - t_start)\n",
    "\n",
    "        if iter_idx % log_interval == 0:\n",
    "            print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "                iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "            iter_loss = 0.\n",
    "            iter_mse = 0.\n",
    "            iter_cnt = 0\n",
    "    # profiler.stop()\n",
    "    # profiler.output_html()\n",
    "    return epoch_loss / len(loader.dataset)\n",
    "\n",
    "def train(args):\n",
    "    ### prepare data and set model\n",
    "    movielens = MovieLens(args.data_name, testing=args.testing,\n",
    "                            test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "    if args.testing:\n",
    "        test_dataset = MovieLensDataset(\n",
    "            movielens.test_rating_pairs, movielens.test_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "    else:\n",
    "        test_dataset = MovieLensDataset(\n",
    "            movielens.valid_rating_pairs, movielens.valid_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "    train_dataset = MovieLensDataset(\n",
    "        movielens.train_rating_pairs, movielens.train_rating_values, movielens.train_graph, \n",
    "        args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "    train_loader = th.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "    test_loader = th.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "\n",
    "    in_feats = (args.hop+1)*2 #+ movielens.train_graph.ndata['refex'].shape[1]\n",
    "    model = IGMC(in_feats=in_feats, \n",
    "                 latent_dim=[32, 32, 32, 32],\n",
    "                 num_relations=5, # movielens.num_rating, \n",
    "                 num_bases=4, \n",
    "                 regression=True, \n",
    "                 edge_dropout=args.edge_dropout,\n",
    "                #  side_features=args.use_features,\n",
    "                #  n_side_features=n_features,\n",
    "                #  multiply_by=args.multiply_by\n",
    "            ).to(args.device)\n",
    "    loss_fn = nn.MSELoss().to(args.device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "    print(\"Loading network finished ...\\n\")\n",
    "\n",
    "    ### prepare the logger\n",
    "    logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "    \n",
    "    best_epoch = 0\n",
    "    best_rmse = np.inf\n",
    "    ### declare the loss information\n",
    "    print(\"Start training ...\")\n",
    "    for epoch_idx in range(1, args.train_epochs+1):\n",
    "        print ('Epoch', epoch_idx)\n",
    "    \n",
    "        train_loss = train_epoch(model, loss_fn, optimizer, args.arr_lambda, \n",
    "                                train_loader, args.device, args.train_log_interval)\n",
    "        test_rmse = evaluate(model, test_loader, args.device)\n",
    "        eval_info = {\n",
    "            'epoch': epoch_idx,\n",
    "            'train_loss': train_loss,\n",
    "            'test_rmse': test_rmse,\n",
    "        }\n",
    "        print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "        if epoch_idx % args.train_lr_decay_step == 0:\n",
    "            for param in optimizer.param_groups:\n",
    "                param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "        logger.log(eval_info, model, optimizer)\n",
    "        if best_rmse > test_rmse:\n",
    "            best_rmse = test_rmse\n",
    "            best_epoch = epoch_idx\n",
    "    eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "    print(eval_info)\n",
    "    with open(os.path.join(args.save_dir, 'log.txt'), 'a') as f:\n",
    "        f.write(eval_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fbabcc-6d45-4d08-8d5e-f9f483e56aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def config():\n",
    "    parser = argparse.ArgumentParser(description='IGMC')\n",
    "    # general settings\n",
    "    parser.add_argument('--testing', action='store_true', default=False,\n",
    "                        help='if set, use testing mode which splits all ratings into train/test;\\\n",
    "                        otherwise, use validation model which splits all ratings into \\\n",
    "                        train/val/test and evaluate on val only')\n",
    "    parser.add_argument('--device', default='0', type=int,\n",
    "                        help='Running device. E.g `--device 0`, if using cpu, set `--device -1`')\n",
    "    parser.add_argument('--seed', type=int, default=1234, metavar='S',\n",
    "                        help='random seed (default: 1234)')\n",
    "    parser.add_argument('--data_name', default='ml-100k', type=str,\n",
    "                        help='The dataset name: ml-100k, ml-1m')\n",
    "    parser.add_argument('--data_test_ratio', type=float, default=0.1) # for ml-100k the test ration is 0.2\n",
    "    parser.add_argument('--num_workers', type=int, default=8)\n",
    "    parser.add_argument('--data_valid_ratio', type=float, default=0.2)\n",
    "    # parser.add_argument('--ensemble', action='store_true', default=False,\n",
    "    #                     help='if True, load a series of model checkpoints and ensemble the results')               \n",
    "    parser.add_argument('--train_log_interval', type=int, default=100)\n",
    "    parser.add_argument('--valid_log_interval', type=int, default=10)\n",
    "    parser.add_argument('--save_appendix', type=str, default='debug', \n",
    "                        help='what to append to save-names when saving results')\n",
    "    # subgraph extraction settings\n",
    "    parser.add_argument('--hop', default=1, metavar='S', \n",
    "                        help='enclosing subgraph hop number')\n",
    "    parser.add_argument('--sample_ratio', type=float, default=1.0, \n",
    "                        help='if < 1, subsample nodes per hop according to the ratio')\n",
    "    parser.add_argument('--max_nodes_per_hop', type=int, default=200, \n",
    "                        help='if > 0, upper bound the # nodes per hop by another subsampling')\n",
    "    # parser.add_argument('--use_features', action='store_true', default=False,\n",
    "    #                     help='whether to use node features (side information)')\n",
    "    # edge dropout settings\n",
    "    parser.add_argument('--edge_dropout', type=float, default=0.2, \n",
    "                        help='if not 0, random drops edges from adjacency matrix with this prob')\n",
    "    parser.add_argument('--force_undirected', action='store_true', default=False, \n",
    "                        help='in edge dropout, force (x, y) and (y, x) to be dropped together')\n",
    "    # optimization settings\n",
    "    parser.add_argument('--train_lr', type=float, default=1e-3)\n",
    "    parser.add_argument('--train_min_lr', type=float, default=1e-6)\n",
    "    parser.add_argument('--train_lr_decay_factor', type=float, default=0.1)\n",
    "    parser.add_argument('--train_lr_decay_step', type=int, default=50)\n",
    "    parser.add_argument('--train_epochs', type=int, default=80)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--arr_lambda', type=float, default=0.001)\n",
    "    parser.add_argument('--num_rgcn_bases', type=int, default=4)\n",
    "                \n",
    "    args = parser.parse_args()\n",
    "    args.device = th.device(args.device) if args.device >= 0 and th.cuda.is_available() else th.device('cpu')\n",
    "    \n",
    "    ### set save_dir according to localtime and test mode\n",
    "    file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "    val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "    local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "    args.save_dir = os.path.join(\n",
    "        file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "            args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "        )\n",
    "    )\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir) \n",
    "    print(args)\n",
    "\n",
    "    # backup current .py files\n",
    "    for f in glob.glob(r\"*.py\"):\n",
    "        copy(f, args.save_dir)\n",
    "\n",
    "    # save command line input\n",
    "    cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "    with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "        f.write(cmd_input)\n",
    "        f.write(\"\\n\")\n",
    "    print('Command line input: ' + cmd_input + ' is saved.')\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a24e649-365e-4f54-b4bd-7796c685b165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     args = config()\n",
    "#     random.seed(args.seed)\n",
    "#     np.random.seed(args.seed)\n",
    "#     th.manual_seed(args.seed)\n",
    "#     if th.cuda.is_available():\n",
    "#         th.cuda.manual_seed_all(args.seed)\n",
    "#     train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff187c-d0a5-44d6-bf40-12a1c7927a3b",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0218e93a-7bb0-4007-a0d4-194dfbf0fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({ \n",
    "    'data_name':            'ml-100k',\n",
    "    'testing':     \t        False,\n",
    "    'device':      \t        0,\n",
    "    'seed':        \t        1234,\n",
    "    'data_test_ratio':      0.1,\n",
    "    'num_workers':   \t    8,\n",
    "    'data_valid_ratio':     0.2,\n",
    "    'train_log_interval':   100,\n",
    "    'valid_log_interval':   10,\n",
    "    'save_appendix':   \t    'debug',\n",
    "    'hop':   \t            1,\n",
    "    'sample_ratio':    \t    1.0,\n",
    "    'max_nodes_per_hop':    200,\n",
    "    'edge_dropout':   \t    0.2,\n",
    "    'force_undirected':     False,\n",
    "    'train_lr':   \t        1e-3,\n",
    "    'train_min_lr':   \t    1e-6,\n",
    "    'train_lr_decay_factor':0.1,\n",
    "    'train_lr_decay_step':  50,\n",
    "    'train_epochs':   \t    80,\n",
    "    'batch_size':   \t    32,\n",
    "    'arr_lambda':   \t    0.001,\n",
    "    'num_rgcn_bases':   \t4,\n",
    "    'train_epochs':   \t    1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eefc4e0-e1a6-47fa-af1b-3f79a748f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_name': 'ml-100k', 'testing': False, 'device': 0, 'seed': 1234, 'data_test_ratio': 0.1, 'num_workers': 8, 'data_valid_ratio': 0.2, 'train_log_interval': 100, 'valid_log_interval': 10, 'save_appendix': 'debug', 'hop': 1, 'sample_ratio': 1.0, 'max_nodes_per_hop': 200, 'edge_dropout': 0.2, 'force_undirected': False, 'train_lr': 0.001, 'train_min_lr': 1e-06, 'train_lr_decay_factor': 0.1, 'train_lr_decay_step': 50, 'train_epochs': 1, 'batch_size': 32, 'arr_lambda': 0.001, 'num_rgcn_bases': 4, 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\graph\\\\Motif-based-inductive-GNN-training-master\\\\log/ml-100k_debug_valmode_2111062256'}\n",
      "Command line input: python3 C:\\Users\\user\\anaconda3\\envs\\graph\\lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\user\\AppData\\Roaming\\jupyter\\runtime\\kernel-09563cc1-42d1-4be6-80ad-88c2428df41e.json is saved.\n"
     ]
    }
   ],
   "source": [
    "### set save_dir according to localtime and test mode\n",
    "file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "args.save_dir = os.path.join(\n",
    "    file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "        args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "    )\n",
    ")\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir) \n",
    "print(args)\n",
    "\n",
    "# backup current .py files\n",
    "for f in glob.glob(r\"*.py\"):\n",
    "    copy(f, args.save_dir)\n",
    "\n",
    "# save command line input\n",
    "cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "    f.write(cmd_input)\n",
    "    f.write(\"\\n\")\n",
    "print('Command line input: ' + cmd_input + ' is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0952c8a-5880-48c8-a6b0-76fa1226074e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_name': 'ml-100k',\n",
       " 'testing': False,\n",
       " 'device': 0,\n",
       " 'seed': 1234,\n",
       " 'data_test_ratio': 0.1,\n",
       " 'num_workers': 8,\n",
       " 'data_valid_ratio': 0.2,\n",
       " 'train_log_interval': 100,\n",
       " 'valid_log_interval': 10,\n",
       " 'save_appendix': 'debug',\n",
       " 'hop': 1,\n",
       " 'sample_ratio': 1.0,\n",
       " 'max_nodes_per_hop': 200,\n",
       " 'edge_dropout': 0.2,\n",
       " 'force_undirected': False,\n",
       " 'train_lr': 0.001,\n",
       " 'train_min_lr': 1e-06,\n",
       " 'train_lr_decay_factor': 0.1,\n",
       " 'train_lr_decay_step': 50,\n",
       " 'train_epochs': 1,\n",
       " 'batch_size': 32,\n",
       " 'arr_lambda': 0.001,\n",
       " 'num_rgcn_bases': 4,\n",
       " 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\graph\\\\Motif-based-inductive-GNN-training-master\\\\log/ml-100k_debug_valmode_2111062256'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e5af39-9646-43f8-87d2-8d9c498b7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "th.manual_seed(args.seed)\n",
    "if th.cuda.is_available():\n",
    "    th.cuda.manual_seed_all(args.seed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3522af7d-43ff-4eb3-85c2-8168f73dcfa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# train(args)\n",
    "\n",
    "# print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0a3e5-c195-47bc-87d4-489c3ddeb093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bcd9d7e-1617-4c32-a8bc-006d4a49ca35",
   "metadata": {},
   "source": [
    "## 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c44d14-7115-4e81-9c99-99f370f93129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using official MovieLens dataset split u1.base/u1.test with 20% validation set size...\n",
      "User features shape: (943, 23)\n",
      "Item features shape: (1682, 18)\n",
      "\tTrain rating pairs : 64000\n",
      "\tValid rating pairs : 16000\n",
      "\tTest rating pairs  : 20000\n"
     ]
    }
   ],
   "source": [
    "### prepare data and set model\n",
    "movielens = MovieLens(args.data_name, testing=args.testing,\n",
    "                        test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a64167d-fcca-4bd7-b0f4-7dfa290178bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3ff8769-41d9-4fe5-938f-51c370d372cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.testing:\n",
    "    test_dataset = MovieLensDataset(\n",
    "        movielens.test_rating_pairs, movielens.test_rating_values, movielens.train_graph, \n",
    "        args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "else:\n",
    "    test_dataset = MovieLensDataset(\n",
    "        movielens.valid_rating_pairs, movielens.valid_rating_values, movielens.train_graph, \n",
    "        args.hop, args.sample_ratio, args.max_nodes_per_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5e9ce45-2ab8-4a5a-bae3-17a9871aad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovieLensDataset(\n",
    "    movielens.train_rating_pairs, movielens.train_rating_values, movielens.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "621bf1ca-2328-439c-bfe9-fd51f892552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = th.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "test_loader = th.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_movielens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c679b72-a7a2-4abb-9c4d-efdebf97dbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network finished ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_feats = (args.hop+1)*2 #+ movielens.train_graph.ndata['refex'].shape[1]\n",
    "model = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=5, # movielens.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "            #  side_features=args.use_features,\n",
    "            #  n_side_features=n_features,\n",
    "            #  multiply_by=args.multiply_by\n",
    "        ).to(args.device)\n",
    "loss_fn = nn.MSELoss().to(args.device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "print(\"Loading network finished ...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85169726-bfc2-4901-9fec-5762453098ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a33c4cb1-b163-4368-8bd7-555f86a56943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3569ea7d-b812-486f-8681-b08d1b9b382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n"
     ]
    }
   ],
   "source": [
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b4b350-a659-41eb-8f85-4baf5495fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Iter=100, loss=1.5105, mse=1.5091, time=0.0576\n",
      "Iter=200, loss=1.1026, mse=1.1012, time=0.0494\n",
      "Iter=300, loss=1.0748, mse=1.0735, time=0.0474\n",
      "Iter=400, loss=1.0725, mse=1.0712, time=0.0469\n",
      "Iter=500, loss=1.0373, mse=1.0361, time=0.0462\n",
      "Iter=600, loss=1.0709, mse=1.0697, time=0.0458\n",
      "Iter=700, loss=1.0266, mse=1.0254, time=0.0455\n",
      "Iter=800, loss=1.0370, mse=1.0359, time=0.0453\n",
      "Iter=900, loss=1.0319, mse=1.0309, time=0.0452\n",
      "Iter=1000, loss=1.0186, mse=1.0176, time=0.0450\n",
      "Iter=1100, loss=0.9805, mse=0.9795, time=0.0449\n",
      "Iter=1200, loss=1.0387, mse=1.0377, time=0.0447\n",
      "Iter=1300, loss=1.0677, mse=1.0667, time=0.0446\n",
      "Iter=1400, loss=1.0453, mse=1.0444, time=0.0445\n",
      "Iter=1500, loss=1.0146, mse=1.0136, time=0.0445\n",
      "Iter=1600, loss=1.0182, mse=1.0173, time=0.0445\n",
      "Iter=1700, loss=1.0209, mse=1.0199, time=0.0444\n",
      "Iter=1800, loss=1.0090, mse=1.0081, time=0.0444\n",
      "Iter=1900, loss=0.9962, mse=0.9953, time=0.0443\n",
      "Iter=2000, loss=0.9997, mse=0.9988, time=0.0442\n",
      "=== Epoch 1, train loss 1.058681, test rmse 0.949829 ===\n",
      "  Training epoch took: 0:02:02\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch_idx in range(1, args.train_epochs+1):\n",
    "    print ('Epoch', epoch_idx)\n",
    "\n",
    "    train_loss = train_epoch(model, loss_fn, optimizer, args.arr_lambda, \n",
    "                            train_loader, args.device, args.train_log_interval)\n",
    "    test_rmse = evaluate(model, test_loader, args.device)\n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model, optimizer)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "646f6c55-8dc5-4999-b2b0-70af13b2248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ends. The best testing rmse is 0.949829 at epoch 1\n"
     ]
    }
   ],
   "source": [
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "with open(os.path.join(args.save_dir, 'log.txt'), 'a') as f:\n",
    "    f.write(eval_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acc35c-e77b-4764-bdb3-47977a789154",
   "metadata": {},
   "source": [
    "- IGMC의 users, items 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "919e8a82-6b5d-472d-a679-e85e57fc7ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=7178, num_edges=160050,\n",
       "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'nlabel': Scheme(shape=(4,), dtype=torch.float32), 'x': Scheme(shape=(4,), dtype=torch.float32)}\n",
       "      edata_schemes={'etype': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64), 'edge_mask': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b673cd3-2dca-471d-b361-5e0106ebd0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_ID': tensor([ 463,    9,   12,  ..., 1819, 1983, 2205], device='cuda:0'), 'nlabel': tensor([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]], device='cuda:0'), 'x': tensor([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]], device='cuda:0')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e5ecab8-943f-455e-aaf0-35ca5e3eb057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.ndata['nlabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d8a6255-f09c-4c0f-ae0c-76b87f5b5670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7178, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.ndata['nlabel'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "209864b6-e545-446e-b566-391921f47b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.ndata['nlabel'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20e81e3a-81b3-4e30-a7a2-ecffbbafb7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0336, -0.0045,  0.0624,  ..., -0.0243, -0.0064, -0.0604],\n",
       "        [ 0.0254,  0.0257,  0.0426,  ...,  0.0041,  0.0395,  0.0285],\n",
       "        [ 0.0158, -0.0024,  0.0317,  ...,  0.0129,  0.0010,  0.0245],\n",
       "        ...,\n",
       "        [ 0.0334,  0.0097,  0.0496,  ...,  0.0013, -0.0036,  0.1082],\n",
       "        [ 0.0260,  0.0028,  0.0675,  ...,  0.0262, -0.0212,  0.0730],\n",
       "        [ 0.0312,  0.0139,  0.0371,  ...,  0.0255,  0.0159,  0.0978]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eac9276d-09af-4230-93a4-28fe437b04e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7178])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3d26473-4f82-4488-9d27-35678e86770a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7178])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bb98d62-2a20-4a65-a020-3fd17b8884ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7178, 128])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.concat_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce6db82a-6550-4093-b637-bbd670ba4c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.3687e-01,  9.8331e-01, -9.7956e-01,  ..., -3.6396e-02,\n",
       "          2.4104e-02, -9.5912e-02],\n",
       "        [-3.0464e-01, -6.2658e-02, -4.9929e-01,  ...,  1.0602e-02,\n",
       "          6.0112e-02,  3.2951e-03],\n",
       "        [-2.0967e-01,  3.7956e-01, -5.5484e-01,  ...,  1.2818e-02,\n",
       "          2.0604e-02, -1.4120e-04],\n",
       "        ...,\n",
       "        [-1.4452e-01, -5.3499e-02, -1.1899e-01,  ...,  2.1447e-02,\n",
       "          5.7941e-03,  1.1428e-01],\n",
       "        [-9.7401e-02,  3.1842e-02,  1.4665e-01,  ...,  3.8342e-02,\n",
       "         -2.0346e-02,  7.9878e-02],\n",
       "        [ 2.6682e-03,  1.9309e-02, -1.2328e-01,  ...,  3.9916e-02,\n",
       "          3.2358e-02,  9.4652e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.concat_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3532cf35-110f-4746-a77a-dfc08acd2786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3369,  0.9833, -0.9796,  ..., -0.0364,  0.0241, -0.0959],\n",
       "        [ 0.9808,  1.0000, -0.9821,  ...,  0.0341, -0.3816, -0.2332],\n",
       "        [-0.0617,  0.9998, -0.9972,  ..., -0.0597, -0.0965, -0.0768],\n",
       "        ...,\n",
       "        [-0.2799,  1.0000, -1.0000,  ..., -0.0302,  0.1381,  0.1117],\n",
       "        [-0.0940,  0.9992, -0.9904,  ...,  0.0135, -0.0629, -0.0124],\n",
       "        [-0.2346,  0.9743, -0.9402,  ..., -0.0601, -0.0506, -0.1147]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.concat_states[model.users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f1a4405-6171-465e-ab4a-358eac28cdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.concat_states[model.users].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ddfd412-4dbd-4821-b9e4-6e4e82c04f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.concat_states[model.items].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c604fefa-8687-4f37-b9ad-3d5c5e5431a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = th.cat([model.concat_states[model.users], model.concat_states[model.items]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "039cd241-2c02-4ae3-9489-1165498a5a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 256])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user, item vector들을 합침\n",
    "concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03faa981-c0e4-438c-846b-bdd142d583ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c728cd9-f005-491f-84dc-d63650c2700a",
   "metadata": {},
   "source": [
    "### Train_epoch 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4bec73f-8cab-45aa-a3cb-beccdda9bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "loss_fn = loss_fn\n",
    "optimizer = optimizer\n",
    "arr_lambda = args.arr_lambda\n",
    "loader = train_loader\n",
    "device = args.device\n",
    "log_interval = args.train_log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df6fd326-b5dc-4acd-8832-9aae253d90a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b454620b-9795-4b72-b151-73be1461b119",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=100, loss=1.0291, mse=1.0282, time=0.0557\n",
      "Iter=200, loss=0.9530, mse=0.9521, time=0.0567\n",
      "Iter=300, loss=0.9845, mse=0.9837, time=0.0542\n",
      "Iter=400, loss=0.9838, mse=0.9830, time=0.0591\n",
      "Iter=500, loss=1.0093, mse=1.0084, time=0.0615\n",
      "Iter=600, loss=0.9993, mse=0.9985, time=0.0615\n",
      "Iter=700, loss=1.0434, mse=1.0426, time=0.0613\n",
      "Iter=800, loss=1.0067, mse=1.0059, time=0.0598\n",
      "Iter=900, loss=1.0343, mse=1.0335, time=0.0581\n",
      "Iter=1000, loss=0.9951, mse=0.9943, time=0.0571\n",
      "Iter=1100, loss=1.0109, mse=1.0101, time=0.0570\n",
      "Iter=1200, loss=0.9816, mse=0.9808, time=0.0570\n",
      "Iter=1300, loss=1.0083, mse=1.0075, time=0.0563\n",
      "Iter=1400, loss=1.0086, mse=1.0078, time=0.0557\n",
      "Iter=1500, loss=0.9849, mse=0.9841, time=0.0566\n",
      "Iter=1600, loss=0.9397, mse=0.9390, time=0.0571\n",
      "Iter=1700, loss=1.0033, mse=1.0025, time=0.0567\n",
      "Iter=1800, loss=0.9553, mse=0.9545, time=0.0567\n",
      "Iter=1900, loss=0.9699, mse=0.9691, time=0.0563\n",
      "Iter=2000, loss=0.9503, mse=0.9494, time=0.0558\n",
      "  Time took: 0:02:03\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.train()\n",
    "\n",
    "epoch_loss = 0.\n",
    "iter_loss = 0.\n",
    "iter_mse = 0.\n",
    "iter_cnt = 0\n",
    "iter_dur = []\n",
    "\n",
    "# 서브그래프 단위로 학습\n",
    "for iter_idx, batch in enumerate(loader, start=1):\n",
    "    t_start = time.time()\n",
    "\n",
    "    inputs = batch[0].to(device)\n",
    "    labels = batch[1].to(device)\n",
    "    preds = model(inputs)\n",
    "    loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item() * preds.shape[0]\n",
    "    iter_loss += loss.item() * preds.shape[0]\n",
    "    iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "    iter_cnt += preds.shape[0]\n",
    "    iter_dur.append(time.time() - t_start)\n",
    "\n",
    "    if iter_idx % log_interval == 0:\n",
    "        print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "            iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "        iter_loss = 0.\n",
    "        iter_mse = 0.\n",
    "        iter_cnt = 0\n",
    "\n",
    "train_epoch_loss = epoch_loss / len(loader.dataset)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d54b44e-f603-4327-9a87-904041c70d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=6450, num_edges=139018,\n",
       "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'nlabel': Scheme(shape=(4,), dtype=torch.float32), 'x': Scheme(shape=(4,), dtype=torch.float32)}\n",
       "      edata_schemes={'etype': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64), 'edge_mask': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "992ba225-8165-40a2-8384-81b354d23b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 3., 2., 3., 0., 2., 1., 4., 4., 3., 4., 0., 1., 4., 1., 1., 3., 2.,\n",
       "        2., 2., 3., 3., 2., 2., 3., 3., 1., 4., 3., 3., 4., 1.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41f4dcf4-1350-4831-9dc5-c356e1daf391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3369, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "987146e4-6ad1-4339-b27f-851e94945000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f305240a-7b5c-4100-8d58-5dab9f972c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9925650261491538"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "613c9bbf-4877-49bd-9cb2-f5927bcd8038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1965, 3.2606, 2.1261, 2.1432, 1.3766, 2.8473, 3.2015, 3.3880, 3.1641,\n",
       "        3.2201, 2.5737, 4.1435, 2.3493, 3.9149, 1.9054, 1.8999, 3.1879, 2.9674,\n",
       "        1.7518, 2.2147, 3.3358, 3.2158, 2.7466, 2.6548, 2.5784, 2.0909, 2.0695,\n",
       "        3.3606, 2.8916, 4.1838, 4.0277, 2.7520], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198de4d4-9dc0-4184-84f4-1a40cc509972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37162a-ee65-4af9-9cab-e4a795fc5099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4c6bc06-0a33-414c-a73b-e409bca5e421",
   "metadata": {},
   "source": [
    "### Evaluate 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb2b26d9-25c4-4328-802b-068c674c8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "loader = test_loader\n",
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47e1a54f-e56b-4650-a9c1-498ad5893824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training epoch took: 0:00:25\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Evaluate RMSE\n",
    "model.eval()\n",
    "mse = 0.\n",
    "for batch in loader:\n",
    "    with th.no_grad():\n",
    "        preds = model(batch[0].to(device))\n",
    "    labels = batch[1].to(device)\n",
    "    mse += ((preds - labels) ** 2).sum().item()\n",
    "mse /= len(loader.dataset)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "437b02ec-0ac8-45fd-aa39-d9ebfe9daa56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6446, 2.4995, 3.3400, 4.1142, 2.6222, 2.7281, 2.7435, 2.6823, 2.5650,\n",
       "        3.0737, 2.6525, 1.7842, 2.4336, 2.8425, 2.9337, 3.1345, 3.2127, 2.4646,\n",
       "        2.2066, 2.2617, 2.9193, 2.4082, 2.0911, 3.1148, 1.7831, 3.2895, 2.2131,\n",
       "        2.8884, 2.1818, 3.5460, 2.3100, 2.8405], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3292c796-c71b-4078-8fd9-a07f58be62b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 2., 3., 4., 2., 2., 3., 1., 3., 3., 3., 2., 2., 3., 3., 3., 4., 3.,\n",
       "        2., 1., 2., 3., 3., 3., 1., 4., 2., 3., 3., 4., 4., 3.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54927b7e-515f-481e-b8ed-d746e8de230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9488357172065862"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab427bd-4cc3-4e74-94f9-b88194b22936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
