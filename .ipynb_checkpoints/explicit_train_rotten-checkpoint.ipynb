{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee754ff-2a3d-4760-9dde-f35b5079e53b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training epoch took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5af6c94-0780-4733-88b7-286a4a08728a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training IGMC model on the MovieLens dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "from shutil import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from explicit_model_rotten import IGMC\n",
    "from explicit_data_rotten import RottenTomato\n",
    "from explicit_dataset_rotten import (RottenTomatoDataset, collate_rotten_tomato,\n",
    "                                     MultiRottenTomatoDataset, multi_collate_rotten_tomato)\n",
    "from utils import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54c1bb83-260d-40b8-900b-6c27d7da5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    predict_list = list()\n",
    "    label_list = list()\n",
    "    \n",
    "    # Evaluate RMSE\n",
    "    model.eval()\n",
    "    mse = 0.\n",
    "    for iter_idx, batch in enumerate(loader):\n",
    "        with th.no_grad():\n",
    "            block_r = batch[0][0].to(device)\n",
    "            block_s = batch[0][1].to(device)\n",
    "            block_e = batch[0][2].to(device)\n",
    "            tmp = model(block_r, block_s, block_e)\n",
    "            preds = (tmp + 1)/2\n",
    "        \n",
    "        tmp_rating = batch[1][0].to(device) # 정답 rating labels\n",
    "        labels = (tmp_rating+1)/2\n",
    "        mse += ((preds - labels) ** 2).sum().item()\n",
    "        \n",
    "        predict_list.append(preds.tolist()) # 예측값 저장\n",
    "        label_list.append(labels.tolist()) # 정답값 저장\n",
    "        \n",
    "        # 2차원 -> 1차원 리스트 변형\n",
    "    predict_list = [element for array in predict_list for element in array]\n",
    "    label_list = [element for array in label_list for element in array]    \n",
    "        \n",
    "    mse /= len(loader.dataset)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse, predict_list, label_list\n",
    "\n",
    "def adj_rating_reg_r(model):\n",
    "    arr_loss = 0\n",
    "    for conv in model.convs_r:\n",
    "        weight = conv.weight.view(conv.num_bases, conv.in_feat * conv.out_feat)\n",
    "        weight = th.matmul(conv.w_comp, weight).view(conv.num_rels, conv.in_feat, conv.out_feat)\n",
    "        arr_loss += th.sum((weight[1:, :, :] - weight[:-1, :, :])**2)\n",
    "    return arr_loss\n",
    "\n",
    "def adj_rating_reg_s(model):\n",
    "    arr_loss = 0\n",
    "    for conv in model.convs_s:\n",
    "        weight = conv.weight.view(conv.num_bases, conv.in_feat * conv.out_feat)\n",
    "        weight = th.matmul(conv.w_comp, weight).view(conv.num_rels, conv.in_feat, conv.out_feat)\n",
    "        arr_loss += th.sum((weight[1:, :, :] - weight[:-1, :, :])**2)\n",
    "    return arr_loss\n",
    "\n",
    "# rating, sentiment, emotion loader를 받음\n",
    "def train_epoch(model, loss_fn, optimizer, arr_lambda, loader, device, log_interval):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.\n",
    "    iter_loss = 0.\n",
    "    iter_mse = 0.\n",
    "    iter_cnt = 0\n",
    "    iter_dur = []\n",
    "\n",
    "    iter_idx = 0\n",
    "    \n",
    "    # 저장 리스트(예측, 정답)\n",
    "    predict_list = list()\n",
    "    label_list = list()\n",
    "    \n",
    "    for iter_idx, batch in enumerate(loader, start=1):\n",
    "        t_start = time.time()\n",
    "        \n",
    "        # rating\n",
    "        inputs_r = batch[0][0].to(device)\n",
    "        labels_r = batch[1][0].to(device)\n",
    "        # sentiment\n",
    "        inputs_s = batch[0][1].to(device)\n",
    "        labels_s = batch[1][1].to(device)\n",
    "        # emotion\n",
    "        inputs_e = batch[0][2].to(device)\n",
    "        labels_e = batch[1][2].to(device)\n",
    "    \n",
    "        preds = model(inputs_r, inputs_s, inputs_e)\n",
    "        preds  = (preds + 1)/2\n",
    "        labels_r = (labels_r + 1)/2\n",
    "        loss = loss_fn(preds, labels_r).mean() + arr_lambda * adj_rating_reg_r(model) + arr_lambda * adj_rating_reg_s(model)\n",
    "#         loss = loss_fn(preds, labels_r).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * preds.shape[0]\n",
    "        iter_loss += loss.item() * preds.shape[0]\n",
    "        iter_mse += ((preds - labels_r) ** 2).sum().item()\n",
    "        iter_cnt += preds.shape[0]\n",
    "        iter_dur.append(time.time() - t_start)\n",
    "\n",
    "        predict_list.append(preds.tolist()) # 예측값 저장\n",
    "        label_list.append(labels_r.tolist()) # 정답값 저장\n",
    "        \n",
    "        if iter_idx % log_interval == 0:\n",
    "            print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "                iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "            iter_loss = 0.\n",
    "            iter_mse = 0.\n",
    "            iter_cnt = 0\n",
    "        \n",
    "    # 2차원 -> 1차원 리스트 변형\n",
    "    predict_list = [element for array in predict_list for element in array]\n",
    "    label_list = [element for array in label_list for element in array]\n",
    "\n",
    "    train_epoch_loss = epoch_loss / len(loader.dataset)  \n",
    "    return train_epoch_loss, predict_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff187c-d0a5-44d6-bf40-12a1c7927a3b",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0218e93a-7bb0-4007-a0d4-194dfbf0fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({ \n",
    "    'data_name':            'rotten',\n",
    "    'testing':     \t        True,\n",
    "    'device':      \t        0,\n",
    "    'seed':        \t        1234,\n",
    "    'data_test_ratio':      0.1,\n",
    "    'num_workers':   \t    8,\n",
    "    'data_valid_ratio':     0.2,\n",
    "    'train_log_interval':   200,\n",
    "    'valid_log_interval':   10,\n",
    "    'save_appendix':   \t    'debug',\n",
    "    'hop':   \t            1,\n",
    "    'sample_ratio':    \t    1.0,\n",
    "    'max_nodes_per_hop':    100,\n",
    "    'edge_dropout':   \t    0.2,\n",
    "    'force_undirected':     False,\n",
    "    'train_lr':   \t        1e-3,\n",
    "    'train_min_lr':   \t    1e-6,\n",
    "    'train_lr_decay_factor':0.1,\n",
    "    'train_lr_decay_step':  50,\n",
    "    'train_epochs':   \t    10,\n",
    "    'batch_size':   \t    16,\n",
    "    'arr_lambda':   \t    0.001,\n",
    "    'num_rgcn_bases':   \t4,\n",
    "    'train_epochs':   \t    1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eefc4e0-e1a6-47fa-af1b-3f79a748f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_name': 'rotten', 'testing': True, 'device': 0, 'seed': 1234, 'data_test_ratio': 0.1, 'num_workers': 8, 'data_valid_ratio': 0.2, 'train_log_interval': 200, 'valid_log_interval': 10, 'save_appendix': 'debug', 'hop': 1, 'sample_ratio': 1.0, 'max_nodes_per_hop': 100, 'edge_dropout': 0.2, 'force_undirected': False, 'train_lr': 0.001, 'train_min_lr': 1e-06, 'train_lr_decay_factor': 0.1, 'train_lr_decay_step': 50, 'train_epochs': 1, 'batch_size': 16, 'arr_lambda': 0.001, 'num_rgcn_bases': 4, 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\IGMC_CX\\\\log/rotten_debug_testmode_2111211658'}\n",
      "Command line input: python3 C:\\Users\\user\\anaconda3\\envs\\graph\\lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\user\\AppData\\Roaming\\jupyter\\runtime\\kernel-2aa2e963-68cd-4b84-8169-2fdecc07b3a6.json is saved.\n"
     ]
    }
   ],
   "source": [
    "### set save_dir according to localtime and test mode\n",
    "file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "args.save_dir = os.path.join(\n",
    "    file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "        args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "    )\n",
    ")\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir) \n",
    "print(args)\n",
    "\n",
    "# backup current .py files\n",
    "for f in glob.glob(r\"*.py\"):\n",
    "    copy(f, args.save_dir)\n",
    "\n",
    "# save command line input\n",
    "cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "    f.write(cmd_input)\n",
    "    f.write(\"\\n\")\n",
    "print('Command line input: ' + cmd_input + ' is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0952c8a-5880-48c8-a6b0-76fa1226074e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_name': 'rotten',\n",
       " 'testing': True,\n",
       " 'device': 0,\n",
       " 'seed': 1234,\n",
       " 'data_test_ratio': 0.1,\n",
       " 'num_workers': 8,\n",
       " 'data_valid_ratio': 0.2,\n",
       " 'train_log_interval': 200,\n",
       " 'valid_log_interval': 10,\n",
       " 'save_appendix': 'debug',\n",
       " 'hop': 1,\n",
       " 'sample_ratio': 1.0,\n",
       " 'max_nodes_per_hop': 100,\n",
       " 'edge_dropout': 0.2,\n",
       " 'force_undirected': False,\n",
       " 'train_lr': 0.001,\n",
       " 'train_min_lr': 1e-06,\n",
       " 'train_lr_decay_factor': 0.1,\n",
       " 'train_lr_decay_step': 50,\n",
       " 'train_epochs': 1,\n",
       " 'batch_size': 16,\n",
       " 'arr_lambda': 0.001,\n",
       " 'num_rgcn_bases': 4,\n",
       " 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\IGMC_CX\\\\log/rotten_debug_testmode_2111211658'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e5af39-9646-43f8-87d2-8d9c498b7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "th.manual_seed(args.seed)\n",
    "if th.cuda.is_available():\n",
    "    th.cuda.manual_seed_all(args.seed)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd9d7e-1617-4c32-a8bc-006d4a49ca35",
   "metadata": {},
   "source": [
    "## 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c44d14-7115-4e81-9c99-99f370f93129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label_type: rating\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n",
      "Label_type: sentiment\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n",
      "Label_type: emotion\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n"
     ]
    }
   ],
   "source": [
    "### prepare data and set model\n",
    "path = './raw_data/rotten_tomato/'\n",
    "rotten_tomato_r = RottenTomato('rating',    path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "rotten_tomato_s = RottenTomato('sentiment', path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "rotten_tomato_e = RottenTomato('emotion',   path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530daf78-1abb-45fc-8e29-7f13a1761c55",
   "metadata": {},
   "source": [
    "### 2-1. multi_rotten_tomato_dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb69f150-c705-4520-914c-998f819fd282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 수정한 것 (단, 그래프의 모든 행의 길이 동일함)\n",
    "train_rating_pairs  = [rotten_tomato_r.train_rating_pairs, rotten_tomato_s.train_rating_pairs, rotten_tomato_e.train_rating_pairs]\n",
    "train_rating_values = [rotten_tomato_r.train_rating_values, rotten_tomato_s.train_rating_values, rotten_tomato_e.train_rating_values]\n",
    "train_graph         = [rotten_tomato_r.train_graph, rotten_tomato_s.train_graph, rotten_tomato_e.train_graph]\n",
    "\n",
    "test_rating_pairs  = [rotten_tomato_r.test_rating_pairs, rotten_tomato_s.test_rating_pairs, rotten_tomato_e.test_rating_pairs]\n",
    "test_rating_values = [rotten_tomato_r.test_rating_values, rotten_tomato_s.test_rating_values, rotten_tomato_e.test_rating_values]\n",
    "test_graph         = [rotten_tomato_r.train_graph, rotten_tomato_s.train_graph, rotten_tomato_e.train_graph]\n",
    "\n",
    "valid_rating_pairs  = [rotten_tomato_r.valid_rating_pairs, rotten_tomato_s.valid_rating_pairs, rotten_tomato_e.valid_rating_pairs]\n",
    "valid_rating_values = [rotten_tomato_r.valid_rating_values, rotten_tomato_s.valid_rating_values, rotten_tomato_e.valid_rating_values]\n",
    "valid_graph         = [rotten_tomato_r.train_graph, rotten_tomato_s.train_graph, rotten_tomato_e.train_graph]\n",
    "\n",
    "hop = [1, 1, 1]\n",
    "sample_ratio = [1.0, 1.0, 1.0]\n",
    "max_nodes_per_hop = [200, 200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af177066-b960-4e61-8bb6-f993f4644086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultiRottenTomatoDataset(train_rating_pairs, train_rating_values, train_graph, hop, sample_ratio, max_nodes_per_hop)\n",
    "train_loader = th.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, \n",
    "                        num_workers=0, collate_fn=multi_collate_rotten_tomato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bb2a9bc-37f2-4178-a458-efab36ebd80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    }
   ],
   "source": [
    "if args.testing:\n",
    "    print('testing')\n",
    "    test_dataset = MultiRottenTomatoDataset(test_rating_pairs, test_rating_values, test_graph, hop, sample_ratio, max_nodes_per_hop)\n",
    "    test_loader = th.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, \n",
    "                            num_workers=0, collate_fn=multi_collate_rotten_tomato)\n",
    "else:\n",
    "    print('valid')\n",
    "    test_dataset = MultiRottenTomatoDataset(valid_rating_pairs, valid_rating_values, valid_graph, hop, sample_ratio, max_nodes_per_hop)\n",
    "    test_loader = th.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=True, \n",
    "                            num_workers=0, collate_fn=multi_collate_rotten_tomato)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e015002-b338-488e-ad01-4cbf7b4a0715",
   "metadata": {},
   "source": [
    "테스트중입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba464e44-2833-4f50-8c5f-abac54c15ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for iter_idx, batch in enumerate(train_loader, start=1):\n",
    "    if iter_idx == 5:\n",
    "        break\n",
    "    print(iter_idx)\n",
    "    \n",
    "    device = args.device\n",
    "    \n",
    "    # rating\n",
    "    inputs_r = batch[0][0].to(device)\n",
    "    labels_r = batch[1][0].to(device)\n",
    "    # sentiment\n",
    "    inputs_s = batch[0][1].to(device)\n",
    "    labels_s = batch[1][1].to(device)\n",
    "    # emotion\n",
    "    inputs_e = batch[0][2].to(device)\n",
    "    labels_e = batch[1][2].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8fb1fe-280e-4258-93a2-2a2ef70dd385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b887251-cbc5-4f77-8959-da25848a404f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c679b72-a7a2-4abb-9c4d-efdebf97dbc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network finished ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_feats = (args.hop+1)*2 #+ rotten_tomato.train_graph.ndata['refex'].shape[1]\n",
    "model = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=10, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "loss_fn = nn.MSELoss().to(args.device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "print(\"Loading network finished ...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b4b350-a659-41eb-8f85-4baf5495fc5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n"
     ]
    }
   ],
   "source": [
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "for epoch_idx in range(1, 2):\n",
    "    print ('Epoch', epoch_idx)\n",
    "\n",
    "    train_loss, predict_train_list, label_train_list  = train_epoch(model, loss_fn, optimizer, args.arr_lambda, \n",
    "                            train_loader, args.device, args.train_log_interval)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(model, test_loader, args.device)\n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model, optimizer)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a90669ed-13ea-413e-800d-0d14044424f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8103740322825607"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25ddbd54-1fd9-4297-acdb-8473e455fc46",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_train_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_52692/3291285701.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_emotion_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_train_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_emotion_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvalid_emotion_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_valid_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_valid_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict_train_list' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_emotion_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "# valid_emotion_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "# valid_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_emotion_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "646f6c55-8dc5-4999-b2b0-70af13b2248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ends. The best testing rmse is 0.804960 at epoch 2\n"
     ]
    }
   ],
   "source": [
    "path = './raw_data/rotten_tomato/explicit/'\n",
    "rate = 1\n",
    "train_emotion_df.to_csv(path + f'explicit_train_emotion_{rate}.csv', index=False)\n",
    "# valid_emotion_df.to_csv(path + f'explicit_valid_emotion_{rate}.csv', index=False)\n",
    "test_emotion_df.to_csv(path + f'explicit_test_emotion_{rate}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ec387-47c1-4660-87ad-f1a5138ef95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03faa981-c0e4-438c-846b-bdd142d583ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c728cd9-f005-491f-84dc-d63650c2700a",
   "metadata": {},
   "source": [
    "### Train_epoch 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4bec73f-8cab-45aa-a3cb-beccdda9bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "loss_fn = loss_fn\n",
    "optimizer = optimizer\n",
    "arr_lambda = args.arr_lambda\n",
    "loader = train_loader\n",
    "device = args.device\n",
    "log_interval = args.train_log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df6fd326-b5dc-4acd-8832-9aae253d90a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82e5500a-2408-4c15-a6dd-0275f00a2a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for iter_idx, batch in enumerate(loader, start=1):\n",
    "    print(iter_idx)\n",
    "    if iter_idx == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b454620b-9795-4b72-b151-73be1461b119",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=200, loss=5.0480, mse=5.0403, time=0.0473\n",
      "Iter=400, loss=3.2373, mse=3.2299, time=0.0425\n",
      "Iter=600, loss=3.2133, mse=3.2064, time=0.0419\n",
      "Iter=800, loss=3.1650, mse=3.1585, time=0.0415\n",
      "Iter=1000, loss=3.1144, mse=3.1082, time=0.0413\n",
      "Iter=1200, loss=3.0636, mse=3.0578, time=0.0411\n",
      "Iter=1400, loss=2.9595, mse=2.9539, time=0.0410\n",
      "Iter=1600, loss=2.9292, mse=2.9239, time=0.0408\n",
      "Iter=1800, loss=2.8808, mse=2.8756, time=0.0408\n",
      "Iter=2000, loss=2.9187, mse=2.9137, time=0.0409\n",
      "Iter=2200, loss=2.9908, mse=2.9861, time=0.0410\n",
      "Iter=2400, loss=2.9135, mse=2.9088, time=0.0412\n",
      "Iter=2600, loss=2.8839, mse=2.8795, time=0.0411\n",
      "Iter=2800, loss=2.9526, mse=2.9484, time=0.0411\n",
      "Iter=3000, loss=2.7681, mse=2.7641, time=0.0411\n",
      "Iter=3200, loss=2.9428, mse=2.9389, time=0.0410\n",
      "Iter=3400, loss=2.8883, mse=2.8843, time=0.0410\n",
      "Iter=3600, loss=2.8257, mse=2.8217, time=0.0413\n",
      "Iter=3800, loss=2.8143, mse=2.8105, time=0.0414\n",
      "Iter=4000, loss=2.8891, mse=2.8853, time=0.0417\n",
      "Iter=4200, loss=2.7421, mse=2.7384, time=0.0417\n",
      "Iter=4400, loss=2.8413, mse=2.8378, time=0.0417\n",
      "Iter=4600, loss=2.7401, mse=2.7365, time=0.0416\n",
      "Iter=4800, loss=2.8078, mse=2.8041, time=0.0416\n",
      "Iter=5000, loss=2.7927, mse=2.7891, time=0.0416\n",
      "Iter=5200, loss=2.7636, mse=2.7601, time=0.0415\n",
      "Iter=5400, loss=2.7138, mse=2.7103, time=0.0417\n",
      "Iter=5600, loss=2.7358, mse=2.7324, time=0.0417\n",
      "Iter=5800, loss=2.7588, mse=2.7552, time=0.0416\n",
      "Iter=6000, loss=2.7475, mse=2.7439, time=0.0416\n",
      "Iter=6200, loss=2.7544, mse=2.7507, time=0.0416\n",
      "Iter=6400, loss=2.8208, mse=2.8171, time=0.0415\n",
      "Iter=6600, loss=2.7839, mse=2.7801, time=0.0416\n",
      "  Time took: 0:04:58\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.train()\n",
    "\n",
    "epoch_loss = 0.\n",
    "iter_loss = 0.\n",
    "iter_mse = 0.\n",
    "iter_cnt = 0\n",
    "iter_dur = []\n",
    "\n",
    "# 서브그래프 단위로 학습\n",
    "for iter_idx, batch in enumerate(loader, start=1):\n",
    "    t_start = time.time()\n",
    "\n",
    "    inputs = batch[0].to(device)\n",
    "    labels = batch[1].to(device)\n",
    "    preds = model(inputs)\n",
    "    loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item() * preds.shape[0]\n",
    "    iter_loss += loss.item() * preds.shape[0]\n",
    "    iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "    iter_cnt += preds.shape[0]\n",
    "    iter_dur.append(time.time() - t_start)\n",
    "\n",
    "    if iter_idx % log_interval == 0:\n",
    "        print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "            iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "        iter_loss = 0.\n",
    "        iter_mse = 0.\n",
    "        iter_cnt = 0\n",
    "\n",
    "train_epoch_loss = epoch_loss / len(loader.dataset)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b29fffa-8cc3-4a70-98ed-4d22a4617f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IGMC"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d54b44e-f603-4327-9a87-904041c70d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=1120, num_edges=31588,\n",
       "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'nlabel': Scheme(shape=(4,), dtype=torch.float32), 'x': Scheme(shape=(4,), dtype=torch.float32)}\n",
       "      edata_schemes={'etype': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64), 'edge_mask': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87899af1-f644-4299-8f35-0cabadb300b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0763, 7.5723, 4.1323, 5.4378, 5.5795, 6.2285, 6.7028, 4.2875],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "992ba225-8165-40a2-8384-81b354d23b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 7., 6., 7., 7., 7., 9., 5.], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41f4dcf4-1350-4831-9dc5-c356e1daf391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9040, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "987146e4-6ad1-4339-b27f-851e94945000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f305240a-7b5c-4100-8d58-5dab9f972c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.727407252259081"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "613c9bbf-4877-49bd-9cb2-f5927bcd8038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.0923, 5.4808, 6.1765, 8.1413, 7.6566, 4.6887, 6.3527, 6.4477, 6.0566,\n",
       "        5.4327, 5.4816, 7.4522, 5.6513, 8.6706, 5.8030, 7.2858, 4.5068, 8.8621,\n",
       "        3.4885, 7.3030, 3.4780, 6.1335, 2.9561, 4.1378, 5.3948, 6.8066, 5.6749,\n",
       "        5.6852, 4.4658, 7.3438, 9.4554, 7.2134], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198de4d4-9dc0-4184-84f4-1a40cc509972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37162a-ee65-4af9-9cab-e4a795fc5099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4c6bc06-0a33-414c-a73b-e409bca5e421",
   "metadata": {},
   "source": [
    "### Evaluate 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb2b26d9-25c4-4328-802b-068c674c8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "loader = test_loader\n",
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47e1a54f-e56b-4650-a9c1-498ad5893824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time took: 0:00:27\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict_ratings = list()\n",
    "real_ratings = list()\n",
    "\n",
    "# Evaluate RMSE\n",
    "model.eval()\n",
    "mse = 0.\n",
    "for batch in loader:\n",
    "    with th.no_grad():\n",
    "        preds = (model(batch[0].to(device)) + 1)/ 2\n",
    "    labels = (batch[1].to(device) + 1)/ 2\n",
    "    mse += ((preds - labels) ** 2).sum().item()\n",
    "    \n",
    "    real_ratings.append(labels)\n",
    "    predict_ratings.append(preds)\n",
    "    \n",
    "mse /= len(loader.dataset)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a533c878-4f4f-4d70-b1ab-1f930ab636b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9968, 3.1041, 2.8940, 3.9403, 4.1405, 3.1857, 3.4408, 4.0894, 2.6228,\n",
       "        3.2692, 2.8797, 2.1028, 2.8179, 3.5234, 3.3022, 4.0670, 4.0670, 2.9974,\n",
       "        2.1890, 2.4611, 1.2208, 2.3978, 3.7354, 2.5466, 3.1223, 3.4322, 2.1431,\n",
       "        2.5878, 2.5878, 3.6192], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3292c796-c71b-4078-8fd9-a07f58be62b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5000, 3.5000, 3.5000, 5.0000, 4.0000, 4.5000, 4.5000, 4.0000, 4.0000,\n",
       "        3.5000, 4.5000, 1.0000, 3.0000, 2.5000, 4.0000, 2.0000, 2.0000, 4.0000,\n",
       "        2.5000, 2.5000, 2.5000, 2.5000, 5.0000, 3.0000, 3.5000, 5.0000, 3.5000,\n",
       "        3.0000, 3.0000, 4.5000], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54927b7e-515f-481e-b8ed-d746e8de230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.838736481576567"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dca19d71-2874-4586-a7a6-5547ed60a2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7650, 2.8793, 2.5193, 2.8136, 3.7364, 2.8414, 2.8343, 3.5618, 3.6456,\n",
       "        3.5358], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ratings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a41bd92d-e324-4a86-9656-da4c8c516a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 3.0000, 3.0000, 2.5000, 3.0000, 3.0000, 3.0000, 4.5000, 3.0000,\n",
       "        2.5000], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_ratings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f0465-ef4c-424f-8a7d-1bd31800fc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae685cc-df32-47d9-ab80-320e40749f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda367ca-52b8-4455-87ec-c8cc7b71562b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
