{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9808d08-eb26-4f02-bc5f-364f9aa033f3",
   "metadata": {},
   "source": [
    "# Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee754ff-2a3d-4760-9dde-f35b5079e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training epoch took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5af6c94-0780-4733-88b7-286a4a08728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training IGMC model on the MovieLens dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "from shutil import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import IGMC\n",
    "from explicit_data_rotten import RottenTomato\n",
    "from dataset_rotten import RottenTomatoDataset, collate_rotten_tomato\n",
    "from utils import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "54c1bb83-260d-40b8-900b-6c27d7da5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(label_type, model, loader, device):\n",
    "    predict_list = list()\n",
    "    label_list = list()\n",
    "\n",
    "    # Evaluate RMSE\n",
    "    model.eval()\n",
    "    mse = 0.\n",
    "    for batch in loader:\n",
    "        with th.no_grad():\n",
    "            preds = model(batch[0].to(device))\n",
    "        labels = batch[1].to(device)\n",
    "\n",
    "        if label_type == 'rating':\n",
    "            preds  = (preds + 1)/2\n",
    "            labels = (labels + 1)/2\n",
    "        else:\n",
    "            preds  = preds + 1\n",
    "            labels = labels + 1\n",
    "        mse += ((preds - labels) ** 2).sum().item()\n",
    "\n",
    "        predict_list.append(preds.tolist()) # 예측값 저장\n",
    "        label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "    # 2차원 -> 1차원 리스트 변형\n",
    "    predict_list = [element for array in predict_list for element in array]\n",
    "    label_list = [element for array in label_list for element in array]    \n",
    "\n",
    "    mse /= len(loader.dataset)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse, predict_list, label_list\n",
    "\n",
    "\n",
    "def adj_rating_reg(model):\n",
    "    arr_loss = 0\n",
    "    for conv in model.convs:\n",
    "        weight = conv.weight.view(conv.num_bases, conv.in_feat * conv.out_feat)\n",
    "        weight = th.matmul(conv.w_comp, weight).view(conv.num_rels, conv.in_feat, conv.out_feat)\n",
    "        arr_loss += th.sum((weight[1:, :, :] - weight[:-1, :, :])**2)\n",
    "    return arr_loss\n",
    "\n",
    "# @profile\n",
    "def train_epoch(label_type, model, loss_fn, optimizer, arr_lambda, loader, device, log_interval):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.\n",
    "    iter_loss = 0.\n",
    "    iter_mse = 0.\n",
    "    iter_cnt = 0\n",
    "    iter_dur = []\n",
    "\n",
    "    # 저장 리스트(예측, 정답)\n",
    "    predict_list = list()\n",
    "    label_list = list()\n",
    "\n",
    "    # 서브그래프 단위로 학습\n",
    "    for iter_idx, batch in enumerate(loader, start=1):\n",
    "        t_start = time.time()\n",
    "\n",
    "        inputs = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "        preds = model(inputs)\n",
    "\n",
    "        if label_type == 'emotion':\n",
    "            loss = loss_fn(preds, labels).mean()\n",
    "        else:\n",
    "            loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * preds.shape[0]\n",
    "        iter_loss += loss.item() * preds.shape[0]\n",
    "        iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "        iter_cnt += preds.shape[0]\n",
    "        iter_dur.append(time.time() - t_start)\n",
    "\n",
    "        if label_type == 'rating':\n",
    "            preds  = (preds + 1)/2\n",
    "            labels = (labels + 1)/2\n",
    "        else:\n",
    "            preds  = preds + 1\n",
    "            labels = labels + 1\n",
    "\n",
    "        predict_list.append(preds.tolist()) # 예측값 저장\n",
    "        label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "        if iter_idx % log_interval == 0:\n",
    "            print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "                iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "            iter_loss = 0.\n",
    "            iter_mse = 0.\n",
    "            iter_cnt = 0\n",
    "\n",
    "    # 2차원 -> 1차원 리스트 변형\n",
    "    predict_list = [element for array in predict_list for element in array]\n",
    "    label_list = [element for array in label_list for element in array]\n",
    "\n",
    "    train_epoch_loss = epoch_loss / len(loader.dataset)  \n",
    "    return train_epoch_loss, predict_list, label_list\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    movielens = MovieLens(args.data_name, testing=args.testing,\n",
    "                            test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "    if args.testing:\n",
    "        test_dataset = RottenTomatoDataset(\n",
    "            movielens.test_rating_pairs, movielens.test_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "    else:\n",
    "        test_dataset = RottenTomatoDataset(\n",
    "            movielens.valid_rating_pairs, movielens.valid_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "    train_dataset = RottenTomatoDataset(\n",
    "        movielens.train_rating_pairs, movielens.train_rating_values, movielens.train_graph, \n",
    "        args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "    train_loader = th.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "    test_loader = th.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "\n",
    "    in_feats = (args.hop+1)*2 #+ movielens.train_graph.ndata['refex'].shape[1]\n",
    "    model = IGMC(in_feats=in_feats, \n",
    "                 latent_dim=[32, 32, 32, 32],\n",
    "                 num_relations=5, # movielens.num_rating, \n",
    "                 num_bases=4, \n",
    "                 regression=True, \n",
    "                 edge_dropout=args.edge_dropout,\n",
    "                #  side_features=args.use_features,\n",
    "                #  n_side_features=n_features,\n",
    "                #  multiply_by=args.multiply_by\n",
    "            ).to(args.device)\n",
    "    loss_fn = nn.MSELoss().to(args.device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "    print(\"Loading network finished ...\\n\")\n",
    "\n",
    "    ### prepare the logger\n",
    "    logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "    \n",
    "    best_epoch = 0\n",
    "    best_rmse = np.inf\n",
    "    ### declare the loss information\n",
    "    print(\"Start training ...\")\n",
    "    for epoch_idx in range(1, args.train_epochs+1):\n",
    "        print ('Epoch', epoch_idx)\n",
    "    \n",
    "        train_loss = train_epoch(model, loss_fn, optimizer, args.arr_lambda, \n",
    "                                train_loader, args.device, args.train_log_interval)\n",
    "        test_rmse = evaluate(model, test_loader, args.device)\n",
    "        eval_info = {\n",
    "            'epoch': epoch_idx,\n",
    "            'train_loss': train_loss,\n",
    "            'test_rmse': test_rmse,\n",
    "        }\n",
    "        print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "        if epoch_idx % args.train_lr_decay_step == 0:\n",
    "            for param in optimizer.param_groups:\n",
    "                param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "        logger.log(eval_info, model, optimizer)\n",
    "        if best_rmse > test_rmse:\n",
    "            best_rmse = test_rmse\n",
    "            best_epoch = epoch_idx\n",
    "    eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "    print(eval_info)\n",
    "    with open(os.path.join(args.save_dir, 'log.txt'), 'a') as f:\n",
    "        f.write(eval_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d4fbabcc-6d45-4d08-8d5e-f9f483e56aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def config():\n",
    "    parser = argparse.ArgumentParser(description='IGMC')\n",
    "    # general settings\n",
    "    parser.add_argument('--testing', action='store_true', default=False,\n",
    "                        help='if set, use testing mode which splits all ratings into train/test;\\\n",
    "                        otherwise, use validation model which splits all ratings into \\\n",
    "                        train/val/test and evaluate on val only')\n",
    "    parser.add_argument('--device', default='0', type=int,\n",
    "                        help='Running device. E.g `--device 0`, if using cpu, set `--device -1`')\n",
    "    parser.add_argument('--seed', type=int, default=1234, metavar='S',\n",
    "                        help='random seed (default: 1234)')\n",
    "    parser.add_argument('--data_name', default='ml-100k', type=str,\n",
    "                        help='The dataset name: ml-100k, ml-1m')\n",
    "    parser.add_argument('--data_test_ratio', type=float, default=0.1) # for ml-100k the test ration is 0.2\n",
    "    parser.add_argument('--num_workers', type=int, default=8)\n",
    "    parser.add_argument('--data_valid_ratio', type=float, default=0.2)\n",
    "    # parser.add_argument('--ensemble', action='store_true', default=False,\n",
    "    #                     help='if True, load a series of model checkpoints and ensemble the results')               \n",
    "    parser.add_argument('--train_log_interval', type=int, default=100)\n",
    "    parser.add_argument('--valid_log_interval', type=int, default=10)\n",
    "    parser.add_argument('--save_appendix', type=str, default='debug', \n",
    "                        help='what to append to save-names when saving results')\n",
    "    # subgraph extraction settings\n",
    "    parser.add_argument('--hop', default=1, metavar='S', \n",
    "                        help='enclosing subgraph hop number')\n",
    "    parser.add_argument('--sample_ratio', type=float, default=1.0, \n",
    "                        help='if < 1, subsample nodes per hop according to the ratio')\n",
    "    parser.add_argument('--max_nodes_per_hop', type=int, default=200, \n",
    "                        help='if > 0, upper bound the # nodes per hop by another subsampling')\n",
    "    # parser.add_argument('--use_features', action='store_true', default=False,\n",
    "    #                     help='whether to use node features (side information)')\n",
    "    # edge dropout settings\n",
    "    parser.add_argument('--edge_dropout', type=float, default=0.2, \n",
    "                        help='if not 0, random drops edges from adjacency matrix with this prob')\n",
    "    parser.add_argument('--force_undirected', action='store_true', default=False, \n",
    "                        help='in edge dropout, force (x, y) and (y, x) to be dropped together')\n",
    "    # optimization settings\n",
    "    parser.add_argument('--train_lr', type=float, default=1e-3)\n",
    "    parser.add_argument('--train_min_lr', type=float, default=1e-6)\n",
    "    parser.add_argument('--train_lr_decay_factor', type=float, default=0.1)\n",
    "    parser.add_argument('--train_lr_decay_step', type=int, default=50)\n",
    "    parser.add_argument('--train_epochs', type=int, default=80)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--arr_lambda', type=float, default=0.001)\n",
    "    parser.add_argument('--num_rgcn_bases', type=int, default=4)\n",
    "                \n",
    "    args = parser.parse_args()\n",
    "    args.device = th.device(args.device) if args.device >= 0 and th.cuda.is_available() else th.device('cpu')\n",
    "    \n",
    "    ### set save_dir according to localtime and test mode\n",
    "    file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "    val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "    local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "    args.save_dir = os.path.join(\n",
    "        file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "            args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "        )\n",
    "    )\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir) \n",
    "    print(args)\n",
    "\n",
    "    # backup current .py files\n",
    "    for f in glob.glob(r\"*.py\"):\n",
    "        copy(f, args.save_dir)\n",
    "\n",
    "    # save command line input\n",
    "    cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "    with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "        f.write(cmd_input)\n",
    "        f.write(\"\\n\")\n",
    "    print('Command line input: ' + cmd_input + ' is saved.')\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff187c-d0a5-44d6-bf40-12a1c7927a3b",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0218e93a-7bb0-4007-a0d4-194dfbf0fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({ \n",
    "    'data_name':            'rotten',\n",
    "    'testing':     \t        True,\n",
    "    'device':      \t        0,\n",
    "    'seed':        \t        1234,\n",
    "    'data_test_ratio':      0.1,\n",
    "    'num_workers':   \t    8,\n",
    "    'data_valid_ratio':     0.2,\n",
    "    'train_log_interval':   200,\n",
    "    'valid_log_interval':   10,\n",
    "    'save_appendix':   \t    'debug',\n",
    "    'hop':   \t            1,\n",
    "    'sample_ratio':    \t    1.0,\n",
    "    'max_nodes_per_hop':    100,\n",
    "    'edge_dropout':   \t    0.2,\n",
    "    'force_undirected':     False,\n",
    "    'train_lr':   \t        1e-3,\n",
    "    'train_min_lr':   \t    1e-6,\n",
    "    'train_lr_decay_factor':0.1,\n",
    "    'train_lr_decay_step':  50,\n",
    "    'train_epochs':   \t    10,\n",
    "    'batch_size':   \t    32,\n",
    "    'arr_lambda':   \t    0.001,\n",
    "    'num_rgcn_bases':   \t4,\n",
    "    'train_epochs':   \t    1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7eefc4e0-e1a6-47fa-af1b-3f79a748f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_name': 'rotten', 'testing': True, 'device': 0, 'seed': 1234, 'data_test_ratio': 0.1, 'num_workers': 8, 'data_valid_ratio': 0.2, 'train_log_interval': 200, 'valid_log_interval': 10, 'save_appendix': 'debug', 'hop': 1, 'sample_ratio': 1.0, 'max_nodes_per_hop': 100, 'edge_dropout': 0.2, 'force_undirected': False, 'train_lr': 0.001, 'train_min_lr': 1e-06, 'train_lr_decay_factor': 0.1, 'train_lr_decay_step': 50, 'train_epochs': 1, 'batch_size': 32, 'arr_lambda': 0.001, 'num_rgcn_bases': 4, 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\IGMC_CX\\\\log/rotten_debug_testmode_2111162042'}\n",
      "Command line input: python3 C:\\Users\\user\\anaconda3\\envs\\graph\\lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\user\\AppData\\Roaming\\jupyter\\runtime\\kernel-0ac5dae0-92ba-4f16-b89e-9354de532105.json is saved.\n"
     ]
    }
   ],
   "source": [
    "### set save_dir according to localtime and test mode\n",
    "file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "args.save_dir = os.path.join(\n",
    "    file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "        args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "    )\n",
    ")\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir) \n",
    "print(args)\n",
    "\n",
    "# backup current .py files\n",
    "for f in glob.glob(r\"*.py\"):\n",
    "    copy(f, args.save_dir)\n",
    "\n",
    "# save command line input\n",
    "cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "    f.write(cmd_input)\n",
    "    f.write(\"\\n\")\n",
    "print('Command line input: ' + cmd_input + ' is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b0e5af39-9646-43f8-87d2-8d9c498b7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "th.manual_seed(args.seed)\n",
    "if th.cuda.is_available():\n",
    "    th.cuda.manual_seed_all(args.seed)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd9d7e-1617-4c32-a8bc-006d4a49ca35",
   "metadata": {},
   "source": [
    "## 2. Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "57c44d14-7115-4e81-9c99-99f370f93129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label_type: rating\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n",
      "Label_type: sentiment\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n",
      "Label_type: emotion\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n"
     ]
    }
   ],
   "source": [
    "### prepare data and set model\n",
    "path = './raw_data/rotten_tomato/'\n",
    "rotten_tomato_r = RottenTomato('rating',    path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "rotten_tomato_s = RottenTomato('sentiment', path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "rotten_tomato_e = RottenTomato('emotion',   path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f3ff8769-41d9-4fe5-938f-51c370d372cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "valid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('testing')\n",
    "test_dataset_r = RottenTomatoDataset(\n",
    "    rotten_tomato_r.test_rating_pairs, rotten_tomato_r.test_rating_values, rotten_tomato_r.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "test_dataset_s = RottenTomatoDataset(\n",
    "    rotten_tomato_s.test_rating_pairs, rotten_tomato_s.test_rating_values, rotten_tomato_s.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "test_dataset_e = RottenTomatoDataset(\n",
    "    rotten_tomato_e.test_rating_pairs, rotten_tomato_e.test_rating_values, rotten_tomato_e.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "\n",
    "print('valid')\n",
    "valid_dataset_r = RottenTomatoDataset(\n",
    "    rotten_tomato_r.valid_rating_pairs, rotten_tomato_r.valid_rating_values, rotten_tomato_r.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "valid_dataset_s = RottenTomatoDataset(\n",
    "    rotten_tomato_s.valid_rating_pairs, rotten_tomato_s.valid_rating_values, rotten_tomato_s.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "valid_dataset_e = RottenTomatoDataset(\n",
    "    rotten_tomato_e.valid_rating_pairs, rotten_tomato_e.valid_rating_values, rotten_tomato_e.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "af5734e1-bc3a-422f-8050-da7ad09bfe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43266\n",
      "28766\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_dataset_r))\n",
    "print(len(test_dataset_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b5e9ce45-2ab8-4a5a-bae3-17a9871aad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_r = RottenTomatoDataset(\n",
    "    rotten_tomato_r.train_rating_pairs, rotten_tomato_r.train_rating_values, rotten_tomato_r.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "train_dataset_s = RottenTomatoDataset(\n",
    "    rotten_tomato_s.train_rating_pairs, rotten_tomato_s.train_rating_values, rotten_tomato_s.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "train_dataset_e = RottenTomatoDataset(\n",
    "    rotten_tomato_e.train_rating_pairs, rotten_tomato_e.train_rating_values, rotten_tomato_e.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "621bf1ca-2328-439c-bfe9-fd51f892552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_r = th.utils.data.DataLoader(train_dataset_r, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "valid_loader_r = th.utils.data.DataLoader(valid_dataset_r, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "test_loader_r = th.utils.data.DataLoader(test_dataset_r, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "\n",
    "train_loader_s = th.utils.data.DataLoader(train_dataset_s, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "valid_loader_s = th.utils.data.DataLoader(valid_dataset_s, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "test_loader_s = th.utils.data.DataLoader(test_dataset_s, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "\n",
    "train_loader_e = th.utils.data.DataLoader(train_dataset_e, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "valid_loader_e = th.utils.data.DataLoader(valid_dataset_e, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "test_loader_e = th.utils.data.DataLoader(test_dataset_e, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6c679b72-a7a2-4abb-9c4d-efdebf97dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feats = (args.hop+1)*2 #+ rotten_tomato.train_graph.ndata['refex'].shape[1]\n",
    "\n",
    "# rating\n",
    "model_r = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=10, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "\n",
    "# sentiment\n",
    "model_s = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=5, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "\n",
    "# emotion\n",
    "model_e = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=6, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss().to(args.device)\n",
    "optimizer_r = optim.Adam(model_r.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "optimizer_s = optim.Adam(model_s.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "optimizer_e = optim.Adam(model_e.parameters(), lr=args.train_lr, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a70cc4-cd48-4c52-8e31-4cb7c27d1205",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326886b9-35e6-41e0-96a1-f5ce214a1a53",
   "metadata": {},
   "source": [
    "### 3-1. rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4b1fbeff-7f20-4c16-a521-7e7a5f041e16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=200, loss=2.5531, mse=2.5484, time=0.0397\n",
      "Iter=400, loss=2.6710, mse=2.6663, time=0.0392\n",
      "Iter=600, loss=2.5331, mse=2.5284, time=0.0402\n",
      "Iter=800, loss=2.7151, mse=2.7104, time=0.0402\n",
      "Iter=1000, loss=2.5887, mse=2.5838, time=0.0405\n",
      "Iter=1200, loss=2.5460, mse=2.5411, time=0.0413\n",
      "Iter=1400, loss=2.7051, mse=2.7003, time=0.0419\n",
      "Iter=1600, loss=2.4696, mse=2.4648, time=0.0419\n",
      "Iter=1800, loss=2.5242, mse=2.5193, time=0.0419\n",
      "Iter=2000, loss=2.5753, mse=2.5705, time=0.0417\n",
      "Iter=2200, loss=2.5677, mse=2.5626, time=0.0417\n",
      "Iter=2400, loss=2.5582, mse=2.5531, time=0.0417\n",
      "Iter=2600, loss=2.6063, mse=2.6012, time=0.0417\n",
      "Iter=2800, loss=2.6448, mse=2.6397, time=0.0417\n",
      "Iter=3000, loss=2.5999, mse=2.5948, time=0.0416\n",
      "Iter=3200, loss=2.5757, mse=2.5707, time=0.0416\n",
      "Iter=3400, loss=2.6155, mse=2.6104, time=0.0417\n",
      "Iter=3600, loss=2.6049, mse=2.5997, time=0.0417\n",
      "Iter=3800, loss=2.6093, mse=2.6040, time=0.0417\n",
      "Iter=4000, loss=2.5521, mse=2.5466, time=0.0419\n",
      "Iter=4200, loss=2.5167, mse=2.5112, time=0.0418\n",
      "Iter=4400, loss=2.4636, mse=2.4582, time=0.0418\n",
      "Iter=4600, loss=2.6374, mse=2.6322, time=0.0417\n",
      "Iter=4800, loss=2.6087, mse=2.6036, time=0.0417\n",
      "Iter=5000, loss=2.4629, mse=2.4578, time=0.0417\n",
      "Iter=5200, loss=2.5630, mse=2.5579, time=0.0418\n",
      "Iter=5400, loss=2.5057, mse=2.5007, time=0.0418\n",
      "Iter=5600, loss=2.6042, mse=2.5992, time=0.0418\n",
      "Iter=5800, loss=2.5098, mse=2.5049, time=0.0419\n",
      "Iter=6000, loss=2.4262, mse=2.4213, time=0.0420\n",
      "Iter=6200, loss=2.5651, mse=2.5600, time=0.0419\n",
      "Iter=6400, loss=2.6068, mse=2.6018, time=0.0419\n",
      "Iter=6600, loss=2.5192, mse=2.5140, time=0.0418\n",
      "=== Epoch 1, train loss 2.567855, test rmse 0.810825 ===\n",
      "Training ends. The best testing rmse is 0.810825 at epoch 1\n",
      "  Training epoch took: 0:06:19\n"
     ]
    }
   ],
   "source": [
    "label_type = 'rating'\n",
    "\n",
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch_idx in range(1, args.train_epochs+1):\n",
    "    print ('Epoch', epoch_idx)\n",
    "    \n",
    "    train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_r, loss_fn, optimizer_r, args.arr_lambda, \n",
    "                                                                   train_loader_r, args.device, args.train_log_interval)\n",
    "    valid_rmse, predict_valid_list, label_valid_list = evaluate(label_type, model_r, valid_loader_r, args.device)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(label_type, model_r, test_loader_r, args.device)\n",
    "    \n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model_r, optimizer_r)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_valid_list = predict_valid_list \n",
    "        best_label_valid_list = label_valid_list\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "\n",
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a501375-be50-45f9-870b-337d7ff63863",
   "metadata": {},
   "source": [
    "- 결과 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "273dda48-ab5e-4aa5-a6c8-8252a7dc0c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216328\n",
      "216328\n"
     ]
    }
   ],
   "source": [
    "print(len(predict_train_list))\n",
    "print(len(label_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c3f7529a-6739-4498-a5ca-d64246448b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43266\n",
      "43266\n"
     ]
    }
   ],
   "source": [
    "print(len(best_predict_valid_list))\n",
    "print(len(best_label_valid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "904ae17b-4e10-4a15-b259-0e234c061981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28766\n",
      "28766\n"
     ]
    }
   ],
   "source": [
    "print(len(best_predict_test_list))\n",
    "print(len(best_label_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ca4add52-d517-43e0-9139-87c1793852b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_rating_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "valid_rating_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "valid_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_rating_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4fe7bc96-0b3a-4a2b-a0ea-d07ed637aa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.833292</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.956709</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.665533</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.518785</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.319540</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.140048</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.572958</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.849046</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.836408</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.449694</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predict  label\n",
       "0  3.833292    5.0\n",
       "1  3.956709    4.5\n",
       "2  2.665533    4.0\n",
       "3  3.518785    3.5\n",
       "4  3.319540    4.0\n",
       "5  4.140048    3.5\n",
       "6  2.572958    1.5\n",
       "7  2.849046    2.5\n",
       "8  2.836408    3.0\n",
       "9  3.449694    3.5"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_rating_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "89aae242-13fc-47a3-aad4-d3e06ebb371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/rotten_tomato/ensemble/'\n",
    "train_rating_df.to_csv(path + 'train_rating.csv', index=False)\n",
    "valid_rating_df.to_csv(path + 'valid_rating.csv', index=False)\n",
    "test_rating_df.to_csv(path + 'test_rating.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acc35c-e77b-4764-bdb3-47977a789154",
   "metadata": {},
   "source": [
    "### 3-2. sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0884d5c0-8804-4b99-ad4d-02275629f742",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=200, loss=1.7348, mse=1.7329, time=0.0391\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35260/431970940.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_s, loss_fn, optimizer_s, args.arr_lambda, \n\u001b[0m\u001b[0;32m     30\u001b[0m                                                                    train_loader_s, args.device, args.train_log_interval)\n\u001b[0;32m     31\u001b[0m     \u001b[0mvalid_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_valid_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_valid_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35260/3847565008.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(label_type, model, loss_fn, optimizer, arr_lambda, loader, device, log_interval)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'emotion'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter_project\\keejun\\IGMC_CX\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# edge mask zero denotes the edge dropped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             x = th.tanh(conv(block, x, block.edata['etype'], \n\u001b[0m\u001b[0;32m     66\u001b[0m                              norm=block.edata['edge_mask'].unsqueeze(1)))\n\u001b[0;32m     67\u001b[0m             \u001b[0mconcat_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\relgraphconv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, feat, etypes, norm)\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[1;31m# Sort the graph based on the etypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m                 \u001b[0msorted_etypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelabel_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m                 \u001b[1;31m# Create a new etypes to be an integer list of number of edges.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_searchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_etypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_rels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\subgraph.py\u001b[0m in \u001b[0;36medge_subgraph\u001b[1;34m(graph, edges, relabel_nodes, store_ids, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[0msgi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minduced_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrelabel_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0minduced_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minduced_nodes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrelabel_nodes\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_create_hetero_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstore_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[0mDGLHeteroGraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_subgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malias_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_subgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\subgraph.py\u001b[0m in \u001b[0;36m_create_hetero_subgraph\u001b[1;34m(parent, sgi, induced_nodes, induced_edges, store_ids)\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[0mnode_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_node_subframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[0medge_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_edge_subframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m     \u001b[0mhsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDGLHeteroGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mntypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0metypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_new_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medge_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\heterograph_index.py\u001b[0m in \u001b[0;36mgraph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m         \"\"\"\n\u001b[1;32m-> 1000\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroSubgraphGetGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mret_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDGLValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mret_tcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         check_call(_LIB.DGLFuncCall(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "label_type = 'sentiment'\n",
    "\n",
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch_idx in range(1, args.train_epochs+1):\n",
    "    print ('Epoch', epoch_idx)\n",
    "    \n",
    "    train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_s, loss_fn, optimizer_s, args.arr_lambda, \n",
    "                                                                   train_loader_s, args.device, args.train_log_interval)\n",
    "    valid_rmse, predict_valid_list, label_valid_list = evaluate(label_type, model_s, valid_loader_s, args.device)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(label_type, model_s, test_loader_s, args.device)\n",
    "    \n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model_s, optimizer_s)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_valid_list = predict_valid_list \n",
    "        best_label_valid_list = label_valid_list\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "\n",
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d01f21-2fb5-4361-86ef-ae9cbe7c1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_rating_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "valid_rating_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "valid_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_rating_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae60ad8-2da2-4c0a-a74d-37d2d60a19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/rotten_tomato/ensemble/'\n",
    "train_rating_df.to_csv(path + 'train_sentiment.csv', index=False)\n",
    "valid_rating_df.to_csv(path + 'valid_sentiment.csv', index=False)\n",
    "test_rating_df.to_csv(path + 'test_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d6b0c-3aab-4512-8402-77a174a23725",
   "metadata": {},
   "source": [
    "### 3-3. emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c37c27-d219-465b-bec2-bc8796d483d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=200, loss=1.4604, mse=1.4604, time=0.0379\n",
      "Iter=400, loss=1.4158, mse=1.4158, time=0.0387\n",
      "Iter=600, loss=1.3134, mse=1.3134, time=0.0398\n",
      "Iter=800, loss=1.3711, mse=1.3711, time=0.0406\n",
      "Iter=1000, loss=1.3509, mse=1.3509, time=0.0405\n",
      "Iter=1200, loss=1.3351, mse=1.3351, time=0.0410\n",
      "Iter=1400, loss=1.3488, mse=1.3488, time=0.0411\n",
      "Iter=1600, loss=1.3021, mse=1.3021, time=0.0410\n",
      "Iter=1800, loss=1.3267, mse=1.3267, time=0.0410\n",
      "Iter=2000, loss=1.3266, mse=1.3266, time=0.0411\n",
      "Iter=2200, loss=1.3206, mse=1.3206, time=0.0411\n",
      "Iter=2400, loss=1.3067, mse=1.3067, time=0.0410\n"
     ]
    }
   ],
   "source": [
    "label_type = 'emotion'\n",
    "\n",
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch_idx in range(1, args.train_epochs+1):\n",
    "    print ('Epoch', epoch_idx)\n",
    "    \n",
    "    train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_e, loss_fn, optimizer_e, args.arr_lambda, \n",
    "                                                                   train_loader_e, args.device, args.train_log_interval)\n",
    "    valid_rmse, predict_valid_list, label_valid_list = evaluate(label_type, model_e, valid_loader_e, args.device)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(label_type, model_e, test_loader_e, args.device)\n",
    "    \n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model_e, optimizer_e)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_valid_list = predict_valid_list \n",
    "        best_label_valid_list = label_valid_list\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "\n",
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109d317-e856-40aa-a3c4-ffe8b030fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_rating_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "valid_rating_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "valid_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_rating_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ae4ab-1fef-4f42-8c1b-ab21c9b522a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/rotten_tomato/ensemble/'\n",
    "train_rating_df.to_csv(path + 'train_emotion.csv', index=False)\n",
    "valid_rating_df.to_csv(path + 'valid_emotion.csv', index=False)\n",
    "test_rating_df.to_csv(path + 'test_emotion.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e8a82-6b5d-472d-a679-e85e57fc7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c728cd9-f005-491f-84dc-d63650c2700a",
   "metadata": {},
   "source": [
    "## 4. Train_epoch 함수 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1185d5-2266-46da-9245-351215a28540",
   "metadata": {},
   "source": [
    "### - Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f4bec73f-8cab-45aa-a3cb-beccdda9bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'rating'\n",
    "model = model_r\n",
    "loss_fn = loss_fn\n",
    "optimizer = optimizer_r\n",
    "arr_lambda = args.arr_lambda\n",
    "loader = train_loader_r\n",
    "device = args.device\n",
    "log_interval = args.train_log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b454620b-9795-4b72-b151-73be1461b119",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=200, loss=2.6334, mse=2.6295, time=0.0434\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35260/1789257228.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'emotion'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter_project\\keejun\\IGMC_CX\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# edge mask zero denotes the edge dropped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             x = th.tanh(conv(block, x, block.edata['etype'], \n\u001b[0m\u001b[0;32m     66\u001b[0m                              norm=block.edata['edge_mask'].unsqueeze(1)))\n\u001b[0;32m     67\u001b[0m             \u001b[0mconcat_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\relgraphconv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, feat, etypes, norm)\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[0mnode_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_repr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m                 \u001b[0mnode_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_repr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_loop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m                 \u001b[0mnode_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_repr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloop_message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.train()\n",
    "\n",
    "epoch_loss = 0.\n",
    "iter_loss = 0.\n",
    "iter_mse = 0.\n",
    "iter_cnt = 0\n",
    "iter_dur = []\n",
    "\n",
    "# 저장 리스트(예측, 정답)\n",
    "predict_list = list()\n",
    "label_list = list()\n",
    "\n",
    "# 서브그래프 단위로 학습\n",
    "for iter_idx, batch in enumerate(loader, start=1):\n",
    "    t_start = time.time()\n",
    "\n",
    "    inputs = batch[0].to(device)\n",
    "    labels = batch[1].to(device)\n",
    "    preds = model(inputs)\n",
    "    \n",
    "    if label_type == 'emotion':\n",
    "        loss = loss_fn(preds, labels).mean()\n",
    "    else:\n",
    "        loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item() * preds.shape[0]\n",
    "    iter_loss += loss.item() * preds.shape[0]\n",
    "    iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "    iter_cnt += preds.shape[0]\n",
    "    iter_dur.append(time.time() - t_start)\n",
    "\n",
    "    if label_type == 'rating':\n",
    "        preds  = (preds + 1)/2\n",
    "        labels = (labels + 1)/2\n",
    "    else:\n",
    "        preds  = preds + 1\n",
    "        labels = labels + 1\n",
    "\n",
    "    predict_list.append(preds.tolist()) # 예측값 저장\n",
    "    label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "    if iter_idx % log_interval == 0:\n",
    "        print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "            iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "        iter_loss = 0.\n",
    "        iter_mse = 0.\n",
    "        iter_cnt = 0\n",
    "\n",
    "# 2차원 -> 1차원 리스트 변형\n",
    "predict_list = [element for array in predict_list for element in array]\n",
    "label_list = [element for array in label_list for element in array]\n",
    "\n",
    "train_epoch_loss = epoch_loss / len(loader.dataset)  \n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "41de0e18-f974-42c6-9381-5c522d4271b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a6f11dc9-55c6-4490-a882-4b3bfa677093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc90f7b1-ec60-4c53-8b42-f63c06868808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.474928617477417,\n",
       " 4.432092189788818,\n",
       " 1.6393139362335205,\n",
       " 3.679456949234009,\n",
       " 2.2003211975097656,\n",
       " 3.414210081100464,\n",
       " 2.7713494300842285,\n",
       " 3.535055160522461,\n",
       " 3.712036371231079,\n",
       " 2.852395534515381]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "228b6092-4141-4df7-881c-74c1ac40727d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5, 3.0, 1.0, 3.0, 2.0, 2.5, 4.5, 3.0, 3.5, 2.0]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6bc06-0a33-414c-a73b-e409bca5e421",
   "metadata": {},
   "source": [
    "### Evaluate 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb2b26d9-25c4-4328-802b-068c674c8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'rating'\n",
    "model = model_r\n",
    "loader = test_loader_r\n",
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "47e1a54f-e56b-4650-a9c1-498ad5893824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time took: 0:00:26\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict_list = list()\n",
    "label_list = list()\n",
    "\n",
    "# Evaluate RMSE\n",
    "model.eval()\n",
    "mse = 0.\n",
    "for batch in loader:\n",
    "    with th.no_grad():\n",
    "        preds = model(batch[0].to(device))\n",
    "    labels = batch[1].to(device)\n",
    "    \n",
    "    if label_type == 'rating':\n",
    "        preds  = (preds + 1)/2\n",
    "        labels = (labels + 1)/2\n",
    "    else:\n",
    "        preds  = preds + 1\n",
    "        labels = labels + 1\n",
    "    mse += ((preds - labels) ** 2).sum().item()\n",
    "    \n",
    "    predict_list.append(preds.tolist()) # 예측값 저장\n",
    "    label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "# 2차원 -> 1차원 리스트 변형\n",
    "predict_list = [element for array in predict_list for element in array]\n",
    "label_list = [element for array in label_list for element in array]    \n",
    "    \n",
    "mse /= len(loader.dataset)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "54927b7e-515f-481e-b8ed-d746e8de230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208980129263855"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f0465-ef4c-424f-8a7d-1bd31800fc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae685cc-df32-47d9-ab80-320e40749f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda367ca-52b8-4455-87ec-c8cc7b71562b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
