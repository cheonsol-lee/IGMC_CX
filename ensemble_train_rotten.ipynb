{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9808d08-eb26-4f02-bc5f-364f9aa033f3",
   "metadata": {},
   "source": [
    "# Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee754ff-2a3d-4760-9dde-f35b5079e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training epoch took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5af6c94-0780-4733-88b7-286a4a08728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training IGMC model on the MovieLens dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "from shutil import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import IGMC\n",
    "from explicit_data_rotten import RottenTomato\n",
    "from dataset_rotten import RottenTomatoDataset, collate_rotten_tomato\n",
    "from utils import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "54c1bb83-260d-40b8-900b-6c27d7da5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(label_type, model, loader, device):\n",
    "    predict_list = list()\n",
    "    label_list = list()\n",
    "\n",
    "    # Evaluate RMSE\n",
    "    model.eval()\n",
    "    mse = 0.\n",
    "    for batch in loader:\n",
    "        with th.no_grad():\n",
    "            preds = model(batch[0].to(device))\n",
    "        labels = batch[1].to(device)\n",
    "\n",
    "        if label_type == 'rating':\n",
    "            preds  = (preds + 1)/2\n",
    "            labels = (labels + 1)/2\n",
    "        else:\n",
    "            preds  = preds + 1\n",
    "            labels = labels + 1\n",
    "        mse += ((preds - labels) ** 2).sum().item()\n",
    "\n",
    "        predict_list.append(preds.tolist()) # 예측값 저장\n",
    "        label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "    # 2차원 -> 1차원 리스트 변형\n",
    "    predict_list = [element for array in predict_list for element in array]\n",
    "    label_list = [element for array in label_list for element in array]    \n",
    "\n",
    "    mse /= len(loader.dataset)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse, predict_list, label_list\n",
    "\n",
    "\n",
    "def adj_rating_reg(model):\n",
    "    arr_loss = 0\n",
    "    for conv in model.convs:\n",
    "        weight = conv.weight.view(conv.num_bases, conv.in_feat * conv.out_feat)\n",
    "        weight = th.matmul(conv.w_comp, weight).view(conv.num_rels, conv.in_feat, conv.out_feat)\n",
    "        arr_loss += th.sum((weight[1:, :, :] - weight[:-1, :, :])**2)\n",
    "    return arr_loss\n",
    "\n",
    "# @profile\n",
    "def train_epoch(label_type, model, loss_fn, optimizer, arr_lambda, loader, device, log_interval):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.\n",
    "    iter_loss = 0.\n",
    "    iter_mse = 0.\n",
    "    iter_cnt = 0\n",
    "    iter_dur = []\n",
    "\n",
    "    # 저장 리스트(예측, 정답)\n",
    "    predict_list = list()\n",
    "    label_list = list()\n",
    "\n",
    "    # 서브그래프 단위로 학습\n",
    "    for iter_idx, batch in enumerate(loader, start=1):\n",
    "        t_start = time.time()\n",
    "\n",
    "        inputs = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "        preds = model(inputs)\n",
    "\n",
    "        if label_type == 'rating':\n",
    "            preds  = (preds + 1)/2\n",
    "            labels = (labels + 1)/2\n",
    "        else:\n",
    "            preds  = preds + 1\n",
    "            labels = labels + 1\n",
    "        \n",
    "        if label_type == 'emotion':\n",
    "            loss = loss_fn(preds, labels).mean()\n",
    "        else:\n",
    "            loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * preds.shape[0]\n",
    "        iter_loss += loss.item() * preds.shape[0]\n",
    "        iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "        iter_cnt += preds.shape[0]\n",
    "        iter_dur.append(time.time() - t_start)\n",
    "\n",
    "        predict_list.append(preds.tolist()) # 예측값 저장\n",
    "        label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "        if iter_idx % log_interval == 0:\n",
    "            print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "                iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "            iter_loss = 0.\n",
    "            iter_mse = 0.\n",
    "            iter_cnt = 0\n",
    "\n",
    "    # 2차원 -> 1차원 리스트 변형\n",
    "    predict_list = [element for array in predict_list for element in array]\n",
    "    label_list = [element for array in label_list for element in array]\n",
    "\n",
    "    train_epoch_loss = epoch_loss / len(loader.dataset)  \n",
    "    return train_epoch_loss, predict_list, label_list\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    movielens = MovieLens(args.data_name, testing=args.testing,\n",
    "                            test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "    if args.testing:\n",
    "        test_dataset = RottenTomatoDataset(\n",
    "            movielens.test_rating_pairs, movielens.test_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "    else:\n",
    "        test_dataset = RottenTomatoDataset(\n",
    "            movielens.valid_rating_pairs, movielens.valid_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "    train_dataset = RottenTomatoDataset(\n",
    "        movielens.train_rating_pairs, movielens.train_rating_values, movielens.train_graph, \n",
    "        args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "    train_loader = th.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "    test_loader = th.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "\n",
    "    in_feats = (args.hop+1)*2 #+ movielens.train_graph.ndata['refex'].shape[1]\n",
    "    model = IGMC(in_feats=in_feats, \n",
    "                 latent_dim=[32, 32, 32, 32],\n",
    "                 num_relations=5, # movielens.num_rating, \n",
    "                 num_bases=4, \n",
    "                 regression=True, \n",
    "                 edge_dropout=args.edge_dropout,\n",
    "                #  side_features=args.use_features,\n",
    "                #  n_side_features=n_features,\n",
    "                #  multiply_by=args.multiply_by\n",
    "            ).to(args.device)\n",
    "    loss_fn = nn.MSELoss().to(args.device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "    print(\"Loading network finished ...\\n\")\n",
    "\n",
    "    ### prepare the logger\n",
    "    logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "    \n",
    "    best_epoch = 0\n",
    "    best_rmse = np.inf\n",
    "    ### declare the loss information\n",
    "    print(\"Start training ...\")\n",
    "    for epoch_idx in range(1, args.train_epochs+1):\n",
    "        print ('Epoch', epoch_idx)\n",
    "    \n",
    "        train_loss = train_epoch(model, loss_fn, optimizer, args.arr_lambda, \n",
    "                                train_loader, args.device, args.train_log_interval)\n",
    "        test_rmse = evaluate(model, test_loader, args.device)\n",
    "        eval_info = {\n",
    "            'epoch': epoch_idx,\n",
    "            'train_loss': train_loss,\n",
    "            'test_rmse': test_rmse,\n",
    "        }\n",
    "        print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "        if epoch_idx % args.train_lr_decay_step == 0:\n",
    "            for param in optimizer.param_groups:\n",
    "                param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "        logger.log(eval_info, model, optimizer)\n",
    "        if best_rmse > test_rmse:\n",
    "            best_rmse = test_rmse\n",
    "            best_epoch = epoch_idx\n",
    "    eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "    print(eval_info)\n",
    "    with open(os.path.join(args.save_dir, 'log.txt'), 'a') as f:\n",
    "        f.write(eval_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d4fbabcc-6d45-4d08-8d5e-f9f483e56aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def config():\n",
    "    parser = argparse.ArgumentParser(description='IGMC')\n",
    "    # general settings\n",
    "    parser.add_argument('--testing', action='store_true', default=False,\n",
    "                        help='if set, use testing mode which splits all ratings into train/test;\\\n",
    "                        otherwise, use validation model which splits all ratings into \\\n",
    "                        train/val/test and evaluate on val only')\n",
    "    parser.add_argument('--device', default='0', type=int,\n",
    "                        help='Running device. E.g `--device 0`, if using cpu, set `--device -1`')\n",
    "    parser.add_argument('--seed', type=int, default=1234, metavar='S',\n",
    "                        help='random seed (default: 1234)')\n",
    "    parser.add_argument('--data_name', default='ml-100k', type=str,\n",
    "                        help='The dataset name: ml-100k, ml-1m')\n",
    "    parser.add_argument('--data_test_ratio', type=float, default=0.1) # for ml-100k the test ration is 0.2\n",
    "    parser.add_argument('--num_workers', type=int, default=8)\n",
    "    parser.add_argument('--data_valid_ratio', type=float, default=0.2)\n",
    "    # parser.add_argument('--ensemble', action='store_true', default=False,\n",
    "    #                     help='if True, load a series of model checkpoints and ensemble the results')               \n",
    "    parser.add_argument('--train_log_interval', type=int, default=100)\n",
    "    parser.add_argument('--valid_log_interval', type=int, default=10)\n",
    "    parser.add_argument('--save_appendix', type=str, default='debug', \n",
    "                        help='what to append to save-names when saving results')\n",
    "    # subgraph extraction settings\n",
    "    parser.add_argument('--hop', default=1, metavar='S', \n",
    "                        help='enclosing subgraph hop number')\n",
    "    parser.add_argument('--sample_ratio', type=float, default=1.0, \n",
    "                        help='if < 1, subsample nodes per hop according to the ratio')\n",
    "    parser.add_argument('--max_nodes_per_hop', type=int, default=200, \n",
    "                        help='if > 0, upper bound the # nodes per hop by another subsampling')\n",
    "    # parser.add_argument('--use_features', action='store_true', default=False,\n",
    "    #                     help='whether to use node features (side information)')\n",
    "    # edge dropout settings\n",
    "    parser.add_argument('--edge_dropout', type=float, default=0.2, \n",
    "                        help='if not 0, random drops edges from adjacency matrix with this prob')\n",
    "    parser.add_argument('--force_undirected', action='store_true', default=False, \n",
    "                        help='in edge dropout, force (x, y) and (y, x) to be dropped together')\n",
    "    # optimization settings\n",
    "    parser.add_argument('--train_lr', type=float, default=1e-3)\n",
    "    parser.add_argument('--train_min_lr', type=float, default=1e-6)\n",
    "    parser.add_argument('--train_lr_decay_factor', type=float, default=0.1)\n",
    "    parser.add_argument('--train_lr_decay_step', type=int, default=50)\n",
    "    parser.add_argument('--train_epochs', type=int, default=80)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--arr_lambda', type=float, default=0.001)\n",
    "    parser.add_argument('--num_rgcn_bases', type=int, default=4)\n",
    "                \n",
    "    args = parser.parse_args()\n",
    "    args.device = th.device(args.device) if args.device >= 0 and th.cuda.is_available() else th.device('cpu')\n",
    "    \n",
    "    ### set save_dir according to localtime and test mode\n",
    "    file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "    val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "    local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "    args.save_dir = os.path.join(\n",
    "        file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "            args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "        )\n",
    "    )\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir) \n",
    "    print(args)\n",
    "\n",
    "    # backup current .py files\n",
    "    for f in glob.glob(r\"*.py\"):\n",
    "        copy(f, args.save_dir)\n",
    "\n",
    "    # save command line input\n",
    "    cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "    with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "        f.write(cmd_input)\n",
    "        f.write(\"\\n\")\n",
    "    print('Command line input: ' + cmd_input + ' is saved.')\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff187c-d0a5-44d6-bf40-12a1c7927a3b",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0218e93a-7bb0-4007-a0d4-194dfbf0fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({ \n",
    "    'data_name':            'rotten',\n",
    "    'testing':     \t        True,\n",
    "    'device':      \t        0,\n",
    "    'seed':        \t        1234,\n",
    "    'data_test_ratio':      0.1,\n",
    "    'num_workers':   \t    8,\n",
    "    'data_valid_ratio':     0.2,\n",
    "    'train_log_interval':   200,\n",
    "    'valid_log_interval':   10,\n",
    "    'save_appendix':   \t    'debug',\n",
    "    'hop':   \t            1,\n",
    "    'sample_ratio':    \t    1.0,\n",
    "    'max_nodes_per_hop':    100,\n",
    "    'edge_dropout':   \t    0.2,\n",
    "    'force_undirected':     False,\n",
    "    'train_lr':   \t        1e-3,\n",
    "    'train_min_lr':   \t    1e-6,\n",
    "    'train_lr_decay_factor':0.1,\n",
    "    'train_lr_decay_step':  50,\n",
    "    'train_epochs':   \t    10,\n",
    "    'batch_size':   \t    32,\n",
    "    'arr_lambda':   \t    0.001,\n",
    "    'num_rgcn_bases':   \t4,\n",
    "    'train_epochs':   \t    1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7eefc4e0-e1a6-47fa-af1b-3f79a748f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_name': 'rotten', 'testing': True, 'device': 0, 'seed': 1234, 'data_test_ratio': 0.1, 'num_workers': 8, 'data_valid_ratio': 0.2, 'train_log_interval': 200, 'valid_log_interval': 10, 'save_appendix': 'debug', 'hop': 1, 'sample_ratio': 1.0, 'max_nodes_per_hop': 100, 'edge_dropout': 0.2, 'force_undirected': False, 'train_lr': 0.001, 'train_min_lr': 1e-06, 'train_lr_decay_factor': 0.1, 'train_lr_decay_step': 50, 'train_epochs': 1, 'batch_size': 32, 'arr_lambda': 0.001, 'num_rgcn_bases': 4, 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\IGMC_CX\\\\log/rotten_debug_testmode_2111162042'}\n",
      "Command line input: python3 C:\\Users\\user\\anaconda3\\envs\\graph\\lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\user\\AppData\\Roaming\\jupyter\\runtime\\kernel-0ac5dae0-92ba-4f16-b89e-9354de532105.json is saved.\n"
     ]
    }
   ],
   "source": [
    "### set save_dir according to localtime and test mode\n",
    "file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "args.save_dir = os.path.join(\n",
    "    file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "        args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "    )\n",
    ")\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir) \n",
    "print(args)\n",
    "\n",
    "# backup current .py files\n",
    "for f in glob.glob(r\"*.py\"):\n",
    "    copy(f, args.save_dir)\n",
    "\n",
    "# save command line input\n",
    "cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "    f.write(cmd_input)\n",
    "    f.write(\"\\n\")\n",
    "print('Command line input: ' + cmd_input + ' is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b0e5af39-9646-43f8-87d2-8d9c498b7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "th.manual_seed(args.seed)\n",
    "if th.cuda.is_available():\n",
    "    th.cuda.manual_seed_all(args.seed)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd9d7e-1617-4c32-a8bc-006d4a49ca35",
   "metadata": {},
   "source": [
    "## 2. Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "57c44d14-7115-4e81-9c99-99f370f93129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label_type: rating\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n",
      "Label_type: sentiment\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n",
      "Label_type: emotion\n",
      "\tTrain rating pairs : 216328\n",
      "\tValid rating pairs : 43266\n",
      "\tTest rating pairs  : 28766\n"
     ]
    }
   ],
   "source": [
    "### prepare data and set model\n",
    "path = './raw_data/rotten_tomato/'\n",
    "rotten_tomato_r = RottenTomato('rating',    path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "rotten_tomato_s = RottenTomato('sentiment', path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "rotten_tomato_e = RottenTomato('emotion',   path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f3ff8769-41d9-4fe5-938f-51c370d372cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "valid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('testing')\n",
    "test_dataset_r = RottenTomatoDataset(\n",
    "    rotten_tomato_r.test_rating_pairs, rotten_tomato_r.test_rating_values, rotten_tomato_r.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "test_dataset_s = RottenTomatoDataset(\n",
    "    rotten_tomato_s.test_rating_pairs, rotten_tomato_s.test_rating_values, rotten_tomato_s.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "test_dataset_e = RottenTomatoDataset(\n",
    "    rotten_tomato_e.test_rating_pairs, rotten_tomato_e.test_rating_values, rotten_tomato_e.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "\n",
    "print('valid')\n",
    "valid_dataset_r = RottenTomatoDataset(\n",
    "    rotten_tomato_r.valid_rating_pairs, rotten_tomato_r.valid_rating_values, rotten_tomato_r.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "valid_dataset_s = RottenTomatoDataset(\n",
    "    rotten_tomato_s.valid_rating_pairs, rotten_tomato_s.valid_rating_values, rotten_tomato_s.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "valid_dataset_e = RottenTomatoDataset(\n",
    "    rotten_tomato_e.valid_rating_pairs, rotten_tomato_e.valid_rating_values, rotten_tomato_e.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "af5734e1-bc3a-422f-8050-da7ad09bfe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43266\n",
      "28766\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_dataset_r))\n",
    "print(len(test_dataset_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b5e9ce45-2ab8-4a5a-bae3-17a9871aad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_r = RottenTomatoDataset(\n",
    "    rotten_tomato_r.train_rating_pairs, rotten_tomato_r.train_rating_values, rotten_tomato_r.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "train_dataset_s = RottenTomatoDataset(\n",
    "    rotten_tomato_s.train_rating_pairs, rotten_tomato_s.train_rating_values, rotten_tomato_s.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "train_dataset_e = RottenTomatoDataset(\n",
    "    rotten_tomato_e.train_rating_pairs, rotten_tomato_e.train_rating_values, rotten_tomato_e.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "621bf1ca-2328-439c-bfe9-fd51f892552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_r = th.utils.data.DataLoader(train_dataset_r, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "valid_loader_r = th.utils.data.DataLoader(valid_dataset_r, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "test_loader_r = th.utils.data.DataLoader(test_dataset_r, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "\n",
    "train_loader_s = th.utils.data.DataLoader(train_dataset_s, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "valid_loader_s = th.utils.data.DataLoader(valid_dataset_s, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "test_loader_s = th.utils.data.DataLoader(test_dataset_s, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "\n",
    "train_loader_e = th.utils.data.DataLoader(train_dataset_e, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "valid_loader_e = th.utils.data.DataLoader(valid_dataset_e, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "test_loader_e = th.utils.data.DataLoader(test_dataset_e, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6c679b72-a7a2-4abb-9c4d-efdebf97dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feats = (args.hop+1)*2 #+ rotten_tomato.train_graph.ndata['refex'].shape[1]\n",
    "\n",
    "# rating\n",
    "model_r = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=10, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "\n",
    "# sentiment\n",
    "model_s = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=5, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "\n",
    "# emotion\n",
    "model_e = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=6, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "        ).to(args.device)\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss().to(args.device)\n",
    "optimizer_r = optim.Adam(model_r.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "optimizer_s = optim.Adam(model_s.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "optimizer_e = optim.Adam(model_e.parameters(), lr=args.train_lr, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a70cc4-cd48-4c52-8e31-4cb7c27d1205",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326886b9-35e6-41e0-96a1-f5ce214a1a53",
   "metadata": {},
   "source": [
    "### 3-1. rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4b1fbeff-7f20-4c16-a521-7e7a5f041e16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=200, loss=2.4773, mse=2.4714, time=0.0436\n",
      "Iter=400, loss=2.5149, mse=2.5088, time=0.0421\n",
      "Iter=600, loss=2.5328, mse=2.5267, time=0.0417\n",
      "Iter=800, loss=2.5247, mse=2.5188, time=0.0420\n",
      "Iter=1000, loss=2.4946, mse=2.4886, time=0.0423\n",
      "Iter=1200, loss=2.4882, mse=2.4822, time=0.0422\n",
      "Iter=1400, loss=2.4536, mse=2.4476, time=0.0421\n",
      "Iter=1600, loss=2.5476, mse=2.5415, time=0.0421\n",
      "Iter=1800, loss=2.5210, mse=2.5149, time=0.0421\n",
      "Iter=2000, loss=2.5425, mse=2.5364, time=0.0422\n",
      "Iter=2200, loss=2.5566, mse=2.5505, time=0.0426\n",
      "Iter=2400, loss=2.4756, mse=2.4696, time=0.0430\n",
      "Iter=2600, loss=2.5307, mse=2.5249, time=0.0430\n",
      "Iter=2800, loss=2.5427, mse=2.5370, time=0.0429\n",
      "Iter=3000, loss=2.5281, mse=2.5225, time=0.0429\n",
      "Iter=3200, loss=2.4675, mse=2.4618, time=0.0429\n",
      "Iter=3400, loss=2.5806, mse=2.5747, time=0.0431\n",
      "Iter=3600, loss=2.5870, mse=2.5808, time=0.0434\n",
      "Iter=3800, loss=2.4086, mse=2.4024, time=0.0433\n",
      "Iter=4000, loss=2.4483, mse=2.4423, time=0.0432\n",
      "Iter=4200, loss=2.5278, mse=2.5217, time=0.0431\n",
      "Iter=4400, loss=2.5207, mse=2.5144, time=0.0429\n",
      "Iter=4600, loss=2.3988, mse=2.3926, time=0.0429\n",
      "Iter=4800, loss=2.4581, mse=2.4520, time=0.0429\n",
      "Iter=5000, loss=2.4447, mse=2.4386, time=0.0429\n",
      "Iter=5200, loss=2.5197, mse=2.5137, time=0.0428\n",
      "Iter=5400, loss=2.5329, mse=2.5268, time=0.0427\n",
      "Iter=5600, loss=2.4994, mse=2.4935, time=0.0427\n",
      "Iter=5800, loss=2.4460, mse=2.4400, time=0.0426\n",
      "Iter=6000, loss=2.5353, mse=2.5294, time=0.0426\n",
      "Iter=6200, loss=2.5712, mse=2.5654, time=0.0425\n",
      "Iter=6400, loss=2.3905, mse=2.3847, time=0.0424\n",
      "Iter=6600, loss=2.5000, mse=2.4942, time=0.0424\n",
      "=== Epoch 1, train loss 2.500692, test rmse 0.810165 ===\n",
      "Epoch 2\n",
      "Iter=200, loss=2.4981, mse=2.4922, time=0.0412\n",
      "Iter=400, loss=2.5052, mse=2.4989, time=0.0407\n",
      "Iter=600, loss=2.4192, mse=2.4128, time=0.0406\n",
      "Iter=800, loss=2.5116, mse=2.5052, time=0.0404\n",
      "Iter=1000, loss=2.4837, mse=2.4772, time=0.0406\n",
      "Iter=1200, loss=2.5394, mse=2.5329, time=0.0407\n",
      "Iter=1400, loss=2.4933, mse=2.4868, time=0.0410\n",
      "Iter=1600, loss=2.4510, mse=2.4445, time=0.0409\n",
      "Iter=1800, loss=2.4758, mse=2.4695, time=0.0409\n",
      "Iter=2000, loss=2.4675, mse=2.4611, time=0.0408\n",
      "Iter=2200, loss=2.5650, mse=2.5582, time=0.0408\n",
      "Iter=2400, loss=2.4699, mse=2.4631, time=0.0408\n",
      "Iter=2600, loss=2.5410, mse=2.5342, time=0.0408\n",
      "Iter=2800, loss=2.5309, mse=2.5242, time=0.0407\n",
      "Iter=3000, loss=2.4990, mse=2.4928, time=0.0410\n",
      "Iter=3200, loss=2.4928, mse=2.4867, time=0.0410\n",
      "Iter=3400, loss=2.5036, mse=2.4975, time=0.0412\n",
      "Iter=3600, loss=2.5149, mse=2.5088, time=0.0413\n",
      "Iter=3800, loss=2.4254, mse=2.4192, time=0.0413\n",
      "Iter=4000, loss=2.5034, mse=2.4971, time=0.0416\n",
      "Iter=4200, loss=2.4974, mse=2.4910, time=0.0418\n",
      "Iter=4400, loss=2.5465, mse=2.5401, time=0.0419\n",
      "Iter=4600, loss=2.5215, mse=2.5151, time=0.0419\n",
      "Iter=4800, loss=2.5744, mse=2.5680, time=0.0418\n",
      "Iter=5000, loss=2.4719, mse=2.4654, time=0.0418\n",
      "Iter=5200, loss=2.5647, mse=2.5583, time=0.0418\n",
      "Iter=5400, loss=2.4625, mse=2.4560, time=0.0418\n",
      "Iter=5600, loss=2.4098, mse=2.4034, time=0.0421\n",
      "Iter=5800, loss=2.4614, mse=2.4548, time=0.0422\n",
      "Iter=6000, loss=2.4922, mse=2.4854, time=0.0422\n",
      "Iter=6200, loss=2.3918, mse=2.3853, time=0.0424\n",
      "Iter=6400, loss=2.4303, mse=2.4239, time=0.0424\n",
      "Iter=6600, loss=2.6040, mse=2.5974, time=0.0424\n",
      "=== Epoch 2, train loss 2.493635, test rmse 0.804943 ===\n",
      "Epoch 3\n",
      "Iter=200, loss=2.4714, mse=2.4646, time=0.0430\n",
      "Iter=400, loss=2.4750, mse=2.4684, time=0.0416\n",
      "Iter=600, loss=2.4746, mse=2.4681, time=0.0415\n",
      "Iter=800, loss=2.5715, mse=2.5649, time=0.0412\n",
      "Iter=1000, loss=2.4752, mse=2.4687, time=0.0412\n",
      "Iter=1200, loss=2.4661, mse=2.4595, time=0.0411\n",
      "Iter=1400, loss=2.4169, mse=2.4103, time=0.0411\n",
      "Iter=1600, loss=2.5490, mse=2.5424, time=0.0411\n",
      "Iter=1800, loss=2.5624, mse=2.5556, time=0.0410\n",
      "Iter=2000, loss=2.4522, mse=2.4458, time=0.0410\n",
      "Iter=2200, loss=2.4267, mse=2.4204, time=0.0410\n",
      "Iter=2400, loss=2.4443, mse=2.4379, time=0.0410\n",
      "Iter=2600, loss=2.4497, mse=2.4432, time=0.0409\n",
      "Iter=2800, loss=2.5217, mse=2.5152, time=0.0409\n",
      "Iter=3000, loss=2.5015, mse=2.4952, time=0.0409\n",
      "Iter=3200, loss=2.4946, mse=2.4884, time=0.0409\n",
      "Iter=3400, loss=2.4647, mse=2.4583, time=0.0409\n",
      "Iter=3600, loss=2.4463, mse=2.4399, time=0.0409\n",
      "Iter=3800, loss=2.4845, mse=2.4782, time=0.0409\n",
      "Iter=4000, loss=2.4887, mse=2.4825, time=0.0408\n",
      "Iter=4200, loss=2.5488, mse=2.5426, time=0.0408\n",
      "Iter=4400, loss=2.5110, mse=2.5048, time=0.0408\n",
      "Iter=4600, loss=2.6157, mse=2.6093, time=0.0408\n",
      "Iter=4800, loss=2.4182, mse=2.4120, time=0.0408\n",
      "Iter=5000, loss=2.5085, mse=2.5021, time=0.0408\n",
      "Iter=5200, loss=2.4800, mse=2.4737, time=0.0408\n",
      "Iter=5400, loss=2.4605, mse=2.4539, time=0.0408\n",
      "Iter=5600, loss=2.5354, mse=2.5289, time=0.0408\n",
      "Iter=5800, loss=2.4510, mse=2.4441, time=0.0408\n",
      "Iter=6000, loss=2.6175, mse=2.6104, time=0.0408\n",
      "Iter=6200, loss=2.4205, mse=2.4137, time=0.0408\n",
      "Iter=6400, loss=2.4965, mse=2.4898, time=0.0408\n",
      "Iter=6600, loss=2.5072, mse=2.5003, time=0.0408\n",
      "=== Epoch 3, train loss 2.493476, test rmse 0.804739 ===\n",
      "Epoch 4\n",
      "Iter=200, loss=2.5634, mse=2.5565, time=0.0425\n",
      "Iter=400, loss=2.5338, mse=2.5267, time=0.0420\n",
      "Iter=600, loss=2.4407, mse=2.4339, time=0.0417\n",
      "Iter=800, loss=2.5042, mse=2.4979, time=0.0414\n",
      "Iter=1000, loss=2.4252, mse=2.4188, time=0.0413\n",
      "Iter=1200, loss=2.4496, mse=2.4431, time=0.0413\n",
      "Iter=1400, loss=2.4832, mse=2.4765, time=0.0414\n",
      "Iter=1600, loss=2.4793, mse=2.4728, time=0.0414\n",
      "Iter=1800, loss=2.5348, mse=2.5283, time=0.0413\n",
      "Iter=2000, loss=2.5219, mse=2.5151, time=0.0413\n",
      "Iter=2200, loss=2.5356, mse=2.5288, time=0.0413\n",
      "Iter=2400, loss=2.4615, mse=2.4547, time=0.0412\n",
      "Iter=2600, loss=2.4752, mse=2.4684, time=0.0412\n",
      "Iter=2800, loss=2.4743, mse=2.4675, time=0.0411\n",
      "Iter=3000, loss=2.4555, mse=2.4484, time=0.0411\n",
      "Iter=3200, loss=2.4728, mse=2.4659, time=0.0411\n",
      "Iter=3400, loss=2.4334, mse=2.4267, time=0.0411\n",
      "Iter=3600, loss=2.3775, mse=2.3705, time=0.0411\n",
      "Iter=3800, loss=2.4450, mse=2.4381, time=0.0411\n",
      "Iter=4000, loss=2.5674, mse=2.5606, time=0.0411\n",
      "Iter=4200, loss=2.5382, mse=2.5314, time=0.0411\n",
      "Iter=4400, loss=2.5257, mse=2.5187, time=0.0411\n",
      "Iter=4600, loss=2.4556, mse=2.4487, time=0.0411\n",
      "Iter=4800, loss=2.5075, mse=2.5005, time=0.0410\n",
      "Iter=5000, loss=2.4669, mse=2.4596, time=0.0410\n",
      "Iter=5200, loss=2.5713, mse=2.5638, time=0.0411\n",
      "Iter=5400, loss=2.4052, mse=2.3980, time=0.0410\n",
      "Iter=5600, loss=2.6252, mse=2.6181, time=0.0410\n",
      "Iter=5800, loss=2.5506, mse=2.5436, time=0.0410\n",
      "Iter=6000, loss=2.4891, mse=2.4821, time=0.0410\n",
      "Iter=6200, loss=2.4444, mse=2.4371, time=0.0410\n",
      "Iter=6400, loss=2.4497, mse=2.4424, time=0.0410\n",
      "Iter=6600, loss=2.4762, mse=2.4692, time=0.0410\n",
      "=== Epoch 4, train loss 2.491206, test rmse 0.802099 ===\n",
      "Epoch 5\n",
      "Iter=200, loss=2.5389, mse=2.5319, time=0.0411\n",
      "Iter=400, loss=2.5182, mse=2.5110, time=0.0408\n",
      "Iter=600, loss=2.5631, mse=2.5563, time=0.0408\n",
      "Iter=800, loss=2.5312, mse=2.5244, time=0.0407\n",
      "Iter=1000, loss=2.4841, mse=2.4771, time=0.0408\n",
      "Iter=1200, loss=2.4244, mse=2.4172, time=0.0407\n",
      "Iter=1400, loss=2.4454, mse=2.4381, time=0.0408\n",
      "Iter=1600, loss=2.5054, mse=2.4980, time=0.0407\n",
      "Iter=1800, loss=2.4331, mse=2.4254, time=0.0408\n",
      "Iter=2000, loss=2.4361, mse=2.4287, time=0.0407\n",
      "Iter=2200, loss=2.4227, mse=2.4155, time=0.0408\n",
      "Iter=2400, loss=2.5614, mse=2.5547, time=0.0407\n",
      "Iter=2600, loss=2.5327, mse=2.5261, time=0.0407\n",
      "Iter=2800, loss=2.3707, mse=2.3638, time=0.0407\n",
      "Iter=3000, loss=2.5355, mse=2.5287, time=0.0407\n",
      "Iter=3200, loss=2.4422, mse=2.4356, time=0.0408\n",
      "Iter=3400, loss=2.4058, mse=2.3993, time=0.0408\n",
      "Iter=3600, loss=2.3839, mse=2.3772, time=0.0409\n",
      "Iter=3800, loss=2.5369, mse=2.5301, time=0.0410\n",
      "Iter=4000, loss=2.4234, mse=2.4165, time=0.0411\n",
      "Iter=4200, loss=2.6151, mse=2.6083, time=0.0412\n",
      "Iter=4400, loss=2.4778, mse=2.4710, time=0.0413\n",
      "Iter=4600, loss=2.5958, mse=2.5884, time=0.0413\n",
      "Iter=4800, loss=2.6483, mse=2.6407, time=0.0413\n",
      "Iter=5000, loss=2.5446, mse=2.5372, time=0.0414\n",
      "Iter=5200, loss=2.4946, mse=2.4872, time=0.0414\n",
      "Iter=5400, loss=2.4805, mse=2.4733, time=0.0415\n",
      "Iter=5600, loss=2.5109, mse=2.5037, time=0.0415\n",
      "Iter=5800, loss=2.4877, mse=2.4807, time=0.0415\n",
      "Iter=6000, loss=2.5616, mse=2.5545, time=0.0415\n",
      "Iter=6200, loss=2.4131, mse=2.4061, time=0.0416\n",
      "Iter=6400, loss=2.4850, mse=2.4778, time=0.0416\n",
      "Iter=6600, loss=2.4888, mse=2.4816, time=0.0417\n",
      "=== Epoch 5, train loss 2.493682, test rmse 0.806401 ===\n",
      "Epoch 6\n",
      "Iter=200, loss=2.5339, mse=2.5264, time=0.0432\n",
      "Iter=400, loss=2.4295, mse=2.4224, time=0.0424\n",
      "Iter=600, loss=2.4674, mse=2.4604, time=0.0427\n",
      "Iter=800, loss=2.4514, mse=2.4444, time=0.0426\n",
      "Iter=1000, loss=2.4676, mse=2.4606, time=0.0428\n",
      "Iter=1200, loss=2.4979, mse=2.4911, time=0.0427\n",
      "Iter=1400, loss=2.4692, mse=2.4627, time=0.0427\n",
      "Iter=1600, loss=2.5092, mse=2.5026, time=0.0427\n",
      "Iter=1800, loss=2.6110, mse=2.6045, time=0.0426\n",
      "Iter=2000, loss=2.3902, mse=2.3837, time=0.0426\n",
      "Iter=2200, loss=2.5196, mse=2.5129, time=0.0425\n",
      "Iter=2400, loss=2.5154, mse=2.5088, time=0.0426\n",
      "Iter=2600, loss=2.5111, mse=2.5045, time=0.0426\n",
      "Iter=2800, loss=2.4484, mse=2.4417, time=0.0427\n",
      "Iter=3000, loss=2.4771, mse=2.4706, time=0.0427\n",
      "Iter=3200, loss=2.5469, mse=2.5399, time=0.0427\n",
      "Iter=3400, loss=2.4649, mse=2.4580, time=0.0426\n",
      "Iter=3600, loss=2.4944, mse=2.4877, time=0.0426\n",
      "Iter=3800, loss=2.5574, mse=2.5505, time=0.0426\n",
      "Iter=4000, loss=2.4835, mse=2.4763, time=0.0426\n",
      "Iter=4200, loss=2.5214, mse=2.5143, time=0.0426\n",
      "Iter=4400, loss=2.4622, mse=2.4554, time=0.0426\n",
      "Iter=4600, loss=2.4814, mse=2.4743, time=0.0426\n",
      "Iter=4800, loss=2.5104, mse=2.5032, time=0.0425\n",
      "Iter=5000, loss=2.5420, mse=2.5345, time=0.0425\n",
      "Iter=5200, loss=2.4071, mse=2.3998, time=0.0425\n",
      "Iter=5400, loss=2.4745, mse=2.4672, time=0.0426\n",
      "Iter=5600, loss=2.5089, mse=2.5018, time=0.0426\n",
      "Iter=5800, loss=2.4754, mse=2.4686, time=0.0426\n",
      "Iter=6000, loss=2.5162, mse=2.5096, time=0.0426\n",
      "Iter=6200, loss=2.4906, mse=2.4840, time=0.0425\n",
      "Iter=6400, loss=2.3944, mse=2.3877, time=0.0426\n",
      "Iter=6600, loss=2.6183, mse=2.6117, time=0.0425\n",
      "=== Epoch 6, train loss 2.489386, test rmse 0.808508 ===\n",
      "Epoch 7\n",
      "Iter=200, loss=2.4619, mse=2.4554, time=0.0446\n",
      "Iter=400, loss=2.4618, mse=2.4551, time=0.0436\n",
      "Iter=600, loss=2.4432, mse=2.4363, time=0.0431\n",
      "Iter=800, loss=2.4574, mse=2.4504, time=0.0430\n",
      "Iter=1000, loss=2.4419, mse=2.4349, time=0.0428\n",
      "Iter=1200, loss=2.5253, mse=2.5187, time=0.0427\n",
      "Iter=1400, loss=2.4863, mse=2.4795, time=0.0428\n",
      "Iter=1600, loss=2.4569, mse=2.4504, time=0.0429\n",
      "Iter=1800, loss=2.4657, mse=2.4591, time=0.0426\n",
      "Iter=2000, loss=2.4906, mse=2.4842, time=0.0424\n",
      "Iter=2200, loss=2.4490, mse=2.4426, time=0.0424\n",
      "Iter=2400, loss=2.6117, mse=2.6053, time=0.0423\n",
      "Iter=2600, loss=2.4415, mse=2.4349, time=0.0422\n",
      "Iter=2800, loss=2.5018, mse=2.4953, time=0.0421\n",
      "Iter=3000, loss=2.5600, mse=2.5535, time=0.0421\n",
      "Iter=3200, loss=2.4348, mse=2.4287, time=0.0420\n",
      "Iter=3400, loss=2.4838, mse=2.4780, time=0.0419\n",
      "Iter=3600, loss=2.5376, mse=2.5319, time=0.0418\n",
      "Iter=3800, loss=2.5784, mse=2.5729, time=0.0418\n",
      "Iter=4000, loss=2.5644, mse=2.5589, time=0.0417\n",
      "Iter=4200, loss=2.5597, mse=2.5543, time=0.0417\n",
      "Iter=4400, loss=2.4913, mse=2.4857, time=0.0417\n",
      "Iter=4600, loss=2.5585, mse=2.5528, time=0.0417\n",
      "Iter=4800, loss=2.4373, mse=2.4317, time=0.0416\n",
      "Iter=5000, loss=2.5080, mse=2.5024, time=0.0416\n",
      "Iter=5200, loss=2.4265, mse=2.4209, time=0.0416\n",
      "Iter=5400, loss=2.5270, mse=2.5214, time=0.0415\n",
      "Iter=5600, loss=2.4505, mse=2.4451, time=0.0415\n",
      "Iter=5800, loss=2.3527, mse=2.3473, time=0.0415\n",
      "Iter=6000, loss=2.4755, mse=2.4700, time=0.0415\n",
      "Iter=6200, loss=2.5426, mse=2.5369, time=0.0414\n",
      "Iter=6400, loss=2.4029, mse=2.3974, time=0.0414\n",
      "Iter=6600, loss=2.6017, mse=2.5961, time=0.0414\n",
      "=== Epoch 7, train loss 2.489994, test rmse 0.813280 ===\n",
      "Epoch 8\n",
      "Iter=200, loss=2.4717, mse=2.4660, time=0.0423\n",
      "Iter=400, loss=2.4527, mse=2.4468, time=0.0414\n",
      "Iter=600, loss=2.4804, mse=2.4743, time=0.0414\n",
      "Iter=800, loss=2.4595, mse=2.4539, time=0.0411\n",
      "Iter=1000, loss=2.4625, mse=2.4569, time=0.0411\n",
      "Iter=1200, loss=2.4653, mse=2.4597, time=0.0410\n",
      "Iter=1400, loss=2.5124, mse=2.5067, time=0.0410\n",
      "Iter=1600, loss=2.4442, mse=2.4383, time=0.0409\n",
      "Iter=1800, loss=2.5059, mse=2.5001, time=0.0409\n",
      "Iter=2000, loss=2.4254, mse=2.4196, time=0.0410\n",
      "Iter=2200, loss=2.5053, mse=2.4996, time=0.0409\n",
      "Iter=2400, loss=2.4662, mse=2.4601, time=0.0409\n",
      "Iter=2600, loss=2.4840, mse=2.4779, time=0.0410\n",
      "Iter=2800, loss=2.4693, mse=2.4631, time=0.0410\n",
      "Iter=3000, loss=2.4445, mse=2.4381, time=0.0409\n",
      "Iter=3200, loss=2.4757, mse=2.4693, time=0.0410\n",
      "Iter=3400, loss=2.4834, mse=2.4772, time=0.0410\n",
      "Iter=3600, loss=2.4370, mse=2.4308, time=0.0410\n",
      "Iter=3800, loss=2.4410, mse=2.4350, time=0.0410\n",
      "Iter=4000, loss=2.5575, mse=2.5515, time=0.0409\n",
      "Iter=4200, loss=2.4670, mse=2.4611, time=0.0409\n",
      "Iter=4400, loss=2.5248, mse=2.5189, time=0.0409\n",
      "Iter=4600, loss=2.5498, mse=2.5443, time=0.0409\n",
      "Iter=4800, loss=2.5118, mse=2.5064, time=0.0409\n",
      "Iter=5000, loss=2.4081, mse=2.4027, time=0.0409\n",
      "Iter=5200, loss=2.5058, mse=2.5003, time=0.0409\n",
      "Iter=5400, loss=2.5142, mse=2.5088, time=0.0409\n",
      "Iter=5600, loss=2.5439, mse=2.5383, time=0.0409\n",
      "Iter=5800, loss=2.4564, mse=2.4509, time=0.0409\n",
      "Iter=6000, loss=2.4816, mse=2.4764, time=0.0409\n",
      "Iter=6200, loss=2.4838, mse=2.4789, time=0.0409\n",
      "Iter=6400, loss=2.5690, mse=2.5640, time=0.0409\n",
      "Iter=6600, loss=2.5007, mse=2.4955, time=0.0409\n",
      "=== Epoch 8, train loss 2.483474, test rmse 0.806354 ===\n",
      "Epoch 9\n",
      "Iter=200, loss=2.4843, mse=2.4789, time=0.0423\n",
      "Iter=400, loss=2.4644, mse=2.4591, time=0.0417\n",
      "Iter=600, loss=2.4515, mse=2.4461, time=0.0416\n",
      "Iter=800, loss=2.4472, mse=2.4418, time=0.0415\n",
      "Iter=1000, loss=2.5426, mse=2.5370, time=0.0414\n",
      "Iter=1200, loss=2.4929, mse=2.4874, time=0.0413\n",
      "Iter=1400, loss=2.3831, mse=2.3775, time=0.0412\n",
      "Iter=1600, loss=2.5067, mse=2.5010, time=0.0413\n",
      "Iter=1800, loss=2.5627, mse=2.5571, time=0.0413\n",
      "Iter=2000, loss=2.4764, mse=2.4708, time=0.0413\n",
      "Iter=2200, loss=2.5851, mse=2.5796, time=0.0413\n",
      "Iter=2400, loss=2.4039, mse=2.3983, time=0.0413\n",
      "Iter=2600, loss=2.4204, mse=2.4148, time=0.0413\n",
      "Iter=2800, loss=2.4686, mse=2.4630, time=0.0413\n",
      "Iter=3000, loss=2.4686, mse=2.4629, time=0.0413\n",
      "Iter=3200, loss=2.5756, mse=2.5697, time=0.0413\n",
      "Iter=3400, loss=2.5148, mse=2.5089, time=0.0413\n",
      "Iter=3600, loss=2.4768, mse=2.4707, time=0.0413\n",
      "Iter=3800, loss=2.4421, mse=2.4363, time=0.0413\n",
      "Iter=4000, loss=2.4981, mse=2.4919, time=0.0412\n",
      "Iter=4200, loss=2.4239, mse=2.4180, time=0.0412\n",
      "Iter=4400, loss=2.4883, mse=2.4821, time=0.0412\n",
      "Iter=4600, loss=2.5123, mse=2.5059, time=0.0412\n",
      "Iter=4800, loss=2.4922, mse=2.4859, time=0.0412\n",
      "Iter=5000, loss=2.4762, mse=2.4698, time=0.0412\n",
      "Iter=5200, loss=2.5627, mse=2.5564, time=0.0411\n",
      "Iter=5400, loss=2.4118, mse=2.4055, time=0.0411\n",
      "Iter=5600, loss=2.4641, mse=2.4580, time=0.0412\n",
      "Iter=5800, loss=2.5482, mse=2.5422, time=0.0412\n",
      "Iter=6000, loss=2.6248, mse=2.6187, time=0.0412\n",
      "Iter=6200, loss=2.5520, mse=2.5457, time=0.0411\n",
      "Iter=6400, loss=2.4702, mse=2.4638, time=0.0412\n",
      "Iter=6600, loss=2.4731, mse=2.4664, time=0.0411\n",
      "=== Epoch 9, train loss 2.489417, test rmse 0.805416 ===\n",
      "Epoch 10\n",
      "Iter=200, loss=2.4634, mse=2.4566, time=0.0412\n",
      "Iter=400, loss=2.4362, mse=2.4296, time=0.0407\n",
      "Iter=600, loss=2.4236, mse=2.4169, time=0.0408\n",
      "Iter=800, loss=2.5621, mse=2.5556, time=0.0407\n",
      "Iter=1000, loss=2.4258, mse=2.4195, time=0.0408\n",
      "Iter=1200, loss=2.4624, mse=2.4559, time=0.0408\n",
      "Iter=1400, loss=2.4046, mse=2.3982, time=0.0409\n",
      "Iter=1600, loss=2.5376, mse=2.5314, time=0.0409\n",
      "Iter=1800, loss=2.4777, mse=2.4716, time=0.0409\n",
      "Iter=2000, loss=2.5090, mse=2.5031, time=0.0409\n",
      "Iter=2200, loss=2.4413, mse=2.4353, time=0.0409\n",
      "Iter=2400, loss=2.5749, mse=2.5688, time=0.0408\n",
      "Iter=2600, loss=2.4549, mse=2.4488, time=0.0409\n",
      "Iter=2800, loss=2.4864, mse=2.4807, time=0.0408\n",
      "Iter=3000, loss=2.4818, mse=2.4762, time=0.0409\n",
      "Iter=3200, loss=2.3524, mse=2.3467, time=0.0409\n",
      "Iter=3400, loss=2.5071, mse=2.5012, time=0.0409\n",
      "Iter=3600, loss=2.6091, mse=2.6031, time=0.0408\n",
      "Iter=3800, loss=2.4537, mse=2.4477, time=0.0408\n",
      "Iter=4000, loss=2.4827, mse=2.4766, time=0.0409\n",
      "Iter=4200, loss=2.5487, mse=2.5426, time=0.0410\n",
      "Iter=4400, loss=2.4462, mse=2.4401, time=0.0412\n",
      "Iter=4600, loss=2.6191, mse=2.6128, time=0.0413\n",
      "Iter=4800, loss=2.4452, mse=2.4385, time=0.0413\n",
      "Iter=5000, loss=2.4472, mse=2.4406, time=0.0412\n",
      "Iter=5200, loss=2.5190, mse=2.5126, time=0.0412\n",
      "Iter=5400, loss=2.5327, mse=2.5263, time=0.0412\n",
      "Iter=5600, loss=2.4820, mse=2.4756, time=0.0411\n",
      "Iter=5800, loss=2.4561, mse=2.4497, time=0.0411\n",
      "Iter=6000, loss=2.4745, mse=2.4681, time=0.0411\n",
      "Iter=6200, loss=2.4430, mse=2.4368, time=0.0411\n",
      "Iter=6400, loss=2.4058, mse=2.3996, time=0.0411\n",
      "Iter=6600, loss=2.5371, mse=2.5310, time=0.0411\n",
      "=== Epoch 10, train loss 2.482109, test rmse 0.803528 ===\n",
      "Epoch 11\n",
      "Iter=200, loss=2.4462, mse=2.4398, time=0.0420\n",
      "Iter=400, loss=2.4020, mse=2.3953, time=0.0415\n",
      "Iter=600, loss=2.3929, mse=2.3864, time=0.0414\n",
      "Iter=800, loss=2.5165, mse=2.5101, time=0.0413\n",
      "Iter=1000, loss=2.4988, mse=2.4926, time=0.0411\n",
      "Iter=1200, loss=2.5115, mse=2.5052, time=0.0411\n",
      "Iter=1400, loss=2.4719, mse=2.4658, time=0.0410\n",
      "Iter=1600, loss=2.4323, mse=2.4263, time=0.0410\n",
      "Iter=1800, loss=2.5701, mse=2.5642, time=0.0409\n",
      "Iter=2000, loss=2.5205, mse=2.5146, time=0.0410\n",
      "Iter=2200, loss=2.5401, mse=2.5341, time=0.0410\n",
      "Iter=2400, loss=2.4818, mse=2.4757, time=0.0409\n",
      "Iter=2600, loss=2.4998, mse=2.4938, time=0.0409\n",
      "Iter=2800, loss=2.5024, mse=2.4960, time=0.0409\n",
      "Iter=3000, loss=2.4788, mse=2.4724, time=0.0409\n",
      "Iter=3200, loss=2.4355, mse=2.4294, time=0.0409\n",
      "Iter=3400, loss=2.4995, mse=2.4935, time=0.0408\n",
      "Iter=3600, loss=2.5419, mse=2.5360, time=0.0409\n",
      "Iter=3800, loss=2.4840, mse=2.4780, time=0.0409\n",
      "Iter=4000, loss=2.4716, mse=2.4658, time=0.0409\n",
      "Iter=4200, loss=2.5193, mse=2.5135, time=0.0409\n",
      "Iter=4400, loss=2.5467, mse=2.5408, time=0.0409\n",
      "Iter=4600, loss=2.5119, mse=2.5062, time=0.0408\n",
      "Iter=4800, loss=2.5293, mse=2.5236, time=0.0408\n",
      "Iter=5000, loss=2.4388, mse=2.4329, time=0.0408\n",
      "Iter=5200, loss=2.5670, mse=2.5610, time=0.0408\n",
      "Iter=5400, loss=2.4469, mse=2.4406, time=0.0408\n",
      "Iter=5600, loss=2.4697, mse=2.4634, time=0.0408\n",
      "Iter=5800, loss=2.5454, mse=2.5393, time=0.0408\n",
      "Iter=6000, loss=2.4893, mse=2.4832, time=0.0408\n",
      "Iter=6200, loss=2.4437, mse=2.4375, time=0.0408\n",
      "Iter=6400, loss=2.5099, mse=2.5037, time=0.0408\n",
      "Iter=6600, loss=2.4112, mse=2.4049, time=0.0408\n",
      "=== Epoch 11, train loss 2.488502, test rmse 0.812193 ===\n",
      "Epoch 12\n",
      "Iter=200, loss=2.4213, mse=2.4152, time=0.0414\n",
      "Iter=400, loss=2.5075, mse=2.5011, time=0.0413\n",
      "Iter=600, loss=2.5560, mse=2.5493, time=0.0413\n",
      "Iter=800, loss=2.4593, mse=2.4527, time=0.0412\n",
      "Iter=1000, loss=2.5416, mse=2.5348, time=0.0414\n",
      "Iter=1200, loss=2.5347, mse=2.5285, time=0.0413\n",
      "Iter=1400, loss=2.4964, mse=2.4905, time=0.0413\n",
      "Iter=1600, loss=2.4698, mse=2.4640, time=0.0412\n",
      "Iter=1800, loss=2.5159, mse=2.5100, time=0.0413\n",
      "Iter=2000, loss=2.4481, mse=2.4421, time=0.0413\n",
      "Iter=2200, loss=2.3268, mse=2.3210, time=0.0413\n",
      "Iter=2400, loss=2.5208, mse=2.5146, time=0.0414\n",
      "Iter=2600, loss=2.4807, mse=2.4743, time=0.0414\n",
      "Iter=2800, loss=2.3497, mse=2.3434, time=0.0413\n",
      "Iter=3000, loss=2.4666, mse=2.4600, time=0.0413\n",
      "Iter=3200, loss=2.4411, mse=2.4347, time=0.0413\n",
      "Iter=3400, loss=2.4905, mse=2.4842, time=0.0413\n",
      "Iter=3600, loss=2.6071, mse=2.6012, time=0.0413\n",
      "Iter=3800, loss=2.4720, mse=2.4660, time=0.0412\n",
      "Iter=4000, loss=2.4401, mse=2.4340, time=0.0412\n",
      "Iter=4200, loss=2.5553, mse=2.5493, time=0.0412\n",
      "Iter=4400, loss=2.5101, mse=2.5040, time=0.0412\n",
      "Iter=4600, loss=2.4003, mse=2.3944, time=0.0412\n",
      "Iter=4800, loss=2.4703, mse=2.4643, time=0.0412\n",
      "Iter=5000, loss=2.3629, mse=2.3568, time=0.0412\n",
      "Iter=5200, loss=2.4592, mse=2.4532, time=0.0412\n",
      "Iter=5400, loss=2.5322, mse=2.5262, time=0.0412\n",
      "Iter=5600, loss=2.4980, mse=2.4916, time=0.0412\n",
      "Iter=5800, loss=2.4838, mse=2.4774, time=0.0412\n",
      "Iter=6000, loss=2.5252, mse=2.5187, time=0.0411\n",
      "Iter=6200, loss=2.4781, mse=2.4715, time=0.0411\n",
      "Iter=6400, loss=2.5001, mse=2.4937, time=0.0411\n",
      "Iter=6600, loss=2.5061, mse=2.4999, time=0.0411\n",
      "=== Epoch 12, train loss 2.481608, test rmse 0.804850 ===\n",
      "Epoch 13\n",
      "Iter=200, loss=2.5019, mse=2.4954, time=0.0420\n",
      "Iter=400, loss=2.4631, mse=2.4565, time=0.0416\n",
      "Iter=600, loss=2.4705, mse=2.4640, time=0.0415\n",
      "Iter=800, loss=2.5323, mse=2.5262, time=0.0413\n",
      "Iter=1000, loss=2.4335, mse=2.4273, time=0.0411\n",
      "Iter=1200, loss=2.5231, mse=2.5168, time=0.0410\n",
      "Iter=1400, loss=2.4461, mse=2.4399, time=0.0410\n",
      "Iter=1600, loss=2.4550, mse=2.4489, time=0.0411\n",
      "Iter=1800, loss=2.4724, mse=2.4663, time=0.0411\n",
      "Iter=2000, loss=2.3728, mse=2.3666, time=0.0411\n",
      "Iter=2200, loss=2.5083, mse=2.5017, time=0.0410\n",
      "Iter=2400, loss=2.4369, mse=2.4306, time=0.0411\n",
      "Iter=2600, loss=2.4889, mse=2.4830, time=0.0412\n",
      "Iter=2800, loss=2.4836, mse=2.4776, time=0.0413\n",
      "Iter=3000, loss=2.4720, mse=2.4655, time=0.0415\n",
      "Iter=3200, loss=2.5772, mse=2.5706, time=0.0414\n",
      "Iter=3400, loss=2.5182, mse=2.5115, time=0.0414\n",
      "Iter=3600, loss=2.5110, mse=2.5045, time=0.0414\n",
      "Iter=3800, loss=2.4770, mse=2.4706, time=0.0414\n",
      "Iter=4000, loss=2.5185, mse=2.5123, time=0.0414\n",
      "Iter=4200, loss=2.4614, mse=2.4550, time=0.0414\n",
      "Iter=4400, loss=2.5510, mse=2.5442, time=0.0414\n",
      "Iter=4600, loss=2.5173, mse=2.5104, time=0.0414\n",
      "Iter=4800, loss=2.3972, mse=2.3903, time=0.0414\n",
      "Iter=5000, loss=2.5594, mse=2.5526, time=0.0414\n",
      "Iter=5200, loss=2.5104, mse=2.5035, time=0.0414\n",
      "Iter=5400, loss=2.5072, mse=2.4999, time=0.0413\n",
      "Iter=5600, loss=2.4114, mse=2.4045, time=0.0413\n",
      "Iter=5800, loss=2.5026, mse=2.4957, time=0.0413\n",
      "Iter=6000, loss=2.5090, mse=2.5025, time=0.0413\n",
      "Iter=6200, loss=2.4571, mse=2.4505, time=0.0413\n",
      "Iter=6400, loss=2.4540, mse=2.4479, time=0.0413\n",
      "Iter=6600, loss=2.4180, mse=2.4119, time=0.0413\n",
      "=== Epoch 13, train loss 2.481790, test rmse 0.798616 ===\n",
      "Epoch 14\n",
      "Iter=200, loss=2.5275, mse=2.5214, time=0.0422\n",
      "Iter=400, loss=2.4986, mse=2.4925, time=0.0415\n",
      "Iter=600, loss=2.4715, mse=2.4653, time=0.0414\n",
      "Iter=800, loss=2.4931, mse=2.4865, time=0.0413\n",
      "Iter=1000, loss=2.5324, mse=2.5260, time=0.0412\n",
      "Iter=1200, loss=2.5212, mse=2.5150, time=0.0411\n",
      "Iter=1400, loss=2.5260, mse=2.5193, time=0.0410\n",
      "Iter=1600, loss=2.5097, mse=2.5033, time=0.0410\n",
      "Iter=1800, loss=2.4660, mse=2.4599, time=0.0410\n",
      "Iter=2000, loss=2.5556, mse=2.5496, time=0.0410\n",
      "Iter=2200, loss=2.5049, mse=2.4991, time=0.0410\n",
      "Iter=2400, loss=2.4458, mse=2.4399, time=0.0410\n",
      "Iter=2600, loss=2.4833, mse=2.4778, time=0.0410\n",
      "Iter=2800, loss=2.4538, mse=2.4482, time=0.0410\n",
      "Iter=3000, loss=2.4908, mse=2.4851, time=0.0410\n",
      "Iter=3200, loss=2.4439, mse=2.4382, time=0.0410\n",
      "Iter=3400, loss=2.5005, mse=2.4947, time=0.0410\n",
      "Iter=3600, loss=2.3427, mse=2.3366, time=0.0410\n",
      "Iter=3800, loss=2.4208, mse=2.4147, time=0.0410\n",
      "Iter=4000, loss=2.4699, mse=2.4635, time=0.0410\n",
      "Iter=4200, loss=2.4751, mse=2.4690, time=0.0410\n",
      "Iter=4400, loss=2.5242, mse=2.5186, time=0.0410\n",
      "Iter=4600, loss=2.4440, mse=2.4383, time=0.0410\n",
      "Iter=4800, loss=2.5247, mse=2.5192, time=0.0410\n",
      "Iter=5000, loss=2.5120, mse=2.5065, time=0.0410\n",
      "Iter=5200, loss=2.4210, mse=2.4155, time=0.0410\n",
      "Iter=5400, loss=2.4047, mse=2.3993, time=0.0410\n",
      "Iter=5600, loss=2.4609, mse=2.4554, time=0.0410\n",
      "Iter=5800, loss=2.4688, mse=2.4633, time=0.0410\n",
      "Iter=6000, loss=2.5075, mse=2.5020, time=0.0410\n",
      "Iter=6200, loss=2.4698, mse=2.4644, time=0.0410\n",
      "Iter=6400, loss=2.4777, mse=2.4724, time=0.0410\n",
      "Iter=6600, loss=2.5051, mse=2.4999, time=0.0410\n",
      "=== Epoch 14, train loss 2.481160, test rmse 0.797599 ===\n",
      "Epoch 15\n",
      "Iter=200, loss=2.4863, mse=2.4810, time=0.0417\n",
      "Iter=400, loss=2.4885, mse=2.4831, time=0.0413\n",
      "Iter=600, loss=2.4876, mse=2.4814, time=0.0410\n",
      "Iter=800, loss=2.5210, mse=2.5148, time=0.0410\n",
      "Iter=1000, loss=2.5006, mse=2.4946, time=0.0409\n",
      "Iter=1200, loss=2.6010, mse=2.5953, time=0.0410\n",
      "Iter=1400, loss=2.4848, mse=2.4790, time=0.0410\n",
      "Iter=1600, loss=2.4906, mse=2.4843, time=0.0409\n",
      "Iter=1800, loss=2.3863, mse=2.3801, time=0.0409\n",
      "Iter=2000, loss=2.5194, mse=2.5131, time=0.0409\n",
      "Iter=2200, loss=2.4932, mse=2.4870, time=0.0409\n",
      "Iter=2400, loss=2.4743, mse=2.4684, time=0.0409\n",
      "Iter=2600, loss=2.4336, mse=2.4279, time=0.0409\n",
      "Iter=2800, loss=2.5076, mse=2.5018, time=0.0409\n",
      "Iter=3000, loss=2.5340, mse=2.5282, time=0.0409\n",
      "Iter=3200, loss=2.5312, mse=2.5252, time=0.0409\n",
      "Iter=3400, loss=2.5282, mse=2.5221, time=0.0409\n",
      "Iter=3600, loss=2.4419, mse=2.4359, time=0.0409\n",
      "Iter=3800, loss=2.4380, mse=2.4323, time=0.0409\n",
      "Iter=4000, loss=2.4403, mse=2.4348, time=0.0409\n",
      "Iter=4200, loss=2.4756, mse=2.4702, time=0.0409\n",
      "Iter=4400, loss=2.5177, mse=2.5124, time=0.0409\n",
      "Iter=4600, loss=2.4925, mse=2.4874, time=0.0409\n",
      "Iter=4800, loss=2.5274, mse=2.5224, time=0.0410\n",
      "Iter=5000, loss=2.4083, mse=2.4031, time=0.0410\n",
      "Iter=5200, loss=2.4566, mse=2.4514, time=0.0410\n",
      "Iter=5400, loss=2.4588, mse=2.4538, time=0.0411\n",
      "Iter=5600, loss=2.5480, mse=2.5432, time=0.0411\n",
      "Iter=5800, loss=2.5228, mse=2.5178, time=0.0411\n",
      "Iter=6000, loss=2.4606, mse=2.4552, time=0.0411\n",
      "Iter=6200, loss=2.4106, mse=2.4052, time=0.0411\n",
      "Iter=6400, loss=2.4656, mse=2.4600, time=0.0411\n",
      "Iter=6600, loss=2.4439, mse=2.4379, time=0.0411\n",
      "=== Epoch 15, train loss 2.481400, test rmse 0.814497 ===\n",
      "Epoch 16\n",
      "Iter=200, loss=2.4225, mse=2.4167, time=0.0418\n",
      "Iter=400, loss=2.5960, mse=2.5903, time=0.0410\n",
      "Iter=600, loss=2.5403, mse=2.5344, time=0.0409\n",
      "Iter=800, loss=2.4083, mse=2.4022, time=0.0409\n",
      "Iter=1000, loss=2.4863, mse=2.4800, time=0.0409\n",
      "Iter=1200, loss=2.4049, mse=2.3985, time=0.0410\n",
      "Iter=1400, loss=2.5006, mse=2.4942, time=0.0410\n",
      "Iter=1600, loss=2.5229, mse=2.5165, time=0.0410\n",
      "Iter=1800, loss=2.4089, mse=2.4024, time=0.0409\n",
      "Iter=2000, loss=2.4637, mse=2.4573, time=0.0409\n",
      "Iter=2200, loss=2.4999, mse=2.4934, time=0.0409\n",
      "Iter=2400, loss=2.4713, mse=2.4651, time=0.0409\n",
      "Iter=2600, loss=2.5016, mse=2.4958, time=0.0409\n",
      "Iter=2800, loss=2.4472, mse=2.4414, time=0.0409\n",
      "Iter=3000, loss=2.4322, mse=2.4259, time=0.0409\n",
      "Iter=3200, loss=2.6336, mse=2.6273, time=0.0409\n",
      "Iter=3400, loss=2.4542, mse=2.4482, time=0.0409\n",
      "Iter=3600, loss=2.5323, mse=2.5265, time=0.0409\n",
      "Iter=3800, loss=2.4434, mse=2.4378, time=0.0409\n",
      "Iter=4000, loss=2.4823, mse=2.4766, time=0.0409\n",
      "Iter=4200, loss=2.5240, mse=2.5183, time=0.0409\n",
      "Iter=4400, loss=2.4989, mse=2.4930, time=0.0409\n",
      "Iter=4600, loss=2.4493, mse=2.4434, time=0.0409\n",
      "Iter=4800, loss=2.4046, mse=2.3984, time=0.0409\n",
      "Iter=5000, loss=2.4915, mse=2.4858, time=0.0409\n",
      "Iter=5200, loss=2.4920, mse=2.4863, time=0.0409\n",
      "Iter=5400, loss=2.5091, mse=2.5036, time=0.0408\n",
      "Iter=5600, loss=2.5058, mse=2.5000, time=0.0408\n",
      "Iter=5800, loss=2.4434, mse=2.4370, time=0.0408\n",
      "Iter=6000, loss=2.5876, mse=2.5811, time=0.0409\n",
      "Iter=6200, loss=2.4661, mse=2.4599, time=0.0409\n",
      "Iter=6400, loss=2.5346, mse=2.5285, time=0.0409\n",
      "Iter=6600, loss=2.4982, mse=2.4921, time=0.0408\n",
      "=== Epoch 16, train loss 2.484589, test rmse 0.798729 ===\n",
      "Epoch 17\n",
      "Iter=200, loss=2.5029, mse=2.4968, time=0.0420\n",
      "Iter=400, loss=2.4869, mse=2.4806, time=0.0420\n",
      "Iter=600, loss=2.4424, mse=2.4358, time=0.0417\n",
      "Iter=800, loss=2.4574, mse=2.4507, time=0.0416\n",
      "Iter=1000, loss=2.4282, mse=2.4218, time=0.0414\n",
      "Iter=1200, loss=2.4218, mse=2.4154, time=0.0413\n",
      "Iter=1400, loss=2.5587, mse=2.5527, time=0.0414\n",
      "Iter=1600, loss=2.5340, mse=2.5283, time=0.0413\n",
      "Iter=1800, loss=2.4521, mse=2.4464, time=0.0413\n",
      "Iter=2000, loss=2.4949, mse=2.4890, time=0.0412\n",
      "Iter=2200, loss=2.4779, mse=2.4720, time=0.0413\n",
      "Iter=2400, loss=2.4817, mse=2.4755, time=0.0412\n",
      "Iter=2600, loss=2.4950, mse=2.4889, time=0.0412\n",
      "Iter=2800, loss=2.4234, mse=2.4176, time=0.0412\n",
      "Iter=3000, loss=2.4340, mse=2.4283, time=0.0413\n",
      "Iter=3200, loss=2.5778, mse=2.5718, time=0.0415\n",
      "Iter=3400, loss=2.5414, mse=2.5356, time=0.0414\n",
      "Iter=3600, loss=2.5027, mse=2.4966, time=0.0414\n",
      "Iter=3800, loss=2.4609, mse=2.4544, time=0.0414\n",
      "Iter=4000, loss=2.4872, mse=2.4805, time=0.0414\n",
      "Iter=4200, loss=2.4979, mse=2.4914, time=0.0413\n",
      "Iter=4400, loss=2.5617, mse=2.5554, time=0.0413\n",
      "Iter=4600, loss=2.4739, mse=2.4677, time=0.0413\n",
      "Iter=4800, loss=2.4063, mse=2.4000, time=0.0413\n",
      "Iter=5000, loss=2.5607, mse=2.5543, time=0.0413\n",
      "Iter=5200, loss=2.4642, mse=2.4580, time=0.0414\n",
      "Iter=5400, loss=2.4376, mse=2.4315, time=0.0413\n",
      "Iter=5600, loss=2.4944, mse=2.4883, time=0.0413\n",
      "Iter=5800, loss=2.5163, mse=2.5105, time=0.0413\n",
      "Iter=6000, loss=2.4675, mse=2.4619, time=0.0413\n",
      "Iter=6200, loss=2.5100, mse=2.5043, time=0.0413\n",
      "Iter=6400, loss=2.4799, mse=2.4744, time=0.0413\n",
      "Iter=6600, loss=2.5635, mse=2.5579, time=0.0413\n",
      "=== Epoch 17, train loss 2.485721, test rmse 0.800800 ===\n",
      "Epoch 18\n",
      "Iter=200, loss=2.4717, mse=2.4659, time=0.0425\n",
      "Iter=400, loss=2.4406, mse=2.4353, time=0.0418\n",
      "Iter=600, loss=2.4623, mse=2.4569, time=0.0413\n",
      "Iter=800, loss=2.5078, mse=2.5020, time=0.0413\n",
      "Iter=1000, loss=2.4432, mse=2.4373, time=0.0411\n",
      "Iter=1200, loss=2.5348, mse=2.5287, time=0.0411\n",
      "Iter=1400, loss=2.5125, mse=2.5066, time=0.0410\n",
      "Iter=1600, loss=2.3945, mse=2.3886, time=0.0410\n",
      "Iter=1800, loss=2.4572, mse=2.4512, time=0.0411\n",
      "Iter=2000, loss=2.5112, mse=2.5048, time=0.0412\n",
      "Iter=2200, loss=2.4891, mse=2.4830, time=0.0411\n",
      "Iter=2400, loss=2.4365, mse=2.4304, time=0.0412\n",
      "Iter=2600, loss=2.5414, mse=2.5354, time=0.0411\n",
      "Iter=2800, loss=2.4691, mse=2.4625, time=0.0410\n",
      "Iter=3000, loss=2.5023, mse=2.4957, time=0.0411\n",
      "Iter=3200, loss=2.4551, mse=2.4486, time=0.0411\n",
      "Iter=3400, loss=2.4423, mse=2.4362, time=0.0411\n",
      "Iter=3600, loss=2.4734, mse=2.4676, time=0.0411\n",
      "Iter=3800, loss=2.4596, mse=2.4537, time=0.0411\n",
      "Iter=4000, loss=2.4528, mse=2.4467, time=0.0411\n",
      "Iter=4200, loss=2.4916, mse=2.4854, time=0.0412\n",
      "Iter=4400, loss=2.5226, mse=2.5165, time=0.0411\n",
      "Iter=4600, loss=2.5224, mse=2.5163, time=0.0411\n",
      "Iter=4800, loss=2.5045, mse=2.4982, time=0.0411\n",
      "Iter=5000, loss=2.5127, mse=2.5065, time=0.0411\n",
      "Iter=5200, loss=2.4650, mse=2.4592, time=0.0411\n",
      "Iter=5400, loss=2.5441, mse=2.5384, time=0.0412\n",
      "Iter=5600, loss=2.4631, mse=2.4574, time=0.0412\n",
      "Iter=5800, loss=2.4063, mse=2.4002, time=0.0412\n",
      "Iter=6000, loss=2.5729, mse=2.5664, time=0.0412\n",
      "Iter=6200, loss=2.5102, mse=2.5039, time=0.0412\n",
      "Iter=6400, loss=2.4918, mse=2.4853, time=0.0412\n",
      "Iter=6600, loss=2.4510, mse=2.4447, time=0.0412\n",
      "=== Epoch 18, train loss 2.482010, test rmse 0.806602 ===\n",
      "Epoch 19\n",
      "Iter=200, loss=2.4646, mse=2.4586, time=0.0420\n",
      "Iter=400, loss=2.4470, mse=2.4408, time=0.0413\n",
      "Iter=600, loss=2.4021, mse=2.3959, time=0.0412\n",
      "Iter=800, loss=2.4564, mse=2.4500, time=0.0410\n",
      "Iter=1000, loss=2.4339, mse=2.4278, time=0.0410\n",
      "Iter=1200, loss=2.5606, mse=2.5542, time=0.0410\n",
      "Iter=1400, loss=2.3920, mse=2.3857, time=0.0410\n",
      "Iter=1600, loss=2.4484, mse=2.4420, time=0.0410\n",
      "Iter=1800, loss=2.5036, mse=2.4972, time=0.0410\n",
      "Iter=2000, loss=2.5006, mse=2.4945, time=0.0410\n",
      "Iter=2200, loss=2.4536, mse=2.4474, time=0.0410\n",
      "Iter=2400, loss=2.4790, mse=2.4731, time=0.0410\n",
      "Iter=2600, loss=2.5377, mse=2.5320, time=0.0410\n",
      "Iter=2800, loss=2.6427, mse=2.6367, time=0.0410\n",
      "Iter=3000, loss=2.5186, mse=2.5123, time=0.0410\n",
      "Iter=3200, loss=2.4565, mse=2.4503, time=0.0410\n",
      "Iter=3400, loss=2.5199, mse=2.5136, time=0.0409\n",
      "Iter=3600, loss=2.5472, mse=2.5402, time=0.0409\n",
      "Iter=3800, loss=2.4733, mse=2.4665, time=0.0409\n",
      "Iter=4000, loss=2.4770, mse=2.4706, time=0.0409\n",
      "Iter=4200, loss=2.5120, mse=2.5055, time=0.0409\n",
      "Iter=4400, loss=2.4409, mse=2.4344, time=0.0410\n",
      "Iter=4600, loss=2.4592, mse=2.4528, time=0.0410\n",
      "Iter=4800, loss=2.5582, mse=2.5517, time=0.0409\n",
      "Iter=5000, loss=2.4773, mse=2.4708, time=0.0409\n",
      "Iter=5200, loss=2.5361, mse=2.5296, time=0.0409\n",
      "Iter=5400, loss=2.3941, mse=2.3882, time=0.0409\n",
      "Iter=5600, loss=2.5474, mse=2.5414, time=0.0409\n",
      "Iter=5800, loss=2.4501, mse=2.4440, time=0.0409\n",
      "Iter=6000, loss=2.4869, mse=2.4806, time=0.0409\n",
      "Iter=6200, loss=2.3853, mse=2.3788, time=0.0409\n",
      "Iter=6400, loss=2.4482, mse=2.4419, time=0.0409\n",
      "Iter=6600, loss=2.5043, mse=2.4986, time=0.0409\n",
      "=== Epoch 19, train loss 2.482410, test rmse 0.806270 ===\n",
      "Epoch 20\n",
      "Iter=200, loss=2.5147, mse=2.5092, time=0.0428\n",
      "Iter=400, loss=2.5087, mse=2.5031, time=0.0417\n",
      "Iter=600, loss=2.4915, mse=2.4859, time=0.0417\n",
      "Iter=800, loss=2.4683, mse=2.4628, time=0.0415\n",
      "Iter=1000, loss=2.5853, mse=2.5800, time=0.0414\n",
      "Iter=1200, loss=2.5052, mse=2.4998, time=0.0413\n",
      "Iter=1400, loss=2.4835, mse=2.4778, time=0.0412\n",
      "Iter=1600, loss=2.5080, mse=2.5021, time=0.0412\n",
      "Iter=1800, loss=2.4896, mse=2.4837, time=0.0412\n",
      "Iter=2000, loss=2.4567, mse=2.4507, time=0.0412\n",
      "Iter=2200, loss=2.4550, mse=2.4493, time=0.0411\n",
      "Iter=2400, loss=2.4465, mse=2.4409, time=0.0411\n",
      "Iter=2600, loss=2.4341, mse=2.4285, time=0.0411\n",
      "Iter=2800, loss=2.4321, mse=2.4268, time=0.0411\n",
      "Iter=3000, loss=2.5900, mse=2.5844, time=0.0411\n",
      "Iter=3200, loss=2.4172, mse=2.4119, time=0.0411\n",
      "Iter=3400, loss=2.5670, mse=2.5614, time=0.0411\n",
      "Iter=3600, loss=2.4908, mse=2.4850, time=0.0411\n",
      "Iter=3800, loss=2.4201, mse=2.4143, time=0.0411\n",
      "Iter=4000, loss=2.5437, mse=2.5378, time=0.0411\n",
      "Iter=4200, loss=2.3935, mse=2.3877, time=0.0411\n",
      "Iter=4400, loss=2.4150, mse=2.4093, time=0.0410\n",
      "Iter=4600, loss=2.5188, mse=2.5129, time=0.0410\n",
      "Iter=4800, loss=2.4600, mse=2.4539, time=0.0411\n",
      "Iter=5000, loss=2.4533, mse=2.4470, time=0.0411\n",
      "Iter=5200, loss=2.4474, mse=2.4414, time=0.0410\n",
      "Iter=5400, loss=2.4904, mse=2.4842, time=0.0410\n",
      "Iter=5600, loss=2.4519, mse=2.4457, time=0.0410\n",
      "Iter=5800, loss=2.4727, mse=2.4664, time=0.0410\n",
      "Iter=6000, loss=2.4435, mse=2.4376, time=0.0410\n",
      "Iter=6200, loss=2.4802, mse=2.4742, time=0.0410\n",
      "Iter=6400, loss=2.4728, mse=2.4667, time=0.0410\n",
      "Iter=6600, loss=2.5540, mse=2.5479, time=0.0410\n",
      "=== Epoch 20, train loss 2.481983, test rmse 0.800757 ===\n",
      "Epoch 21\n",
      "Iter=200, loss=2.4794, mse=2.4736, time=0.0412\n",
      "Iter=400, loss=2.4933, mse=2.4874, time=0.0415\n",
      "Iter=600, loss=2.5112, mse=2.5053, time=0.0411\n",
      "Iter=800, loss=2.4813, mse=2.4752, time=0.0411\n",
      "Iter=1000, loss=2.5561, mse=2.5497, time=0.0411\n",
      "Iter=1200, loss=2.4816, mse=2.4752, time=0.0411\n",
      "Iter=1400, loss=2.5459, mse=2.5394, time=0.0411\n",
      "Iter=1600, loss=2.5323, mse=2.5258, time=0.0410\n",
      "Iter=1800, loss=2.4934, mse=2.4871, time=0.0411\n",
      "Iter=2000, loss=2.5128, mse=2.5067, time=0.0410\n",
      "Iter=2200, loss=2.4599, mse=2.4539, time=0.0411\n",
      "Iter=2400, loss=2.5039, mse=2.4982, time=0.0411\n",
      "Iter=2600, loss=2.5403, mse=2.5346, time=0.0411\n",
      "Iter=2800, loss=2.5042, mse=2.4983, time=0.0411\n",
      "Iter=3000, loss=2.5488, mse=2.5430, time=0.0410\n",
      "Iter=3200, loss=2.5133, mse=2.5075, time=0.0410\n",
      "Iter=3400, loss=2.4851, mse=2.4794, time=0.0410\n",
      "Iter=3600, loss=2.4094, mse=2.4034, time=0.0410\n",
      "Iter=3800, loss=2.4292, mse=2.4233, time=0.0411\n",
      "Iter=4000, loss=2.4608, mse=2.4546, time=0.0411\n",
      "Iter=4200, loss=2.4511, mse=2.4448, time=0.0410\n",
      "Iter=4400, loss=2.4333, mse=2.4269, time=0.0410\n",
      "Iter=4600, loss=2.4549, mse=2.4487, time=0.0410\n",
      "Iter=4800, loss=2.4651, mse=2.4589, time=0.0410\n",
      "Iter=5000, loss=2.3719, mse=2.3657, time=0.0410\n",
      "Iter=5200, loss=2.3900, mse=2.3837, time=0.0410\n",
      "Iter=5400, loss=2.5141, mse=2.5076, time=0.0410\n",
      "Iter=5600, loss=2.4756, mse=2.4691, time=0.0410\n",
      "Iter=5800, loss=2.4569, mse=2.4504, time=0.0410\n",
      "Iter=6000, loss=2.4484, mse=2.4421, time=0.0410\n",
      "Iter=6200, loss=2.5617, mse=2.5557, time=0.0410\n",
      "Iter=6400, loss=2.4380, mse=2.4321, time=0.0410\n",
      "Iter=6600, loss=2.3859, mse=2.3799, time=0.0410\n",
      "=== Epoch 21, train loss 2.478876, test rmse 0.802505 ===\n",
      "Epoch 22\n",
      "Iter=200, loss=2.4884, mse=2.4822, time=0.0420\n",
      "Iter=400, loss=2.4545, mse=2.4481, time=0.0411\n",
      "Iter=600, loss=2.4386, mse=2.4321, time=0.0411\n",
      "Iter=800, loss=2.4734, mse=2.4670, time=0.0409\n",
      "Iter=1000, loss=2.4399, mse=2.4333, time=0.0409\n",
      "Iter=1200, loss=2.5804, mse=2.5739, time=0.0409\n",
      "Iter=1400, loss=2.5131, mse=2.5065, time=0.0409\n",
      "Iter=1600, loss=2.5018, mse=2.4954, time=0.0409\n",
      "Iter=1800, loss=2.5530, mse=2.5467, time=0.0408\n",
      "Iter=2000, loss=2.3648, mse=2.3585, time=0.0408\n",
      "Iter=2200, loss=2.4698, mse=2.4636, time=0.0408\n",
      "Iter=2400, loss=2.4106, mse=2.4042, time=0.0409\n",
      "Iter=2600, loss=2.4224, mse=2.4161, time=0.0409\n",
      "Iter=2800, loss=2.5080, mse=2.5017, time=0.0409\n",
      "Iter=3000, loss=2.5176, mse=2.5112, time=0.0409\n",
      "Iter=3200, loss=2.4532, mse=2.4464, time=0.0409\n",
      "Iter=3400, loss=2.5264, mse=2.5200, time=0.0409\n",
      "Iter=3600, loss=2.4985, mse=2.4924, time=0.0409\n",
      "Iter=3800, loss=2.3773, mse=2.3713, time=0.0409\n",
      "Iter=4000, loss=2.6019, mse=2.5956, time=0.0409\n",
      "Iter=4200, loss=2.5140, mse=2.5080, time=0.0409\n",
      "Iter=4400, loss=2.4605, mse=2.4542, time=0.0409\n",
      "Iter=4600, loss=2.5558, mse=2.5492, time=0.0409\n",
      "Iter=4800, loss=2.4616, mse=2.4552, time=0.0409\n",
      "Iter=5000, loss=2.4683, mse=2.4621, time=0.0409\n",
      "Iter=5200, loss=2.5069, mse=2.5007, time=0.0409\n",
      "Iter=5400, loss=2.5098, mse=2.5031, time=0.0409\n",
      "Iter=5600, loss=2.5096, mse=2.5028, time=0.0409\n",
      "Iter=5800, loss=2.4749, mse=2.4680, time=0.0409\n",
      "Iter=6000, loss=2.5311, mse=2.5245, time=0.0409\n",
      "Iter=6200, loss=2.3952, mse=2.3881, time=0.0409\n",
      "Iter=6400, loss=2.5325, mse=2.5256, time=0.0409\n",
      "Iter=6600, loss=2.4727, mse=2.4660, time=0.0409\n",
      "=== Epoch 22, train loss 2.482794, test rmse 0.811134 ===\n",
      "Epoch 23\n",
      "Iter=200, loss=2.5328, mse=2.5259, time=0.0425\n",
      "Iter=400, loss=2.5134, mse=2.5068, time=0.0418\n",
      "Iter=600, loss=2.4156, mse=2.4088, time=0.0413\n",
      "Iter=800, loss=2.4407, mse=2.4337, time=0.0411\n",
      "Iter=1000, loss=2.4467, mse=2.4401, time=0.0410\n",
      "Iter=1200, loss=2.5061, mse=2.4993, time=0.0409\n",
      "Iter=1400, loss=2.4434, mse=2.4365, time=0.0409\n",
      "Iter=1600, loss=2.5166, mse=2.5099, time=0.0408\n",
      "Iter=1800, loss=2.5549, mse=2.5486, time=0.0409\n",
      "Iter=2000, loss=2.4481, mse=2.4416, time=0.0408\n",
      "Iter=2200, loss=2.5050, mse=2.4985, time=0.0408\n",
      "Iter=2400, loss=2.4665, mse=2.4598, time=0.0408\n",
      "Iter=2600, loss=2.5321, mse=2.5255, time=0.0408\n",
      "Iter=2800, loss=2.5254, mse=2.5185, time=0.0407\n",
      "Iter=3000, loss=2.4371, mse=2.4302, time=0.0408\n",
      "Iter=3200, loss=2.4465, mse=2.4395, time=0.0407\n",
      "Iter=3400, loss=2.4220, mse=2.4150, time=0.0407\n",
      "Iter=3600, loss=2.4208, mse=2.4138, time=0.0407\n",
      "Iter=3800, loss=2.4477, mse=2.4411, time=0.0407\n",
      "Iter=4000, loss=2.4652, mse=2.4586, time=0.0407\n",
      "Iter=4200, loss=2.4665, mse=2.4595, time=0.0407\n",
      "Iter=4400, loss=2.5056, mse=2.4989, time=0.0407\n",
      "Iter=4600, loss=2.4655, mse=2.4591, time=0.0407\n",
      "Iter=4800, loss=2.5456, mse=2.5395, time=0.0407\n",
      "Iter=5000, loss=2.4725, mse=2.4668, time=0.0407\n",
      "Iter=5200, loss=2.4901, mse=2.4843, time=0.0407\n",
      "Iter=5400, loss=2.5373, mse=2.5316, time=0.0407\n",
      "Iter=5600, loss=2.5463, mse=2.5407, time=0.0407\n",
      "Iter=5800, loss=2.5675, mse=2.5618, time=0.0407\n",
      "Iter=6000, loss=2.4509, mse=2.4449, time=0.0407\n",
      "Iter=6200, loss=2.4847, mse=2.4786, time=0.0407\n",
      "Iter=6400, loss=2.4818, mse=2.4760, time=0.0407\n",
      "Iter=6600, loss=2.4638, mse=2.4581, time=0.0407\n",
      "=== Epoch 23, train loss 2.482017, test rmse 0.811005 ===\n",
      "Epoch 24\n",
      "Iter=200, loss=2.4714, mse=2.4658, time=0.0414\n",
      "Iter=400, loss=2.3504, mse=2.3448, time=0.0410\n",
      "Iter=600, loss=2.5155, mse=2.5097, time=0.0411\n",
      "Iter=800, loss=2.6021, mse=2.5962, time=0.0409\n",
      "Iter=1000, loss=2.4864, mse=2.4805, time=0.0409\n",
      "Iter=1200, loss=2.5178, mse=2.5118, time=0.0408\n",
      "Iter=1400, loss=2.5180, mse=2.5119, time=0.0408\n",
      "Iter=1600, loss=2.5643, mse=2.5582, time=0.0407\n",
      "Iter=1800, loss=2.4913, mse=2.4849, time=0.0408\n",
      "Iter=2000, loss=2.4758, mse=2.4693, time=0.0408\n",
      "Iter=2200, loss=2.5196, mse=2.5135, time=0.0408\n",
      "Iter=2400, loss=2.5021, mse=2.4960, time=0.0408\n",
      "Iter=2600, loss=2.5429, mse=2.5364, time=0.0408\n",
      "Iter=2800, loss=2.5282, mse=2.5217, time=0.0408\n",
      "Iter=3000, loss=2.5354, mse=2.5290, time=0.0408\n",
      "Iter=3200, loss=2.4765, mse=2.4704, time=0.0408\n",
      "Iter=3400, loss=2.5381, mse=2.5316, time=0.0408\n",
      "Iter=3600, loss=2.4721, mse=2.4656, time=0.0408\n",
      "Iter=3800, loss=2.5074, mse=2.5010, time=0.0407\n",
      "Iter=4000, loss=2.5432, mse=2.5368, time=0.0407\n",
      "Iter=4200, loss=2.4195, mse=2.4128, time=0.0408\n",
      "Iter=4400, loss=2.4200, mse=2.4135, time=0.0408\n",
      "Iter=4600, loss=2.4375, mse=2.4313, time=0.0408\n",
      "Iter=4800, loss=2.4196, mse=2.4137, time=0.0407\n",
      "Iter=5000, loss=2.3863, mse=2.3804, time=0.0407\n",
      "Iter=5200, loss=2.4846, mse=2.4785, time=0.0408\n",
      "Iter=5400, loss=2.3818, mse=2.3758, time=0.0407\n",
      "Iter=5600, loss=2.4853, mse=2.4790, time=0.0407\n",
      "Iter=5800, loss=2.4444, mse=2.4379, time=0.0407\n",
      "Iter=6000, loss=2.5304, mse=2.5242, time=0.0407\n",
      "Iter=6200, loss=2.4395, mse=2.4332, time=0.0407\n",
      "Iter=6400, loss=2.4408, mse=2.4345, time=0.0407\n",
      "Iter=6600, loss=2.4460, mse=2.4396, time=0.0407\n",
      "=== Epoch 24, train loss 2.484576, test rmse 0.801978 ===\n",
      "Epoch 25\n",
      "Iter=200, loss=2.4651, mse=2.4591, time=0.0417\n",
      "Iter=400, loss=2.4651, mse=2.4587, time=0.0412\n",
      "Iter=600, loss=2.5321, mse=2.5251, time=0.0411\n",
      "Iter=800, loss=2.4297, mse=2.4228, time=0.0411\n",
      "Iter=1000, loss=2.4408, mse=2.4340, time=0.0411\n",
      "Iter=1200, loss=2.5192, mse=2.5128, time=0.0411\n",
      "Iter=1400, loss=2.4404, mse=2.4335, time=0.0411\n",
      "Iter=1600, loss=2.5440, mse=2.5372, time=0.0411\n",
      "Iter=1800, loss=2.4411, mse=2.4340, time=0.0410\n",
      "Iter=2000, loss=2.4825, mse=2.4758, time=0.0410\n",
      "Iter=2200, loss=2.4709, mse=2.4645, time=0.0410\n",
      "Iter=2400, loss=2.5208, mse=2.5144, time=0.0409\n",
      "Iter=2600, loss=2.4591, mse=2.4529, time=0.0409\n",
      "Iter=2800, loss=2.4992, mse=2.4932, time=0.0410\n",
      "Iter=3000, loss=2.4993, mse=2.4930, time=0.0410\n",
      "Iter=3200, loss=2.4778, mse=2.4714, time=0.0410\n",
      "Iter=3400, loss=2.4164, mse=2.4101, time=0.0410\n",
      "Iter=3600, loss=2.4671, mse=2.4606, time=0.0410\n",
      "Iter=3800, loss=2.5262, mse=2.5194, time=0.0410\n",
      "Iter=4000, loss=2.5493, mse=2.5418, time=0.0410\n",
      "Iter=4200, loss=2.5035, mse=2.4959, time=0.0410\n",
      "Iter=4400, loss=2.5283, mse=2.5211, time=0.0410\n",
      "Iter=4600, loss=2.4992, mse=2.4920, time=0.0410\n",
      "Iter=4800, loss=2.4602, mse=2.4533, time=0.0410\n",
      "Iter=5000, loss=2.3953, mse=2.3887, time=0.0410\n",
      "Iter=5200, loss=2.4305, mse=2.4243, time=0.0410\n",
      "Iter=5400, loss=2.5091, mse=2.5031, time=0.0410\n",
      "Iter=5600, loss=2.4978, mse=2.4919, time=0.0410\n",
      "Iter=5800, loss=2.4242, mse=2.4183, time=0.0410\n",
      "Iter=6000, loss=2.4711, mse=2.4649, time=0.0410\n",
      "Iter=6200, loss=2.4535, mse=2.4474, time=0.0410\n",
      "Iter=6400, loss=2.3541, mse=2.3481, time=0.0410\n",
      "Iter=6600, loss=2.4759, mse=2.4699, time=0.0410\n",
      "=== Epoch 25, train loss 2.475991, test rmse 0.809500 ===\n",
      "Epoch 26\n",
      "Iter=200, loss=2.5028, mse=2.4968, time=0.0419\n",
      "Iter=400, loss=2.4933, mse=2.4870, time=0.0412\n",
      "Iter=600, loss=2.4768, mse=2.4702, time=0.0410\n",
      "Iter=800, loss=2.4834, mse=2.4771, time=0.0410\n",
      "Iter=1000, loss=2.5171, mse=2.5109, time=0.0409\n",
      "Iter=1200, loss=2.5175, mse=2.5109, time=0.0409\n",
      "Iter=1400, loss=2.4677, mse=2.4613, time=0.0410\n",
      "Iter=1600, loss=2.4899, mse=2.4841, time=0.0409\n",
      "Iter=1800, loss=2.4400, mse=2.4343, time=0.0409\n",
      "Iter=2000, loss=2.4704, mse=2.4646, time=0.0408\n",
      "Iter=2200, loss=2.4955, mse=2.4898, time=0.0409\n",
      "Iter=2400, loss=2.4490, mse=2.4433, time=0.0409\n",
      "Iter=2600, loss=2.4551, mse=2.4495, time=0.0408\n",
      "Iter=2800, loss=2.4989, mse=2.4927, time=0.0409\n",
      "Iter=3000, loss=2.4084, mse=2.4023, time=0.0409\n",
      "Iter=3200, loss=2.4737, mse=2.4673, time=0.0409\n",
      "Iter=3400, loss=2.5179, mse=2.5116, time=0.0410\n",
      "Iter=3600, loss=2.5914, mse=2.5853, time=0.0410\n",
      "Iter=3800, loss=2.5419, mse=2.5360, time=0.0410\n",
      "Iter=4000, loss=2.5323, mse=2.5262, time=0.0410\n",
      "Iter=4200, loss=2.4720, mse=2.4660, time=0.0410\n",
      "Iter=4400, loss=2.4844, mse=2.4786, time=0.0410\n",
      "Iter=4600, loss=2.3849, mse=2.3789, time=0.0410\n",
      "Iter=4800, loss=2.4743, mse=2.4682, time=0.0410\n",
      "Iter=5000, loss=2.4567, mse=2.4506, time=0.0410\n",
      "Iter=5200, loss=2.4027, mse=2.3968, time=0.0410\n",
      "Iter=5400, loss=2.5586, mse=2.5528, time=0.0410\n",
      "Iter=5600, loss=2.4425, mse=2.4366, time=0.0410\n",
      "Iter=5800, loss=2.3800, mse=2.3739, time=0.0410\n",
      "Iter=6000, loss=2.5230, mse=2.5170, time=0.0410\n",
      "Iter=6200, loss=2.4802, mse=2.4740, time=0.0410\n",
      "Iter=6400, loss=2.4825, mse=2.4764, time=0.0410\n",
      "Iter=6600, loss=2.4596, mse=2.4536, time=0.0410\n",
      "=== Epoch 26, train loss 2.477430, test rmse 0.801618 ===\n",
      "Epoch 27\n",
      "Iter=200, loss=2.5258, mse=2.5195, time=0.0426\n",
      "Iter=400, loss=2.5777, mse=2.5705, time=0.0414\n",
      "Iter=600, loss=2.3640, mse=2.3569, time=0.0414\n",
      "Iter=800, loss=2.5029, mse=2.4962, time=0.0410\n",
      "Iter=1000, loss=2.4984, mse=2.4916, time=0.0411\n",
      "Iter=1200, loss=2.4402, mse=2.4339, time=0.0410\n",
      "Iter=1400, loss=2.3788, mse=2.3724, time=0.0410\n",
      "Iter=1600, loss=2.5283, mse=2.5218, time=0.0409\n",
      "Iter=1800, loss=2.4745, mse=2.4683, time=0.0409\n",
      "Iter=2000, loss=2.4550, mse=2.4488, time=0.0409\n",
      "Iter=2200, loss=2.5024, mse=2.4959, time=0.0408\n",
      "Iter=2400, loss=2.4475, mse=2.4410, time=0.0409\n",
      "Iter=2600, loss=2.4847, mse=2.4781, time=0.0409\n",
      "Iter=2800, loss=2.5349, mse=2.5277, time=0.0409\n",
      "Iter=3000, loss=2.4806, mse=2.4735, time=0.0408\n",
      "Iter=3200, loss=2.5073, mse=2.5007, time=0.0408\n",
      "Iter=3400, loss=2.4813, mse=2.4745, time=0.0408\n",
      "Iter=3600, loss=2.4582, mse=2.4517, time=0.0408\n",
      "Iter=3800, loss=2.4285, mse=2.4220, time=0.0408\n",
      "Iter=4000, loss=2.5680, mse=2.5615, time=0.0408\n",
      "Iter=4200, loss=2.5236, mse=2.5169, time=0.0408\n",
      "Iter=4400, loss=2.4874, mse=2.4807, time=0.0408\n",
      "Iter=4600, loss=2.4665, mse=2.4602, time=0.0408\n",
      "Iter=4800, loss=2.4597, mse=2.4533, time=0.0408\n",
      "Iter=5000, loss=2.4997, mse=2.4933, time=0.0408\n",
      "Iter=5200, loss=2.5325, mse=2.5257, time=0.0408\n",
      "Iter=5400, loss=2.4230, mse=2.4161, time=0.0408\n",
      "Iter=5600, loss=2.4562, mse=2.4491, time=0.0408\n",
      "Iter=5800, loss=2.4793, mse=2.4719, time=0.0408\n",
      "Iter=6000, loss=2.4670, mse=2.4599, time=0.0407\n",
      "Iter=6200, loss=2.5313, mse=2.5243, time=0.0407\n",
      "Iter=6400, loss=2.4221, mse=2.4152, time=0.0407\n",
      "Iter=6600, loss=2.4359, mse=2.4290, time=0.0407\n",
      "=== Epoch 27, train loss 2.479399, test rmse 0.802095 ===\n",
      "Epoch 28\n",
      "Iter=200, loss=2.5485, mse=2.5412, time=0.0421\n",
      "Iter=400, loss=2.4561, mse=2.4492, time=0.0415\n",
      "Iter=600, loss=2.5753, mse=2.5681, time=0.0412\n",
      "Iter=800, loss=2.4051, mse=2.3980, time=0.0413\n",
      "Iter=1000, loss=2.4811, mse=2.4743, time=0.0413\n",
      "Iter=1200, loss=2.4699, mse=2.4633, time=0.0414\n",
      "Iter=1400, loss=2.5256, mse=2.5191, time=0.0413\n",
      "Iter=1600, loss=2.4789, mse=2.4721, time=0.0413\n",
      "Iter=1800, loss=2.4744, mse=2.4678, time=0.0412\n",
      "Iter=2000, loss=2.4981, mse=2.4915, time=0.0413\n",
      "Iter=2200, loss=2.4326, mse=2.4257, time=0.0413\n",
      "Iter=2400, loss=2.4809, mse=2.4740, time=0.0412\n",
      "Iter=2600, loss=2.4818, mse=2.4749, time=0.0412\n",
      "Iter=2800, loss=2.4817, mse=2.4751, time=0.0412\n",
      "Iter=3000, loss=2.4953, mse=2.4885, time=0.0412\n",
      "Iter=3200, loss=2.4762, mse=2.4694, time=0.0412\n",
      "Iter=3400, loss=2.4926, mse=2.4862, time=0.0411\n",
      "Iter=3600, loss=2.4887, mse=2.4825, time=0.0411\n",
      "Iter=3800, loss=2.3751, mse=2.3682, time=0.0411\n",
      "Iter=4000, loss=2.4828, mse=2.4761, time=0.0411\n",
      "Iter=4200, loss=2.5050, mse=2.4985, time=0.0411\n",
      "Iter=4400, loss=2.5668, mse=2.5605, time=0.0411\n",
      "Iter=4600, loss=2.5104, mse=2.5040, time=0.0411\n",
      "Iter=4800, loss=2.3557, mse=2.3492, time=0.0411\n",
      "Iter=5000, loss=2.4905, mse=2.4840, time=0.0411\n",
      "Iter=5200, loss=2.4903, mse=2.4838, time=0.0411\n",
      "Iter=5400, loss=2.4251, mse=2.4186, time=0.0410\n",
      "Iter=5600, loss=2.4155, mse=2.4091, time=0.0410\n",
      "Iter=5800, loss=2.3949, mse=2.3876, time=0.0410\n",
      "Iter=6000, loss=2.4285, mse=2.4209, time=0.0410\n",
      "Iter=6200, loss=2.4816, mse=2.4744, time=0.0410\n",
      "Iter=6400, loss=2.3987, mse=2.3914, time=0.0410\n",
      "Iter=6600, loss=2.5318, mse=2.5244, time=0.0410\n",
      "=== Epoch 28, train loss 2.473836, test rmse 0.799073 ===\n",
      "Epoch 29\n",
      "Iter=200, loss=2.4404, mse=2.4331, time=0.0419\n",
      "Iter=400, loss=2.5136, mse=2.5062, time=0.0413\n",
      "Iter=600, loss=2.5070, mse=2.5002, time=0.0414\n",
      "Iter=800, loss=2.5829, mse=2.5761, time=0.0412\n",
      "Iter=1000, loss=2.5059, mse=2.4981, time=0.0411\n",
      "Iter=1200, loss=2.5121, mse=2.5043, time=0.0410\n",
      "Iter=1400, loss=2.4547, mse=2.4463, time=0.0410\n",
      "Iter=1600, loss=2.5082, mse=2.4999, time=0.0410\n",
      "Iter=1800, loss=2.5417, mse=2.5346, time=0.0411\n",
      "Iter=2000, loss=2.4360, mse=2.4287, time=0.0411\n",
      "Iter=2200, loss=2.4289, mse=2.4218, time=0.0411\n",
      "Iter=2400, loss=2.4389, mse=2.4317, time=0.0410\n",
      "Iter=2600, loss=2.4972, mse=2.4901, time=0.0411\n",
      "Iter=2800, loss=2.4618, mse=2.4552, time=0.0410\n",
      "Iter=3000, loss=2.4546, mse=2.4482, time=0.0410\n",
      "Iter=3200, loss=2.5358, mse=2.5292, time=0.0410\n",
      "Iter=3400, loss=2.5020, mse=2.4953, time=0.0410\n",
      "Iter=3600, loss=2.4510, mse=2.4445, time=0.0410\n",
      "Iter=3800, loss=2.5132, mse=2.5063, time=0.0410\n",
      "Iter=4000, loss=2.5025, mse=2.4953, time=0.0411\n",
      "Iter=4200, loss=2.3674, mse=2.3602, time=0.0410\n",
      "Iter=4400, loss=2.4579, mse=2.4507, time=0.0410\n",
      "Iter=4600, loss=2.5998, mse=2.5922, time=0.0410\n",
      "Iter=4800, loss=2.4551, mse=2.4473, time=0.0410\n",
      "Iter=5000, loss=2.4722, mse=2.4653, time=0.0410\n",
      "Iter=5200, loss=2.4774, mse=2.4706, time=0.0410\n",
      "Iter=5400, loss=2.4788, mse=2.4719, time=0.0410\n",
      "Iter=5600, loss=2.5852, mse=2.5780, time=0.0410\n",
      "Iter=5800, loss=2.4174, mse=2.4104, time=0.0410\n",
      "Iter=6000, loss=2.4335, mse=2.4266, time=0.0410\n",
      "Iter=6200, loss=2.4888, mse=2.4817, time=0.0410\n",
      "Iter=6400, loss=2.4528, mse=2.4462, time=0.0410\n",
      "Iter=6600, loss=2.4297, mse=2.4229, time=0.0410\n",
      "=== Epoch 29, train loss 2.480519, test rmse 0.804193 ===\n",
      "Epoch 30\n",
      "Iter=200, loss=2.4710, mse=2.4630, time=0.0421\n",
      "Iter=400, loss=2.4457, mse=2.4379, time=0.0416\n",
      "Iter=600, loss=2.5542, mse=2.5470, time=0.0411\n",
      "Iter=800, loss=2.4469, mse=2.4395, time=0.0410\n",
      "Iter=1000, loss=2.4357, mse=2.4284, time=0.0410\n",
      "Iter=1200, loss=2.5093, mse=2.5020, time=0.0410\n",
      "Iter=1400, loss=2.5175, mse=2.5105, time=0.0409\n",
      "Iter=1600, loss=2.5587, mse=2.5517, time=0.0410\n",
      "Iter=1800, loss=2.4300, mse=2.4230, time=0.0410\n",
      "Iter=2000, loss=2.4479, mse=2.4410, time=0.0410\n",
      "Iter=2200, loss=2.5212, mse=2.5142, time=0.0410\n",
      "Iter=2400, loss=2.4484, mse=2.4419, time=0.0409\n",
      "Iter=2600, loss=2.4653, mse=2.4585, time=0.0409\n",
      "Iter=2800, loss=2.4157, mse=2.4092, time=0.0409\n",
      "Iter=3000, loss=2.5209, mse=2.5146, time=0.0409\n",
      "Iter=3200, loss=2.5191, mse=2.5129, time=0.0408\n",
      "Iter=3400, loss=2.4757, mse=2.4694, time=0.0408\n",
      "Iter=3600, loss=2.4191, mse=2.4130, time=0.0408\n",
      "Iter=3800, loss=2.4260, mse=2.4198, time=0.0408\n",
      "Iter=4000, loss=2.4872, mse=2.4809, time=0.0408\n",
      "Iter=4200, loss=2.5181, mse=2.5116, time=0.0408\n",
      "Iter=4400, loss=2.4750, mse=2.4686, time=0.0408\n",
      "Iter=4600, loss=2.5456, mse=2.5397, time=0.0408\n",
      "Iter=4800, loss=2.4614, mse=2.4553, time=0.0408\n",
      "Iter=5000, loss=2.4823, mse=2.4764, time=0.0408\n",
      "Iter=5200, loss=2.4059, mse=2.3993, time=0.0408\n",
      "Iter=5400, loss=2.4538, mse=2.4476, time=0.0408\n",
      "Iter=5600, loss=2.4850, mse=2.4784, time=0.0408\n",
      "Iter=5800, loss=2.4507, mse=2.4438, time=0.0408\n",
      "Iter=6000, loss=2.4826, mse=2.4756, time=0.0408\n",
      "Iter=6200, loss=2.4179, mse=2.4111, time=0.0408\n",
      "Iter=6400, loss=2.4359, mse=2.4292, time=0.0408\n",
      "Iter=6600, loss=2.4598, mse=2.4532, time=0.0408\n",
      "=== Epoch 30, train loss 2.472859, test rmse 0.808086 ===\n",
      "Epoch 31\n",
      "Iter=200, loss=2.5359, mse=2.5290, time=0.0420\n",
      "Iter=400, loss=2.4540, mse=2.4473, time=0.0412\n",
      "Iter=600, loss=2.4924, mse=2.4856, time=0.0410\n",
      "Iter=800, loss=2.4862, mse=2.4791, time=0.0408\n",
      "Iter=1000, loss=2.6088, mse=2.6016, time=0.0407\n",
      "Iter=1200, loss=2.4430, mse=2.4358, time=0.0407\n",
      "Iter=1400, loss=2.4915, mse=2.4844, time=0.0407\n",
      "Iter=1600, loss=2.4985, mse=2.4915, time=0.0408\n",
      "Iter=1800, loss=2.4134, mse=2.4063, time=0.0408\n",
      "Iter=2000, loss=2.5133, mse=2.5062, time=0.0407\n",
      "Iter=2200, loss=2.3196, mse=2.3123, time=0.0407\n",
      "Iter=2400, loss=2.4277, mse=2.4206, time=0.0407\n",
      "Iter=2600, loss=2.4821, mse=2.4746, time=0.0407\n",
      "Iter=2800, loss=2.4876, mse=2.4801, time=0.0407\n",
      "Iter=3000, loss=2.4741, mse=2.4665, time=0.0407\n",
      "Iter=3200, loss=2.4785, mse=2.4717, time=0.0407\n",
      "Iter=3400, loss=2.5421, mse=2.5352, time=0.0408\n",
      "Iter=3600, loss=2.4687, mse=2.4623, time=0.0407\n",
      "Iter=3800, loss=2.4511, mse=2.4445, time=0.0407\n",
      "Iter=4000, loss=2.4984, mse=2.4915, time=0.0407\n",
      "Iter=4200, loss=2.4388, mse=2.4321, time=0.0407\n",
      "Iter=4400, loss=2.5167, mse=2.5097, time=0.0407\n",
      "Iter=4600, loss=2.4974, mse=2.4900, time=0.0407\n",
      "Iter=4800, loss=2.4411, mse=2.4342, time=0.0407\n",
      "Iter=5000, loss=2.4654, mse=2.4585, time=0.0407\n",
      "Iter=5200, loss=2.5409, mse=2.5338, time=0.0407\n",
      "Iter=5400, loss=2.4297, mse=2.4227, time=0.0407\n",
      "Iter=5600, loss=2.4604, mse=2.4531, time=0.0407\n",
      "Iter=5800, loss=2.5098, mse=2.5016, time=0.0407\n",
      "Iter=6000, loss=2.5662, mse=2.5588, time=0.0407\n",
      "Iter=6200, loss=2.5088, mse=2.5015, time=0.0407\n",
      "Iter=6400, loss=2.4282, mse=2.4211, time=0.0407\n",
      "Iter=6600, loss=2.4955, mse=2.4882, time=0.0407\n",
      "=== Epoch 31, train loss 2.481198, test rmse 0.802709 ===\n",
      "Epoch 32\n",
      "Iter=200, loss=2.4264, mse=2.4192, time=0.0424\n",
      "Iter=400, loss=2.5635, mse=2.5567, time=0.0417\n",
      "Iter=600, loss=2.4436, mse=2.4371, time=0.0417\n",
      "Iter=800, loss=2.5009, mse=2.4944, time=0.0416\n",
      "Iter=1000, loss=2.4233, mse=2.4171, time=0.0414\n",
      "Iter=1200, loss=2.4722, mse=2.4662, time=0.0413\n",
      "Iter=1400, loss=2.4820, mse=2.4760, time=0.0413\n",
      "Iter=1600, loss=2.3985, mse=2.3922, time=0.0412\n",
      "Iter=1800, loss=2.4938, mse=2.4870, time=0.0412\n",
      "Iter=2000, loss=2.5608, mse=2.5545, time=0.0411\n",
      "Iter=2200, loss=2.5764, mse=2.5704, time=0.0412\n",
      "Iter=2400, loss=2.4925, mse=2.4862, time=0.0412\n",
      "Iter=2600, loss=2.4371, mse=2.4308, time=0.0412\n",
      "Iter=2800, loss=2.4146, mse=2.4084, time=0.0412\n",
      "Iter=3000, loss=2.4275, mse=2.4211, time=0.0412\n",
      "Iter=3200, loss=2.4259, mse=2.4194, time=0.0412\n",
      "Iter=3400, loss=2.5292, mse=2.5224, time=0.0411\n",
      "Iter=3600, loss=2.5301, mse=2.5219, time=0.0412\n",
      "Iter=3800, loss=2.4714, mse=2.4625, time=0.0411\n",
      "Iter=4000, loss=2.5526, mse=2.5445, time=0.0411\n",
      "Iter=4200, loss=2.5135, mse=2.5066, time=0.0412\n",
      "Iter=4400, loss=2.5773, mse=2.5710, time=0.0413\n",
      "Iter=4600, loss=2.5419, mse=2.5356, time=0.0414\n",
      "Iter=4800, loss=2.5441, mse=2.5380, time=0.0413\n",
      "Iter=5000, loss=2.3994, mse=2.3936, time=0.0413\n",
      "Iter=5200, loss=2.4577, mse=2.4518, time=0.0413\n",
      "Iter=5400, loss=2.4781, mse=2.4719, time=0.0413\n",
      "Iter=5600, loss=2.4620, mse=2.4554, time=0.0413\n",
      "Iter=5800, loss=2.4496, mse=2.4436, time=0.0413\n",
      "Iter=6000, loss=2.4656, mse=2.4599, time=0.0413\n",
      "Iter=6200, loss=2.4459, mse=2.4403, time=0.0413\n",
      "Iter=6400, loss=2.4625, mse=2.4565, time=0.0413\n",
      "Iter=6600, loss=2.4782, mse=2.4719, time=0.0413\n",
      "=== Epoch 32, train loss 2.482689, test rmse 0.799873 ===\n",
      "Epoch 33\n",
      "Iter=200, loss=2.4962, mse=2.4898, time=0.0413\n",
      "Iter=400, loss=2.5560, mse=2.5497, time=0.0411\n",
      "Iter=600, loss=2.5511, mse=2.5445, time=0.0410\n",
      "Iter=800, loss=2.4642, mse=2.4579, time=0.0411\n",
      "Iter=1000, loss=2.5495, mse=2.5428, time=0.0411\n",
      "Iter=1200, loss=2.5041, mse=2.4974, time=0.0411\n",
      "Iter=1400, loss=2.4043, mse=2.3979, time=0.0410\n",
      "Iter=1600, loss=2.4447, mse=2.4383, time=0.0410\n",
      "Iter=1800, loss=2.5337, mse=2.5273, time=0.0410\n",
      "Iter=2000, loss=2.4543, mse=2.4477, time=0.0410\n",
      "Iter=2200, loss=2.4478, mse=2.4411, time=0.0410\n",
      "Iter=2400, loss=2.4809, mse=2.4737, time=0.0410\n",
      "Iter=2600, loss=2.5718, mse=2.5651, time=0.0410\n",
      "Iter=2800, loss=2.5057, mse=2.4990, time=0.0410\n",
      "Iter=3000, loss=2.4664, mse=2.4594, time=0.0410\n",
      "Iter=3200, loss=2.4375, mse=2.4308, time=0.0409\n",
      "Iter=3400, loss=2.5707, mse=2.5641, time=0.0410\n",
      "Iter=3600, loss=2.4981, mse=2.4914, time=0.0409\n",
      "Iter=3800, loss=2.4475, mse=2.4408, time=0.0409\n",
      "Iter=4000, loss=2.5403, mse=2.5334, time=0.0409\n",
      "Iter=4200, loss=2.5305, mse=2.5233, time=0.0409\n",
      "Iter=4400, loss=2.4568, mse=2.4495, time=0.0409\n",
      "Iter=4600, loss=2.4592, mse=2.4527, time=0.0409\n",
      "Iter=4800, loss=2.4486, mse=2.4424, time=0.0410\n",
      "Iter=5000, loss=2.3397, mse=2.3329, time=0.0409\n",
      "Iter=5200, loss=2.4242, mse=2.4174, time=0.0409\n",
      "Iter=5400, loss=2.4679, mse=2.4612, time=0.0409\n",
      "Iter=5600, loss=2.4373, mse=2.4303, time=0.0409\n",
      "Iter=5800, loss=2.4263, mse=2.4195, time=0.0409\n",
      "Iter=6000, loss=2.4767, mse=2.4700, time=0.0409\n",
      "Iter=6200, loss=2.5503, mse=2.5438, time=0.0409\n",
      "Iter=6400, loss=2.5402, mse=2.5335, time=0.0409\n",
      "Iter=6600, loss=2.4751, mse=2.4682, time=0.0409\n",
      "=== Epoch 33, train loss 2.480722, test rmse 0.801174 ===\n",
      "Epoch 34\n",
      "Iter=200, loss=2.5131, mse=2.5064, time=0.0429\n",
      "Iter=400, loss=2.4864, mse=2.4799, time=0.0416\n",
      "Iter=600, loss=2.4989, mse=2.4925, time=0.0414\n",
      "Iter=800, loss=2.5420, mse=2.5358, time=0.0412\n",
      "Iter=1000, loss=2.5791, mse=2.5730, time=0.0411\n",
      "Iter=1200, loss=2.5303, mse=2.5238, time=0.0410\n",
      "Iter=1400, loss=2.5684, mse=2.5623, time=0.0411\n",
      "Iter=1600, loss=2.4465, mse=2.4402, time=0.0410\n",
      "Iter=1800, loss=2.3837, mse=2.3776, time=0.0411\n",
      "Iter=2000, loss=2.5514, mse=2.5450, time=0.0410\n",
      "Iter=2200, loss=2.4760, mse=2.4696, time=0.0410\n",
      "Iter=2400, loss=2.5135, mse=2.5067, time=0.0410\n",
      "Iter=2600, loss=2.5301, mse=2.5236, time=0.0410\n",
      "Iter=2800, loss=2.4054, mse=2.3987, time=0.0410\n",
      "Iter=3000, loss=2.4612, mse=2.4545, time=0.0410\n",
      "Iter=3200, loss=2.4950, mse=2.4887, time=0.0411\n",
      "Iter=3400, loss=2.5296, mse=2.5235, time=0.0411\n",
      "Iter=3600, loss=2.4689, mse=2.4627, time=0.0411\n",
      "Iter=3800, loss=2.4701, mse=2.4633, time=0.0411\n",
      "Iter=4000, loss=2.4144, mse=2.4079, time=0.0410\n",
      "Iter=4200, loss=2.5231, mse=2.5165, time=0.0410\n",
      "Iter=4400, loss=2.4721, mse=2.4656, time=0.0410\n",
      "Iter=4600, loss=2.4930, mse=2.4865, time=0.0410\n",
      "Iter=4800, loss=2.4843, mse=2.4780, time=0.0410\n",
      "Iter=5000, loss=2.4561, mse=2.4501, time=0.0410\n",
      "Iter=5200, loss=2.4790, mse=2.4730, time=0.0410\n",
      "Iter=5400, loss=2.4481, mse=2.4422, time=0.0410\n",
      "Iter=5600, loss=2.4357, mse=2.4295, time=0.0410\n",
      "Iter=5800, loss=2.4583, mse=2.4515, time=0.0410\n",
      "Iter=6000, loss=2.4921, mse=2.4850, time=0.0410\n",
      "Iter=6200, loss=2.4155, mse=2.4086, time=0.0410\n",
      "Iter=6400, loss=2.4653, mse=2.4584, time=0.0410\n",
      "Iter=6600, loss=2.4838, mse=2.4770, time=0.0410\n",
      "=== Epoch 34, train loss 2.481810, test rmse 0.809413 ===\n",
      "Epoch 35\n",
      "Iter=200, loss=2.4796, mse=2.4727, time=0.0413\n",
      "Iter=400, loss=2.5045, mse=2.4974, time=0.0414\n",
      "Iter=600, loss=2.4301, mse=2.4229, time=0.0412\n",
      "Iter=800, loss=2.4085, mse=2.4015, time=0.0411\n",
      "Iter=1000, loss=2.5477, mse=2.5412, time=0.0408\n",
      "Iter=1200, loss=2.3598, mse=2.3534, time=0.0408\n",
      "Iter=1400, loss=2.4336, mse=2.4270, time=0.0408\n",
      "Iter=1600, loss=2.4676, mse=2.4610, time=0.0408\n",
      "Iter=1800, loss=2.5181, mse=2.5115, time=0.0407\n",
      "Iter=2000, loss=2.5387, mse=2.5325, time=0.0407\n",
      "Iter=2200, loss=2.5703, mse=2.5641, time=0.0407\n",
      "Iter=2400, loss=2.4665, mse=2.4603, time=0.0407\n",
      "Iter=2600, loss=2.4648, mse=2.4586, time=0.0407\n",
      "Iter=2800, loss=2.4673, mse=2.4611, time=0.0407\n",
      "Iter=3000, loss=2.5000, mse=2.4935, time=0.0407\n",
      "Iter=3200, loss=2.4818, mse=2.4750, time=0.0406\n",
      "Iter=3400, loss=2.4379, mse=2.4315, time=0.0407\n",
      "Iter=3600, loss=2.4115, mse=2.4051, time=0.0407\n",
      "Iter=3800, loss=2.5866, mse=2.5801, time=0.0407\n",
      "Iter=4000, loss=2.4866, mse=2.4797, time=0.0407\n",
      "Iter=4200, loss=2.5178, mse=2.5113, time=0.0407\n",
      "Iter=4400, loss=2.4339, mse=2.4271, time=0.0407\n",
      "Iter=4600, loss=2.5256, mse=2.5181, time=0.0407\n",
      "Iter=4800, loss=2.4957, mse=2.4883, time=0.0407\n",
      "Iter=5000, loss=2.5141, mse=2.5067, time=0.0407\n",
      "Iter=5200, loss=2.4628, mse=2.4555, time=0.0407\n",
      "Iter=5400, loss=2.4499, mse=2.4423, time=0.0407\n",
      "Iter=5600, loss=2.4863, mse=2.4788, time=0.0407\n",
      "Iter=5800, loss=2.5175, mse=2.5096, time=0.0407\n",
      "Iter=6000, loss=2.4641, mse=2.4539, time=0.0407\n",
      "Iter=6200, loss=2.4525, mse=2.4427, time=0.0407\n",
      "Iter=6400, loss=2.5534, mse=2.5447, time=0.0407\n",
      "Iter=6600, loss=2.5160, mse=2.5080, time=0.0407\n",
      "=== Epoch 35, train loss 2.483428, test rmse 0.802506 ===\n",
      "Epoch 36\n",
      "Iter=200, loss=2.4536, mse=2.4458, time=0.0415\n",
      "Iter=400, loss=2.4344, mse=2.4269, time=0.0412\n",
      "Iter=600, loss=2.4834, mse=2.4751, time=0.0410\n",
      "Iter=800, loss=2.4864, mse=2.4777, time=0.0411\n",
      "Iter=1000, loss=2.4382, mse=2.4295, time=0.0409\n",
      "Iter=1200, loss=2.5285, mse=2.5206, time=0.0409\n",
      "Iter=1400, loss=2.3740, mse=2.3661, time=0.0409\n",
      "Iter=1600, loss=2.5362, mse=2.5285, time=0.0408\n",
      "Iter=1800, loss=2.4632, mse=2.4556, time=0.0409\n",
      "Iter=2000, loss=2.4826, mse=2.4754, time=0.0409\n",
      "Iter=2200, loss=2.6009, mse=2.5932, time=0.0409\n",
      "Iter=2400, loss=2.4079, mse=2.4007, time=0.0409\n",
      "Iter=2600, loss=2.4865, mse=2.4792, time=0.0409\n",
      "Iter=2800, loss=2.4360, mse=2.4289, time=0.0409\n",
      "Iter=3000, loss=2.5223, mse=2.5155, time=0.0410\n",
      "Iter=3200, loss=2.4940, mse=2.4871, time=0.0409\n",
      "Iter=3400, loss=2.4421, mse=2.4351, time=0.0409\n",
      "Iter=3600, loss=2.4682, mse=2.4603, time=0.0409\n",
      "Iter=3800, loss=2.5347, mse=2.5263, time=0.0409\n",
      "Iter=4000, loss=2.4958, mse=2.4867, time=0.0410\n",
      "Iter=4200, loss=2.4984, mse=2.4895, time=0.0409\n",
      "Iter=4400, loss=2.5207, mse=2.5123, time=0.0410\n",
      "Iter=4600, loss=2.4559, mse=2.4477, time=0.0409\n",
      "Iter=4800, loss=2.4258, mse=2.4180, time=0.0409\n",
      "Iter=5000, loss=2.4525, mse=2.4451, time=0.0409\n",
      "Iter=5200, loss=2.4858, mse=2.4784, time=0.0409\n",
      "Iter=5400, loss=2.5162, mse=2.5088, time=0.0409\n",
      "Iter=5600, loss=2.4117, mse=2.4043, time=0.0409\n",
      "Iter=5800, loss=2.4946, mse=2.4867, time=0.0409\n",
      "Iter=6000, loss=2.5176, mse=2.5087, time=0.0409\n",
      "Iter=6200, loss=2.5247, mse=2.5167, time=0.0409\n",
      "Iter=6400, loss=2.5493, mse=2.5417, time=0.0409\n",
      "Iter=6600, loss=2.5246, mse=2.5173, time=0.0409\n",
      "=== Epoch 36, train loss 2.485144, test rmse 0.802685 ===\n",
      "Epoch 37\n",
      "Iter=200, loss=2.4513, mse=2.4443, time=0.0427\n",
      "Iter=400, loss=2.4269, mse=2.4191, time=0.0418\n",
      "Iter=600, loss=2.5040, mse=2.4964, time=0.0416\n",
      "Iter=800, loss=2.5429, mse=2.5353, time=0.0413\n",
      "Iter=1000, loss=2.4934, mse=2.4859, time=0.0412\n",
      "Iter=1200, loss=2.4310, mse=2.4237, time=0.0410\n",
      "Iter=1400, loss=2.5801, mse=2.5720, time=0.0411\n",
      "Iter=1600, loss=2.4634, mse=2.4552, time=0.0411\n",
      "Iter=1800, loss=2.4851, mse=2.4771, time=0.0411\n",
      "Iter=2000, loss=2.4969, mse=2.4884, time=0.0411\n",
      "Iter=2200, loss=2.4414, mse=2.4328, time=0.0411\n",
      "Iter=2400, loss=2.4072, mse=2.3997, time=0.0411\n",
      "Iter=2600, loss=2.4849, mse=2.4776, time=0.0410\n",
      "Iter=2800, loss=2.5277, mse=2.5201, time=0.0410\n",
      "Iter=3000, loss=2.4889, mse=2.4816, time=0.0410\n",
      "Iter=3200, loss=2.4146, mse=2.4075, time=0.0410\n",
      "Iter=3400, loss=2.4486, mse=2.4406, time=0.0410\n",
      "Iter=3600, loss=2.4804, mse=2.4728, time=0.0410\n",
      "Iter=3800, loss=2.3977, mse=2.3904, time=0.0410\n",
      "Iter=4000, loss=2.4560, mse=2.4485, time=0.0410\n",
      "Iter=4200, loss=2.5208, mse=2.5134, time=0.0410\n",
      "Iter=4400, loss=2.4380, mse=2.4307, time=0.0410\n",
      "Iter=4600, loss=2.5282, mse=2.5204, time=0.0410\n",
      "Iter=4800, loss=2.5395, mse=2.5312, time=0.0410\n",
      "Iter=5000, loss=2.4577, mse=2.4498, time=0.0410\n",
      "Iter=5200, loss=2.4668, mse=2.4589, time=0.0410\n",
      "Iter=5400, loss=2.5097, mse=2.5016, time=0.0410\n",
      "Iter=5600, loss=2.5664, mse=2.5581, time=0.0410\n",
      "Iter=5800, loss=2.5171, mse=2.5095, time=0.0410\n",
      "Iter=6000, loss=2.4710, mse=2.4634, time=0.0410\n",
      "Iter=6200, loss=2.5277, mse=2.5201, time=0.0410\n",
      "Iter=6400, loss=2.5178, mse=2.5103, time=0.0410\n",
      "Iter=6600, loss=2.4927, mse=2.4858, time=0.0410\n",
      "=== Epoch 37, train loss 2.484751, test rmse 0.808045 ===\n",
      "Epoch 38\n",
      "Iter=200, loss=2.5120, mse=2.5049, time=0.0418\n",
      "Iter=400, loss=2.4655, mse=2.4585, time=0.0416\n",
      "Iter=600, loss=2.5549, mse=2.5477, time=0.0413\n",
      "Iter=800, loss=2.3930, mse=2.3854, time=0.0414\n",
      "Iter=1000, loss=2.4399, mse=2.4327, time=0.0412\n",
      "Iter=1200, loss=2.5231, mse=2.5159, time=0.0412\n",
      "Iter=1400, loss=2.4008, mse=2.3938, time=0.0411\n",
      "Iter=1600, loss=2.5598, mse=2.5527, time=0.0411\n",
      "Iter=1800, loss=2.4086, mse=2.4015, time=0.0411\n",
      "Iter=2000, loss=2.5250, mse=2.5178, time=0.0411\n",
      "Iter=2200, loss=2.5010, mse=2.4937, time=0.0411\n",
      "Iter=2400, loss=2.4525, mse=2.4454, time=0.0411\n",
      "Iter=2600, loss=2.5176, mse=2.5104, time=0.0410\n",
      "Iter=2800, loss=2.5121, mse=2.5049, time=0.0410\n",
      "Iter=3000, loss=2.4325, mse=2.4259, time=0.0410\n",
      "Iter=3200, loss=2.5350, mse=2.5283, time=0.0410\n",
      "Iter=3400, loss=2.4809, mse=2.4740, time=0.0409\n",
      "Iter=3600, loss=2.4788, mse=2.4720, time=0.0409\n",
      "Iter=3800, loss=2.4953, mse=2.4885, time=0.0410\n",
      "Iter=4000, loss=2.4721, mse=2.4652, time=0.0410\n",
      "Iter=4200, loss=2.5286, mse=2.5219, time=0.0409\n",
      "Iter=4400, loss=2.5052, mse=2.4986, time=0.0409\n",
      "Iter=4600, loss=2.4545, mse=2.4481, time=0.0409\n",
      "Iter=4800, loss=2.4903, mse=2.4833, time=0.0409\n",
      "Iter=5000, loss=2.4711, mse=2.4642, time=0.0409\n",
      "Iter=5200, loss=2.4039, mse=2.3967, time=0.0409\n",
      "Iter=5400, loss=2.4784, mse=2.4713, time=0.0409\n",
      "Iter=5600, loss=2.5042, mse=2.4971, time=0.0409\n",
      "Iter=5800, loss=2.4913, mse=2.4840, time=0.0409\n",
      "Iter=6000, loss=2.4701, mse=2.4628, time=0.0409\n",
      "Iter=6200, loss=2.4732, mse=2.4657, time=0.0409\n",
      "Iter=6400, loss=2.5762, mse=2.5685, time=0.0409\n",
      "Iter=6600, loss=2.5317, mse=2.5241, time=0.0409\n",
      "=== Epoch 38, train loss 2.484908, test rmse 0.810114 ===\n",
      "Epoch 39\n",
      "Iter=200, loss=2.4771, mse=2.4700, time=0.0421\n",
      "Iter=400, loss=2.4958, mse=2.4893, time=0.0415\n",
      "Iter=600, loss=2.4782, mse=2.4713, time=0.0415\n",
      "Iter=800, loss=2.6206, mse=2.6137, time=0.0413\n",
      "Iter=1000, loss=2.5490, mse=2.5421, time=0.0412\n",
      "Iter=1200, loss=2.3877, mse=2.3805, time=0.0411\n",
      "Iter=1400, loss=2.5370, mse=2.5298, time=0.0411\n",
      "Iter=1600, loss=2.4386, mse=2.4312, time=0.0411\n",
      "Iter=1800, loss=2.4529, mse=2.4460, time=0.0410\n",
      "Iter=2000, loss=2.5067, mse=2.4996, time=0.0410\n",
      "Iter=2200, loss=2.3994, mse=2.3918, time=0.0411\n",
      "Iter=2400, loss=2.5110, mse=2.5032, time=0.0414\n",
      "Iter=2600, loss=2.3736, mse=2.3656, time=0.0417\n",
      "Iter=2800, loss=2.5232, mse=2.5154, time=0.0418\n",
      "Iter=3000, loss=2.4838, mse=2.4761, time=0.0417\n",
      "Iter=3200, loss=2.5120, mse=2.5040, time=0.0418\n",
      "Iter=3400, loss=2.4934, mse=2.4854, time=0.0418\n",
      "Iter=3600, loss=2.4689, mse=2.4608, time=0.0417\n",
      "Iter=3800, loss=2.4591, mse=2.4510, time=0.0417\n",
      "Iter=4000, loss=2.4849, mse=2.4773, time=0.0417\n",
      "Iter=4200, loss=2.4923, mse=2.4849, time=0.0416\n",
      "Iter=4400, loss=2.4541, mse=2.4469, time=0.0416\n",
      "Iter=4600, loss=2.4284, mse=2.4214, time=0.0416\n",
      "Iter=4800, loss=2.4691, mse=2.4612, time=0.0415\n",
      "Iter=5000, loss=2.4733, mse=2.4650, time=0.0415\n",
      "Iter=5200, loss=2.4942, mse=2.4868, time=0.0415\n",
      "Iter=5400, loss=2.5106, mse=2.5031, time=0.0414\n",
      "Iter=5600, loss=2.5582, mse=2.5506, time=0.0414\n",
      "Iter=5800, loss=2.4751, mse=2.4674, time=0.0414\n",
      "Iter=6000, loss=2.4235, mse=2.4152, time=0.0414\n",
      "Iter=6200, loss=2.3957, mse=2.3874, time=0.0414\n",
      "Iter=6400, loss=2.4904, mse=2.4822, time=0.0414\n",
      "Iter=6600, loss=2.5334, mse=2.5256, time=0.0413\n",
      "=== Epoch 39, train loss 2.479241, test rmse 0.800613 ===\n",
      "Epoch 40\n",
      "Iter=200, loss=2.5024, mse=2.4950, time=0.0417\n",
      "Iter=400, loss=2.5433, mse=2.5357, time=0.0412\n",
      "Iter=600, loss=2.4599, mse=2.4522, time=0.0409\n",
      "Iter=800, loss=2.4387, mse=2.4304, time=0.0409\n",
      "Iter=1000, loss=2.4615, mse=2.4535, time=0.0407\n",
      "Iter=1200, loss=2.4489, mse=2.4407, time=0.0408\n",
      "Iter=1400, loss=2.3944, mse=2.3863, time=0.0407\n",
      "Iter=1600, loss=2.5331, mse=2.5253, time=0.0407\n",
      "Iter=1800, loss=2.5297, mse=2.5220, time=0.0408\n",
      "Iter=2000, loss=2.4951, mse=2.4872, time=0.0407\n",
      "Iter=2200, loss=2.4574, mse=2.4494, time=0.0407\n",
      "Iter=2400, loss=2.4654, mse=2.4568, time=0.0407\n",
      "Iter=2600, loss=2.4288, mse=2.4205, time=0.0407\n",
      "Iter=2800, loss=2.5069, mse=2.4986, time=0.0407\n",
      "Iter=3000, loss=2.5105, mse=2.5030, time=0.0407\n",
      "Iter=3200, loss=2.4951, mse=2.4876, time=0.0407\n",
      "Iter=3400, loss=2.5092, mse=2.5015, time=0.0407\n",
      "Iter=3600, loss=2.5457, mse=2.5382, time=0.0407\n",
      "Iter=3800, loss=2.5355, mse=2.5283, time=0.0407\n",
      "Iter=4000, loss=2.5031, mse=2.4958, time=0.0407\n",
      "Iter=4200, loss=2.5528, mse=2.5459, time=0.0407\n",
      "Iter=4400, loss=2.4749, mse=2.4679, time=0.0407\n",
      "Iter=4600, loss=2.4917, mse=2.4851, time=0.0407\n",
      "Iter=4800, loss=2.4858, mse=2.4793, time=0.0408\n",
      "Iter=5000, loss=2.5050, mse=2.4978, time=0.0408\n",
      "Iter=5200, loss=2.5173, mse=2.5100, time=0.0407\n",
      "Iter=5400, loss=2.5195, mse=2.5125, time=0.0407\n",
      "Iter=5600, loss=2.4929, mse=2.4861, time=0.0407\n",
      "Iter=5800, loss=2.5558, mse=2.5490, time=0.0407\n",
      "Iter=6000, loss=2.4430, mse=2.4361, time=0.0407\n",
      "Iter=6200, loss=2.5083, mse=2.5017, time=0.0407\n",
      "Iter=6400, loss=2.5034, mse=2.4963, time=0.0407\n",
      "Iter=6600, loss=2.4003, mse=2.3935, time=0.0407\n",
      "=== Epoch 40, train loss 2.490850, test rmse 0.801179 ===\n",
      "Epoch 41\n",
      "Iter=200, loss=2.4567, mse=2.4497, time=0.0418\n",
      "Iter=400, loss=2.4912, mse=2.4840, time=0.0410\n",
      "Iter=600, loss=2.5369, mse=2.5301, time=0.0412\n",
      "Iter=800, loss=2.5095, mse=2.5030, time=0.0412\n",
      "Iter=1000, loss=2.5147, mse=2.5082, time=0.0411\n",
      "Iter=1200, loss=2.5342, mse=2.5273, time=0.0409\n",
      "Iter=1400, loss=2.4856, mse=2.4792, time=0.0409\n",
      "Iter=1600, loss=2.5290, mse=2.5225, time=0.0409\n",
      "Iter=1800, loss=2.5193, mse=2.5127, time=0.0410\n",
      "Iter=2000, loss=2.4960, mse=2.4890, time=0.0410\n",
      "Iter=2200, loss=2.4264, mse=2.4195, time=0.0410\n",
      "Iter=2400, loss=2.5058, mse=2.4987, time=0.0410\n",
      "Iter=2600, loss=2.4431, mse=2.4361, time=0.0412\n",
      "Iter=2800, loss=2.5277, mse=2.5203, time=0.0414\n",
      "Iter=3000, loss=2.4470, mse=2.4396, time=0.0413\n",
      "Iter=3200, loss=2.4940, mse=2.4868, time=0.0413\n",
      "Iter=3400, loss=2.5476, mse=2.5405, time=0.0413\n",
      "Iter=3600, loss=2.5142, mse=2.5069, time=0.0413\n",
      "Iter=3800, loss=2.4447, mse=2.4375, time=0.0413\n",
      "Iter=4000, loss=2.5199, mse=2.5126, time=0.0413\n",
      "Iter=4200, loss=2.4864, mse=2.4790, time=0.0412\n",
      "Iter=4400, loss=2.4871, mse=2.4795, time=0.0412\n",
      "Iter=4600, loss=2.5101, mse=2.5024, time=0.0412\n",
      "Iter=4800, loss=2.4343, mse=2.4267, time=0.0412\n",
      "Iter=5000, loss=2.5821, mse=2.5745, time=0.0412\n",
      "Iter=5200, loss=2.4808, mse=2.4729, time=0.0412\n",
      "Iter=5400, loss=2.4936, mse=2.4861, time=0.0412\n",
      "Iter=5600, loss=2.3969, mse=2.3896, time=0.0412\n",
      "Iter=5800, loss=2.4081, mse=2.4003, time=0.0412\n",
      "Iter=6000, loss=2.4528, mse=2.4452, time=0.0411\n",
      "Iter=6200, loss=2.4111, mse=2.4033, time=0.0412\n",
      "Iter=6400, loss=2.5257, mse=2.5183, time=0.0412\n",
      "Iter=6600, loss=2.4940, mse=2.4862, time=0.0412\n",
      "=== Epoch 41, train loss 2.489775, test rmse 0.807759 ===\n",
      "Epoch 42\n",
      "Iter=200, loss=2.3536, mse=2.3461, time=0.0416\n",
      "Iter=400, loss=2.5258, mse=2.5186, time=0.0414\n",
      "Iter=600, loss=2.4861, mse=2.4788, time=0.0411\n",
      "Iter=800, loss=2.5432, mse=2.5362, time=0.0423\n",
      "Iter=1000, loss=2.4664, mse=2.4591, time=0.0424\n",
      "Iter=1200, loss=2.6483, mse=2.6412, time=0.0424\n",
      "Iter=1400, loss=2.5146, mse=2.5075, time=0.0422\n",
      "Iter=1600, loss=2.5403, mse=2.5332, time=0.0420\n",
      "Iter=1800, loss=2.4772, mse=2.4694, time=0.0420\n",
      "Iter=2000, loss=2.5206, mse=2.5129, time=0.0418\n",
      "Iter=2200, loss=2.4987, mse=2.4908, time=0.0418\n",
      "Iter=2400, loss=2.5023, mse=2.4940, time=0.0417\n",
      "Iter=2600, loss=2.5138, mse=2.5057, time=0.0417\n",
      "Iter=2800, loss=2.3876, mse=2.3795, time=0.0416\n",
      "Iter=3000, loss=2.4927, mse=2.4847, time=0.0416\n",
      "Iter=3200, loss=2.4995, mse=2.4916, time=0.0415\n",
      "Iter=3400, loss=2.5650, mse=2.5578, time=0.0415\n",
      "Iter=3600, loss=2.5408, mse=2.5337, time=0.0415\n",
      "Iter=3800, loss=2.4886, mse=2.4816, time=0.0414\n",
      "Iter=4000, loss=2.5009, mse=2.4938, time=0.0415\n",
      "Iter=4200, loss=2.4464, mse=2.4390, time=0.0415\n",
      "Iter=4400, loss=2.4752, mse=2.4675, time=0.0415\n",
      "Iter=4600, loss=2.5339, mse=2.5262, time=0.0414\n",
      "Iter=4800, loss=2.5409, mse=2.5336, time=0.0414\n",
      "Iter=5000, loss=2.5617, mse=2.5545, time=0.0414\n",
      "Iter=5200, loss=2.4007, mse=2.3934, time=0.0414\n",
      "Iter=5400, loss=2.4752, mse=2.4679, time=0.0414\n",
      "Iter=5600, loss=2.4975, mse=2.4899, time=0.0414\n",
      "Iter=5800, loss=2.4136, mse=2.4061, time=0.0413\n",
      "Iter=6000, loss=2.5287, mse=2.5210, time=0.0413\n",
      "Iter=6200, loss=2.4802, mse=2.4729, time=0.0413\n",
      "Iter=6400, loss=2.4811, mse=2.4734, time=0.0413\n",
      "Iter=6600, loss=2.4102, mse=2.4027, time=0.0413\n",
      "=== Epoch 42, train loss 2.494300, test rmse 0.804413 ===\n",
      "Epoch 43\n",
      "Iter=200, loss=2.5133, mse=2.5056, time=0.0423\n",
      "Iter=400, loss=2.3791, mse=2.3711, time=0.0418\n",
      "Iter=600, loss=2.4853, mse=2.4779, time=0.0414\n",
      "Iter=800, loss=2.3761, mse=2.3690, time=0.0412\n",
      "Iter=1000, loss=2.5431, mse=2.5359, time=0.0412\n",
      "Iter=1200, loss=2.4936, mse=2.4861, time=0.0411\n",
      "Iter=1400, loss=2.4834, mse=2.4762, time=0.0411\n",
      "Iter=1600, loss=2.4015, mse=2.3945, time=0.0411\n",
      "Iter=1800, loss=2.5457, mse=2.5386, time=0.0411\n",
      "Iter=2000, loss=2.4271, mse=2.4198, time=0.0411\n",
      "Iter=2200, loss=2.4584, mse=2.4514, time=0.0410\n",
      "Iter=2400, loss=2.5304, mse=2.5232, time=0.0410\n",
      "Iter=2600, loss=2.4910, mse=2.4839, time=0.0410\n",
      "Iter=2800, loss=2.4678, mse=2.4600, time=0.0410\n",
      "Iter=3000, loss=2.4853, mse=2.4769, time=0.0410\n",
      "Iter=3200, loss=2.4970, mse=2.4890, time=0.0410\n",
      "Iter=3400, loss=2.5444, mse=2.5361, time=0.0410\n",
      "Iter=3600, loss=2.5809, mse=2.5723, time=0.0410\n",
      "Iter=3800, loss=2.5243, mse=2.5162, time=0.0410\n",
      "Iter=4000, loss=2.5118, mse=2.5034, time=0.0410\n",
      "Iter=4200, loss=2.5420, mse=2.5333, time=0.0410\n",
      "Iter=4400, loss=2.4845, mse=2.4759, time=0.0410\n",
      "Iter=4600, loss=2.4526, mse=2.4444, time=0.0410\n",
      "Iter=4800, loss=2.4515, mse=2.4440, time=0.0410\n",
      "Iter=5000, loss=2.4465, mse=2.4390, time=0.0410\n",
      "Iter=5200, loss=2.4449, mse=2.4372, time=0.0410\n",
      "Iter=5400, loss=2.4148, mse=2.4069, time=0.0410\n",
      "Iter=5600, loss=2.4973, mse=2.4894, time=0.0410\n",
      "Iter=5800, loss=2.4965, mse=2.4889, time=0.0410\n",
      "Iter=6000, loss=2.5235, mse=2.5160, time=0.0410\n",
      "Iter=6200, loss=2.4289, mse=2.4215, time=0.0410\n",
      "Iter=6400, loss=2.4978, mse=2.4905, time=0.0410\n",
      "Iter=6600, loss=2.5187, mse=2.5114, time=0.0410\n",
      "=== Epoch 43, train loss 2.483754, test rmse 0.806782 ===\n",
      "Epoch 44\n",
      "Iter=200, loss=2.5139, mse=2.5064, time=0.0425\n",
      "Iter=400, loss=2.5566, mse=2.5494, time=0.0417\n",
      "Iter=600, loss=2.5099, mse=2.5029, time=0.0412\n",
      "Iter=800, loss=2.4408, mse=2.4341, time=0.0413\n",
      "Iter=1000, loss=2.5032, mse=2.4964, time=0.0411\n",
      "Iter=1200, loss=2.5114, mse=2.5044, time=0.0411\n",
      "Iter=1400, loss=2.4845, mse=2.4775, time=0.0410\n",
      "Iter=1600, loss=2.4472, mse=2.4402, time=0.0410\n",
      "Iter=1800, loss=2.4627, mse=2.4556, time=0.0410\n",
      "Iter=2000, loss=2.4829, mse=2.4755, time=0.0410\n",
      "Iter=2200, loss=2.4438, mse=2.4358, time=0.0411\n",
      "Iter=2400, loss=2.4608, mse=2.4532, time=0.0411\n",
      "Iter=2600, loss=2.4776, mse=2.4696, time=0.0410\n",
      "Iter=2800, loss=2.5602, mse=2.5521, time=0.0410\n",
      "Iter=3000, loss=2.5312, mse=2.5232, time=0.0411\n",
      "Iter=3200, loss=2.5335, mse=2.5257, time=0.0411\n",
      "Iter=3400, loss=2.4234, mse=2.4157, time=0.0411\n",
      "Iter=3600, loss=2.3497, mse=2.3421, time=0.0412\n",
      "Iter=3800, loss=2.4615, mse=2.4539, time=0.0412\n",
      "Iter=4000, loss=2.4916, mse=2.4840, time=0.0412\n",
      "Iter=4200, loss=2.5005, mse=2.4935, time=0.0412\n",
      "Iter=4400, loss=2.4412, mse=2.4342, time=0.0412\n",
      "Iter=4600, loss=2.4761, mse=2.4690, time=0.0411\n",
      "Iter=4800, loss=2.4779, mse=2.4703, time=0.0411\n",
      "Iter=5000, loss=2.4923, mse=2.4847, time=0.0411\n",
      "Iter=5200, loss=2.5100, mse=2.5027, time=0.0411\n",
      "Iter=5400, loss=2.4484, mse=2.4403, time=0.0411\n",
      "Iter=5600, loss=2.4759, mse=2.4681, time=0.0411\n",
      "Iter=5800, loss=2.5507, mse=2.5436, time=0.0411\n",
      "Iter=6000, loss=2.5617, mse=2.5548, time=0.0411\n",
      "Iter=6200, loss=2.4770, mse=2.4697, time=0.0411\n",
      "Iter=6400, loss=2.5163, mse=2.5090, time=0.0411\n",
      "Iter=6600, loss=2.3907, mse=2.3831, time=0.0411\n",
      "=== Epoch 44, train loss 2.486612, test rmse 0.799738 ===\n",
      "Epoch 45\n",
      "Iter=200, loss=2.5028, mse=2.4952, time=0.0422\n",
      "Iter=400, loss=2.4404, mse=2.4328, time=0.0413\n",
      "Iter=600, loss=2.4110, mse=2.4037, time=0.0412\n",
      "Iter=800, loss=2.4738, mse=2.4669, time=0.0408\n",
      "Iter=1000, loss=2.3996, mse=2.3929, time=0.0408\n",
      "Iter=1200, loss=2.5379, mse=2.5314, time=0.0407\n",
      "Iter=1400, loss=2.5585, mse=2.5513, time=0.0408\n",
      "Iter=1600, loss=2.4248, mse=2.4178, time=0.0407\n",
      "Iter=1800, loss=2.4480, mse=2.4406, time=0.0408\n",
      "Iter=2000, loss=2.4208, mse=2.4128, time=0.0408\n",
      "Iter=2200, loss=2.5634, mse=2.5562, time=0.0408\n",
      "Iter=2400, loss=2.4489, mse=2.4413, time=0.0408\n",
      "Iter=2600, loss=2.4915, mse=2.4836, time=0.0408\n",
      "Iter=2800, loss=2.4325, mse=2.4248, time=0.0408\n",
      "Iter=3000, loss=2.5175, mse=2.5099, time=0.0408\n",
      "Iter=3200, loss=2.4251, mse=2.4173, time=0.0409\n",
      "Iter=3400, loss=2.4190, mse=2.4118, time=0.0408\n",
      "Iter=3600, loss=2.5721, mse=2.5648, time=0.0409\n",
      "Iter=3800, loss=2.4641, mse=2.4571, time=0.0408\n",
      "Iter=4000, loss=2.5163, mse=2.5089, time=0.0408\n",
      "Iter=4200, loss=2.5237, mse=2.5160, time=0.0408\n",
      "Iter=4400, loss=2.4573, mse=2.4496, time=0.0408\n",
      "Iter=4600, loss=2.4445, mse=2.4368, time=0.0409\n",
      "Iter=4800, loss=2.5038, mse=2.4962, time=0.0409\n",
      "Iter=5000, loss=2.4642, mse=2.4569, time=0.0409\n",
      "Iter=5200, loss=2.5277, mse=2.5203, time=0.0409\n",
      "Iter=5400, loss=2.5925, mse=2.5851, time=0.0409\n",
      "Iter=5600, loss=2.4807, mse=2.4734, time=0.0409\n",
      "Iter=5800, loss=2.4744, mse=2.4674, time=0.0409\n",
      "Iter=6000, loss=2.4715, mse=2.4644, time=0.0409\n",
      "Iter=6200, loss=2.4418, mse=2.4342, time=0.0409\n",
      "Iter=6400, loss=2.6343, mse=2.6267, time=0.0409\n",
      "Iter=6600, loss=2.5202, mse=2.5126, time=0.0409\n",
      "=== Epoch 45, train loss 2.485438, test rmse 0.810898 ===\n",
      "Epoch 46\n",
      "Iter=200, loss=2.5347, mse=2.5277, time=0.0422\n",
      "Iter=400, loss=2.5089, mse=2.5020, time=0.0414\n",
      "Iter=600, loss=2.4778, mse=2.4710, time=0.0410\n",
      "Iter=800, loss=2.5068, mse=2.5000, time=0.0410\n",
      "Iter=1000, loss=2.4726, mse=2.4659, time=0.0409\n",
      "Iter=1200, loss=2.4927, mse=2.4856, time=0.0410\n",
      "Iter=1400, loss=2.5425, mse=2.5349, time=0.0410\n",
      "Iter=1600, loss=2.4436, mse=2.4358, time=0.0410\n",
      "Iter=1800, loss=2.5026, mse=2.4952, time=0.0410\n",
      "Iter=2000, loss=2.5172, mse=2.5100, time=0.0411\n",
      "Iter=2200, loss=2.4353, mse=2.4280, time=0.0412\n",
      "Iter=2400, loss=2.5677, mse=2.5605, time=0.0411\n",
      "Iter=2600, loss=2.4580, mse=2.4504, time=0.0411\n",
      "Iter=2800, loss=2.5202, mse=2.5125, time=0.0411\n",
      "Iter=3000, loss=2.4865, mse=2.4792, time=0.0411\n",
      "Iter=3200, loss=2.4826, mse=2.4748, time=0.0411\n",
      "Iter=3400, loss=2.4694, mse=2.4616, time=0.0411\n",
      "Iter=3600, loss=2.5078, mse=2.5003, time=0.0411\n",
      "Iter=3800, loss=2.4388, mse=2.4312, time=0.0411\n",
      "Iter=4000, loss=2.5836, mse=2.5762, time=0.0410\n",
      "Iter=4200, loss=2.5489, mse=2.5416, time=0.0410\n",
      "Iter=4400, loss=2.5375, mse=2.5305, time=0.0410\n",
      "Iter=4600, loss=2.4334, mse=2.4264, time=0.0410\n",
      "Iter=4800, loss=2.4089, mse=2.4024, time=0.0410\n",
      "Iter=5000, loss=2.5176, mse=2.5110, time=0.0410\n",
      "Iter=5200, loss=2.5145, mse=2.5078, time=0.0410\n",
      "Iter=5400, loss=2.3528, mse=2.3457, time=0.0410\n",
      "Iter=5600, loss=2.4429, mse=2.4355, time=0.0410\n",
      "Iter=5800, loss=2.5330, mse=2.5258, time=0.0410\n",
      "Iter=6000, loss=2.5246, mse=2.5173, time=0.0410\n",
      "Iter=6200, loss=2.3815, mse=2.3743, time=0.0410\n",
      "Iter=6400, loss=2.4685, mse=2.4611, time=0.0410\n",
      "Iter=6600, loss=2.5031, mse=2.4958, time=0.0410\n",
      "=== Epoch 46, train loss 2.487153, test rmse 0.805566 ===\n",
      "Epoch 47\n",
      "Iter=200, loss=2.4264, mse=2.4186, time=0.0447\n",
      "Iter=400, loss=2.5308, mse=2.5236, time=0.0441\n",
      "Iter=600, loss=2.4553, mse=2.4482, time=0.0438\n",
      "Iter=800, loss=2.4538, mse=2.4468, time=0.0435\n",
      "Iter=1000, loss=2.5402, mse=2.5336, time=0.0433\n",
      "Iter=1200, loss=2.5416, mse=2.5345, time=0.0433\n",
      "Iter=1400, loss=2.5234, mse=2.5161, time=0.0432\n",
      "Iter=1600, loss=2.5286, mse=2.5211, time=0.0433\n",
      "Iter=1800, loss=2.4983, mse=2.4909, time=0.0433\n",
      "Iter=2000, loss=2.4535, mse=2.4463, time=0.0433\n",
      "Iter=2200, loss=2.4891, mse=2.4821, time=0.0433\n",
      "Iter=2400, loss=2.4338, mse=2.4270, time=0.0433\n",
      "Iter=2600, loss=2.4102, mse=2.4033, time=0.0433\n",
      "Iter=2800, loss=2.4790, mse=2.4720, time=0.0432\n",
      "Iter=3000, loss=2.5028, mse=2.4958, time=0.0432\n",
      "Iter=3200, loss=2.4583, mse=2.4503, time=0.0432\n",
      "Iter=3400, loss=2.4997, mse=2.4924, time=0.0432\n",
      "Iter=3600, loss=2.5158, mse=2.5078, time=0.0432\n",
      "Iter=3800, loss=2.5650, mse=2.5571, time=0.0431\n",
      "Iter=4000, loss=2.4880, mse=2.4801, time=0.0431\n",
      "Iter=4200, loss=2.5215, mse=2.5134, time=0.0431\n",
      "Iter=4400, loss=2.5173, mse=2.5094, time=0.0431\n",
      "Iter=4600, loss=2.5471, mse=2.5391, time=0.0431\n",
      "Iter=4800, loss=2.5208, mse=2.5133, time=0.0430\n",
      "Iter=5000, loss=2.4363, mse=2.4290, time=0.0430\n",
      "Iter=5200, loss=2.4741, mse=2.4676, time=0.0431\n",
      "Iter=5400, loss=2.4277, mse=2.4213, time=0.0430\n",
      "Iter=5600, loss=2.4620, mse=2.4557, time=0.0430\n",
      "Iter=5800, loss=2.4508, mse=2.4443, time=0.0430\n",
      "Iter=6000, loss=2.5238, mse=2.5171, time=0.0430\n",
      "Iter=6200, loss=2.4060, mse=2.3993, time=0.0429\n",
      "Iter=6400, loss=2.5648, mse=2.5581, time=0.0429\n",
      "Iter=6600, loss=2.5045, mse=2.4979, time=0.0429\n",
      "=== Epoch 47, train loss 2.489583, test rmse 0.809094 ===\n",
      "Epoch 48\n",
      "Iter=200, loss=2.4603, mse=2.4542, time=0.0431\n",
      "Iter=400, loss=2.3892, mse=2.3830, time=0.0444\n",
      "Iter=600, loss=2.5545, mse=2.5487, time=0.0443\n",
      "Iter=800, loss=2.6610, mse=2.6552, time=0.0441\n",
      "Iter=1000, loss=2.5379, mse=2.5324, time=0.0440\n",
      "Iter=1200, loss=2.5180, mse=2.5125, time=0.0437\n",
      "Iter=1400, loss=2.4399, mse=2.4342, time=0.0437\n",
      "Iter=1600, loss=2.4405, mse=2.4349, time=0.0435\n",
      "Iter=1800, loss=2.4175, mse=2.4118, time=0.0436\n",
      "Iter=2000, loss=2.6119, mse=2.6059, time=0.0435\n",
      "Iter=2200, loss=2.4542, mse=2.4480, time=0.0434\n",
      "Iter=2400, loss=2.4601, mse=2.4541, time=0.0434\n",
      "Iter=2600, loss=2.5257, mse=2.5200, time=0.0433\n",
      "Iter=2800, loss=2.4451, mse=2.4392, time=0.0433\n",
      "Iter=3000, loss=2.4724, mse=2.4668, time=0.0433\n",
      "Iter=3200, loss=2.4235, mse=2.4179, time=0.0433\n",
      "Iter=3400, loss=2.5147, mse=2.5091, time=0.0434\n",
      "Iter=3600, loss=2.5314, mse=2.5261, time=0.0434\n",
      "Iter=3800, loss=2.4938, mse=2.4889, time=0.0434\n",
      "Iter=4000, loss=2.5160, mse=2.5112, time=0.0434\n",
      "Iter=4200, loss=2.5858, mse=2.5804, time=0.0434\n",
      "Iter=4400, loss=2.4863, mse=2.4807, time=0.0433\n",
      "Iter=4600, loss=2.4284, mse=2.4230, time=0.0433\n",
      "Iter=4800, loss=2.4909, mse=2.4854, time=0.0434\n",
      "Iter=5000, loss=2.4958, mse=2.4900, time=0.0433\n",
      "Iter=5200, loss=2.4778, mse=2.4718, time=0.0432\n",
      "Iter=5400, loss=2.4047, mse=2.3986, time=0.0431\n",
      "Iter=5600, loss=2.4696, mse=2.4631, time=0.0430\n",
      "Iter=5800, loss=2.4749, mse=2.4685, time=0.0430\n",
      "Iter=6000, loss=2.5884, mse=2.5822, time=0.0429\n",
      "Iter=6200, loss=2.5079, mse=2.5020, time=0.0428\n",
      "Iter=6400, loss=2.4198, mse=2.4137, time=0.0428\n",
      "Iter=6600, loss=2.4526, mse=2.4456, time=0.0427\n",
      "=== Epoch 48, train loss 2.487473, test rmse 0.802288 ===\n",
      "Epoch 49\n",
      "Iter=200, loss=2.4749, mse=2.4683, time=0.0424\n",
      "Iter=400, loss=2.4482, mse=2.4411, time=0.0415\n",
      "Iter=600, loss=2.5145, mse=2.5072, time=0.0414\n",
      "Iter=800, loss=2.5625, mse=2.5550, time=0.0413\n",
      "Iter=1000, loss=2.5335, mse=2.5260, time=0.0413\n",
      "Iter=1200, loss=2.5481, mse=2.5407, time=0.0411\n",
      "Iter=1400, loss=2.4899, mse=2.4823, time=0.0412\n",
      "Iter=1600, loss=2.4226, mse=2.4149, time=0.0412\n",
      "Iter=1800, loss=2.5414, mse=2.5336, time=0.0412\n",
      "Iter=2000, loss=2.5463, mse=2.5388, time=0.0411\n",
      "Iter=2200, loss=2.5146, mse=2.5075, time=0.0411\n",
      "Iter=2400, loss=2.4341, mse=2.4273, time=0.0411\n",
      "Iter=2600, loss=2.4855, mse=2.4788, time=0.0411\n",
      "Iter=2800, loss=2.4028, mse=2.3960, time=0.0411\n",
      "Iter=3000, loss=2.4657, mse=2.4588, time=0.0411\n",
      "Iter=3200, loss=2.5053, mse=2.4980, time=0.0411\n",
      "Iter=3400, loss=2.4792, mse=2.4719, time=0.0411\n",
      "Iter=3600, loss=2.5806, mse=2.5738, time=0.0411\n",
      "Iter=3800, loss=2.4609, mse=2.4540, time=0.0411\n",
      "Iter=4000, loss=2.4483, mse=2.4406, time=0.0411\n",
      "Iter=4200, loss=2.4348, mse=2.4267, time=0.0410\n",
      "Iter=4400, loss=2.4578, mse=2.4505, time=0.0410\n",
      "Iter=4600, loss=2.5041, mse=2.4969, time=0.0410\n",
      "Iter=4800, loss=2.5273, mse=2.5206, time=0.0410\n",
      "Iter=5000, loss=2.5185, mse=2.5117, time=0.0410\n",
      "Iter=5200, loss=2.4545, mse=2.4481, time=0.0410\n",
      "Iter=5400, loss=2.4219, mse=2.4156, time=0.0410\n",
      "Iter=5600, loss=2.4245, mse=2.4177, time=0.0409\n",
      "Iter=5800, loss=2.4968, mse=2.4900, time=0.0410\n",
      "Iter=6000, loss=2.4153, mse=2.4084, time=0.0409\n",
      "Iter=6200, loss=2.5023, mse=2.4956, time=0.0409\n",
      "Iter=6400, loss=2.6053, mse=2.5991, time=0.0409\n",
      "Iter=6600, loss=2.5269, mse=2.5207, time=0.0410\n",
      "=== Epoch 49, train loss 2.490396, test rmse 0.807377 ===\n",
      "Epoch 50\n",
      "Iter=200, loss=2.4926, mse=2.4868, time=0.0422\n",
      "Iter=400, loss=2.5126, mse=2.5064, time=0.0416\n",
      "Iter=600, loss=2.4654, mse=2.4589, time=0.0415\n",
      "Iter=800, loss=2.4760, mse=2.4698, time=0.0414\n",
      "Iter=1000, loss=2.4725, mse=2.4661, time=0.0412\n",
      "Iter=1200, loss=2.5176, mse=2.5108, time=0.0412\n",
      "Iter=1400, loss=2.3880, mse=2.3810, time=0.0411\n",
      "Iter=1600, loss=2.4326, mse=2.4257, time=0.0412\n",
      "Iter=1800, loss=2.4875, mse=2.4810, time=0.0411\n",
      "Iter=2000, loss=2.4870, mse=2.4805, time=0.0412\n",
      "Iter=2200, loss=2.5271, mse=2.5203, time=0.0411\n",
      "Iter=2400, loss=2.5474, mse=2.5402, time=0.0411\n",
      "Iter=2600, loss=2.4783, mse=2.4716, time=0.0411\n",
      "Iter=2800, loss=2.5696, mse=2.5632, time=0.0410\n",
      "Iter=3000, loss=2.4997, mse=2.4932, time=0.0411\n",
      "Iter=3200, loss=2.4733, mse=2.4666, time=0.0411\n",
      "Iter=3400, loss=2.4135, mse=2.4064, time=0.0411\n",
      "Iter=3600, loss=2.4838, mse=2.4760, time=0.0411\n",
      "Iter=3800, loss=2.4742, mse=2.4666, time=0.0411\n",
      "Iter=4000, loss=2.6413, mse=2.6341, time=0.0410\n",
      "Iter=4200, loss=2.3882, mse=2.3809, time=0.0410\n",
      "Iter=4400, loss=2.4867, mse=2.4796, time=0.0410\n",
      "Iter=4600, loss=2.4706, mse=2.4635, time=0.0410\n",
      "Iter=4800, loss=2.4936, mse=2.4864, time=0.0410\n",
      "Iter=5000, loss=2.4927, mse=2.4855, time=0.0409\n",
      "Iter=5200, loss=2.5462, mse=2.5387, time=0.0409\n",
      "Iter=5400, loss=2.5612, mse=2.5539, time=0.0409\n",
      "Iter=5600, loss=2.4981, mse=2.4908, time=0.0409\n",
      "Iter=5800, loss=2.4567, mse=2.4490, time=0.0409\n",
      "Iter=6000, loss=2.5223, mse=2.5143, time=0.0409\n",
      "Iter=6200, loss=2.5263, mse=2.5183, time=0.0409\n",
      "Iter=6400, loss=2.5023, mse=2.4948, time=0.0409\n",
      "Iter=6600, loss=2.4574, mse=2.4501, time=0.0409\n",
      "=== Epoch 50, train loss 2.491286, test rmse 0.801885 ===\n",
      "Epoch 51\n",
      "Iter=200, loss=2.5134, mse=2.5065, time=0.0427\n",
      "Iter=400, loss=2.4695, mse=2.4623, time=0.0416\n",
      "Iter=600, loss=2.4419, mse=2.4347, time=0.0417\n",
      "Iter=800, loss=2.5251, mse=2.5186, time=0.0414\n",
      "Iter=1000, loss=2.5029, mse=2.4960, time=0.0414\n",
      "Iter=1200, loss=2.4436, mse=2.4369, time=0.0415\n",
      "Iter=1400, loss=2.5264, mse=2.5196, time=0.0414\n",
      "Iter=1600, loss=2.4585, mse=2.4514, time=0.0413\n",
      "Iter=1800, loss=2.5461, mse=2.5384, time=0.0413\n",
      "Iter=2000, loss=2.4449, mse=2.4374, time=0.0413\n",
      "Iter=2200, loss=2.4096, mse=2.4022, time=0.0413\n",
      "Iter=2400, loss=2.5051, mse=2.4975, time=0.0412\n",
      "Iter=2600, loss=2.4640, mse=2.4566, time=0.0412\n",
      "Iter=2800, loss=2.5984, mse=2.5909, time=0.0412\n",
      "Iter=3000, loss=2.5442, mse=2.5361, time=0.0412\n",
      "Iter=3200, loss=2.4490, mse=2.4398, time=0.0412\n",
      "Iter=3400, loss=2.4589, mse=2.4503, time=0.0411\n",
      "Iter=3600, loss=2.5216, mse=2.5134, time=0.0412\n",
      "Iter=3800, loss=2.5076, mse=2.4999, time=0.0412\n",
      "Iter=4000, loss=2.4897, mse=2.4822, time=0.0412\n",
      "Iter=4200, loss=2.4905, mse=2.4827, time=0.0411\n",
      "Iter=4400, loss=2.5434, mse=2.5348, time=0.0411\n",
      "Iter=4600, loss=2.4387, mse=2.4304, time=0.0411\n",
      "Iter=4800, loss=2.5430, mse=2.5348, time=0.0411\n",
      "Iter=5000, loss=2.4339, mse=2.4260, time=0.0411\n",
      "Iter=5200, loss=2.5095, mse=2.5017, time=0.0412\n",
      "Iter=5400, loss=2.5627, mse=2.5543, time=0.0413\n",
      "Iter=5600, loss=2.5026, mse=2.4944, time=0.0413\n",
      "Iter=5800, loss=2.5061, mse=2.4982, time=0.0413\n",
      "Iter=6000, loss=2.6017, mse=2.5943, time=0.0413\n",
      "Iter=6200, loss=2.4087, mse=2.4012, time=0.0413\n",
      "Iter=6400, loss=2.4950, mse=2.4876, time=0.0413\n",
      "Iter=6600, loss=2.4099, mse=2.4027, time=0.0413\n",
      "=== Epoch 51, train loss 2.491851, test rmse 0.805461 ===\n",
      "Epoch 52\n",
      "Iter=200, loss=2.4622, mse=2.4549, time=0.0412\n",
      "Iter=400, loss=2.5345, mse=2.5274, time=0.0408\n",
      "Iter=600, loss=2.4538, mse=2.4465, time=0.0408\n",
      "Iter=800, loss=2.4506, mse=2.4432, time=0.0410\n",
      "Iter=1000, loss=2.3806, mse=2.3730, time=0.0409\n",
      "Iter=1200, loss=2.5310, mse=2.5237, time=0.0410\n",
      "Iter=1400, loss=2.5221, mse=2.5146, time=0.0410\n",
      "Iter=1600, loss=2.5356, mse=2.5276, time=0.0410\n",
      "Iter=1800, loss=2.4133, mse=2.4052, time=0.0410\n",
      "Iter=2000, loss=2.4735, mse=2.4648, time=0.0410\n",
      "Iter=2200, loss=2.5652, mse=2.5562, time=0.0410\n",
      "Iter=2400, loss=2.4427, mse=2.4339, time=0.0410\n",
      "Iter=2600, loss=2.5510, mse=2.5431, time=0.0410\n",
      "Iter=2800, loss=2.5929, mse=2.5847, time=0.0410\n",
      "Iter=3000, loss=2.5285, mse=2.5209, time=0.0410\n",
      "Iter=3200, loss=2.4792, mse=2.4718, time=0.0409\n",
      "Iter=3400, loss=2.5268, mse=2.5195, time=0.0409\n",
      "Iter=3600, loss=2.4782, mse=2.4707, time=0.0409\n",
      "Iter=3800, loss=2.4906, mse=2.4831, time=0.0409\n",
      "Iter=4000, loss=2.4327, mse=2.4250, time=0.0409\n",
      "Iter=4200, loss=2.5316, mse=2.5233, time=0.0409\n",
      "Iter=4400, loss=2.4377, mse=2.4297, time=0.0408\n",
      "Iter=4600, loss=2.5160, mse=2.5087, time=0.0408\n",
      "Iter=4800, loss=2.4785, mse=2.4712, time=0.0408\n",
      "Iter=5000, loss=2.4646, mse=2.4567, time=0.0408\n",
      "Iter=5200, loss=2.4116, mse=2.4039, time=0.0408\n",
      "Iter=5400, loss=2.5144, mse=2.5070, time=0.0408\n",
      "Iter=5600, loss=2.5042, mse=2.4967, time=0.0408\n",
      "Iter=5800, loss=2.4456, mse=2.4377, time=0.0408\n",
      "Iter=6000, loss=2.4983, mse=2.4888, time=0.0408\n",
      "Iter=6200, loss=2.5243, mse=2.5161, time=0.0408\n",
      "Iter=6400, loss=2.5182, mse=2.5103, time=0.0408\n",
      "Iter=6600, loss=2.4549, mse=2.4473, time=0.0408\n",
      "=== Epoch 52, train loss 2.491172, test rmse 0.802041 ===\n",
      "Epoch 53\n",
      "Iter=200, loss=2.4898, mse=2.4827, time=0.0423\n",
      "Iter=400, loss=2.4852, mse=2.4779, time=0.0415\n",
      "Iter=600, loss=2.4368, mse=2.4294, time=0.0415\n",
      "Iter=800, loss=2.4956, mse=2.4880, time=0.0412\n",
      "Iter=1000, loss=2.4447, mse=2.4368, time=0.0412\n",
      "Iter=1200, loss=2.4413, mse=2.4330, time=0.0411\n",
      "Iter=1400, loss=2.4799, mse=2.4716, time=0.0412\n",
      "Iter=1600, loss=2.5050, mse=2.4971, time=0.0413\n",
      "Iter=1800, loss=2.3936, mse=2.3855, time=0.0412\n",
      "Iter=2000, loss=2.4201, mse=2.4117, time=0.0412\n",
      "Iter=2200, loss=2.4886, mse=2.4803, time=0.0412\n",
      "Iter=2400, loss=2.5275, mse=2.5200, time=0.0412\n",
      "Iter=2600, loss=2.4869, mse=2.4794, time=0.0412\n",
      "Iter=2800, loss=2.5691, mse=2.5610, time=0.0412\n",
      "Iter=3000, loss=2.5740, mse=2.5660, time=0.0411\n",
      "Iter=3200, loss=2.5263, mse=2.5183, time=0.0411\n",
      "Iter=3400, loss=2.5778, mse=2.5694, time=0.0411\n",
      "Iter=3600, loss=2.4855, mse=2.4779, time=0.0411\n",
      "Iter=3800, loss=2.4833, mse=2.4751, time=0.0411\n",
      "Iter=4000, loss=2.4447, mse=2.4364, time=0.0411\n",
      "Iter=4200, loss=2.4760, mse=2.4677, time=0.0411\n",
      "Iter=4400, loss=2.4925, mse=2.4846, time=0.0411\n",
      "Iter=4600, loss=2.4586, mse=2.4506, time=0.0411\n",
      "Iter=4800, loss=2.5134, mse=2.5057, time=0.0411\n",
      "Iter=5000, loss=2.5307, mse=2.5234, time=0.0411\n",
      "Iter=5200, loss=2.4851, mse=2.4779, time=0.0411\n",
      "Iter=5400, loss=2.5057, mse=2.4981, time=0.0411\n",
      "Iter=5600, loss=2.5073, mse=2.4994, time=0.0411\n",
      "Iter=5800, loss=2.4663, mse=2.4586, time=0.0411\n",
      "Iter=6000, loss=2.4584, mse=2.4505, time=0.0411\n",
      "Iter=6200, loss=2.6060, mse=2.5981, time=0.0411\n",
      "Iter=6400, loss=2.4428, mse=2.4353, time=0.0411\n",
      "Iter=6600, loss=2.4223, mse=2.4144, time=0.0411\n",
      "=== Epoch 53, train loss 2.486922, test rmse 0.812823 ===\n",
      "Epoch 54\n",
      "Iter=200, loss=2.4666, mse=2.4589, time=0.0428\n",
      "Iter=400, loss=2.5458, mse=2.5376, time=0.0420\n",
      "Iter=600, loss=2.5446, mse=2.5361, time=0.0418\n",
      "Iter=800, loss=2.5874, mse=2.5793, time=0.0416\n",
      "Iter=1000, loss=2.4323, mse=2.4244, time=0.0414\n",
      "Iter=1200, loss=2.4038, mse=2.3957, time=0.0415\n",
      "Iter=1400, loss=2.5508, mse=2.5429, time=0.0414\n",
      "Iter=1600, loss=2.5504, mse=2.5430, time=0.0414\n",
      "Iter=1800, loss=2.5231, mse=2.5159, time=0.0414\n",
      "Iter=2000, loss=2.4083, mse=2.4011, time=0.0414\n",
      "Iter=2200, loss=2.4721, mse=2.4647, time=0.0414\n",
      "Iter=2400, loss=2.4245, mse=2.4168, time=0.0414\n",
      "Iter=2600, loss=2.4208, mse=2.4132, time=0.0414\n",
      "Iter=2800, loss=2.5149, mse=2.5073, time=0.0414\n",
      "Iter=3000, loss=2.5306, mse=2.5231, time=0.0414\n",
      "Iter=3200, loss=2.4543, mse=2.4469, time=0.0413\n",
      "Iter=3400, loss=2.5454, mse=2.5384, time=0.0413\n",
      "Iter=3600, loss=2.4927, mse=2.4851, time=0.0413\n",
      "Iter=3800, loss=2.5434, mse=2.5357, time=0.0413\n",
      "Iter=4000, loss=2.5303, mse=2.5229, time=0.0412\n",
      "Iter=4200, loss=2.4197, mse=2.4128, time=0.0412\n",
      "Iter=4400, loss=2.4859, mse=2.4787, time=0.0412\n",
      "Iter=4600, loss=2.4422, mse=2.4346, time=0.0412\n",
      "Iter=4800, loss=2.5432, mse=2.5360, time=0.0412\n",
      "Iter=5000, loss=2.4750, mse=2.4680, time=0.0412\n",
      "Iter=5200, loss=2.4702, mse=2.4631, time=0.0412\n",
      "Iter=5400, loss=2.5388, mse=2.5320, time=0.0412\n",
      "Iter=5600, loss=2.5140, mse=2.5073, time=0.0411\n",
      "Iter=5800, loss=2.5430, mse=2.5357, time=0.0411\n",
      "Iter=6000, loss=2.3843, mse=2.3770, time=0.0411\n",
      "Iter=6200, loss=2.5202, mse=2.5129, time=0.0411\n",
      "Iter=6400, loss=2.5299, mse=2.5223, time=0.0411\n",
      "Iter=6600, loss=2.4806, mse=2.4719, time=0.0411\n",
      "=== Epoch 54, train loss 2.493808, test rmse 0.800585 ===\n",
      "Epoch 55\n",
      "Iter=200, loss=2.5153, mse=2.5070, time=0.0423\n",
      "Iter=400, loss=2.4958, mse=2.4875, time=0.0415\n",
      "Iter=600, loss=2.5536, mse=2.5449, time=0.0413\n",
      "Iter=800, loss=2.4771, mse=2.4687, time=0.0415\n",
      "Iter=1000, loss=2.5690, mse=2.5603, time=0.0423\n",
      "Iter=1200, loss=2.5015, mse=2.4930, time=0.0430\n",
      "Iter=1400, loss=2.5249, mse=2.5167, time=0.0448\n",
      "Iter=1600, loss=2.4894, mse=2.4809, time=0.0453\n",
      "Iter=1800, loss=2.4723, mse=2.4637, time=0.0449\n",
      "Iter=2000, loss=2.5044, mse=2.4960, time=0.0445\n",
      "Iter=2200, loss=2.4612, mse=2.4522, time=0.0442\n",
      "Iter=2400, loss=2.3982, mse=2.3888, time=0.0440\n",
      "Iter=2600, loss=2.5061, mse=2.4976, time=0.0437\n",
      "Iter=2800, loss=2.4011, mse=2.3929, time=0.0436\n",
      "Iter=3000, loss=2.5006, mse=2.4922, time=0.0434\n",
      "Iter=3200, loss=2.4925, mse=2.4836, time=0.0432\n",
      "Iter=3400, loss=2.5174, mse=2.5089, time=0.0431\n",
      "Iter=3600, loss=2.4610, mse=2.4526, time=0.0430\n",
      "Iter=3800, loss=2.5113, mse=2.5029, time=0.0429\n",
      "Iter=4000, loss=2.3992, mse=2.3910, time=0.0428\n",
      "Iter=4200, loss=2.4645, mse=2.4563, time=0.0428\n",
      "Iter=4400, loss=2.4865, mse=2.4785, time=0.0427\n",
      "Iter=4600, loss=2.4447, mse=2.4367, time=0.0426\n",
      "Iter=4800, loss=2.4146, mse=2.4069, time=0.0426\n",
      "Iter=5000, loss=2.5175, mse=2.5098, time=0.0425\n",
      "Iter=5200, loss=2.6037, mse=2.5961, time=0.0424\n",
      "Iter=5400, loss=2.5492, mse=2.5417, time=0.0424\n",
      "Iter=5600, loss=2.4599, mse=2.4524, time=0.0423\n",
      "Iter=5800, loss=2.5292, mse=2.5212, time=0.0423\n",
      "Iter=6000, loss=2.5191, mse=2.5117, time=0.0423\n",
      "Iter=6200, loss=2.5161, mse=2.5087, time=0.0422\n",
      "Iter=6400, loss=2.5036, mse=2.4955, time=0.0422\n",
      "Iter=6600, loss=2.5300, mse=2.5219, time=0.0421\n",
      "=== Epoch 55, train loss 2.493338, test rmse 0.801752 ===\n",
      "Epoch 56\n",
      "Iter=200, loss=2.5068, mse=2.4993, time=0.0458\n",
      "Iter=400, loss=2.4994, mse=2.4917, time=0.0436\n",
      "Iter=600, loss=2.4583, mse=2.4505, time=0.0427\n",
      "Iter=800, loss=2.4718, mse=2.4642, time=0.0422\n",
      "Iter=1000, loss=2.4977, mse=2.4900, time=0.0421\n",
      "Iter=1200, loss=2.4973, mse=2.4888, time=0.0420\n",
      "Iter=1400, loss=2.4940, mse=2.4853, time=0.0418\n",
      "Iter=1600, loss=2.4971, mse=2.4877, time=0.0417\n",
      "Iter=1800, loss=2.4956, mse=2.4861, time=0.0416\n",
      "Iter=2000, loss=2.4382, mse=2.4292, time=0.0416\n",
      "Iter=2200, loss=2.4636, mse=2.4544, time=0.0415\n",
      "Iter=2400, loss=2.4076, mse=2.3985, time=0.0415\n",
      "Iter=2600, loss=2.5187, mse=2.5095, time=0.0414\n",
      "Iter=2800, loss=2.4249, mse=2.4145, time=0.0414\n",
      "Iter=3000, loss=2.4726, mse=2.4628, time=0.0414\n",
      "Iter=3200, loss=2.5296, mse=2.5208, time=0.0414\n",
      "Iter=3400, loss=2.5142, mse=2.5054, time=0.0413\n",
      "Iter=3600, loss=2.5000, mse=2.4911, time=0.0413\n",
      "Iter=3800, loss=2.4077, mse=2.3992, time=0.0413\n",
      "Iter=4000, loss=2.4837, mse=2.4743, time=0.0413\n",
      "Iter=4200, loss=2.6121, mse=2.6023, time=0.0413\n",
      "Iter=4400, loss=2.5343, mse=2.5250, time=0.0413\n",
      "Iter=4600, loss=2.5394, mse=2.5301, time=0.0413\n",
      "Iter=4800, loss=2.4990, mse=2.4901, time=0.0412\n",
      "Iter=5000, loss=2.4816, mse=2.4725, time=0.0412\n",
      "Iter=5200, loss=2.4743, mse=2.4652, time=0.0412\n",
      "Iter=5400, loss=2.4147, mse=2.4061, time=0.0412\n",
      "Iter=5600, loss=2.5493, mse=2.5402, time=0.0412\n",
      "Iter=5800, loss=2.5908, mse=2.5823, time=0.0412\n",
      "Iter=6000, loss=2.5368, mse=2.5288, time=0.0412\n",
      "Iter=6200, loss=2.4753, mse=2.4672, time=0.0411\n",
      "Iter=6400, loss=2.4779, mse=2.4698, time=0.0411\n",
      "Iter=6600, loss=2.4821, mse=2.4741, time=0.0411\n",
      "=== Epoch 56, train loss 2.489604, test rmse 0.803090 ===\n",
      "Epoch 57\n",
      "Iter=200, loss=2.4207, mse=2.4124, time=0.0419\n",
      "Iter=400, loss=2.4786, mse=2.4708, time=0.0416\n",
      "Iter=600, loss=2.4527, mse=2.4452, time=0.0414\n",
      "Iter=800, loss=2.5932, mse=2.5853, time=0.0413\n",
      "Iter=1000, loss=2.4624, mse=2.4549, time=0.0412\n",
      "Iter=1200, loss=2.5689, mse=2.5612, time=0.0411\n",
      "Iter=1400, loss=2.4212, mse=2.4127, time=0.0410\n",
      "Iter=1600, loss=2.5103, mse=2.5024, time=0.0409\n",
      "Iter=1800, loss=2.4729, mse=2.4650, time=0.0410\n",
      "Iter=2000, loss=2.4794, mse=2.4716, time=0.0410\n",
      "Iter=2200, loss=2.5883, mse=2.5808, time=0.0410\n",
      "Iter=2400, loss=2.5354, mse=2.5277, time=0.0409\n",
      "Iter=2600, loss=2.4983, mse=2.4905, time=0.0409\n",
      "Iter=2800, loss=2.4164, mse=2.4087, time=0.0409\n",
      "Iter=3000, loss=2.5494, mse=2.5420, time=0.0409\n",
      "Iter=3200, loss=2.4018, mse=2.3944, time=0.0409\n",
      "Iter=3400, loss=2.4928, mse=2.4852, time=0.0409\n",
      "Iter=3600, loss=2.3855, mse=2.3777, time=0.0409\n",
      "Iter=3800, loss=2.5293, mse=2.5214, time=0.0409\n",
      "Iter=4000, loss=2.5147, mse=2.5069, time=0.0409\n",
      "Iter=4200, loss=2.5902, mse=2.5821, time=0.0409\n",
      "Iter=4400, loss=2.5280, mse=2.5199, time=0.0408\n",
      "Iter=4600, loss=2.5166, mse=2.5085, time=0.0408\n",
      "Iter=4800, loss=2.4804, mse=2.4725, time=0.0408\n",
      "Iter=5000, loss=2.4392, mse=2.4318, time=0.0409\n",
      "Iter=5200, loss=2.5780, mse=2.5706, time=0.0409\n",
      "Iter=5400, loss=2.5812, mse=2.5738, time=0.0409\n",
      "Iter=5600, loss=2.4384, mse=2.4311, time=0.0409\n",
      "Iter=5800, loss=2.4214, mse=2.4140, time=0.0408\n",
      "Iter=6000, loss=2.3980, mse=2.3905, time=0.0409\n",
      "Iter=6200, loss=2.4975, mse=2.4896, time=0.0409\n",
      "Iter=6400, loss=2.4635, mse=2.4555, time=0.0409\n",
      "Iter=6600, loss=2.5138, mse=2.5054, time=0.0409\n",
      "=== Epoch 57, train loss 2.490956, test rmse 0.803551 ===\n",
      "Epoch 58\n",
      "Iter=200, loss=2.5571, mse=2.5492, time=0.0426\n",
      "Iter=400, loss=2.5446, mse=2.5372, time=0.0417\n",
      "Iter=600, loss=2.4907, mse=2.4819, time=0.0416\n",
      "Iter=800, loss=2.4979, mse=2.4895, time=0.0414\n",
      "Iter=1000, loss=2.5627, mse=2.5550, time=0.0414\n",
      "Iter=1200, loss=2.5091, mse=2.5009, time=0.0413\n",
      "Iter=1400, loss=2.4949, mse=2.4865, time=0.0412\n",
      "Iter=1600, loss=2.4955, mse=2.4871, time=0.0412\n",
      "Iter=1800, loss=2.6035, mse=2.5952, time=0.0412\n",
      "Iter=2000, loss=2.4200, mse=2.4112, time=0.0412\n",
      "Iter=2200, loss=2.5029, mse=2.4948, time=0.0412\n",
      "Iter=2400, loss=2.5180, mse=2.5100, time=0.0412\n",
      "Iter=2600, loss=2.4674, mse=2.4595, time=0.0412\n",
      "Iter=2800, loss=2.5473, mse=2.5397, time=0.0412\n",
      "Iter=3000, loss=2.5351, mse=2.5274, time=0.0412\n",
      "Iter=3200, loss=2.4417, mse=2.4342, time=0.0412\n",
      "Iter=3400, loss=2.5262, mse=2.5185, time=0.0411\n",
      "Iter=3600, loss=2.4761, mse=2.4678, time=0.0412\n",
      "Iter=3800, loss=2.5344, mse=2.5260, time=0.0411\n",
      "Iter=4000, loss=2.5318, mse=2.5238, time=0.0412\n",
      "Iter=4200, loss=2.4685, mse=2.4607, time=0.0412\n",
      "Iter=4400, loss=2.4455, mse=2.4365, time=0.0411\n",
      "Iter=4600, loss=2.4760, mse=2.4671, time=0.0411\n",
      "Iter=4800, loss=2.4779, mse=2.4699, time=0.0411\n",
      "Iter=5000, loss=2.5134, mse=2.5054, time=0.0411\n",
      "Iter=5200, loss=2.5003, mse=2.4916, time=0.0411\n",
      "Iter=5400, loss=2.4635, mse=2.4550, time=0.0411\n",
      "Iter=5600, loss=2.3826, mse=2.3745, time=0.0411\n",
      "Iter=5800, loss=2.5113, mse=2.5035, time=0.0411\n",
      "Iter=6000, loss=2.4325, mse=2.4240, time=0.0411\n",
      "Iter=6200, loss=2.4899, mse=2.4808, time=0.0411\n",
      "Iter=6400, loss=2.4987, mse=2.4902, time=0.0411\n",
      "Iter=6600, loss=2.4416, mse=2.4333, time=0.0411\n",
      "=== Epoch 58, train loss 2.496454, test rmse 0.802178 ===\n",
      "Epoch 59\n",
      "Iter=200, loss=2.4549, mse=2.4463, time=0.0416\n",
      "Iter=400, loss=2.4819, mse=2.4731, time=0.0414\n",
      "Iter=600, loss=2.5491, mse=2.5407, time=0.0409\n",
      "Iter=800, loss=2.4870, mse=2.4786, time=0.0409\n",
      "Iter=1000, loss=2.5048, mse=2.4963, time=0.0407\n",
      "Iter=1200, loss=2.4839, mse=2.4752, time=0.0414\n",
      "Iter=1400, loss=2.4130, mse=2.4046, time=0.0413\n",
      "Iter=1600, loss=2.5338, mse=2.5251, time=0.0412\n",
      "Iter=1800, loss=2.4607, mse=2.4518, time=0.0412\n",
      "Iter=2000, loss=2.4760, mse=2.4675, time=0.0411\n",
      "Iter=2200, loss=2.5282, mse=2.5198, time=0.0410\n",
      "Iter=2400, loss=2.5737, mse=2.5650, time=0.0410\n",
      "Iter=2600, loss=2.5636, mse=2.5541, time=0.0410\n",
      "Iter=2800, loss=2.4556, mse=2.4469, time=0.0410\n",
      "Iter=3000, loss=2.5215, mse=2.5128, time=0.0410\n",
      "Iter=3200, loss=2.5747, mse=2.5664, time=0.0410\n",
      "Iter=3400, loss=2.5067, mse=2.4987, time=0.0410\n",
      "Iter=3600, loss=2.4956, mse=2.4878, time=0.0410\n",
      "Iter=3800, loss=2.5648, mse=2.5565, time=0.0410\n",
      "Iter=4000, loss=2.4874, mse=2.4787, time=0.0410\n",
      "Iter=4200, loss=2.5271, mse=2.5179, time=0.0409\n",
      "Iter=4400, loss=2.4646, mse=2.4555, time=0.0410\n",
      "Iter=4600, loss=2.4475, mse=2.4387, time=0.0409\n",
      "Iter=4800, loss=2.5356, mse=2.5259, time=0.0409\n",
      "Iter=5000, loss=2.4221, mse=2.4121, time=0.0409\n",
      "Iter=5200, loss=2.4594, mse=2.4496, time=0.0409\n",
      "Iter=5400, loss=2.5535, mse=2.5439, time=0.0409\n",
      "Iter=5600, loss=2.4707, mse=2.4613, time=0.0409\n",
      "Iter=5800, loss=2.4718, mse=2.4630, time=0.0409\n",
      "Iter=6000, loss=2.4330, mse=2.4236, time=0.0409\n",
      "Iter=6200, loss=2.5031, mse=2.4940, time=0.0408\n",
      "Iter=6400, loss=2.4978, mse=2.4891, time=0.0408\n",
      "Iter=6600, loss=2.5736, mse=2.5647, time=0.0408\n",
      "=== Epoch 59, train loss 2.498058, test rmse 0.810126 ===\n",
      "Epoch 60\n",
      "Iter=200, loss=2.4522, mse=2.4434, time=0.0421\n",
      "Iter=400, loss=2.5263, mse=2.5178, time=0.0415\n",
      "Iter=600, loss=2.5126, mse=2.5045, time=0.0413\n",
      "Iter=800, loss=2.4525, mse=2.4444, time=0.0411\n",
      "Iter=1000, loss=2.5420, mse=2.5338, time=0.0410\n",
      "Iter=1200, loss=2.5467, mse=2.5389, time=0.0409\n",
      "Iter=1400, loss=2.4480, mse=2.4399, time=0.0409\n",
      "Iter=1600, loss=2.5078, mse=2.4991, time=0.0408\n",
      "Iter=1800, loss=2.5264, mse=2.5175, time=0.0408\n",
      "Iter=2000, loss=2.6069, mse=2.5982, time=0.0408\n",
      "Iter=2200, loss=2.5282, mse=2.5188, time=0.0408\n",
      "Iter=2400, loss=2.4586, mse=2.4492, time=0.0408\n",
      "Iter=2600, loss=2.5250, mse=2.5160, time=0.0409\n",
      "Iter=2800, loss=2.4934, mse=2.4846, time=0.0408\n",
      "Iter=3000, loss=2.5049, mse=2.4962, time=0.0408\n",
      "Iter=3200, loss=2.5401, mse=2.5318, time=0.0408\n",
      "Iter=3400, loss=2.5029, mse=2.4942, time=0.0408\n",
      "Iter=3600, loss=2.5678, mse=2.5590, time=0.0408\n",
      "Iter=3800, loss=2.4878, mse=2.4800, time=0.0408\n",
      "Iter=4000, loss=2.4800, mse=2.4730, time=0.0408\n",
      "Iter=4200, loss=2.4579, mse=2.4509, time=0.0408\n",
      "Iter=4400, loss=2.5450, mse=2.5374, time=0.0407\n",
      "Iter=4600, loss=2.4777, mse=2.4704, time=0.0407\n",
      "Iter=4800, loss=2.4676, mse=2.4608, time=0.0408\n",
      "Iter=5000, loss=2.4964, mse=2.4889, time=0.0407\n",
      "Iter=5200, loss=2.3810, mse=2.3731, time=0.0407\n",
      "Iter=5400, loss=2.4936, mse=2.4855, time=0.0407\n",
      "Iter=5600, loss=2.4864, mse=2.4779, time=0.0407\n",
      "Iter=5800, loss=2.5425, mse=2.5329, time=0.0407\n",
      "Iter=6000, loss=2.5194, mse=2.5108, time=0.0407\n",
      "Iter=6200, loss=2.4779, mse=2.4695, time=0.0407\n",
      "Iter=6400, loss=2.4522, mse=2.4438, time=0.0407\n",
      "Iter=6600, loss=2.5165, mse=2.5083, time=0.0407\n",
      "=== Epoch 60, train loss 2.501426, test rmse 0.802536 ===\n",
      "Epoch 61\n",
      "Iter=200, loss=2.4990, mse=2.4898, time=0.0417\n",
      "Iter=400, loss=2.4793, mse=2.4701, time=0.0409\n",
      "Iter=600, loss=2.5294, mse=2.5206, time=0.0411\n",
      "Iter=800, loss=2.5432, mse=2.5349, time=0.0410\n",
      "Iter=1000, loss=2.3885, mse=2.3803, time=0.0410\n",
      "Iter=1200, loss=2.5221, mse=2.5140, time=0.0415\n",
      "Iter=1400, loss=2.5357, mse=2.5273, time=0.0415\n",
      "Iter=1600, loss=2.4637, mse=2.4558, time=0.0416\n",
      "Iter=1800, loss=2.4969, mse=2.4887, time=0.0415\n",
      "Iter=2000, loss=2.4458, mse=2.4375, time=0.0414\n",
      "Iter=2200, loss=2.4673, mse=2.4587, time=0.0414\n",
      "Iter=2400, loss=2.5332, mse=2.5245, time=0.0413\n",
      "Iter=2600, loss=2.5119, mse=2.5034, time=0.0413\n",
      "Iter=2800, loss=2.4853, mse=2.4763, time=0.0413\n",
      "Iter=3000, loss=2.5173, mse=2.5075, time=0.0412\n",
      "Iter=3200, loss=2.5580, mse=2.5485, time=0.0412\n",
      "Iter=3400, loss=2.4196, mse=2.4099, time=0.0411\n",
      "Iter=3600, loss=2.4207, mse=2.4119, time=0.0411\n",
      "Iter=3800, loss=2.5527, mse=2.5441, time=0.0411\n",
      "Iter=4000, loss=2.5055, mse=2.4972, time=0.0411\n",
      "Iter=4200, loss=2.4803, mse=2.4715, time=0.0411\n",
      "Iter=4400, loss=2.5690, mse=2.5604, time=0.0410\n",
      "Iter=4600, loss=2.4732, mse=2.4644, time=0.0410\n",
      "Iter=4800, loss=2.5642, mse=2.5544, time=0.0410\n",
      "Iter=5000, loss=2.5609, mse=2.5509, time=0.0410\n",
      "Iter=5200, loss=2.5316, mse=2.5216, time=0.0409\n",
      "Iter=5400, loss=2.4507, mse=2.4417, time=0.0409\n",
      "Iter=5600, loss=2.5105, mse=2.5019, time=0.0409\n",
      "Iter=5800, loss=2.3797, mse=2.3714, time=0.0409\n",
      "Iter=6000, loss=2.4454, mse=2.4372, time=0.0409\n",
      "Iter=6200, loss=2.5165, mse=2.5074, time=0.0409\n",
      "Iter=6400, loss=2.5208, mse=2.5115, time=0.0409\n",
      "Iter=6600, loss=2.4977, mse=2.4889, time=0.0409\n",
      "=== Epoch 61, train loss 2.495543, test rmse 0.804537 ===\n",
      "Epoch 62\n",
      "Iter=200, loss=2.5253, mse=2.5166, time=0.0412\n",
      "Iter=400, loss=2.5009, mse=2.4918, time=0.0411\n",
      "Iter=600, loss=2.5329, mse=2.5241, time=0.0410\n",
      "Iter=800, loss=2.4978, mse=2.4886, time=0.0410\n",
      "Iter=1000, loss=2.5176, mse=2.5087, time=0.0409\n",
      "Iter=1200, loss=2.4658, mse=2.4570, time=0.0409\n",
      "Iter=1400, loss=2.5272, mse=2.5187, time=0.0409\n",
      "Iter=1600, loss=2.6071, mse=2.5988, time=0.0410\n",
      "Iter=1800, loss=2.5265, mse=2.5158, time=0.0409\n",
      "Iter=2000, loss=2.5105, mse=2.5004, time=0.0410\n",
      "Iter=2200, loss=2.5069, mse=2.4976, time=0.0410\n",
      "Iter=2400, loss=2.4688, mse=2.4596, time=0.0410\n",
      "Iter=2600, loss=2.5532, mse=2.5446, time=0.0410\n",
      "Iter=2800, loss=2.5565, mse=2.5485, time=0.0409\n",
      "Iter=3000, loss=2.4947, mse=2.4868, time=0.0410\n",
      "Iter=3200, loss=2.4299, mse=2.4220, time=0.0410\n",
      "Iter=3400, loss=2.3987, mse=2.3900, time=0.0410\n",
      "Iter=3600, loss=2.4249, mse=2.4162, time=0.0409\n",
      "Iter=3800, loss=2.4617, mse=2.4529, time=0.0409\n",
      "Iter=4000, loss=2.4718, mse=2.4634, time=0.0409\n",
      "Iter=4200, loss=2.4678, mse=2.4595, time=0.0409\n",
      "Iter=4400, loss=2.4483, mse=2.4401, time=0.0409\n",
      "Iter=4600, loss=2.5542, mse=2.5465, time=0.0409\n",
      "Iter=4800, loss=2.5356, mse=2.5276, time=0.0409\n",
      "Iter=5000, loss=2.5552, mse=2.5464, time=0.0409\n",
      "Iter=5200, loss=2.4750, mse=2.4673, time=0.0409\n",
      "Iter=5400, loss=2.4991, mse=2.4917, time=0.0409\n",
      "Iter=5600, loss=2.4704, mse=2.4629, time=0.0409\n",
      "Iter=5800, loss=2.4361, mse=2.4277, time=0.0409\n",
      "Iter=6000, loss=2.4693, mse=2.4611, time=0.0409\n",
      "Iter=6200, loss=2.4221, mse=2.4143, time=0.0409\n",
      "Iter=6400, loss=2.5638, mse=2.5563, time=0.0409\n",
      "Iter=6600, loss=2.4014, mse=2.3944, time=0.0409\n",
      "=== Epoch 62, train loss 2.495358, test rmse 0.805622 ===\n",
      "Epoch 63\n",
      "Iter=200, loss=2.5604, mse=2.5534, time=0.0422\n",
      "Iter=400, loss=2.5087, mse=2.5019, time=0.0413\n",
      "Iter=600, loss=2.5321, mse=2.5247, time=0.0415\n",
      "Iter=800, loss=2.4958, mse=2.4880, time=0.0412\n",
      "Iter=1000, loss=2.4916, mse=2.4837, time=0.0411\n",
      "Iter=1200, loss=2.4137, mse=2.4054, time=0.0410\n",
      "Iter=1400, loss=2.4382, mse=2.4302, time=0.0410\n",
      "Iter=1600, loss=2.5582, mse=2.5503, time=0.0410\n",
      "Iter=1800, loss=2.4402, mse=2.4326, time=0.0410\n",
      "Iter=2000, loss=2.5439, mse=2.5362, time=0.0410\n",
      "Iter=2200, loss=2.5379, mse=2.5301, time=0.0410\n",
      "Iter=2400, loss=2.4250, mse=2.4165, time=0.0410\n",
      "Iter=2600, loss=2.3902, mse=2.3821, time=0.0410\n",
      "Iter=2800, loss=2.4655, mse=2.4575, time=0.0409\n",
      "Iter=3000, loss=2.4647, mse=2.4567, time=0.0409\n",
      "Iter=3200, loss=2.4959, mse=2.4880, time=0.0409\n",
      "Iter=3400, loss=2.4169, mse=2.4095, time=0.0409\n",
      "Iter=3600, loss=2.5338, mse=2.5266, time=0.0409\n",
      "Iter=3800, loss=2.5366, mse=2.5290, time=0.0410\n",
      "Iter=4000, loss=2.4865, mse=2.4789, time=0.0410\n",
      "Iter=4200, loss=2.4910, mse=2.4831, time=0.0409\n",
      "Iter=4400, loss=2.4986, mse=2.4906, time=0.0409\n",
      "Iter=4600, loss=2.5247, mse=2.5163, time=0.0409\n",
      "Iter=4800, loss=2.4636, mse=2.4553, time=0.0409\n",
      "Iter=5000, loss=2.4684, mse=2.4603, time=0.0410\n",
      "Iter=5200, loss=2.5358, mse=2.5273, time=0.0409\n",
      "Iter=5400, loss=2.5828, mse=2.5746, time=0.0410\n",
      "Iter=5600, loss=2.5433, mse=2.5346, time=0.0410\n",
      "Iter=5800, loss=2.4354, mse=2.4265, time=0.0409\n",
      "Iter=6000, loss=2.4512, mse=2.4425, time=0.0409\n",
      "Iter=6200, loss=2.4199, mse=2.4112, time=0.0409\n",
      "Iter=6400, loss=2.5159, mse=2.5071, time=0.0409\n",
      "Iter=6600, loss=2.5787, mse=2.5701, time=0.0409\n",
      "=== Epoch 63, train loss 2.493573, test rmse 0.805484 ===\n",
      "Epoch 64\n",
      "Iter=200, loss=2.5336, mse=2.5250, time=0.0418\n",
      "Iter=400, loss=2.5638, mse=2.5547, time=0.0415\n",
      "Iter=600, loss=2.4430, mse=2.4335, time=0.0412\n",
      "Iter=800, loss=2.4809, mse=2.4718, time=0.0412\n",
      "Iter=1000, loss=2.4746, mse=2.4657, time=0.0411\n",
      "Iter=1200, loss=2.4070, mse=2.3977, time=0.0412\n",
      "Iter=1400, loss=2.4286, mse=2.4192, time=0.0411\n",
      "Iter=1600, loss=2.5198, mse=2.5101, time=0.0411\n",
      "Iter=1800, loss=2.4926, mse=2.4833, time=0.0410\n",
      "Iter=2000, loss=2.4834, mse=2.4739, time=0.0410\n",
      "Iter=2200, loss=2.5179, mse=2.5084, time=0.0409\n",
      "Iter=2400, loss=2.6107, mse=2.6012, time=0.0409\n",
      "Iter=2600, loss=2.5496, mse=2.5397, time=0.0409\n",
      "Iter=2800, loss=2.5115, mse=2.5017, time=0.0409\n",
      "Iter=3000, loss=2.4488, mse=2.4390, time=0.0409\n",
      "Iter=3200, loss=2.5517, mse=2.5420, time=0.0410\n",
      "Iter=3400, loss=2.3987, mse=2.3890, time=0.0410\n",
      "Iter=3600, loss=2.5064, mse=2.4973, time=0.0410\n",
      "Iter=3800, loss=2.4853, mse=2.4765, time=0.0410\n",
      "Iter=4000, loss=2.4704, mse=2.4607, time=0.0410\n",
      "Iter=4200, loss=2.6071, mse=2.5964, time=0.0410\n",
      "Iter=4400, loss=2.3791, mse=2.3689, time=0.0410\n",
      "Iter=4600, loss=2.4875, mse=2.4785, time=0.0410\n",
      "Iter=4800, loss=2.5054, mse=2.4966, time=0.0410\n",
      "Iter=5000, loss=2.4304, mse=2.4217, time=0.0409\n",
      "Iter=5200, loss=2.5025, mse=2.4929, time=0.0409\n",
      "Iter=5400, loss=2.4946, mse=2.4857, time=0.0409\n",
      "Iter=5600, loss=2.6103, mse=2.5996, time=0.0409\n",
      "Iter=5800, loss=2.4869, mse=2.4759, time=0.0409\n",
      "Iter=6000, loss=2.5315, mse=2.5202, time=0.0409\n",
      "Iter=6200, loss=2.5241, mse=2.5124, time=0.0409\n",
      "Iter=6400, loss=2.5397, mse=2.5296, time=0.0409\n",
      "Iter=6600, loss=2.4456, mse=2.4361, time=0.0409\n",
      "=== Epoch 64, train loss 2.498347, test rmse 0.801980 ===\n",
      "Epoch 65\n",
      "Iter=200, loss=2.4949, mse=2.4865, time=0.0426\n",
      "Iter=400, loss=2.4894, mse=2.4814, time=0.0414\n",
      "Iter=600, loss=2.4991, mse=2.4917, time=0.0413\n",
      "Iter=800, loss=2.5816, mse=2.5743, time=0.0411\n",
      "Iter=1000, loss=2.4426, mse=2.4350, time=0.0411\n",
      "Iter=1200, loss=2.4841, mse=2.4763, time=0.0410\n",
      "Iter=1400, loss=2.5327, mse=2.5246, time=0.0411\n",
      "Iter=1600, loss=2.4705, mse=2.4627, time=0.0410\n",
      "Iter=1800, loss=2.5134, mse=2.5058, time=0.0411\n",
      "Iter=2000, loss=2.3873, mse=2.3792, time=0.0411\n",
      "Iter=2200, loss=2.4658, mse=2.4576, time=0.0411\n",
      "Iter=2400, loss=2.6059, mse=2.5974, time=0.0412\n",
      "Iter=2600, loss=2.5095, mse=2.5009, time=0.0411\n",
      "Iter=2800, loss=2.4555, mse=2.4470, time=0.0411\n",
      "Iter=3000, loss=2.4650, mse=2.4570, time=0.0411\n",
      "Iter=3200, loss=2.4835, mse=2.4759, time=0.0412\n",
      "Iter=3400, loss=2.4954, mse=2.4875, time=0.0412\n",
      "Iter=3600, loss=2.4520, mse=2.4435, time=0.0412\n",
      "Iter=3800, loss=2.5181, mse=2.5095, time=0.0411\n",
      "Iter=4000, loss=2.5267, mse=2.5179, time=0.0411\n",
      "Iter=4200, loss=2.5612, mse=2.5522, time=0.0411\n",
      "Iter=4400, loss=2.4434, mse=2.4347, time=0.0411\n",
      "Iter=4600, loss=2.5673, mse=2.5588, time=0.0411\n",
      "Iter=4800, loss=2.4257, mse=2.4170, time=0.0411\n",
      "Iter=5000, loss=2.5488, mse=2.5399, time=0.0411\n",
      "Iter=5200, loss=2.5652, mse=2.5565, time=0.0411\n",
      "Iter=5400, loss=2.4089, mse=2.4006, time=0.0411\n",
      "Iter=5600, loss=2.4435, mse=2.4347, time=0.0411\n",
      "Iter=5800, loss=2.4934, mse=2.4848, time=0.0411\n",
      "Iter=6000, loss=2.5473, mse=2.5389, time=0.0410\n",
      "Iter=6200, loss=2.5562, mse=2.5477, time=0.0410\n",
      "Iter=6400, loss=2.4417, mse=2.4328, time=0.0410\n",
      "Iter=6600, loss=2.4917, mse=2.4832, time=0.0410\n",
      "=== Epoch 65, train loss 2.495872, test rmse 0.812931 ===\n",
      "Epoch 66\n",
      "Iter=200, loss=2.4831, mse=2.4746, time=0.0413\n",
      "Iter=400, loss=2.4818, mse=2.4728, time=0.0411\n",
      "Iter=600, loss=2.5420, mse=2.5329, time=0.0410\n",
      "Iter=800, loss=2.4506, mse=2.4409, time=0.0410\n",
      "Iter=1000, loss=2.4923, mse=2.4824, time=0.0410\n",
      "Iter=1200, loss=2.5236, mse=2.5135, time=0.0409\n",
      "Iter=1400, loss=2.5257, mse=2.5156, time=0.0410\n",
      "Iter=1600, loss=2.4853, mse=2.4753, time=0.0409\n",
      "Iter=1800, loss=2.5776, mse=2.5669, time=0.0409\n",
      "Iter=2000, loss=2.4827, mse=2.4723, time=0.0409\n",
      "Iter=2200, loss=2.5193, mse=2.5091, time=0.0409\n",
      "Iter=2400, loss=2.5024, mse=2.4921, time=0.0410\n",
      "Iter=2600, loss=2.4030, mse=2.3932, time=0.0410\n",
      "Iter=2800, loss=2.4143, mse=2.4044, time=0.0409\n",
      "Iter=3000, loss=2.5033, mse=2.4931, time=0.0410\n",
      "Iter=3200, loss=2.5233, mse=2.5128, time=0.0409\n",
      "Iter=3400, loss=2.4991, mse=2.4889, time=0.0409\n",
      "Iter=3600, loss=2.4582, mse=2.4476, time=0.0409\n",
      "Iter=3800, loss=2.4299, mse=2.4201, time=0.0410\n",
      "Iter=4000, loss=2.4660, mse=2.4566, time=0.0410\n",
      "Iter=4200, loss=2.5646, mse=2.5553, time=0.0410\n",
      "Iter=4400, loss=2.4821, mse=2.4726, time=0.0410\n",
      "Iter=4600, loss=2.4870, mse=2.4774, time=0.0409\n",
      "Iter=4800, loss=2.5066, mse=2.4970, time=0.0409\n",
      "Iter=5000, loss=2.4993, mse=2.4894, time=0.0410\n",
      "Iter=5200, loss=2.4732, mse=2.4628, time=0.0410\n",
      "Iter=5400, loss=2.5156, mse=2.5055, time=0.0409\n",
      "Iter=5600, loss=2.5133, mse=2.5038, time=0.0409\n",
      "Iter=5800, loss=2.4637, mse=2.4543, time=0.0409\n",
      "Iter=6000, loss=2.4259, mse=2.4164, time=0.0409\n",
      "Iter=6200, loss=2.5735, mse=2.5636, time=0.0409\n",
      "Iter=6400, loss=2.6184, mse=2.6081, time=0.0409\n",
      "Iter=6600, loss=2.4676, mse=2.4580, time=0.0409\n",
      "=== Epoch 66, train loss 2.495338, test rmse 0.809105 ===\n",
      "Epoch 67\n",
      "Iter=200, loss=2.5205, mse=2.5111, time=0.0418\n",
      "Iter=400, loss=2.5367, mse=2.5272, time=0.0412\n",
      "Iter=600, loss=2.4614, mse=2.4517, time=0.0415\n",
      "Iter=800, loss=2.4772, mse=2.4678, time=0.0411\n",
      "Iter=1000, loss=2.4875, mse=2.4785, time=0.0412\n",
      "Iter=1200, loss=2.5255, mse=2.5168, time=0.0412\n",
      "Iter=1400, loss=2.5084, mse=2.4995, time=0.0411\n",
      "Iter=1600, loss=2.5641, mse=2.5552, time=0.0411\n",
      "Iter=1800, loss=2.5634, mse=2.5549, time=0.0410\n",
      "Iter=2000, loss=2.5191, mse=2.5111, time=0.0411\n",
      "Iter=2200, loss=2.3927, mse=2.3844, time=0.0410\n",
      "Iter=2400, loss=2.4607, mse=2.4518, time=0.0410\n",
      "Iter=2600, loss=2.3726, mse=2.3638, time=0.0410\n",
      "Iter=2800, loss=2.4643, mse=2.4558, time=0.0410\n",
      "Iter=3000, loss=2.5155, mse=2.5074, time=0.0410\n",
      "Iter=3200, loss=2.6074, mse=2.5988, time=0.0410\n",
      "Iter=3400, loss=2.5544, mse=2.5459, time=0.0410\n",
      "Iter=3600, loss=2.5311, mse=2.5229, time=0.0410\n",
      "Iter=3800, loss=2.5023, mse=2.4940, time=0.0410\n",
      "Iter=4000, loss=2.4052, mse=2.3969, time=0.0410\n",
      "Iter=4200, loss=2.5087, mse=2.5007, time=0.0410\n",
      "Iter=4400, loss=2.4994, mse=2.4910, time=0.0410\n",
      "Iter=4600, loss=2.4574, mse=2.4492, time=0.0410\n",
      "Iter=4800, loss=2.5362, mse=2.5280, time=0.0410\n",
      "Iter=5000, loss=2.5022, mse=2.4934, time=0.0410\n",
      "Iter=5200, loss=2.4624, mse=2.4538, time=0.0410\n",
      "Iter=5400, loss=2.4586, mse=2.4500, time=0.0410\n",
      "Iter=5600, loss=2.4128, mse=2.4042, time=0.0410\n",
      "Iter=5800, loss=2.5957, mse=2.5870, time=0.0410\n",
      "Iter=6000, loss=2.5576, mse=2.5493, time=0.0410\n",
      "Iter=6200, loss=2.4592, mse=2.4515, time=0.0410\n",
      "Iter=6400, loss=2.5045, mse=2.4967, time=0.0409\n",
      "Iter=6600, loss=2.4270, mse=2.4192, time=0.0409\n",
      "=== Epoch 67, train loss 2.493716, test rmse 0.806256 ===\n",
      "Epoch 68\n",
      "Iter=200, loss=2.4712, mse=2.4631, time=0.0413\n",
      "Iter=400, loss=2.5282, mse=2.5204, time=0.0410\n",
      "Iter=600, loss=2.5823, mse=2.5738, time=0.0408\n",
      "Iter=800, loss=2.5101, mse=2.5018, time=0.0407\n",
      "Iter=1000, loss=2.4501, mse=2.4421, time=0.0406\n",
      "Iter=1200, loss=2.4873, mse=2.4797, time=0.0406\n",
      "Iter=1400, loss=2.3366, mse=2.3295, time=0.0405\n",
      "Iter=1600, loss=2.5121, mse=2.5049, time=0.0406\n",
      "Iter=1800, loss=2.5512, mse=2.5441, time=0.0406\n",
      "Iter=2000, loss=2.4336, mse=2.4268, time=0.0406\n",
      "Iter=2200, loss=2.4336, mse=2.4267, time=0.0406\n",
      "Iter=2400, loss=2.5623, mse=2.5548, time=0.0406\n",
      "Iter=2600, loss=2.4897, mse=2.4822, time=0.0406\n",
      "Iter=2800, loss=2.4932, mse=2.4858, time=0.0407\n",
      "Iter=3000, loss=2.5325, mse=2.5250, time=0.0407\n",
      "Iter=3200, loss=2.5003, mse=2.4930, time=0.0407\n",
      "Iter=3400, loss=2.4268, mse=2.4198, time=0.0407\n",
      "Iter=3600, loss=2.4652, mse=2.4584, time=0.0407\n",
      "Iter=3800, loss=2.5335, mse=2.5266, time=0.0407\n",
      "Iter=4000, loss=2.5437, mse=2.5367, time=0.0407\n",
      "Iter=4200, loss=2.5594, mse=2.5523, time=0.0407\n",
      "Iter=4400, loss=2.4484, mse=2.4416, time=0.0407\n",
      "Iter=4600, loss=2.5042, mse=2.4971, time=0.0407\n",
      "Iter=4800, loss=2.5192, mse=2.5122, time=0.0408\n",
      "Iter=5000, loss=2.5652, mse=2.5579, time=0.0408\n",
      "Iter=5200, loss=2.5055, mse=2.4985, time=0.0407\n",
      "Iter=5400, loss=2.4985, mse=2.4910, time=0.0407\n",
      "Iter=5600, loss=2.5934, mse=2.5859, time=0.0407\n",
      "Iter=5800, loss=2.4551, mse=2.4478, time=0.0407\n",
      "Iter=6000, loss=2.4617, mse=2.4550, time=0.0407\n",
      "Iter=6200, loss=2.5066, mse=2.4990, time=0.0407\n",
      "Iter=6400, loss=2.5094, mse=2.5018, time=0.0407\n",
      "Iter=6600, loss=2.5461, mse=2.5386, time=0.0407\n",
      "=== Epoch 68, train loss 2.501082, test rmse 0.808913 ===\n",
      "Epoch 69\n",
      "Iter=200, loss=2.5553, mse=2.5475, time=0.0412\n",
      "Iter=400, loss=2.5852, mse=2.5772, time=0.0412\n",
      "Iter=600, loss=2.5212, mse=2.5129, time=0.0411\n",
      "Iter=800, loss=2.5276, mse=2.5190, time=0.0410\n",
      "Iter=1000, loss=2.5000, mse=2.4921, time=0.0410\n",
      "Iter=1200, loss=2.4353, mse=2.4273, time=0.0408\n",
      "Iter=1400, loss=2.5862, mse=2.5782, time=0.0408\n",
      "Iter=1600, loss=2.4339, mse=2.4259, time=0.0407\n",
      "Iter=1800, loss=2.4777, mse=2.4696, time=0.0408\n",
      "Iter=2000, loss=2.5199, mse=2.5118, time=0.0408\n",
      "Iter=2200, loss=2.4931, mse=2.4848, time=0.0408\n",
      "Iter=2400, loss=2.5508, mse=2.5421, time=0.0408\n",
      "Iter=2600, loss=2.4551, mse=2.4462, time=0.0408\n",
      "Iter=2800, loss=2.4785, mse=2.4697, time=0.0408\n",
      "Iter=3000, loss=2.4967, mse=2.4879, time=0.0408\n",
      "Iter=3200, loss=2.5869, mse=2.5780, time=0.0408\n",
      "Iter=3400, loss=2.4495, mse=2.4405, time=0.0408\n",
      "Iter=3600, loss=2.4197, mse=2.4105, time=0.0408\n",
      "Iter=3800, loss=2.4448, mse=2.4349, time=0.0408\n",
      "Iter=4000, loss=2.5024, mse=2.4935, time=0.0408\n",
      "Iter=4200, loss=2.4992, mse=2.4902, time=0.0408\n",
      "Iter=4400, loss=2.5331, mse=2.5247, time=0.0408\n",
      "Iter=4600, loss=2.5474, mse=2.5390, time=0.0408\n",
      "Iter=4800, loss=2.4598, mse=2.4519, time=0.0408\n",
      "Iter=5000, loss=2.5643, mse=2.5566, time=0.0407\n",
      "Iter=5200, loss=2.4040, mse=2.3961, time=0.0408\n",
      "Iter=5400, loss=2.4551, mse=2.4465, time=0.0407\n",
      "Iter=5600, loss=2.5067, mse=2.4988, time=0.0407\n",
      "Iter=5800, loss=2.5318, mse=2.5240, time=0.0407\n",
      "Iter=6000, loss=2.5606, mse=2.5525, time=0.0407\n",
      "Iter=6200, loss=2.5552, mse=2.5469, time=0.0407\n",
      "Iter=6400, loss=2.4887, mse=2.4811, time=0.0407\n",
      "Iter=6600, loss=2.4998, mse=2.4918, time=0.0407\n",
      "=== Epoch 69, train loss 2.504875, test rmse 0.830442 ===\n",
      "Epoch 70\n",
      "Iter=200, loss=2.4499, mse=2.4412, time=0.0424\n",
      "Iter=400, loss=2.4894, mse=2.4803, time=0.0417\n",
      "Iter=600, loss=2.4516, mse=2.4420, time=0.0416\n",
      "Iter=800, loss=2.5410, mse=2.5326, time=0.0413\n",
      "Iter=1000, loss=2.4779, mse=2.4697, time=0.0414\n",
      "Iter=1200, loss=2.5153, mse=2.5067, time=0.0412\n",
      "Iter=1400, loss=2.5453, mse=2.5371, time=0.0413\n",
      "Iter=1600, loss=2.4905, mse=2.4829, time=0.0413\n",
      "Iter=1800, loss=2.4530, mse=2.4454, time=0.0412\n",
      "Iter=2000, loss=2.4911, mse=2.4835, time=0.0412\n",
      "Iter=2200, loss=2.4943, mse=2.4868, time=0.0411\n",
      "Iter=2400, loss=2.5836, mse=2.5759, time=0.0411\n",
      "Iter=2600, loss=2.4812, mse=2.4737, time=0.0411\n",
      "Iter=2800, loss=2.4837, mse=2.4762, time=0.0411\n",
      "Iter=3000, loss=2.4579, mse=2.4503, time=0.0411\n",
      "Iter=3200, loss=2.4535, mse=2.4458, time=0.0411\n",
      "Iter=3400, loss=2.4794, mse=2.4715, time=0.0411\n",
      "Iter=3600, loss=2.4795, mse=2.4719, time=0.0410\n",
      "Iter=3800, loss=2.5174, mse=2.5101, time=0.0411\n",
      "Iter=4000, loss=2.4693, mse=2.4619, time=0.0411\n",
      "Iter=4200, loss=2.5385, mse=2.5307, time=0.0411\n",
      "Iter=4400, loss=2.5657, mse=2.5584, time=0.0411\n",
      "Iter=4600, loss=2.5619, mse=2.5544, time=0.0411\n",
      "Iter=4800, loss=2.4430, mse=2.4350, time=0.0410\n",
      "Iter=5000, loss=2.5607, mse=2.5527, time=0.0410\n",
      "Iter=5200, loss=2.5544, mse=2.5465, time=0.0410\n",
      "Iter=5400, loss=2.5118, mse=2.5040, time=0.0410\n",
      "Iter=5600, loss=2.5262, mse=2.5187, time=0.0410\n",
      "Iter=5800, loss=2.4594, mse=2.4521, time=0.0411\n",
      "Iter=6000, loss=2.4808, mse=2.4734, time=0.0411\n",
      "Iter=6200, loss=2.5004, mse=2.4923, time=0.0411\n",
      "Iter=6400, loss=2.4395, mse=2.4316, time=0.0411\n",
      "Iter=6600, loss=2.5363, mse=2.5282, time=0.0412\n",
      "=== Epoch 70, train loss 2.499555, test rmse 0.808899 ===\n",
      "Epoch 71\n",
      "Iter=200, loss=2.4353, mse=2.4273, time=0.0413\n",
      "Iter=400, loss=2.4885, mse=2.4799, time=0.0412\n",
      "Iter=600, loss=2.4419, mse=2.4336, time=0.0409\n",
      "Iter=800, loss=2.4180, mse=2.4101, time=0.0410\n",
      "Iter=1000, loss=2.4858, mse=2.4777, time=0.0410\n",
      "Iter=1200, loss=2.5197, mse=2.5114, time=0.0411\n",
      "Iter=1400, loss=2.4647, mse=2.4566, time=0.0411\n",
      "Iter=1600, loss=2.4370, mse=2.4289, time=0.0411\n",
      "Iter=1800, loss=2.5160, mse=2.5079, time=0.0411\n",
      "Iter=2000, loss=2.5148, mse=2.5067, time=0.0410\n",
      "Iter=2200, loss=2.5154, mse=2.5079, time=0.0410\n",
      "Iter=2400, loss=2.5117, mse=2.5038, time=0.0410\n",
      "Iter=2600, loss=2.4244, mse=2.4163, time=0.0410\n",
      "Iter=2800, loss=2.5527, mse=2.5453, time=0.0410\n",
      "Iter=3000, loss=2.5657, mse=2.5586, time=0.0410\n",
      "Iter=3200, loss=2.4880, mse=2.4806, time=0.0409\n",
      "Iter=3400, loss=2.5399, mse=2.5321, time=0.0410\n",
      "Iter=3600, loss=2.5245, mse=2.5167, time=0.0410\n",
      "Iter=3800, loss=2.5512, mse=2.5438, time=0.0410\n",
      "Iter=4000, loss=2.5055, mse=2.4978, time=0.0410\n",
      "Iter=4200, loss=2.4569, mse=2.4489, time=0.0410\n",
      "Iter=4400, loss=2.5328, mse=2.5250, time=0.0409\n",
      "Iter=4600, loss=2.5109, mse=2.5029, time=0.0410\n",
      "Iter=4800, loss=2.5345, mse=2.5264, time=0.0410\n",
      "Iter=5000, loss=2.6062, mse=2.5978, time=0.0410\n",
      "Iter=5200, loss=2.5318, mse=2.5233, time=0.0410\n",
      "Iter=5400, loss=2.4683, mse=2.4598, time=0.0410\n",
      "Iter=5600, loss=2.4538, mse=2.4454, time=0.0410\n",
      "Iter=5800, loss=2.5338, mse=2.5255, time=0.0409\n",
      "Iter=6000, loss=2.4400, mse=2.4319, time=0.0409\n",
      "Iter=6200, loss=2.3709, mse=2.3624, time=0.0409\n",
      "Iter=6400, loss=2.5660, mse=2.5581, time=0.0409\n",
      "Iter=6600, loss=2.5717, mse=2.5645, time=0.0409\n",
      "=== Epoch 71, train loss 2.498284, test rmse 0.833496 ===\n",
      "Epoch 72\n",
      "Iter=200, loss=2.5380, mse=2.5305, time=0.0428\n",
      "Iter=400, loss=2.4942, mse=2.4864, time=0.0417\n",
      "Iter=600, loss=2.4925, mse=2.4847, time=0.0414\n",
      "Iter=800, loss=2.4881, mse=2.4808, time=0.0411\n",
      "Iter=1000, loss=2.4917, mse=2.4838, time=0.0411\n",
      "Iter=1200, loss=2.4273, mse=2.4191, time=0.0410\n",
      "Iter=1400, loss=2.5336, mse=2.5256, time=0.0410\n",
      "Iter=1600, loss=2.5029, mse=2.4950, time=0.0409\n",
      "Iter=1800, loss=2.4926, mse=2.4854, time=0.0408\n",
      "Iter=2000, loss=2.5701, mse=2.5625, time=0.0408\n",
      "Iter=2200, loss=2.5924, mse=2.5850, time=0.0408\n",
      "Iter=2400, loss=2.4868, mse=2.4788, time=0.0409\n",
      "Iter=2600, loss=2.4343, mse=2.4266, time=0.0409\n",
      "Iter=2800, loss=2.5511, mse=2.5425, time=0.0409\n",
      "Iter=3000, loss=2.4391, mse=2.4307, time=0.0409\n",
      "Iter=3200, loss=2.4431, mse=2.4349, time=0.0409\n",
      "Iter=3400, loss=2.5423, mse=2.5340, time=0.0408\n",
      "Iter=3600, loss=2.4598, mse=2.4518, time=0.0408\n",
      "Iter=3800, loss=2.4510, mse=2.4434, time=0.0408\n",
      "Iter=4000, loss=2.4679, mse=2.4605, time=0.0408\n",
      "Iter=4200, loss=2.4660, mse=2.4589, time=0.0408\n",
      "Iter=4400, loss=2.4864, mse=2.4794, time=0.0408\n",
      "Iter=4600, loss=2.5350, mse=2.5279, time=0.0408\n",
      "Iter=4800, loss=2.5054, mse=2.4983, time=0.0408\n",
      "Iter=5000, loss=2.5217, mse=2.5146, time=0.0408\n",
      "Iter=5200, loss=2.4670, mse=2.4594, time=0.0408\n",
      "Iter=5400, loss=2.4178, mse=2.4109, time=0.0408\n",
      "Iter=5600, loss=2.6024, mse=2.5955, time=0.0408\n",
      "Iter=5800, loss=2.4761, mse=2.4694, time=0.0408\n",
      "Iter=6000, loss=2.5102, mse=2.5032, time=0.0407\n",
      "Iter=6200, loss=2.5125, mse=2.5051, time=0.0407\n",
      "Iter=6400, loss=2.5659, mse=2.5587, time=0.0407\n",
      "Iter=6600, loss=2.6128, mse=2.6060, time=0.0407\n",
      "=== Epoch 72, train loss 2.503611, test rmse 0.805048 ===\n",
      "Epoch 73\n",
      "Iter=200, loss=2.5448, mse=2.5377, time=0.0423\n",
      "Iter=400, loss=2.4824, mse=2.4752, time=0.0417\n",
      "Iter=600, loss=2.5252, mse=2.5170, time=0.0418\n",
      "Iter=800, loss=2.4533, mse=2.4455, time=0.0418\n",
      "Iter=1000, loss=2.5231, mse=2.5145, time=0.0417\n",
      "Iter=1200, loss=2.4341, mse=2.4259, time=0.0416\n",
      "Iter=1400, loss=2.4470, mse=2.4396, time=0.0416\n",
      "Iter=1600, loss=2.4527, mse=2.4452, time=0.0414\n",
      "Iter=1800, loss=2.4998, mse=2.4925, time=0.0413\n",
      "Iter=2000, loss=2.5413, mse=2.5340, time=0.0414\n",
      "Iter=2200, loss=2.5875, mse=2.5794, time=0.0413\n",
      "Iter=2400, loss=2.4493, mse=2.4412, time=0.0412\n",
      "Iter=2600, loss=2.5125, mse=2.5036, time=0.0413\n",
      "Iter=2800, loss=2.5036, mse=2.4951, time=0.0412\n",
      "Iter=3000, loss=2.4134, mse=2.4051, time=0.0413\n",
      "Iter=3200, loss=2.5238, mse=2.5152, time=0.0412\n",
      "Iter=3400, loss=2.5371, mse=2.5287, time=0.0412\n",
      "Iter=3600, loss=2.4808, mse=2.4731, time=0.0412\n",
      "Iter=3800, loss=2.4893, mse=2.4818, time=0.0412\n",
      "Iter=4000, loss=2.5811, mse=2.5733, time=0.0412\n",
      "Iter=4200, loss=2.4834, mse=2.4753, time=0.0411\n",
      "Iter=4400, loss=2.4907, mse=2.4823, time=0.0411\n",
      "Iter=4600, loss=2.5113, mse=2.5022, time=0.0411\n",
      "Iter=4800, loss=2.5043, mse=2.4950, time=0.0411\n",
      "Iter=5000, loss=2.4889, mse=2.4797, time=0.0411\n",
      "Iter=5200, loss=2.5998, mse=2.5905, time=0.0411\n",
      "Iter=5400, loss=2.4751, mse=2.4657, time=0.0411\n",
      "Iter=5600, loss=2.5538, mse=2.5452, time=0.0411\n",
      "Iter=5800, loss=2.5304, mse=2.5214, time=0.0411\n",
      "Iter=6000, loss=2.5751, mse=2.5663, time=0.0411\n",
      "Iter=6200, loss=2.4008, mse=2.3920, time=0.0411\n",
      "Iter=6400, loss=2.5332, mse=2.5247, time=0.0411\n",
      "Iter=6600, loss=2.4267, mse=2.4190, time=0.0411\n",
      "=== Epoch 73, train loss 2.502334, test rmse 0.802606 ===\n",
      "Epoch 74\n",
      "Iter=200, loss=2.5332, mse=2.5250, time=0.0422\n",
      "Iter=400, loss=2.4696, mse=2.4619, time=0.0414\n",
      "Iter=600, loss=2.5416, mse=2.5337, time=0.0412\n",
      "Iter=800, loss=2.4663, mse=2.4575, time=0.0408\n",
      "Iter=1000, loss=2.4926, mse=2.4821, time=0.0409\n",
      "Iter=1200, loss=2.5403, mse=2.5299, time=0.0408\n",
      "Iter=1400, loss=2.4006, mse=2.3913, time=0.0408\n",
      "Iter=1600, loss=2.4485, mse=2.4397, time=0.0407\n",
      "Iter=1800, loss=2.5549, mse=2.5464, time=0.0408\n",
      "Iter=2000, loss=2.5068, mse=2.4987, time=0.0408\n",
      "Iter=2200, loss=2.5139, mse=2.5059, time=0.0408\n",
      "Iter=2400, loss=2.5725, mse=2.5651, time=0.0408\n",
      "Iter=2600, loss=2.5730, mse=2.5654, time=0.0407\n",
      "Iter=2800, loss=2.5478, mse=2.5403, time=0.0407\n",
      "Iter=3000, loss=2.5396, mse=2.5320, time=0.0407\n",
      "Iter=3200, loss=2.4366, mse=2.4282, time=0.0407\n",
      "Iter=3400, loss=2.4435, mse=2.4348, time=0.0407\n",
      "Iter=3600, loss=2.5465, mse=2.5377, time=0.0407\n",
      "Iter=3800, loss=2.4921, mse=2.4833, time=0.0408\n",
      "Iter=4000, loss=2.4233, mse=2.4152, time=0.0408\n",
      "Iter=4200, loss=2.4482, mse=2.4400, time=0.0408\n",
      "Iter=4400, loss=2.5160, mse=2.5077, time=0.0408\n",
      "Iter=4600, loss=2.5648, mse=2.5560, time=0.0408\n",
      "Iter=4800, loss=2.5069, mse=2.4984, time=0.0408\n",
      "Iter=5000, loss=2.4350, mse=2.4257, time=0.0407\n",
      "Iter=5200, loss=2.4625, mse=2.4531, time=0.0407\n",
      "Iter=5400, loss=2.4994, mse=2.4889, time=0.0407\n",
      "Iter=5600, loss=2.5741, mse=2.5645, time=0.0407\n",
      "Iter=5800, loss=2.4166, mse=2.4075, time=0.0407\n",
      "Iter=6000, loss=2.4528, mse=2.4447, time=0.0407\n",
      "Iter=6200, loss=2.5017, mse=2.4937, time=0.0407\n",
      "Iter=6400, loss=2.5538, mse=2.5456, time=0.0407\n",
      "Iter=6600, loss=2.5164, mse=2.5082, time=0.0407\n",
      "=== Epoch 74, train loss 2.499388, test rmse 0.816333 ===\n",
      "Epoch 75\n",
      "Iter=200, loss=2.4888, mse=2.4796, time=0.0417\n",
      "Iter=400, loss=2.4273, mse=2.4181, time=0.0412\n",
      "Iter=600, loss=2.4832, mse=2.4742, time=0.0414\n",
      "Iter=800, loss=2.4750, mse=2.4663, time=0.0413\n",
      "Iter=1000, loss=2.4901, mse=2.4814, time=0.0412\n",
      "Iter=1200, loss=2.5347, mse=2.5265, time=0.0412\n",
      "Iter=1400, loss=2.4773, mse=2.4691, time=0.0411\n",
      "Iter=1600, loss=2.5018, mse=2.4938, time=0.0412\n",
      "Iter=1800, loss=2.4213, mse=2.4131, time=0.0411\n",
      "Iter=2000, loss=2.4364, mse=2.4277, time=0.0412\n",
      "Iter=2200, loss=2.5091, mse=2.5009, time=0.0411\n",
      "Iter=2400, loss=2.5879, mse=2.5789, time=0.0412\n",
      "Iter=2600, loss=2.4264, mse=2.4171, time=0.0412\n",
      "Iter=2800, loss=2.5212, mse=2.5127, time=0.0412\n",
      "Iter=3000, loss=2.4793, mse=2.4707, time=0.0411\n",
      "Iter=3200, loss=2.5065, mse=2.4981, time=0.0411\n",
      "Iter=3400, loss=2.4915, mse=2.4828, time=0.0412\n",
      "Iter=3600, loss=2.5196, mse=2.5102, time=0.0411\n",
      "Iter=3800, loss=2.5133, mse=2.5040, time=0.0411\n",
      "Iter=4000, loss=2.4687, mse=2.4585, time=0.0411\n",
      "Iter=4200, loss=2.4962, mse=2.4863, time=0.0411\n",
      "Iter=4400, loss=2.5652, mse=2.5559, time=0.0411\n",
      "Iter=4600, loss=2.4223, mse=2.4138, time=0.0411\n",
      "Iter=4800, loss=2.5444, mse=2.5355, time=0.0410\n",
      "Iter=5000, loss=2.4983, mse=2.4890, time=0.0410\n",
      "Iter=5200, loss=2.5340, mse=2.5252, time=0.0410\n",
      "Iter=5400, loss=2.5631, mse=2.5542, time=0.0410\n",
      "Iter=5600, loss=2.4365, mse=2.4272, time=0.0410\n",
      "Iter=5800, loss=2.5416, mse=2.5328, time=0.0410\n",
      "Iter=6000, loss=2.4559, mse=2.4475, time=0.0410\n",
      "Iter=6200, loss=2.4658, mse=2.4573, time=0.0410\n",
      "Iter=6400, loss=2.6099, mse=2.6009, time=0.0410\n",
      "Iter=6600, loss=2.5956, mse=2.5872, time=0.0410\n",
      "=== Epoch 75, train loss 2.498982, test rmse 0.802632 ===\n",
      "Epoch 76\n",
      "Iter=200, loss=2.5441, mse=2.5367, time=0.0413\n",
      "Iter=400, loss=2.5123, mse=2.5047, time=0.0411\n",
      "Iter=600, loss=2.3795, mse=2.3719, time=0.0408\n",
      "Iter=800, loss=2.4317, mse=2.4238, time=0.0408\n",
      "Iter=1000, loss=2.5941, mse=2.5855, time=0.0409\n",
      "Iter=1200, loss=2.4816, mse=2.4729, time=0.0409\n",
      "Iter=1400, loss=2.4455, mse=2.4371, time=0.0409\n",
      "Iter=1600, loss=2.4373, mse=2.4292, time=0.0409\n",
      "Iter=1800, loss=2.5758, mse=2.5679, time=0.0409\n",
      "Iter=2000, loss=2.5096, mse=2.5011, time=0.0409\n",
      "Iter=2200, loss=2.5104, mse=2.5030, time=0.0409\n",
      "Iter=2400, loss=2.5107, mse=2.5033, time=0.0409\n",
      "Iter=2600, loss=2.5824, mse=2.5749, time=0.0409\n",
      "Iter=2800, loss=2.4148, mse=2.4078, time=0.0409\n",
      "Iter=3000, loss=2.5568, mse=2.5497, time=0.0409\n",
      "Iter=3200, loss=2.5379, mse=2.5301, time=0.0409\n",
      "Iter=3400, loss=2.5109, mse=2.5029, time=0.0409\n",
      "Iter=3600, loss=2.4968, mse=2.4890, time=0.0408\n",
      "Iter=3800, loss=2.5314, mse=2.5242, time=0.0408\n",
      "Iter=4000, loss=2.4858, mse=2.4789, time=0.0409\n",
      "Iter=4200, loss=2.5215, mse=2.5146, time=0.0409\n",
      "Iter=4400, loss=2.4874, mse=2.4802, time=0.0409\n",
      "Iter=4600, loss=2.5164, mse=2.5091, time=0.0409\n",
      "Iter=4800, loss=2.4140, mse=2.4070, time=0.0409\n",
      "Iter=5000, loss=2.4596, mse=2.4527, time=0.0409\n",
      "Iter=5200, loss=2.6103, mse=2.6027, time=0.0409\n",
      "Iter=5400, loss=2.5232, mse=2.5158, time=0.0409\n",
      "Iter=5600, loss=2.4204, mse=2.4130, time=0.0409\n",
      "Iter=5800, loss=2.3995, mse=2.3918, time=0.0409\n",
      "Iter=6000, loss=2.4991, mse=2.4919, time=0.0409\n",
      "Iter=6200, loss=2.5077, mse=2.5003, time=0.0409\n",
      "Iter=6400, loss=2.4926, mse=2.4853, time=0.0409\n",
      "Iter=6600, loss=2.4640, mse=2.4568, time=0.0409\n",
      "=== Epoch 76, train loss 2.497108, test rmse 0.810046 ===\n",
      "Epoch 77\n",
      "Iter=200, loss=2.4584, mse=2.4514, time=0.0425\n",
      "Iter=400, loss=2.4954, mse=2.4888, time=0.0418\n",
      "Iter=600, loss=2.4261, mse=2.4192, time=0.0414\n",
      "Iter=800, loss=2.4706, mse=2.4635, time=0.0411\n",
      "Iter=1000, loss=2.4384, mse=2.4316, time=0.0410\n",
      "Iter=1200, loss=2.4991, mse=2.4924, time=0.0410\n",
      "Iter=1400, loss=2.5557, mse=2.5481, time=0.0409\n",
      "Iter=1600, loss=2.5397, mse=2.5327, time=0.0409\n",
      "Iter=1800, loss=2.5986, mse=2.5920, time=0.0409\n",
      "Iter=2000, loss=2.5920, mse=2.5848, time=0.0409\n",
      "Iter=2200, loss=2.4619, mse=2.4543, time=0.0408\n",
      "Iter=2400, loss=2.5289, mse=2.5220, time=0.0408\n",
      "Iter=2600, loss=2.4579, mse=2.4509, time=0.0408\n",
      "Iter=2800, loss=2.4888, mse=2.4819, time=0.0407\n",
      "Iter=3000, loss=2.5377, mse=2.5307, time=0.0407\n",
      "Iter=3200, loss=2.4939, mse=2.4872, time=0.0407\n",
      "Iter=3400, loss=2.4171, mse=2.4105, time=0.0407\n",
      "Iter=3600, loss=2.4532, mse=2.4466, time=0.0407\n",
      "Iter=3800, loss=2.4835, mse=2.4770, time=0.0407\n",
      "Iter=4000, loss=2.4514, mse=2.4449, time=0.0407\n",
      "Iter=4200, loss=2.4923, mse=2.4856, time=0.0407\n",
      "Iter=4400, loss=2.5828, mse=2.5756, time=0.0407\n",
      "Iter=4600, loss=2.5067, mse=2.4994, time=0.0407\n",
      "Iter=4800, loss=2.4789, mse=2.4713, time=0.0407\n",
      "Iter=5000, loss=2.4727, mse=2.4644, time=0.0408\n",
      "Iter=5200, loss=2.5236, mse=2.5147, time=0.0407\n",
      "Iter=5400, loss=2.5506, mse=2.5427, time=0.0407\n",
      "Iter=5600, loss=2.4562, mse=2.4484, time=0.0407\n",
      "Iter=5800, loss=2.5677, mse=2.5600, time=0.0407\n",
      "Iter=6000, loss=2.5026, mse=2.4948, time=0.0407\n",
      "Iter=6200, loss=2.4882, mse=2.4802, time=0.0407\n",
      "Iter=6400, loss=2.5212, mse=2.5131, time=0.0407\n",
      "Iter=6600, loss=2.4681, mse=2.4604, time=0.0407\n",
      "=== Epoch 77, train loss 2.496291, test rmse 0.803661 ===\n",
      "Epoch 78\n",
      "Iter=200, loss=2.4569, mse=2.4493, time=0.0419\n",
      "Iter=400, loss=2.5183, mse=2.5104, time=0.0415\n",
      "Iter=600, loss=2.5259, mse=2.5183, time=0.0411\n",
      "Iter=800, loss=2.4247, mse=2.4168, time=0.0412\n",
      "Iter=1000, loss=2.5128, mse=2.5049, time=0.0412\n",
      "Iter=1200, loss=2.5435, mse=2.5349, time=0.0412\n",
      "Iter=1400, loss=2.4858, mse=2.4773, time=0.0411\n",
      "Iter=1600, loss=2.4840, mse=2.4760, time=0.0411\n",
      "Iter=1800, loss=2.4117, mse=2.4039, time=0.0410\n",
      "Iter=2000, loss=2.5565, mse=2.5488, time=0.0410\n",
      "Iter=2200, loss=2.4633, mse=2.4557, time=0.0410\n",
      "Iter=2400, loss=2.4861, mse=2.4782, time=0.0410\n",
      "Iter=2600, loss=2.4575, mse=2.4491, time=0.0410\n",
      "Iter=2800, loss=2.4741, mse=2.4659, time=0.0409\n",
      "Iter=3000, loss=2.5548, mse=2.5467, time=0.0409\n",
      "Iter=3200, loss=2.5255, mse=2.5171, time=0.0409\n",
      "Iter=3400, loss=2.5153, mse=2.5068, time=0.0409\n",
      "Iter=3600, loss=2.5248, mse=2.5161, time=0.0409\n",
      "Iter=3800, loss=2.4486, mse=2.4403, time=0.0409\n",
      "Iter=4000, loss=2.5280, mse=2.5202, time=0.0409\n",
      "Iter=4200, loss=2.5406, mse=2.5326, time=0.0408\n",
      "Iter=4400, loss=2.4894, mse=2.4815, time=0.0408\n",
      "Iter=4600, loss=2.5452, mse=2.5373, time=0.0408\n",
      "Iter=4800, loss=2.3894, mse=2.3816, time=0.0408\n",
      "Iter=5000, loss=2.4712, mse=2.4631, time=0.0408\n",
      "Iter=5200, loss=2.4761, mse=2.4679, time=0.0408\n",
      "Iter=5400, loss=2.5911, mse=2.5820, time=0.0408\n",
      "Iter=5600, loss=2.4715, mse=2.4623, time=0.0408\n",
      "Iter=5800, loss=2.4918, mse=2.4829, time=0.0408\n",
      "Iter=6000, loss=2.4514, mse=2.4424, time=0.0408\n",
      "Iter=6200, loss=2.5829, mse=2.5745, time=0.0408\n",
      "Iter=6400, loss=2.5187, mse=2.5107, time=0.0408\n",
      "Iter=6600, loss=2.5009, mse=2.4921, time=0.0408\n",
      "=== Epoch 78, train loss 2.498366, test rmse 0.805598 ===\n",
      "Epoch 79\n",
      "Iter=200, loss=2.5488, mse=2.5390, time=0.0414\n",
      "Iter=400, loss=2.6288, mse=2.6188, time=0.0410\n",
      "Iter=600, loss=2.5362, mse=2.5271, time=0.0411\n",
      "Iter=800, loss=2.4659, mse=2.4574, time=0.0410\n",
      "Iter=1000, loss=2.4703, mse=2.4619, time=0.0410\n",
      "Iter=1200, loss=2.5363, mse=2.5279, time=0.0410\n",
      "Iter=1400, loss=2.4629, mse=2.4548, time=0.0411\n",
      "Iter=1600, loss=2.3230, mse=2.3148, time=0.0412\n",
      "Iter=1800, loss=2.4925, mse=2.4844, time=0.0412\n",
      "Iter=2000, loss=2.4915, mse=2.4832, time=0.0411\n",
      "Iter=2200, loss=2.5304, mse=2.5222, time=0.0411\n",
      "Iter=2400, loss=2.4635, mse=2.4554, time=0.0410\n",
      "Iter=2600, loss=2.4952, mse=2.4870, time=0.0410\n",
      "Iter=2800, loss=2.5361, mse=2.5279, time=0.0410\n",
      "Iter=3000, loss=2.5308, mse=2.5231, time=0.0410\n",
      "Iter=3200, loss=2.4193, mse=2.4101, time=0.0410\n",
      "Iter=3400, loss=2.4736, mse=2.4658, time=0.0410\n",
      "Iter=3600, loss=2.5620, mse=2.5543, time=0.0410\n",
      "Iter=3800, loss=2.5079, mse=2.5004, time=0.0410\n",
      "Iter=4000, loss=2.4318, mse=2.4241, time=0.0410\n",
      "Iter=4200, loss=2.4899, mse=2.4826, time=0.0410\n",
      "Iter=4400, loss=2.3908, mse=2.3827, time=0.0410\n",
      "Iter=4600, loss=2.5325, mse=2.5243, time=0.0410\n",
      "Iter=4800, loss=2.5740, mse=2.5663, time=0.0411\n",
      "Iter=5000, loss=2.5338, mse=2.5261, time=0.0412\n",
      "Iter=5200, loss=2.5598, mse=2.5520, time=0.0412\n",
      "Iter=5400, loss=2.4355, mse=2.4278, time=0.0412\n",
      "Iter=5600, loss=2.5966, mse=2.5875, time=0.0412\n",
      "Iter=5800, loss=2.4348, mse=2.4246, time=0.0412\n",
      "Iter=6000, loss=2.4941, mse=2.4854, time=0.0412\n",
      "Iter=6200, loss=2.4950, mse=2.4860, time=0.0412\n",
      "Iter=6400, loss=2.5118, mse=2.5034, time=0.0412\n",
      "Iter=6600, loss=2.5478, mse=2.5395, time=0.0412\n",
      "=== Epoch 79, train loss 2.499177, test rmse 0.808945 ===\n",
      "Training ends. The best testing rmse is 0.797599 at epoch 14\n",
      "  Training epoch took: 8:15:34\n"
     ]
    }
   ],
   "source": [
    "label_type = 'rating'\n",
    "\n",
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch_idx in range(1, 80):\n",
    "    print ('Epoch', epoch_idx)\n",
    "    \n",
    "    train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_r, loss_fn, optimizer_r, args.arr_lambda, \n",
    "                                                                   train_loader_r, args.device, args.train_log_interval)\n",
    "    valid_rmse, predict_valid_list, label_valid_list = evaluate(label_type, model_r, valid_loader_r, args.device)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(label_type, model_r, test_loader_r, args.device)\n",
    "    \n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model_r, optimizer_r)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_valid_list = predict_valid_list \n",
    "        best_label_valid_list = label_valid_list\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "\n",
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a501375-be50-45f9-870b-337d7ff63863",
   "metadata": {},
   "source": [
    "- 결과 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "273dda48-ab5e-4aa5-a6c8-8252a7dc0c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216328\n",
      "216328\n"
     ]
    }
   ],
   "source": [
    "print(len(predict_train_list))\n",
    "print(len(label_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c3f7529a-6739-4498-a5ca-d64246448b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43266\n",
      "43266\n"
     ]
    }
   ],
   "source": [
    "print(len(best_predict_valid_list))\n",
    "print(len(best_label_valid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "904ae17b-4e10-4a15-b259-0e234c061981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28766\n",
      "28766\n"
     ]
    }
   ],
   "source": [
    "print(len(best_predict_test_list))\n",
    "print(len(best_label_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ca4add52-d517-43e0-9139-87c1793852b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_rating_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "valid_rating_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "valid_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_rating_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_rating_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_rating_df2 = pd.DataFrame([x for x in zip(predict_test_list, label_test_list)])\n",
    "test_rating_df2.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "89aae242-13fc-47a3-aad4-d3e06ebb371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/rotten_tomato/ensemble/'\n",
    "train_rating_df.to_csv(path + 'train_rating.csv', index=False)\n",
    "valid_rating_df.to_csv(path + 'valid_rating.csv', index=False)\n",
    "test_rating_df.to_csv(path + 'test_rating.csv', index=False)\n",
    "test_rating_df2.to_csv(path + 'test_rating2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acc35c-e77b-4764-bdb3-47977a789154",
   "metadata": {},
   "source": [
    "### 3-2. sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0884d5c0-8804-4b99-ad4d-02275629f742",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=200, loss=1.5511, mse=1.5494, time=0.0424\n",
      "Iter=400, loss=1.5360, mse=1.5345, time=0.0423\n",
      "Iter=600, loss=1.5444, mse=1.5430, time=0.0434\n",
      "Iter=800, loss=1.4904, mse=1.4891, time=0.0444\n",
      "Iter=1000, loss=1.4986, mse=1.4973, time=0.0460\n",
      "Iter=1200, loss=1.4771, mse=1.4759, time=0.0461\n",
      "Iter=1400, loss=1.4886, mse=1.4875, time=0.0457\n",
      "Iter=1600, loss=1.4702, mse=1.4692, time=0.0453\n",
      "Iter=1800, loss=1.4903, mse=1.4893, time=0.0449\n",
      "Iter=2000, loss=1.4588, mse=1.4578, time=0.0447\n",
      "Iter=2200, loss=1.4533, mse=1.4523, time=0.0446\n",
      "Iter=2400, loss=1.4961, mse=1.4951, time=0.0447\n",
      "Iter=2600, loss=1.4613, mse=1.4604, time=0.0445\n",
      "Iter=2800, loss=1.4696, mse=1.4688, time=0.0443\n",
      "Iter=3000, loss=1.4235, mse=1.4227, time=0.0442\n",
      "Iter=3200, loss=1.4581, mse=1.4573, time=0.0439\n",
      "Iter=3400, loss=1.4327, mse=1.4319, time=0.0443\n",
      "Iter=3600, loss=1.4304, mse=1.4296, time=0.0441\n",
      "Iter=3800, loss=1.4488, mse=1.4481, time=0.0440\n",
      "Iter=4000, loss=1.4846, mse=1.4839, time=0.0438\n",
      "Iter=4200, loss=1.4146, mse=1.4139, time=0.0437\n",
      "Iter=4400, loss=1.4421, mse=1.4415, time=0.0435\n",
      "Iter=4600, loss=1.4221, mse=1.4215, time=0.0434\n",
      "Iter=4800, loss=1.4264, mse=1.4258, time=0.0433\n",
      "Iter=5000, loss=1.4522, mse=1.4516, time=0.0432\n",
      "Iter=5200, loss=1.4285, mse=1.4279, time=0.0431\n",
      "Iter=5400, loss=1.4216, mse=1.4210, time=0.0430\n",
      "Iter=5600, loss=1.4420, mse=1.4414, time=0.0429\n",
      "Iter=5800, loss=1.4583, mse=1.4577, time=0.0428\n",
      "Iter=6000, loss=1.4502, mse=1.4496, time=0.0428\n",
      "Iter=6200, loss=1.4124, mse=1.4118, time=0.0426\n",
      "Iter=6400, loss=1.4064, mse=1.4058, time=0.0426\n",
      "Iter=6600, loss=1.4194, mse=1.4189, time=0.0425\n",
      "=== Epoch 1, train loss 1.458404, test rmse 1.181308 ===\n",
      "Epoch 2\n",
      "Iter=200, loss=1.4036, mse=1.4030, time=0.0425\n",
      "Iter=400, loss=1.4357, mse=1.4351, time=0.0414\n",
      "Iter=600, loss=1.3981, mse=1.3976, time=0.0413\n",
      "Iter=800, loss=1.4193, mse=1.4187, time=0.0411\n",
      "Iter=1000, loss=1.4015, mse=1.4010, time=0.0409\n",
      "Iter=1200, loss=1.4283, mse=1.4278, time=0.0410\n",
      "Iter=1400, loss=1.4207, mse=1.4202, time=0.0409\n",
      "Iter=1600, loss=1.4021, mse=1.4016, time=0.0409\n",
      "Iter=1800, loss=1.4478, mse=1.4473, time=0.0408\n",
      "Iter=2000, loss=1.3985, mse=1.3980, time=0.0408\n",
      "Iter=2200, loss=1.4129, mse=1.4124, time=0.0408\n",
      "Iter=2400, loss=1.4018, mse=1.4012, time=0.0409\n",
      "Iter=2600, loss=1.4266, mse=1.4261, time=0.0408\n",
      "Iter=2800, loss=1.4356, mse=1.4351, time=0.0409\n",
      "Iter=3000, loss=1.4076, mse=1.4070, time=0.0409\n",
      "Iter=3200, loss=1.4033, mse=1.4028, time=0.0409\n",
      "Iter=3400, loss=1.4352, mse=1.4347, time=0.0408\n",
      "Iter=3600, loss=1.4159, mse=1.4153, time=0.0408\n",
      "Iter=3800, loss=1.3699, mse=1.3694, time=0.0408\n",
      "Iter=4000, loss=1.4090, mse=1.4085, time=0.0408\n",
      "Iter=4200, loss=1.3856, mse=1.3851, time=0.0408\n",
      "Iter=4400, loss=1.3858, mse=1.3853, time=0.0408\n",
      "Iter=4600, loss=1.4029, mse=1.4024, time=0.0408\n",
      "Iter=4800, loss=1.3607, mse=1.3602, time=0.0408\n",
      "Iter=5000, loss=1.4081, mse=1.4076, time=0.0408\n",
      "Iter=5200, loss=1.3815, mse=1.3811, time=0.0408\n",
      "Iter=5400, loss=1.4202, mse=1.4198, time=0.0407\n",
      "Iter=5600, loss=1.4340, mse=1.4335, time=0.0407\n",
      "Iter=5800, loss=1.4380, mse=1.4375, time=0.0406\n",
      "Iter=6000, loss=1.4037, mse=1.4032, time=0.0406\n",
      "Iter=6200, loss=1.3816, mse=1.3811, time=0.0406\n",
      "Iter=6400, loss=1.3800, mse=1.3795, time=0.0406\n",
      "Iter=6600, loss=1.4047, mse=1.4042, time=0.0406\n",
      "=== Epoch 2, train loss 1.407492, test rmse 1.178304 ===\n",
      "Epoch 3\n",
      "Iter=200, loss=1.4095, mse=1.4090, time=0.0419\n",
      "Iter=400, loss=1.4465, mse=1.4460, time=0.0411\n",
      "Iter=600, loss=1.3996, mse=1.3991, time=0.0409\n",
      "Iter=800, loss=1.4115, mse=1.4109, time=0.0408\n",
      "Iter=1000, loss=1.3918, mse=1.3912, time=0.0409\n",
      "Iter=1200, loss=1.4003, mse=1.3998, time=0.0409\n",
      "Iter=1400, loss=1.3531, mse=1.3526, time=0.0409\n",
      "Iter=1600, loss=1.3859, mse=1.3855, time=0.0409\n",
      "Iter=1800, loss=1.3899, mse=1.3894, time=0.0410\n",
      "Iter=2000, loss=1.3685, mse=1.3681, time=0.0409\n",
      "Iter=2200, loss=1.3722, mse=1.3717, time=0.0409\n",
      "Iter=2400, loss=1.4320, mse=1.4316, time=0.0409\n",
      "Iter=2600, loss=1.4006, mse=1.4002, time=0.0409\n",
      "Iter=2800, loss=1.4137, mse=1.4132, time=0.0409\n",
      "Iter=3000, loss=1.4104, mse=1.4099, time=0.0409\n",
      "Iter=3200, loss=1.3972, mse=1.3967, time=0.0409\n",
      "Iter=3400, loss=1.4105, mse=1.4100, time=0.0408\n",
      "Iter=3600, loss=1.3699, mse=1.3694, time=0.0408\n",
      "Iter=3800, loss=1.3744, mse=1.3739, time=0.0408\n",
      "Iter=4000, loss=1.4040, mse=1.4035, time=0.0408\n",
      "Iter=4200, loss=1.3641, mse=1.3637, time=0.0408\n",
      "Iter=4400, loss=1.4164, mse=1.4159, time=0.0408\n",
      "Iter=4600, loss=1.3934, mse=1.3929, time=0.0408\n",
      "Iter=4800, loss=1.4072, mse=1.4067, time=0.0408\n",
      "Iter=5000, loss=1.3983, mse=1.3979, time=0.0408\n",
      "Iter=5200, loss=1.4096, mse=1.4092, time=0.0409\n",
      "Iter=5400, loss=1.4076, mse=1.4071, time=0.0409\n",
      "Iter=5600, loss=1.3919, mse=1.3914, time=0.0409\n",
      "Iter=5800, loss=1.3987, mse=1.3982, time=0.0410\n",
      "Iter=6000, loss=1.4191, mse=1.4186, time=0.0411\n",
      "Iter=6200, loss=1.3924, mse=1.3919, time=0.0411\n",
      "Iter=6400, loss=1.4060, mse=1.4056, time=0.0411\n",
      "Iter=6600, loss=1.3821, mse=1.3817, time=0.0411\n",
      "=== Epoch 3, train loss 1.398482, test rmse 1.170668 ===\n",
      "Epoch 4\n",
      "Iter=200, loss=1.3924, mse=1.3920, time=0.0415\n",
      "Iter=400, loss=1.3966, mse=1.3961, time=0.0412\n",
      "Iter=600, loss=1.3704, mse=1.3700, time=0.0409\n",
      "Iter=800, loss=1.4060, mse=1.4055, time=0.0411\n",
      "Iter=1000, loss=1.4207, mse=1.4202, time=0.0409\n",
      "Iter=1200, loss=1.3925, mse=1.3920, time=0.0408\n",
      "Iter=1400, loss=1.3923, mse=1.3918, time=0.0409\n",
      "Iter=1600, loss=1.4049, mse=1.4045, time=0.0408\n",
      "Iter=1800, loss=1.3559, mse=1.3554, time=0.0408\n",
      "Iter=2000, loss=1.4200, mse=1.4196, time=0.0408\n",
      "Iter=2200, loss=1.3866, mse=1.3862, time=0.0407\n",
      "Iter=2400, loss=1.3822, mse=1.3817, time=0.0407\n",
      "Iter=2600, loss=1.3745, mse=1.3741, time=0.0407\n",
      "Iter=2800, loss=1.3841, mse=1.3836, time=0.0407\n",
      "Iter=3000, loss=1.3666, mse=1.3662, time=0.0407\n",
      "Iter=3200, loss=1.4257, mse=1.4253, time=0.0407\n",
      "Iter=3400, loss=1.3989, mse=1.3984, time=0.0407\n",
      "Iter=3600, loss=1.3760, mse=1.3755, time=0.0406\n",
      "Iter=3800, loss=1.4052, mse=1.4047, time=0.0406\n",
      "Iter=4000, loss=1.3835, mse=1.3831, time=0.0405\n",
      "Iter=4200, loss=1.4048, mse=1.4044, time=0.0405\n",
      "Iter=4400, loss=1.4011, mse=1.4007, time=0.0405\n",
      "Iter=4600, loss=1.3796, mse=1.3792, time=0.0406\n",
      "Iter=4800, loss=1.3835, mse=1.3830, time=0.0406\n",
      "Iter=5000, loss=1.3658, mse=1.3653, time=0.0406\n",
      "Iter=5200, loss=1.3711, mse=1.3706, time=0.0406\n",
      "Iter=5400, loss=1.3945, mse=1.3940, time=0.0406\n",
      "Iter=5600, loss=1.4276, mse=1.4272, time=0.0407\n",
      "Iter=5800, loss=1.4227, mse=1.4223, time=0.0406\n",
      "Iter=6000, loss=1.4118, mse=1.4114, time=0.0407\n",
      "Iter=6200, loss=1.4138, mse=1.4133, time=0.0407\n",
      "Iter=6400, loss=1.4039, mse=1.4035, time=0.0407\n",
      "Iter=6600, loss=1.3959, mse=1.3955, time=0.0407\n",
      "=== Epoch 4, train loss 1.394145, test rmse 1.165756 ===\n",
      "Epoch 5\n",
      "Iter=200, loss=1.3766, mse=1.3761, time=0.0418\n",
      "Iter=400, loss=1.3504, mse=1.3499, time=0.0412\n",
      "Iter=600, loss=1.3673, mse=1.3669, time=0.0411\n",
      "Iter=800, loss=1.3690, mse=1.3685, time=0.0409\n",
      "Iter=1000, loss=1.3829, mse=1.3824, time=0.0408\n",
      "Iter=1200, loss=1.3960, mse=1.3955, time=0.0407\n",
      "Iter=1400, loss=1.3643, mse=1.3638, time=0.0406\n",
      "Iter=1600, loss=1.4167, mse=1.4163, time=0.0406\n",
      "Iter=1800, loss=1.3832, mse=1.3827, time=0.0406\n",
      "Iter=2000, loss=1.4047, mse=1.4043, time=0.0407\n",
      "Iter=2200, loss=1.4038, mse=1.4034, time=0.0406\n",
      "Iter=2400, loss=1.3977, mse=1.3973, time=0.0407\n",
      "Iter=2600, loss=1.3851, mse=1.3847, time=0.0406\n",
      "Iter=2800, loss=1.4023, mse=1.4019, time=0.0405\n",
      "Iter=3000, loss=1.3757, mse=1.3753, time=0.0404\n",
      "Iter=3200, loss=1.4477, mse=1.4473, time=0.0404\n",
      "Iter=3400, loss=1.3960, mse=1.3956, time=0.0404\n",
      "Iter=3600, loss=1.3930, mse=1.3926, time=0.0405\n",
      "Iter=3800, loss=1.3844, mse=1.3840, time=0.0405\n",
      "Iter=4000, loss=1.4317, mse=1.4313, time=0.0405\n",
      "Iter=4200, loss=1.3771, mse=1.3767, time=0.0405\n",
      "Iter=4400, loss=1.3948, mse=1.3944, time=0.0405\n",
      "Iter=4600, loss=1.3795, mse=1.3791, time=0.0406\n",
      "Iter=4800, loss=1.4297, mse=1.4292, time=0.0406\n",
      "Iter=5000, loss=1.4156, mse=1.4152, time=0.0406\n",
      "Iter=5200, loss=1.3932, mse=1.3928, time=0.0406\n",
      "Iter=5400, loss=1.3994, mse=1.3989, time=0.0406\n",
      "Iter=5600, loss=1.3601, mse=1.3597, time=0.0406\n",
      "Iter=5800, loss=1.4011, mse=1.4006, time=0.0406\n",
      "Iter=6000, loss=1.3621, mse=1.3617, time=0.0406\n",
      "Iter=6200, loss=1.3813, mse=1.3809, time=0.0406\n",
      "Iter=6400, loss=1.3974, mse=1.3969, time=0.0406\n",
      "Iter=6600, loss=1.3772, mse=1.3768, time=0.0406\n",
      "=== Epoch 5, train loss 1.390404, test rmse 1.169243 ===\n",
      "Epoch 6\n",
      "Iter=200, loss=1.3727, mse=1.3723, time=0.0424\n",
      "Iter=400, loss=1.3880, mse=1.3876, time=0.0414\n",
      "Iter=600, loss=1.3709, mse=1.3704, time=0.0413\n",
      "Iter=800, loss=1.3772, mse=1.3768, time=0.0413\n",
      "Iter=1000, loss=1.3524, mse=1.3520, time=0.0412\n",
      "Iter=1200, loss=1.3882, mse=1.3878, time=0.0410\n",
      "Iter=1400, loss=1.3481, mse=1.3476, time=0.0409\n",
      "Iter=1600, loss=1.3945, mse=1.3941, time=0.0408\n",
      "Iter=1800, loss=1.4204, mse=1.4199, time=0.0407\n",
      "Iter=2000, loss=1.4100, mse=1.4096, time=0.0405\n",
      "Iter=2200, loss=1.4208, mse=1.4204, time=0.0404\n",
      "Iter=2400, loss=1.4009, mse=1.4005, time=0.0404\n",
      "Iter=2600, loss=1.3850, mse=1.3846, time=0.0404\n",
      "Iter=2800, loss=1.4088, mse=1.4084, time=0.0404\n",
      "Iter=3000, loss=1.4076, mse=1.4072, time=0.0405\n",
      "Iter=3200, loss=1.3798, mse=1.3794, time=0.0405\n",
      "Iter=3400, loss=1.3994, mse=1.3990, time=0.0405\n",
      "Iter=3600, loss=1.4081, mse=1.4077, time=0.0406\n",
      "Iter=3800, loss=1.3737, mse=1.3732, time=0.0406\n",
      "Iter=4000, loss=1.4062, mse=1.4058, time=0.0407\n",
      "Iter=4200, loss=1.4015, mse=1.4011, time=0.0407\n",
      "Iter=4400, loss=1.3673, mse=1.3669, time=0.0407\n",
      "Iter=4600, loss=1.3709, mse=1.3705, time=0.0407\n",
      "Iter=4800, loss=1.3856, mse=1.3852, time=0.0407\n",
      "Iter=5000, loss=1.4189, mse=1.4184, time=0.0406\n",
      "Iter=5200, loss=1.3788, mse=1.3783, time=0.0407\n",
      "Iter=5400, loss=1.3427, mse=1.3422, time=0.0407\n",
      "Iter=5600, loss=1.3684, mse=1.3680, time=0.0407\n",
      "Iter=5800, loss=1.3930, mse=1.3926, time=0.0407\n",
      "Iter=6000, loss=1.3943, mse=1.3939, time=0.0407\n",
      "Iter=6200, loss=1.4126, mse=1.4122, time=0.0407\n",
      "Iter=6400, loss=1.4162, mse=1.4158, time=0.0407\n",
      "Iter=6600, loss=1.4407, mse=1.4403, time=0.0407\n",
      "=== Epoch 6, train loss 1.390525, test rmse 1.163907 ===\n",
      "Epoch 7\n",
      "Iter=200, loss=1.3478, mse=1.3474, time=0.0435\n",
      "Iter=400, loss=1.3454, mse=1.3450, time=0.0426\n",
      "Iter=600, loss=1.3985, mse=1.3982, time=0.0417\n",
      "Iter=800, loss=1.3820, mse=1.3816, time=0.0413\n",
      "Iter=1000, loss=1.3532, mse=1.3528, time=0.0407\n",
      "Iter=1200, loss=1.4079, mse=1.4075, time=0.0406\n",
      "Iter=1400, loss=1.3943, mse=1.3939, time=0.0403\n",
      "Iter=1600, loss=1.3633, mse=1.3629, time=0.0403\n",
      "Iter=1800, loss=1.4483, mse=1.4479, time=0.0404\n",
      "Iter=2000, loss=1.3935, mse=1.3931, time=0.0405\n",
      "Iter=2200, loss=1.4054, mse=1.4050, time=0.0405\n",
      "Iter=2400, loss=1.4368, mse=1.4364, time=0.0406\n",
      "Iter=2600, loss=1.3942, mse=1.3938, time=0.0406\n",
      "Iter=2800, loss=1.3832, mse=1.3828, time=0.0406\n",
      "Iter=3000, loss=1.3723, mse=1.3719, time=0.0407\n",
      "Iter=3200, loss=1.4152, mse=1.4148, time=0.0408\n",
      "Iter=3400, loss=1.3971, mse=1.3967, time=0.0408\n",
      "Iter=3600, loss=1.3866, mse=1.3862, time=0.0408\n",
      "Iter=3800, loss=1.3956, mse=1.3952, time=0.0408\n",
      "Iter=4000, loss=1.3960, mse=1.3957, time=0.0407\n",
      "Iter=4200, loss=1.4053, mse=1.4050, time=0.0407\n",
      "Iter=4400, loss=1.4046, mse=1.4042, time=0.0407\n",
      "Iter=4600, loss=1.4049, mse=1.4045, time=0.0407\n",
      "Iter=4800, loss=1.4008, mse=1.4004, time=0.0407\n",
      "Iter=5000, loss=1.3735, mse=1.3731, time=0.0407\n",
      "Iter=5200, loss=1.4032, mse=1.4028, time=0.0407\n",
      "Iter=5400, loss=1.3912, mse=1.3908, time=0.0407\n",
      "Iter=5600, loss=1.4010, mse=1.4006, time=0.0407\n",
      "Iter=5800, loss=1.3835, mse=1.3831, time=0.0407\n",
      "Iter=6000, loss=1.3852, mse=1.3848, time=0.0407\n",
      "Iter=6200, loss=1.3947, mse=1.3943, time=0.0407\n",
      "Iter=6400, loss=1.3629, mse=1.3625, time=0.0407\n",
      "Iter=6600, loss=1.3804, mse=1.3800, time=0.0407\n",
      "=== Epoch 7, train loss 1.391296, test rmse 1.164311 ===\n",
      "Epoch 8\n",
      "Iter=200, loss=1.4002, mse=1.3999, time=0.0406\n",
      "Iter=400, loss=1.3982, mse=1.3978, time=0.0397\n",
      "Iter=600, loss=1.3593, mse=1.3589, time=0.0399\n",
      "Iter=800, loss=1.3816, mse=1.3812, time=0.0401\n",
      "Iter=1000, loss=1.3820, mse=1.3816, time=0.0403\n",
      "Iter=1200, loss=1.4214, mse=1.4210, time=0.0402\n",
      "Iter=1400, loss=1.3926, mse=1.3922, time=0.0404\n",
      "Iter=1600, loss=1.3793, mse=1.3789, time=0.0404\n",
      "Iter=1800, loss=1.3761, mse=1.3757, time=0.0405\n",
      "Iter=2000, loss=1.3658, mse=1.3654, time=0.0405\n",
      "Iter=2200, loss=1.4112, mse=1.4109, time=0.0405\n",
      "Iter=2400, loss=1.4266, mse=1.4262, time=0.0406\n",
      "Iter=2600, loss=1.3723, mse=1.3719, time=0.0406\n",
      "Iter=2800, loss=1.4064, mse=1.4060, time=0.0406\n",
      "Iter=3000, loss=1.3471, mse=1.3467, time=0.0406\n",
      "Iter=3200, loss=1.4040, mse=1.4036, time=0.0406\n",
      "Iter=3400, loss=1.3851, mse=1.3846, time=0.0406\n",
      "Iter=3600, loss=1.3810, mse=1.3806, time=0.0406\n",
      "Iter=3800, loss=1.3845, mse=1.3840, time=0.0407\n",
      "Iter=4000, loss=1.4078, mse=1.4074, time=0.0407\n",
      "Iter=4200, loss=1.3675, mse=1.3671, time=0.0407\n",
      "Iter=4400, loss=1.3896, mse=1.3892, time=0.0407\n",
      "Iter=4600, loss=1.4203, mse=1.4199, time=0.0407\n",
      "Iter=4800, loss=1.4029, mse=1.4025, time=0.0407\n",
      "Iter=5000, loss=1.4116, mse=1.4112, time=0.0407\n",
      "Iter=5200, loss=1.3696, mse=1.3692, time=0.0407\n",
      "Iter=5400, loss=1.3561, mse=1.3557, time=0.0407\n",
      "Iter=5600, loss=1.3700, mse=1.3696, time=0.0407\n",
      "Iter=5800, loss=1.4104, mse=1.4100, time=0.0407\n",
      "Iter=6000, loss=1.4157, mse=1.4153, time=0.0407\n",
      "Iter=6200, loss=1.4033, mse=1.4029, time=0.0407\n",
      "Iter=6400, loss=1.3809, mse=1.3805, time=0.0407\n",
      "Iter=6600, loss=1.3992, mse=1.3988, time=0.0407\n",
      "=== Epoch 8, train loss 1.390189, test rmse 1.165701 ===\n",
      "Epoch 9\n",
      "Iter=200, loss=1.3671, mse=1.3668, time=0.0413\n",
      "Iter=400, loss=1.3847, mse=1.3843, time=0.0412\n",
      "Iter=600, loss=1.3844, mse=1.3840, time=0.0410\n",
      "Iter=800, loss=1.4098, mse=1.4094, time=0.0410\n",
      "Iter=1000, loss=1.4163, mse=1.4159, time=0.0411\n",
      "Iter=1200, loss=1.4146, mse=1.4142, time=0.0411\n",
      "Iter=1400, loss=1.3773, mse=1.3769, time=0.0410\n",
      "Iter=1600, loss=1.3913, mse=1.3909, time=0.0410\n",
      "Iter=1800, loss=1.4044, mse=1.4040, time=0.0410\n",
      "Iter=2000, loss=1.3760, mse=1.3757, time=0.0410\n",
      "Iter=2200, loss=1.4012, mse=1.4008, time=0.0410\n",
      "Iter=2400, loss=1.4050, mse=1.4047, time=0.0409\n",
      "Iter=2600, loss=1.3848, mse=1.3845, time=0.0409\n",
      "Iter=2800, loss=1.4121, mse=1.4117, time=0.0409\n",
      "Iter=3000, loss=1.3629, mse=1.3625, time=0.0409\n",
      "Iter=3200, loss=1.3961, mse=1.3957, time=0.0408\n",
      "Iter=3400, loss=1.3967, mse=1.3963, time=0.0408\n",
      "Iter=3600, loss=1.3697, mse=1.3693, time=0.0408\n",
      "Iter=3800, loss=1.4103, mse=1.4099, time=0.0408\n",
      "Iter=4000, loss=1.3899, mse=1.3896, time=0.0408\n",
      "Iter=4200, loss=1.4072, mse=1.4068, time=0.0408\n",
      "Iter=4400, loss=1.3631, mse=1.3627, time=0.0409\n",
      "Iter=4600, loss=1.4052, mse=1.4048, time=0.0408\n",
      "Iter=4800, loss=1.3607, mse=1.3604, time=0.0408\n",
      "Iter=5000, loss=1.4053, mse=1.4049, time=0.0408\n",
      "Iter=5200, loss=1.3871, mse=1.3867, time=0.0408\n",
      "Iter=5400, loss=1.3688, mse=1.3684, time=0.0408\n",
      "Iter=5600, loss=1.3566, mse=1.3563, time=0.0408\n",
      "Iter=5800, loss=1.3717, mse=1.3713, time=0.0408\n",
      "Iter=6000, loss=1.3779, mse=1.3776, time=0.0408\n",
      "Iter=6200, loss=1.3941, mse=1.3937, time=0.0408\n",
      "Iter=6400, loss=1.3641, mse=1.3637, time=0.0408\n",
      "Iter=6600, loss=1.3775, mse=1.3771, time=0.0407\n",
      "=== Epoch 9, train loss 1.388560, test rmse 1.169393 ===\n",
      "Epoch 10\n",
      "Iter=200, loss=1.3764, mse=1.3760, time=0.0431\n",
      "Iter=400, loss=1.3746, mse=1.3742, time=0.0415\n",
      "Iter=600, loss=1.4447, mse=1.4444, time=0.0412\n",
      "Iter=800, loss=1.4223, mse=1.4219, time=0.0410\n",
      "Iter=1000, loss=1.3726, mse=1.3722, time=0.0410\n",
      "Iter=1200, loss=1.3816, mse=1.3812, time=0.0409\n",
      "Iter=1400, loss=1.4058, mse=1.4054, time=0.0411\n",
      "Iter=1600, loss=1.3838, mse=1.3834, time=0.0410\n",
      "Iter=1800, loss=1.3923, mse=1.3919, time=0.0410\n",
      "Iter=2000, loss=1.3987, mse=1.3983, time=0.0409\n",
      "Iter=2200, loss=1.3865, mse=1.3862, time=0.0409\n",
      "Iter=2400, loss=1.3904, mse=1.3900, time=0.0409\n",
      "Iter=2600, loss=1.3910, mse=1.3906, time=0.0409\n",
      "Iter=2800, loss=1.4126, mse=1.4122, time=0.0409\n",
      "Iter=3000, loss=1.3872, mse=1.3868, time=0.0408\n",
      "Iter=3200, loss=1.3635, mse=1.3631, time=0.0408\n",
      "Iter=3400, loss=1.3959, mse=1.3955, time=0.0408\n",
      "Iter=3600, loss=1.4110, mse=1.4107, time=0.0408\n",
      "Iter=3800, loss=1.3797, mse=1.3793, time=0.0408\n",
      "Iter=4000, loss=1.3691, mse=1.3687, time=0.0408\n",
      "Iter=4200, loss=1.4269, mse=1.4265, time=0.0408\n",
      "Iter=4400, loss=1.3677, mse=1.3673, time=0.0408\n",
      "Iter=4600, loss=1.3715, mse=1.3711, time=0.0408\n",
      "Iter=4800, loss=1.3804, mse=1.3800, time=0.0408\n",
      "Iter=5000, loss=1.3950, mse=1.3945, time=0.0408\n",
      "Iter=5200, loss=1.3998, mse=1.3994, time=0.0408\n",
      "Iter=5400, loss=1.4275, mse=1.4271, time=0.0407\n",
      "Iter=5600, loss=1.3529, mse=1.3526, time=0.0407\n",
      "Iter=5800, loss=1.4167, mse=1.4164, time=0.0407\n",
      "Iter=6000, loss=1.3903, mse=1.3899, time=0.0406\n",
      "Iter=6200, loss=1.3756, mse=1.3752, time=0.0406\n",
      "Iter=6400, loss=1.3802, mse=1.3798, time=0.0406\n",
      "Iter=6600, loss=1.3884, mse=1.3880, time=0.0406\n",
      "=== Epoch 10, train loss 1.390589, test rmse 1.168470 ===\n",
      "Epoch 11\n",
      "Iter=200, loss=1.4047, mse=1.4043, time=0.0416\n",
      "Iter=400, loss=1.3930, mse=1.3926, time=0.0413\n",
      "Iter=600, loss=1.3785, mse=1.3781, time=0.0410\n",
      "Iter=800, loss=1.4089, mse=1.4085, time=0.0410\n",
      "Iter=1000, loss=1.3489, mse=1.3485, time=0.0410\n",
      "Iter=1200, loss=1.4140, mse=1.4136, time=0.0409\n",
      "Iter=1400, loss=1.4101, mse=1.4098, time=0.0409\n",
      "Iter=1600, loss=1.4049, mse=1.4046, time=0.0410\n",
      "Iter=1800, loss=1.4059, mse=1.4056, time=0.0410\n",
      "Iter=2000, loss=1.4172, mse=1.4169, time=0.0409\n",
      "Iter=2200, loss=1.4206, mse=1.4203, time=0.0409\n",
      "Iter=2400, loss=1.3844, mse=1.3841, time=0.0408\n",
      "Iter=2600, loss=1.4014, mse=1.4011, time=0.0408\n",
      "Iter=2800, loss=1.3659, mse=1.3655, time=0.0408\n",
      "Iter=3000, loss=1.3972, mse=1.3968, time=0.0408\n",
      "Iter=3200, loss=1.3850, mse=1.3846, time=0.0408\n",
      "Iter=3400, loss=1.3723, mse=1.3719, time=0.0408\n",
      "Iter=3600, loss=1.4092, mse=1.4089, time=0.0408\n",
      "Iter=3800, loss=1.3442, mse=1.3438, time=0.0408\n",
      "Iter=4000, loss=1.3715, mse=1.3711, time=0.0408\n",
      "Iter=4200, loss=1.3625, mse=1.3621, time=0.0407\n",
      "Iter=4400, loss=1.3492, mse=1.3488, time=0.0407\n",
      "Iter=4600, loss=1.4089, mse=1.4085, time=0.0407\n",
      "Iter=4800, loss=1.4012, mse=1.4008, time=0.0406\n",
      "Iter=5000, loss=1.4104, mse=1.4100, time=0.0406\n",
      "Iter=5200, loss=1.4213, mse=1.4210, time=0.0406\n",
      "Iter=5400, loss=1.3644, mse=1.3640, time=0.0406\n",
      "Iter=5600, loss=1.3419, mse=1.3415, time=0.0406\n",
      "Iter=5800, loss=1.4026, mse=1.4023, time=0.0406\n",
      "Iter=6000, loss=1.3816, mse=1.3812, time=0.0406\n",
      "Iter=6200, loss=1.3923, mse=1.3919, time=0.0406\n",
      "Iter=6400, loss=1.3831, mse=1.3828, time=0.0407\n",
      "Iter=6600, loss=1.3990, mse=1.3987, time=0.0407\n",
      "=== Epoch 11, train loss 1.390163, test rmse 1.163835 ===\n",
      "Epoch 12\n",
      "Iter=200, loss=1.3803, mse=1.3799, time=0.0423\n",
      "Iter=400, loss=1.4289, mse=1.4285, time=0.0414\n",
      "Iter=600, loss=1.3872, mse=1.3869, time=0.0414\n",
      "Iter=800, loss=1.4070, mse=1.4066, time=0.0411\n",
      "Iter=1000, loss=1.3994, mse=1.3990, time=0.0411\n",
      "Iter=1200, loss=1.3829, mse=1.3826, time=0.0411\n",
      "Iter=1400, loss=1.3760, mse=1.3756, time=0.0410\n",
      "Iter=1600, loss=1.3717, mse=1.3713, time=0.0410\n",
      "Iter=1800, loss=1.3670, mse=1.3667, time=0.0410\n",
      "Iter=2000, loss=1.3568, mse=1.3564, time=0.0410\n",
      "Iter=2200, loss=1.3963, mse=1.3959, time=0.0409\n",
      "Iter=2400, loss=1.3913, mse=1.3909, time=0.0409\n",
      "Iter=2600, loss=1.4062, mse=1.4058, time=0.0409\n",
      "Iter=2800, loss=1.3808, mse=1.3805, time=0.0409\n",
      "Iter=3000, loss=1.3949, mse=1.3946, time=0.0409\n",
      "Iter=3200, loss=1.3963, mse=1.3960, time=0.0408\n",
      "Iter=3400, loss=1.4185, mse=1.4181, time=0.0408\n",
      "Iter=3600, loss=1.4099, mse=1.4096, time=0.0407\n",
      "Iter=3800, loss=1.3842, mse=1.3838, time=0.0406\n",
      "Iter=4000, loss=1.3870, mse=1.3866, time=0.0406\n",
      "Iter=4200, loss=1.3926, mse=1.3923, time=0.0406\n",
      "Iter=4400, loss=1.4126, mse=1.4123, time=0.0406\n",
      "Iter=4600, loss=1.3749, mse=1.3746, time=0.0406\n",
      "Iter=4800, loss=1.3870, mse=1.3867, time=0.0406\n",
      "Iter=5000, loss=1.3772, mse=1.3768, time=0.0406\n",
      "Iter=5200, loss=1.3927, mse=1.3923, time=0.0406\n",
      "Iter=5400, loss=1.3856, mse=1.3853, time=0.0406\n",
      "Iter=5600, loss=1.3965, mse=1.3961, time=0.0406\n",
      "Iter=5800, loss=1.3653, mse=1.3649, time=0.0407\n",
      "Iter=6000, loss=1.3874, mse=1.3870, time=0.0406\n",
      "Iter=6200, loss=1.4206, mse=1.4203, time=0.0406\n",
      "Iter=6400, loss=1.3773, mse=1.3769, time=0.0406\n",
      "Iter=6600, loss=1.3775, mse=1.3771, time=0.0406\n",
      "=== Epoch 12, train loss 1.390117, test rmse 1.168544 ===\n",
      "Epoch 13\n",
      "Iter=200, loss=1.3629, mse=1.3626, time=0.0424\n",
      "Iter=400, loss=1.3860, mse=1.3857, time=0.0414\n",
      "Iter=600, loss=1.3995, mse=1.3992, time=0.0411\n",
      "Iter=800, loss=1.4023, mse=1.4020, time=0.0409\n",
      "Iter=1000, loss=1.3734, mse=1.3731, time=0.0411\n",
      "Iter=1200, loss=1.3753, mse=1.3750, time=0.0409\n",
      "Iter=1400, loss=1.3737, mse=1.3734, time=0.0410\n",
      "Iter=1600, loss=1.4308, mse=1.4305, time=0.0409\n",
      "Iter=1800, loss=1.3708, mse=1.3704, time=0.0409\n",
      "Iter=2000, loss=1.3874, mse=1.3870, time=0.0408\n",
      "Iter=2200, loss=1.3894, mse=1.3891, time=0.0408\n",
      "Iter=2400, loss=1.3948, mse=1.3944, time=0.0408\n",
      "Iter=2600, loss=1.4206, mse=1.4202, time=0.0408\n",
      "Iter=2800, loss=1.3743, mse=1.3739, time=0.0407\n",
      "Iter=3000, loss=1.3812, mse=1.3809, time=0.0406\n",
      "Iter=3200, loss=1.3849, mse=1.3846, time=0.0405\n",
      "Iter=3400, loss=1.3733, mse=1.3730, time=0.0405\n",
      "Iter=3600, loss=1.4024, mse=1.4021, time=0.0405\n",
      "Iter=3800, loss=1.3929, mse=1.3926, time=0.0405\n",
      "Iter=4000, loss=1.3861, mse=1.3858, time=0.0406\n",
      "Iter=4200, loss=1.3579, mse=1.3575, time=0.0406\n",
      "Iter=4400, loss=1.4019, mse=1.4016, time=0.0406\n",
      "Iter=4600, loss=1.3739, mse=1.3736, time=0.0407\n",
      "Iter=4800, loss=1.3964, mse=1.3961, time=0.0407\n",
      "Iter=5000, loss=1.3996, mse=1.3993, time=0.0406\n",
      "Iter=5200, loss=1.3899, mse=1.3895, time=0.0406\n",
      "Iter=5400, loss=1.3672, mse=1.3669, time=0.0406\n",
      "Iter=5600, loss=1.4034, mse=1.4031, time=0.0406\n",
      "Iter=5800, loss=1.4070, mse=1.4066, time=0.0406\n",
      "Iter=6000, loss=1.3870, mse=1.3866, time=0.0406\n",
      "Iter=6200, loss=1.3794, mse=1.3791, time=0.0406\n",
      "Iter=6400, loss=1.4220, mse=1.4217, time=0.0406\n",
      "Iter=6600, loss=1.3961, mse=1.3958, time=0.0406\n",
      "=== Epoch 13, train loss 1.389266, test rmse 1.169462 ===\n",
      "Epoch 14\n",
      "Iter=200, loss=1.3677, mse=1.3674, time=0.0419\n",
      "Iter=400, loss=1.3699, mse=1.3695, time=0.0411\n",
      "Iter=600, loss=1.3727, mse=1.3723, time=0.0410\n",
      "Iter=800, loss=1.3888, mse=1.3884, time=0.0410\n",
      "Iter=1000, loss=1.3763, mse=1.3760, time=0.0408\n",
      "Iter=1200, loss=1.4003, mse=1.4000, time=0.0408\n",
      "Iter=1400, loss=1.4079, mse=1.4076, time=0.0408\n",
      "Iter=1600, loss=1.3998, mse=1.3995, time=0.0407\n",
      "Iter=1800, loss=1.3646, mse=1.3643, time=0.0406\n",
      "Iter=2000, loss=1.4097, mse=1.4094, time=0.0405\n",
      "Iter=2200, loss=1.4059, mse=1.4056, time=0.0405\n",
      "Iter=2400, loss=1.3736, mse=1.3733, time=0.0406\n",
      "Iter=2600, loss=1.3838, mse=1.3834, time=0.0406\n",
      "Iter=2800, loss=1.3873, mse=1.3869, time=0.0406\n",
      "Iter=3000, loss=1.3734, mse=1.3731, time=0.0407\n",
      "Iter=3200, loss=1.3818, mse=1.3815, time=0.0407\n",
      "Iter=3400, loss=1.3910, mse=1.3907, time=0.0407\n",
      "Iter=3600, loss=1.3946, mse=1.3943, time=0.0407\n",
      "Iter=3800, loss=1.4097, mse=1.4094, time=0.0408\n",
      "Iter=4000, loss=1.3692, mse=1.3689, time=0.0407\n",
      "Iter=4200, loss=1.4132, mse=1.4129, time=0.0408\n",
      "Iter=4400, loss=1.3793, mse=1.3790, time=0.0407\n",
      "Iter=4600, loss=1.4011, mse=1.4008, time=0.0408\n",
      "Iter=4800, loss=1.3669, mse=1.3666, time=0.0407\n",
      "Iter=5000, loss=1.3722, mse=1.3719, time=0.0407\n",
      "Iter=5200, loss=1.3715, mse=1.3712, time=0.0407\n",
      "Iter=5400, loss=1.3973, mse=1.3970, time=0.0407\n",
      "Iter=5600, loss=1.3731, mse=1.3727, time=0.0407\n",
      "Iter=5800, loss=1.3912, mse=1.3909, time=0.0407\n",
      "Iter=6000, loss=1.4045, mse=1.4042, time=0.0407\n",
      "Iter=6200, loss=1.3828, mse=1.3825, time=0.0407\n",
      "Iter=6400, loss=1.4143, mse=1.4139, time=0.0407\n",
      "Iter=6600, loss=1.4096, mse=1.4093, time=0.0407\n",
      "=== Epoch 14, train loss 1.388760, test rmse 1.164884 ===\n",
      "Epoch 15\n",
      "Iter=200, loss=1.3767, mse=1.3763, time=0.0419\n",
      "Iter=400, loss=1.4024, mse=1.4021, time=0.0413\n",
      "Iter=600, loss=1.3838, mse=1.3835, time=0.0410\n",
      "Iter=800, loss=1.3895, mse=1.3892, time=0.0406\n",
      "Iter=1000, loss=1.3917, mse=1.3913, time=0.0404\n",
      "Iter=1200, loss=1.3853, mse=1.3850, time=0.0403\n",
      "Iter=1400, loss=1.3714, mse=1.3710, time=0.0404\n",
      "Iter=1600, loss=1.3712, mse=1.3708, time=0.0404\n",
      "Iter=1800, loss=1.3910, mse=1.3906, time=0.0405\n",
      "Iter=2000, loss=1.3955, mse=1.3951, time=0.0405\n",
      "Iter=2200, loss=1.3835, mse=1.3831, time=0.0405\n",
      "Iter=2400, loss=1.3792, mse=1.3789, time=0.0406\n",
      "Iter=2600, loss=1.3626, mse=1.3622, time=0.0406\n",
      "Iter=2800, loss=1.4080, mse=1.4077, time=0.0407\n",
      "Iter=3000, loss=1.4086, mse=1.4083, time=0.0407\n",
      "Iter=3200, loss=1.3560, mse=1.3556, time=0.0406\n",
      "Iter=3400, loss=1.3791, mse=1.3788, time=0.0407\n",
      "Iter=3600, loss=1.4100, mse=1.4097, time=0.0407\n",
      "Iter=3800, loss=1.4287, mse=1.4284, time=0.0407\n",
      "Iter=4000, loss=1.3754, mse=1.3751, time=0.0407\n",
      "Iter=4200, loss=1.4064, mse=1.4061, time=0.0407\n",
      "Iter=4400, loss=1.3793, mse=1.3790, time=0.0407\n",
      "Iter=4600, loss=1.4079, mse=1.4076, time=0.0407\n",
      "Iter=4800, loss=1.3841, mse=1.3838, time=0.0407\n",
      "Iter=5000, loss=1.4158, mse=1.4155, time=0.0407\n",
      "Iter=5200, loss=1.3756, mse=1.3753, time=0.0407\n",
      "Iter=5400, loss=1.3895, mse=1.3891, time=0.0407\n",
      "Iter=5600, loss=1.3844, mse=1.3841, time=0.0407\n",
      "Iter=5800, loss=1.4025, mse=1.4021, time=0.0407\n",
      "Iter=6000, loss=1.4068, mse=1.4065, time=0.0407\n",
      "Iter=6200, loss=1.3951, mse=1.3948, time=0.0407\n",
      "Iter=6400, loss=1.3599, mse=1.3596, time=0.0408\n",
      "Iter=6600, loss=1.4003, mse=1.4000, time=0.0409\n",
      "=== Epoch 15, train loss 1.389058, test rmse 1.163720 ===\n",
      "Epoch 16\n",
      "Iter=200, loss=1.3747, mse=1.3743, time=0.0413\n",
      "Iter=400, loss=1.3713, mse=1.3710, time=0.0410\n",
      "Iter=600, loss=1.3864, mse=1.3861, time=0.0408\n",
      "Iter=800, loss=1.3988, mse=1.3984, time=0.0410\n",
      "Iter=1000, loss=1.4321, mse=1.4318, time=0.0409\n",
      "Iter=1200, loss=1.4058, mse=1.4055, time=0.0408\n",
      "Iter=1400, loss=1.3628, mse=1.3625, time=0.0408\n",
      "Iter=1600, loss=1.4180, mse=1.4176, time=0.0408\n",
      "Iter=1800, loss=1.3626, mse=1.3622, time=0.0408\n",
      "Iter=2000, loss=1.3916, mse=1.3912, time=0.0407\n",
      "Iter=2200, loss=1.3922, mse=1.3918, time=0.0407\n",
      "Iter=2400, loss=1.3940, mse=1.3936, time=0.0407\n",
      "Iter=2600, loss=1.4286, mse=1.4283, time=0.0406\n",
      "Iter=2800, loss=1.3473, mse=1.3470, time=0.0406\n",
      "Iter=3000, loss=1.3595, mse=1.3592, time=0.0407\n",
      "Iter=3200, loss=1.3820, mse=1.3817, time=0.0407\n",
      "Iter=3400, loss=1.4052, mse=1.4049, time=0.0407\n",
      "Iter=3600, loss=1.3936, mse=1.3933, time=0.0407\n",
      "Iter=3800, loss=1.4117, mse=1.4113, time=0.0407\n",
      "Iter=4000, loss=1.4000, mse=1.3997, time=0.0408\n",
      "Iter=4200, loss=1.3866, mse=1.3863, time=0.0408\n",
      "Iter=4400, loss=1.3957, mse=1.3954, time=0.0408\n",
      "Iter=4600, loss=1.3583, mse=1.3580, time=0.0409\n",
      "Iter=4800, loss=1.4133, mse=1.4130, time=0.0410\n",
      "Iter=5000, loss=1.3908, mse=1.3905, time=0.0410\n",
      "Iter=5200, loss=1.3753, mse=1.3750, time=0.0410\n",
      "Iter=5400, loss=1.3794, mse=1.3791, time=0.0410\n",
      "Iter=5600, loss=1.3727, mse=1.3724, time=0.0410\n",
      "Iter=5800, loss=1.3887, mse=1.3884, time=0.0410\n",
      "Iter=6000, loss=1.4016, mse=1.4012, time=0.0410\n",
      "Iter=6200, loss=1.3642, mse=1.3638, time=0.0410\n",
      "Iter=6400, loss=1.3873, mse=1.3869, time=0.0409\n",
      "Iter=6600, loss=1.4296, mse=1.4292, time=0.0409\n",
      "=== Epoch 16, train loss 1.389296, test rmse 1.171993 ===\n",
      "Epoch 17\n",
      "Iter=200, loss=1.3919, mse=1.3915, time=0.0419\n",
      "Iter=400, loss=1.3950, mse=1.3946, time=0.0413\n",
      "Iter=600, loss=1.3814, mse=1.3810, time=0.0413\n",
      "Iter=800, loss=1.3974, mse=1.3971, time=0.0413\n",
      "Iter=1000, loss=1.3664, mse=1.3661, time=0.0411\n",
      "Iter=1200, loss=1.4085, mse=1.4082, time=0.0411\n",
      "Iter=1400, loss=1.3937, mse=1.3934, time=0.0409\n",
      "Iter=1600, loss=1.3728, mse=1.3725, time=0.0409\n",
      "Iter=1800, loss=1.3653, mse=1.3650, time=0.0409\n",
      "Iter=2000, loss=1.3817, mse=1.3814, time=0.0409\n",
      "Iter=2200, loss=1.3714, mse=1.3711, time=0.0409\n",
      "Iter=2400, loss=1.3884, mse=1.3881, time=0.0409\n",
      "Iter=2600, loss=1.3871, mse=1.3867, time=0.0409\n",
      "Iter=2800, loss=1.4277, mse=1.4273, time=0.0409\n",
      "Iter=3000, loss=1.3844, mse=1.3840, time=0.0409\n",
      "Iter=3200, loss=1.4150, mse=1.4146, time=0.0409\n",
      "Iter=3400, loss=1.4025, mse=1.4021, time=0.0409\n",
      "Iter=3600, loss=1.4040, mse=1.4037, time=0.0409\n",
      "Iter=3800, loss=1.4058, mse=1.4054, time=0.0408\n",
      "Iter=4000, loss=1.3998, mse=1.3995, time=0.0408\n",
      "Iter=4200, loss=1.3673, mse=1.3669, time=0.0408\n",
      "Iter=4400, loss=1.3653, mse=1.3650, time=0.0408\n",
      "Iter=4600, loss=1.4340, mse=1.4337, time=0.0408\n",
      "Iter=4800, loss=1.4089, mse=1.4086, time=0.0408\n",
      "Iter=5000, loss=1.4024, mse=1.4021, time=0.0408\n",
      "Iter=5200, loss=1.3806, mse=1.3803, time=0.0408\n",
      "Iter=5400, loss=1.3981, mse=1.3977, time=0.0408\n",
      "Iter=5600, loss=1.3879, mse=1.3875, time=0.0408\n",
      "Iter=5800, loss=1.3626, mse=1.3623, time=0.0408\n",
      "Iter=6000, loss=1.3974, mse=1.3971, time=0.0408\n",
      "Iter=6200, loss=1.3278, mse=1.3275, time=0.0407\n",
      "Iter=6400, loss=1.3748, mse=1.3745, time=0.0407\n",
      "Iter=6600, loss=1.3927, mse=1.3924, time=0.0406\n",
      "=== Epoch 17, train loss 1.389014, test rmse 1.166167 ===\n",
      "Epoch 18\n",
      "Iter=200, loss=1.3530, mse=1.3527, time=0.0421\n",
      "Iter=400, loss=1.3521, mse=1.3518, time=0.0410\n",
      "Iter=600, loss=1.3938, mse=1.3934, time=0.0409\n",
      "Iter=800, loss=1.4267, mse=1.4263, time=0.0408\n",
      "Iter=1000, loss=1.3829, mse=1.3826, time=0.0408\n",
      "Iter=1200, loss=1.3632, mse=1.3629, time=0.0408\n",
      "Iter=1400, loss=1.3840, mse=1.3837, time=0.0408\n",
      "Iter=1600, loss=1.3658, mse=1.3654, time=0.0408\n",
      "Iter=1800, loss=1.4033, mse=1.4029, time=0.0409\n",
      "Iter=2000, loss=1.3709, mse=1.3706, time=0.0408\n",
      "Iter=2200, loss=1.3790, mse=1.3787, time=0.0408\n",
      "Iter=2400, loss=1.3842, mse=1.3839, time=0.0408\n",
      "Iter=2600, loss=1.3630, mse=1.3627, time=0.0408\n",
      "Iter=2800, loss=1.3687, mse=1.3684, time=0.0408\n",
      "Iter=3000, loss=1.3998, mse=1.3995, time=0.0408\n",
      "Iter=3200, loss=1.3987, mse=1.3984, time=0.0408\n",
      "Iter=3400, loss=1.4062, mse=1.4059, time=0.0408\n",
      "Iter=3600, loss=1.4136, mse=1.4133, time=0.0408\n",
      "Iter=3800, loss=1.3797, mse=1.3794, time=0.0408\n",
      "Iter=4000, loss=1.3953, mse=1.3950, time=0.0408\n",
      "Iter=4200, loss=1.3625, mse=1.3622, time=0.0408\n",
      "Iter=4400, loss=1.4129, mse=1.4125, time=0.0408\n",
      "Iter=4600, loss=1.3919, mse=1.3916, time=0.0408\n",
      "Iter=4800, loss=1.4138, mse=1.4135, time=0.0408\n",
      "Iter=5000, loss=1.4037, mse=1.4034, time=0.0408\n",
      "Iter=5200, loss=1.3722, mse=1.3719, time=0.0407\n",
      "Iter=5400, loss=1.4337, mse=1.4334, time=0.0407\n",
      "Iter=5600, loss=1.3797, mse=1.3794, time=0.0406\n",
      "Iter=5800, loss=1.3947, mse=1.3943, time=0.0407\n",
      "Iter=6000, loss=1.3583, mse=1.3579, time=0.0407\n",
      "Iter=6200, loss=1.4011, mse=1.4007, time=0.0407\n",
      "Iter=6400, loss=1.4013, mse=1.4009, time=0.0407\n",
      "Iter=6600, loss=1.3649, mse=1.3646, time=0.0407\n",
      "=== Epoch 18, train loss 1.387804, test rmse 1.165306 ===\n",
      "Epoch 19\n",
      "Iter=200, loss=1.4168, mse=1.4165, time=0.0415\n",
      "Iter=400, loss=1.4275, mse=1.4271, time=0.0415\n",
      "Iter=600, loss=1.3843, mse=1.3839, time=0.0412\n",
      "Iter=800, loss=1.3988, mse=1.3984, time=0.0411\n",
      "Iter=1000, loss=1.4029, mse=1.4025, time=0.0410\n",
      "Iter=1200, loss=1.3643, mse=1.3639, time=0.0410\n",
      "Iter=1400, loss=1.3711, mse=1.3707, time=0.0410\n",
      "Iter=1600, loss=1.3560, mse=1.3556, time=0.0409\n",
      "Iter=1800, loss=1.3923, mse=1.3919, time=0.0409\n",
      "Iter=2000, loss=1.4322, mse=1.4319, time=0.0408\n",
      "Iter=2200, loss=1.3940, mse=1.3936, time=0.0409\n",
      "Iter=2400, loss=1.4045, mse=1.4041, time=0.0409\n",
      "Iter=2600, loss=1.3921, mse=1.3917, time=0.0408\n",
      "Iter=2800, loss=1.4048, mse=1.4044, time=0.0408\n",
      "Iter=3000, loss=1.3893, mse=1.3890, time=0.0408\n",
      "Iter=3200, loss=1.3772, mse=1.3769, time=0.0408\n",
      "Iter=3400, loss=1.3902, mse=1.3898, time=0.0408\n",
      "Iter=3600, loss=1.3802, mse=1.3798, time=0.0408\n",
      "Iter=3800, loss=1.3847, mse=1.3843, time=0.0408\n",
      "Iter=4000, loss=1.3401, mse=1.3398, time=0.0408\n",
      "Iter=4200, loss=1.3865, mse=1.3861, time=0.0407\n",
      "Iter=4400, loss=1.3681, mse=1.3677, time=0.0407\n",
      "Iter=4600, loss=1.3667, mse=1.3663, time=0.0407\n",
      "Iter=4800, loss=1.4032, mse=1.4029, time=0.0407\n",
      "Iter=5000, loss=1.3996, mse=1.3993, time=0.0407\n",
      "Iter=5200, loss=1.3771, mse=1.3768, time=0.0407\n",
      "Iter=5400, loss=1.3562, mse=1.3559, time=0.0407\n",
      "Iter=5600, loss=1.4021, mse=1.4017, time=0.0407\n",
      "Iter=5800, loss=1.4118, mse=1.4114, time=0.0407\n",
      "Iter=6000, loss=1.3705, mse=1.3701, time=0.0407\n",
      "Iter=6200, loss=1.3802, mse=1.3799, time=0.0407\n",
      "Iter=6400, loss=1.4029, mse=1.4025, time=0.0407\n",
      "Iter=6600, loss=1.3610, mse=1.3606, time=0.0407\n",
      "=== Epoch 19, train loss 1.388022, test rmse 1.164883 ===\n",
      "Epoch 20\n",
      "Iter=200, loss=1.3978, mse=1.3975, time=0.0423\n",
      "Iter=400, loss=1.3937, mse=1.3934, time=0.0414\n",
      "Iter=600, loss=1.4031, mse=1.4027, time=0.0410\n",
      "Iter=800, loss=1.3991, mse=1.3987, time=0.0409\n",
      "Iter=1000, loss=1.3656, mse=1.3653, time=0.0409\n",
      "Iter=1200, loss=1.3739, mse=1.3735, time=0.0409\n",
      "Iter=1400, loss=1.3787, mse=1.3783, time=0.0408\n",
      "Iter=1600, loss=1.3806, mse=1.3803, time=0.0408\n",
      "Iter=1800, loss=1.4098, mse=1.4094, time=0.0407\n",
      "Iter=2000, loss=1.3850, mse=1.3847, time=0.0408\n",
      "Iter=2200, loss=1.3615, mse=1.3611, time=0.0407\n",
      "Iter=2400, loss=1.3914, mse=1.3911, time=0.0408\n",
      "Iter=2600, loss=1.4167, mse=1.4164, time=0.0408\n",
      "Iter=2800, loss=1.3819, mse=1.3816, time=0.0408\n",
      "Iter=3000, loss=1.3667, mse=1.3663, time=0.0406\n",
      "Iter=3200, loss=1.4049, mse=1.4046, time=0.0406\n",
      "Iter=3400, loss=1.4157, mse=1.4154, time=0.0405\n",
      "Iter=3600, loss=1.3807, mse=1.3803, time=0.0405\n",
      "Iter=3800, loss=1.3348, mse=1.3345, time=0.0405\n",
      "Iter=4000, loss=1.3903, mse=1.3899, time=0.0405\n",
      "Iter=4200, loss=1.3591, mse=1.3587, time=0.0405\n",
      "Iter=4400, loss=1.4010, mse=1.4006, time=0.0406\n",
      "Iter=4600, loss=1.3963, mse=1.3959, time=0.0406\n",
      "Iter=4800, loss=1.3783, mse=1.3779, time=0.0406\n",
      "Iter=5000, loss=1.4103, mse=1.4099, time=0.0406\n",
      "Iter=5200, loss=1.4073, mse=1.4069, time=0.0406\n",
      "Iter=5400, loss=1.4022, mse=1.4018, time=0.0406\n",
      "Iter=5600, loss=1.3799, mse=1.3795, time=0.0406\n",
      "Iter=5800, loss=1.3819, mse=1.3815, time=0.0406\n",
      "Iter=6000, loss=1.3930, mse=1.3927, time=0.0406\n",
      "Iter=6200, loss=1.4008, mse=1.4005, time=0.0406\n",
      "Iter=6400, loss=1.3823, mse=1.3820, time=0.0406\n",
      "Iter=6600, loss=1.3588, mse=1.3584, time=0.0406\n",
      "=== Epoch 20, train loss 1.386195, test rmse 1.166451 ===\n",
      "Epoch 21\n",
      "Iter=200, loss=1.3945, mse=1.3942, time=0.0425\n",
      "Iter=400, loss=1.3765, mse=1.3762, time=0.0414\n",
      "Iter=600, loss=1.4071, mse=1.4068, time=0.0414\n",
      "Iter=800, loss=1.3717, mse=1.3714, time=0.0411\n",
      "Iter=1000, loss=1.3756, mse=1.3752, time=0.0410\n",
      "Iter=1200, loss=1.4090, mse=1.4087, time=0.0409\n",
      "Iter=1400, loss=1.4141, mse=1.4137, time=0.0409\n",
      "Iter=1600, loss=1.4093, mse=1.4090, time=0.0409\n",
      "Iter=1800, loss=1.4081, mse=1.4078, time=0.0409\n",
      "Iter=2000, loss=1.3769, mse=1.3766, time=0.0408\n",
      "Iter=2200, loss=1.3938, mse=1.3935, time=0.0407\n",
      "Iter=2400, loss=1.3773, mse=1.3770, time=0.0406\n",
      "Iter=2600, loss=1.3916, mse=1.3912, time=0.0405\n",
      "Iter=2800, loss=1.3857, mse=1.3853, time=0.0405\n",
      "Iter=3000, loss=1.3848, mse=1.3845, time=0.0405\n",
      "Iter=3200, loss=1.3647, mse=1.3644, time=0.0405\n",
      "Iter=3400, loss=1.3813, mse=1.3810, time=0.0405\n",
      "Iter=3600, loss=1.3873, mse=1.3869, time=0.0406\n",
      "Iter=3800, loss=1.4052, mse=1.4049, time=0.0406\n",
      "Iter=4000, loss=1.3964, mse=1.3961, time=0.0406\n",
      "Iter=4200, loss=1.3911, mse=1.3907, time=0.0407\n",
      "Iter=4400, loss=1.3696, mse=1.3693, time=0.0407\n",
      "Iter=4600, loss=1.4072, mse=1.4068, time=0.0407\n",
      "Iter=4800, loss=1.3365, mse=1.3362, time=0.0407\n",
      "Iter=5000, loss=1.3917, mse=1.3914, time=0.0407\n",
      "Iter=5200, loss=1.3796, mse=1.3793, time=0.0407\n",
      "Iter=5400, loss=1.3760, mse=1.3756, time=0.0407\n",
      "Iter=5600, loss=1.3768, mse=1.3765, time=0.0407\n",
      "Iter=5800, loss=1.3810, mse=1.3807, time=0.0407\n",
      "Iter=6000, loss=1.3770, mse=1.3767, time=0.0407\n",
      "Iter=6200, loss=1.3929, mse=1.3926, time=0.0407\n",
      "Iter=6400, loss=1.3953, mse=1.3950, time=0.0407\n",
      "Iter=6600, loss=1.4005, mse=1.4002, time=0.0407\n",
      "=== Epoch 21, train loss 1.387417, test rmse 1.171544 ===\n",
      "Epoch 22\n",
      "Iter=200, loss=1.4039, mse=1.4035, time=0.0417\n",
      "Iter=400, loss=1.3658, mse=1.3654, time=0.0410\n",
      "Iter=600, loss=1.3935, mse=1.3932, time=0.0407\n",
      "Iter=800, loss=1.3939, mse=1.3935, time=0.0407\n",
      "Iter=1000, loss=1.3637, mse=1.3634, time=0.0406\n",
      "Iter=1200, loss=1.3947, mse=1.3944, time=0.0405\n",
      "Iter=1400, loss=1.3931, mse=1.3928, time=0.0402\n",
      "Iter=1600, loss=1.4005, mse=1.4002, time=0.0402\n",
      "Iter=1800, loss=1.4014, mse=1.4011, time=0.0402\n",
      "Iter=2000, loss=1.3962, mse=1.3959, time=0.0404\n",
      "Iter=2200, loss=1.3892, mse=1.3889, time=0.0405\n",
      "Iter=2400, loss=1.4023, mse=1.4019, time=0.0406\n",
      "Iter=2600, loss=1.3828, mse=1.3825, time=0.0413\n",
      "Iter=2800, loss=1.3814, mse=1.3811, time=0.0417\n",
      "Iter=3000, loss=1.3841, mse=1.3838, time=0.0419\n",
      "Iter=3200, loss=1.3772, mse=1.3769, time=0.0420\n",
      "Iter=3400, loss=1.3590, mse=1.3586, time=0.0421\n",
      "Iter=3600, loss=1.3510, mse=1.3506, time=0.0421\n",
      "Iter=3800, loss=1.3836, mse=1.3832, time=0.0421\n",
      "Iter=4000, loss=1.3868, mse=1.3864, time=0.0422\n",
      "Iter=4200, loss=1.4092, mse=1.4088, time=0.0422\n",
      "Iter=4400, loss=1.4176, mse=1.4172, time=0.0422\n",
      "Iter=4600, loss=1.3904, mse=1.3900, time=0.0423\n",
      "Iter=4800, loss=1.3561, mse=1.3557, time=0.0423\n",
      "Iter=5000, loss=1.4105, mse=1.4101, time=0.0424\n",
      "Iter=5200, loss=1.3851, mse=1.3847, time=0.0425\n",
      "Iter=5400, loss=1.4082, mse=1.4078, time=0.0426\n",
      "Iter=5600, loss=1.3839, mse=1.3836, time=0.0427\n",
      "Iter=5800, loss=1.3919, mse=1.3915, time=0.0428\n",
      "Iter=6000, loss=1.4125, mse=1.4121, time=0.0428\n",
      "Iter=6200, loss=1.3974, mse=1.3970, time=0.0428\n",
      "Iter=6400, loss=1.3866, mse=1.3863, time=0.0429\n",
      "Iter=6600, loss=1.4117, mse=1.4114, time=0.0430\n",
      "=== Epoch 22, train loss 1.389839, test rmse 1.168159 ===\n",
      "Epoch 23\n",
      "Iter=200, loss=1.4036, mse=1.4033, time=0.0421\n",
      "Iter=400, loss=1.3887, mse=1.3884, time=0.0425\n",
      "Iter=600, loss=1.3739, mse=1.3735, time=0.0428\n",
      "Iter=800, loss=1.3914, mse=1.3910, time=0.0428\n",
      "Iter=1000, loss=1.3585, mse=1.3582, time=0.0430\n",
      "Iter=1200, loss=1.4039, mse=1.4036, time=0.0430\n",
      "Iter=1400, loss=1.3948, mse=1.3945, time=0.0430\n",
      "Iter=1600, loss=1.3520, mse=1.3516, time=0.0430\n",
      "Iter=1800, loss=1.4237, mse=1.4234, time=0.0432\n",
      "Iter=2000, loss=1.3775, mse=1.3772, time=0.0432\n",
      "Iter=2200, loss=1.3972, mse=1.3969, time=0.0432\n",
      "Iter=2400, loss=1.3859, mse=1.3856, time=0.0433\n",
      "Iter=2600, loss=1.4035, mse=1.4032, time=0.0432\n",
      "Iter=2800, loss=1.3788, mse=1.3785, time=0.0432\n",
      "Iter=3000, loss=1.3782, mse=1.3779, time=0.0432\n",
      "Iter=3200, loss=1.4072, mse=1.4069, time=0.0432\n",
      "Iter=3400, loss=1.4098, mse=1.4095, time=0.0432\n",
      "Iter=3600, loss=1.3751, mse=1.3747, time=0.0432\n",
      "Iter=3800, loss=1.3769, mse=1.3765, time=0.0432\n",
      "Iter=4000, loss=1.3840, mse=1.3836, time=0.0433\n",
      "Iter=4200, loss=1.3917, mse=1.3914, time=0.0435\n",
      "Iter=4400, loss=1.3806, mse=1.3803, time=0.0439\n",
      "Iter=4600, loss=1.4059, mse=1.4056, time=0.0437\n",
      "Iter=4800, loss=1.3956, mse=1.3953, time=0.0437\n",
      "Iter=5000, loss=1.3694, mse=1.3691, time=0.0435\n",
      "Iter=5200, loss=1.3810, mse=1.3807, time=0.0435\n",
      "Iter=5400, loss=1.3545, mse=1.3542, time=0.0433\n",
      "Iter=5600, loss=1.3960, mse=1.3957, time=0.0433\n",
      "Iter=5800, loss=1.3932, mse=1.3929, time=0.0432\n",
      "Iter=6000, loss=1.3847, mse=1.3843, time=0.0431\n",
      "Iter=6200, loss=1.4013, mse=1.4010, time=0.0430\n",
      "Iter=6400, loss=1.3734, mse=1.3731, time=0.0430\n",
      "Iter=6600, loss=1.3877, mse=1.3874, time=0.0429\n",
      "=== Epoch 23, train loss 1.388014, test rmse 1.165498 ===\n",
      "Epoch 24\n",
      "Iter=200, loss=1.3919, mse=1.3916, time=0.0423\n",
      "Iter=400, loss=1.4026, mse=1.4022, time=0.0416\n",
      "Iter=600, loss=1.3929, mse=1.3926, time=0.0414\n",
      "Iter=800, loss=1.4101, mse=1.4097, time=0.0413\n",
      "Iter=1000, loss=1.3750, mse=1.3747, time=0.0413\n",
      "Iter=1200, loss=1.3778, mse=1.3775, time=0.0413\n",
      "Iter=1400, loss=1.3909, mse=1.3906, time=0.0411\n",
      "Iter=1600, loss=1.3861, mse=1.3858, time=0.0411\n",
      "Iter=1800, loss=1.4033, mse=1.4030, time=0.0410\n",
      "Iter=2000, loss=1.3665, mse=1.3662, time=0.0411\n",
      "Iter=2200, loss=1.3599, mse=1.3596, time=0.0410\n",
      "Iter=2400, loss=1.3798, mse=1.3794, time=0.0410\n",
      "Iter=2600, loss=1.3716, mse=1.3712, time=0.0410\n",
      "Iter=2800, loss=1.3936, mse=1.3932, time=0.0409\n",
      "Iter=3000, loss=1.3744, mse=1.3741, time=0.0409\n",
      "Iter=3200, loss=1.3924, mse=1.3921, time=0.0409\n",
      "Iter=3400, loss=1.3747, mse=1.3744, time=0.0409\n",
      "Iter=3600, loss=1.3561, mse=1.3558, time=0.0409\n",
      "Iter=3800, loss=1.3871, mse=1.3868, time=0.0409\n",
      "Iter=4000, loss=1.4078, mse=1.4075, time=0.0409\n",
      "Iter=4200, loss=1.3888, mse=1.3885, time=0.0409\n",
      "Iter=4400, loss=1.3878, mse=1.3875, time=0.0408\n",
      "Iter=4600, loss=1.4078, mse=1.4075, time=0.0408\n",
      "Iter=4800, loss=1.3682, mse=1.3679, time=0.0408\n",
      "Iter=5000, loss=1.3910, mse=1.3907, time=0.0408\n",
      "Iter=5200, loss=1.4308, mse=1.4305, time=0.0407\n",
      "Iter=5400, loss=1.4104, mse=1.4101, time=0.0407\n",
      "Iter=5600, loss=1.4019, mse=1.4016, time=0.0407\n",
      "Iter=5800, loss=1.3776, mse=1.3773, time=0.0407\n",
      "Iter=6000, loss=1.3877, mse=1.3874, time=0.0407\n",
      "Iter=6200, loss=1.3625, mse=1.3622, time=0.0407\n",
      "Iter=6400, loss=1.3890, mse=1.3887, time=0.0407\n",
      "Iter=6600, loss=1.3939, mse=1.3936, time=0.0406\n",
      "=== Epoch 24, train loss 1.387807, test rmse 1.162945 ===\n",
      "Epoch 25\n",
      "Iter=200, loss=1.3806, mse=1.3803, time=0.0416\n",
      "Iter=400, loss=1.3638, mse=1.3635, time=0.0411\n",
      "Iter=600, loss=1.4091, mse=1.4088, time=0.0408\n",
      "Iter=800, loss=1.4068, mse=1.4065, time=0.0407\n",
      "Iter=1000, loss=1.4035, mse=1.4032, time=0.0407\n",
      "Iter=1200, loss=1.3405, mse=1.3402, time=0.0405\n",
      "Iter=1400, loss=1.4200, mse=1.4197, time=0.0407\n",
      "Iter=1600, loss=1.3728, mse=1.3724, time=0.0407\n",
      "Iter=1800, loss=1.3583, mse=1.3580, time=0.0407\n",
      "Iter=2000, loss=1.3806, mse=1.3803, time=0.0406\n",
      "Iter=2200, loss=1.4309, mse=1.4306, time=0.0407\n",
      "Iter=2400, loss=1.3462, mse=1.3459, time=0.0407\n",
      "Iter=2600, loss=1.4137, mse=1.4134, time=0.0407\n",
      "Iter=2800, loss=1.3938, mse=1.3935, time=0.0407\n",
      "Iter=3000, loss=1.4277, mse=1.4274, time=0.0407\n",
      "Iter=3200, loss=1.3649, mse=1.3646, time=0.0407\n",
      "Iter=3400, loss=1.3533, mse=1.3530, time=0.0407\n",
      "Iter=3600, loss=1.4036, mse=1.4032, time=0.0407\n",
      "Iter=3800, loss=1.4056, mse=1.4052, time=0.0406\n",
      "Iter=4000, loss=1.3995, mse=1.3992, time=0.0407\n",
      "Iter=4200, loss=1.3617, mse=1.3614, time=0.0407\n",
      "Iter=4400, loss=1.3959, mse=1.3955, time=0.0407\n",
      "Iter=4600, loss=1.3672, mse=1.3668, time=0.0407\n",
      "Iter=4800, loss=1.3999, mse=1.3996, time=0.0407\n",
      "Iter=5000, loss=1.3901, mse=1.3898, time=0.0406\n",
      "Iter=5200, loss=1.3768, mse=1.3765, time=0.0407\n",
      "Iter=5400, loss=1.4176, mse=1.4173, time=0.0406\n",
      "Iter=5600, loss=1.3731, mse=1.3728, time=0.0405\n",
      "Iter=5800, loss=1.3944, mse=1.3941, time=0.0405\n",
      "Iter=6000, loss=1.3958, mse=1.3954, time=0.0404\n",
      "Iter=6200, loss=1.3762, mse=1.3759, time=0.0404\n",
      "Iter=6400, loss=1.3707, mse=1.3704, time=0.0405\n",
      "Iter=6600, loss=1.4063, mse=1.4060, time=0.0404\n",
      "=== Epoch 25, train loss 1.389592, test rmse 1.163553 ===\n",
      "Epoch 26\n",
      "Iter=200, loss=1.3947, mse=1.3944, time=0.0414\n",
      "Iter=400, loss=1.4097, mse=1.4094, time=0.0414\n",
      "Iter=600, loss=1.4023, mse=1.4020, time=0.0412\n",
      "Iter=800, loss=1.4006, mse=1.4003, time=0.0412\n",
      "Iter=1000, loss=1.3902, mse=1.3898, time=0.0410\n",
      "Iter=1200, loss=1.4016, mse=1.4013, time=0.0410\n",
      "Iter=1400, loss=1.3596, mse=1.3593, time=0.0410\n",
      "Iter=1600, loss=1.3911, mse=1.3908, time=0.0410\n",
      "Iter=1800, loss=1.3885, mse=1.3882, time=0.0409\n",
      "Iter=2000, loss=1.3875, mse=1.3872, time=0.0409\n",
      "Iter=2200, loss=1.3767, mse=1.3763, time=0.0409\n",
      "Iter=2400, loss=1.3679, mse=1.3676, time=0.0409\n",
      "Iter=2600, loss=1.4190, mse=1.4187, time=0.0409\n",
      "Iter=2800, loss=1.3581, mse=1.3577, time=0.0409\n",
      "Iter=3000, loss=1.4265, mse=1.4262, time=0.0409\n",
      "Iter=3200, loss=1.3445, mse=1.3442, time=0.0408\n",
      "Iter=3400, loss=1.4055, mse=1.4052, time=0.0409\n",
      "Iter=3600, loss=1.3959, mse=1.3956, time=0.0408\n",
      "Iter=3800, loss=1.4011, mse=1.4008, time=0.0408\n",
      "Iter=4000, loss=1.3600, mse=1.3596, time=0.0408\n",
      "Iter=4200, loss=1.3857, mse=1.3854, time=0.0408\n",
      "Iter=4400, loss=1.3607, mse=1.3604, time=0.0408\n",
      "Iter=4600, loss=1.4199, mse=1.4196, time=0.0408\n",
      "Iter=4800, loss=1.3932, mse=1.3929, time=0.0407\n",
      "Iter=5000, loss=1.3629, mse=1.3626, time=0.0406\n",
      "Iter=5200, loss=1.3439, mse=1.3436, time=0.0406\n",
      "Iter=5400, loss=1.4000, mse=1.3997, time=0.0406\n",
      "Iter=5600, loss=1.3780, mse=1.3777, time=0.0406\n",
      "Iter=5800, loss=1.4269, mse=1.4266, time=0.0406\n",
      "Iter=6000, loss=1.3919, mse=1.3916, time=0.0407\n",
      "Iter=6200, loss=1.4140, mse=1.4137, time=0.0406\n",
      "Iter=6400, loss=1.3772, mse=1.3769, time=0.0407\n",
      "Iter=6600, loss=1.3800, mse=1.3797, time=0.0407\n",
      "=== Epoch 26, train loss 1.388297, test rmse 1.164143 ===\n",
      "Epoch 27\n",
      "Iter=200, loss=1.3852, mse=1.3849, time=0.0426\n",
      "Iter=400, loss=1.3856, mse=1.3853, time=0.0415\n",
      "Iter=600, loss=1.4002, mse=1.3999, time=0.0413\n",
      "Iter=800, loss=1.3766, mse=1.3763, time=0.0413\n",
      "Iter=1000, loss=1.3994, mse=1.3991, time=0.0413\n",
      "Iter=1200, loss=1.3631, mse=1.3628, time=0.0412\n",
      "Iter=1400, loss=1.3936, mse=1.3933, time=0.0412\n",
      "Iter=1600, loss=1.3961, mse=1.3958, time=0.0411\n",
      "Iter=1800, loss=1.3860, mse=1.3857, time=0.0411\n",
      "Iter=2000, loss=1.3840, mse=1.3837, time=0.0410\n",
      "Iter=2200, loss=1.3825, mse=1.3822, time=0.0409\n",
      "Iter=2400, loss=1.3767, mse=1.3764, time=0.0410\n",
      "Iter=2600, loss=1.3582, mse=1.3578, time=0.0409\n",
      "Iter=2800, loss=1.3960, mse=1.3957, time=0.0409\n",
      "Iter=3000, loss=1.3545, mse=1.3542, time=0.0409\n",
      "Iter=3200, loss=1.3893, mse=1.3890, time=0.0409\n",
      "Iter=3400, loss=1.4159, mse=1.4155, time=0.0408\n",
      "Iter=3600, loss=1.3922, mse=1.3918, time=0.0408\n",
      "Iter=3800, loss=1.4026, mse=1.4022, time=0.0407\n",
      "Iter=4000, loss=1.3671, mse=1.3668, time=0.0407\n",
      "Iter=4200, loss=1.3547, mse=1.3544, time=0.0407\n",
      "Iter=4400, loss=1.4243, mse=1.4240, time=0.0407\n",
      "Iter=4600, loss=1.3922, mse=1.3919, time=0.0407\n",
      "Iter=4800, loss=1.4029, mse=1.4026, time=0.0407\n",
      "Iter=5000, loss=1.3815, mse=1.3812, time=0.0407\n",
      "Iter=5200, loss=1.3884, mse=1.3881, time=0.0407\n",
      "Iter=5400, loss=1.3877, mse=1.3874, time=0.0407\n",
      "Iter=5600, loss=1.4119, mse=1.4116, time=0.0407\n",
      "Iter=5800, loss=1.3705, mse=1.3702, time=0.0407\n",
      "Iter=6000, loss=1.3726, mse=1.3723, time=0.0407\n",
      "Iter=6200, loss=1.4116, mse=1.4112, time=0.0407\n",
      "Iter=6400, loss=1.3827, mse=1.3824, time=0.0407\n",
      "Iter=6600, loss=1.3828, mse=1.3826, time=0.0407\n",
      "=== Epoch 27, train loss 1.386776, test rmse 1.164348 ===\n",
      "Epoch 28\n",
      "Iter=200, loss=1.3829, mse=1.3826, time=0.0413\n",
      "Iter=400, loss=1.4197, mse=1.4194, time=0.0411\n",
      "Iter=600, loss=1.3660, mse=1.3656, time=0.0410\n",
      "Iter=800, loss=1.4218, mse=1.4215, time=0.0409\n",
      "Iter=1000, loss=1.4094, mse=1.4091, time=0.0407\n",
      "Iter=1200, loss=1.3605, mse=1.3602, time=0.0406\n",
      "Iter=1400, loss=1.3563, mse=1.3561, time=0.0407\n",
      "Iter=1600, loss=1.3536, mse=1.3534, time=0.0407\n",
      "Iter=1800, loss=1.3889, mse=1.3887, time=0.0407\n",
      "Iter=2000, loss=1.3997, mse=1.3994, time=0.0407\n",
      "Iter=2200, loss=1.3906, mse=1.3903, time=0.0408\n",
      "Iter=2400, loss=1.3705, mse=1.3702, time=0.0407\n",
      "Iter=2600, loss=1.3738, mse=1.3735, time=0.0407\n",
      "Iter=2800, loss=1.4277, mse=1.4274, time=0.0405\n",
      "Iter=3000, loss=1.3899, mse=1.3897, time=0.0405\n",
      "Iter=3200, loss=1.3944, mse=1.3942, time=0.0404\n",
      "Iter=3400, loss=1.3931, mse=1.3928, time=0.0404\n",
      "Iter=3600, loss=1.3671, mse=1.3668, time=0.0404\n",
      "Iter=3800, loss=1.3919, mse=1.3916, time=0.0405\n",
      "Iter=4000, loss=1.4111, mse=1.4108, time=0.0405\n",
      "Iter=4200, loss=1.4124, mse=1.4121, time=0.0406\n",
      "Iter=4400, loss=1.3472, mse=1.3469, time=0.0406\n",
      "Iter=4600, loss=1.3901, mse=1.3897, time=0.0406\n",
      "Iter=4800, loss=1.4133, mse=1.4130, time=0.0406\n",
      "Iter=5000, loss=1.4053, mse=1.4049, time=0.0406\n",
      "Iter=5200, loss=1.3901, mse=1.3898, time=0.0406\n",
      "Iter=5400, loss=1.3646, mse=1.3642, time=0.0406\n",
      "Iter=5600, loss=1.3927, mse=1.3924, time=0.0406\n",
      "Iter=5800, loss=1.3726, mse=1.3722, time=0.0406\n",
      "Iter=6000, loss=1.3577, mse=1.3574, time=0.0406\n",
      "Iter=6200, loss=1.4092, mse=1.4089, time=0.0406\n",
      "Iter=6400, loss=1.3700, mse=1.3696, time=0.0406\n",
      "Iter=6600, loss=1.3625, mse=1.3622, time=0.0406\n",
      "=== Epoch 28, train loss 1.386913, test rmse 1.169290 ===\n",
      "Epoch 29\n",
      "Iter=200, loss=1.4057, mse=1.4053, time=0.0420\n",
      "Iter=400, loss=1.3931, mse=1.3928, time=0.0409\n",
      "Iter=600, loss=1.3838, mse=1.3835, time=0.0408\n",
      "Iter=800, loss=1.3955, mse=1.3951, time=0.0407\n",
      "Iter=1000, loss=1.3722, mse=1.3719, time=0.0406\n",
      "Iter=1200, loss=1.3881, mse=1.3877, time=0.0406\n",
      "Iter=1400, loss=1.4030, mse=1.4026, time=0.0405\n",
      "Iter=1600, loss=1.3864, mse=1.3860, time=0.0404\n",
      "Iter=1800, loss=1.3949, mse=1.3946, time=0.0404\n",
      "Iter=2000, loss=1.4087, mse=1.4083, time=0.0403\n",
      "Iter=2200, loss=1.4067, mse=1.4064, time=0.0402\n",
      "Iter=2400, loss=1.3871, mse=1.3867, time=0.0403\n",
      "Iter=2600, loss=1.3922, mse=1.3919, time=0.0403\n",
      "Iter=2800, loss=1.4070, mse=1.4067, time=0.0403\n",
      "Iter=3000, loss=1.3808, mse=1.3804, time=0.0404\n",
      "Iter=3200, loss=1.3979, mse=1.3975, time=0.0405\n",
      "Iter=3400, loss=1.3745, mse=1.3742, time=0.0405\n",
      "Iter=3600, loss=1.3790, mse=1.3787, time=0.0405\n",
      "Iter=3800, loss=1.3696, mse=1.3693, time=0.0406\n",
      "Iter=4000, loss=1.3590, mse=1.3587, time=0.0406\n",
      "Iter=4200, loss=1.3878, mse=1.3875, time=0.0406\n",
      "Iter=4400, loss=1.4104, mse=1.4101, time=0.0406\n",
      "Iter=4600, loss=1.4079, mse=1.4076, time=0.0406\n",
      "Iter=4800, loss=1.3897, mse=1.3894, time=0.0406\n",
      "Iter=5000, loss=1.3736, mse=1.3733, time=0.0406\n",
      "Iter=5200, loss=1.3573, mse=1.3570, time=0.0406\n",
      "Iter=5400, loss=1.4290, mse=1.4287, time=0.0406\n",
      "Iter=5600, loss=1.3732, mse=1.3728, time=0.0406\n",
      "Iter=5800, loss=1.4011, mse=1.4008, time=0.0406\n",
      "Iter=6000, loss=1.3908, mse=1.3905, time=0.0406\n",
      "Iter=6200, loss=1.3797, mse=1.3794, time=0.0406\n",
      "Iter=6400, loss=1.4116, mse=1.4112, time=0.0406\n",
      "Iter=6600, loss=1.3772, mse=1.3768, time=0.0406\n",
      "=== Epoch 29, train loss 1.388984, test rmse 1.164896 ===\n",
      "Epoch 30\n",
      "Iter=200, loss=1.3877, mse=1.3874, time=0.0417\n",
      "Iter=400, loss=1.3505, mse=1.3502, time=0.0415\n",
      "Iter=600, loss=1.3993, mse=1.3990, time=0.0413\n",
      "Iter=800, loss=1.3801, mse=1.3798, time=0.0407\n",
      "Iter=1000, loss=1.3711, mse=1.3707, time=0.0404\n",
      "Iter=1200, loss=1.3885, mse=1.3881, time=0.0400\n",
      "Iter=1400, loss=1.4215, mse=1.4212, time=0.0400\n",
      "Iter=1600, loss=1.3692, mse=1.3689, time=0.0401\n",
      "Iter=1800, loss=1.3927, mse=1.3924, time=0.0402\n",
      "Iter=2000, loss=1.3714, mse=1.3711, time=0.0402\n",
      "Iter=2200, loss=1.4009, mse=1.4006, time=0.0403\n",
      "Iter=2400, loss=1.4000, mse=1.3997, time=0.0404\n",
      "Iter=2600, loss=1.3975, mse=1.3972, time=0.0404\n",
      "Iter=2800, loss=1.4231, mse=1.4227, time=0.0405\n",
      "Iter=3000, loss=1.3675, mse=1.3672, time=0.0406\n",
      "Iter=3200, loss=1.3787, mse=1.3784, time=0.0406\n",
      "Iter=3400, loss=1.4143, mse=1.4139, time=0.0405\n",
      "Iter=3600, loss=1.3444, mse=1.3440, time=0.0406\n",
      "Iter=3800, loss=1.3811, mse=1.3807, time=0.0406\n",
      "Iter=4000, loss=1.3571, mse=1.3568, time=0.0406\n",
      "Iter=4200, loss=1.4053, mse=1.4050, time=0.0406\n",
      "Iter=4400, loss=1.3706, mse=1.3702, time=0.0406\n",
      "Iter=4600, loss=1.3978, mse=1.3975, time=0.0405\n",
      "Iter=4800, loss=1.4119, mse=1.4116, time=0.0406\n",
      "Iter=5000, loss=1.3913, mse=1.3910, time=0.0405\n",
      "Iter=5200, loss=1.3947, mse=1.3943, time=0.0406\n",
      "Iter=5400, loss=1.3818, mse=1.3815, time=0.0406\n",
      "Iter=5600, loss=1.3741, mse=1.3737, time=0.0406\n",
      "Iter=5800, loss=1.3783, mse=1.3780, time=0.0406\n",
      "Iter=6000, loss=1.4420, mse=1.4417, time=0.0406\n",
      "Iter=6200, loss=1.3510, mse=1.3507, time=0.0406\n",
      "Iter=6400, loss=1.4068, mse=1.4065, time=0.0406\n",
      "Iter=6600, loss=1.3937, mse=1.3934, time=0.0406\n",
      "=== Epoch 30, train loss 1.387963, test rmse 1.161992 ===\n",
      "Epoch 31\n",
      "Iter=200, loss=1.4012, mse=1.4008, time=0.0412\n",
      "Iter=400, loss=1.4191, mse=1.4187, time=0.0408\n",
      "Iter=600, loss=1.3648, mse=1.3644, time=0.0409\n",
      "Iter=800, loss=1.3820, mse=1.3816, time=0.0407\n",
      "Iter=1000, loss=1.4129, mse=1.4125, time=0.0407\n",
      "Iter=1200, loss=1.4105, mse=1.4102, time=0.0409\n",
      "Iter=1400, loss=1.3538, mse=1.3534, time=0.0408\n",
      "Iter=1600, loss=1.3809, mse=1.3806, time=0.0408\n",
      "Iter=1800, loss=1.4153, mse=1.4150, time=0.0408\n",
      "Iter=2000, loss=1.3778, mse=1.3774, time=0.0409\n",
      "Iter=2200, loss=1.3642, mse=1.3638, time=0.0408\n",
      "Iter=2400, loss=1.4004, mse=1.4001, time=0.0408\n",
      "Iter=2600, loss=1.4229, mse=1.4226, time=0.0409\n",
      "Iter=2800, loss=1.3868, mse=1.3864, time=0.0409\n",
      "Iter=3000, loss=1.3477, mse=1.3474, time=0.0409\n",
      "Iter=3200, loss=1.3872, mse=1.3869, time=0.0408\n",
      "Iter=3400, loss=1.3963, mse=1.3960, time=0.0408\n",
      "Iter=3600, loss=1.3843, mse=1.3840, time=0.0409\n",
      "Iter=3800, loss=1.3946, mse=1.3943, time=0.0409\n",
      "Iter=4000, loss=1.3817, mse=1.3814, time=0.0408\n",
      "Iter=4200, loss=1.4007, mse=1.4004, time=0.0408\n",
      "Iter=4400, loss=1.4072, mse=1.4068, time=0.0408\n",
      "Iter=4600, loss=1.4228, mse=1.4225, time=0.0408\n",
      "Iter=4800, loss=1.4126, mse=1.4123, time=0.0408\n",
      "Iter=5000, loss=1.3749, mse=1.3745, time=0.0408\n",
      "Iter=5200, loss=1.3847, mse=1.3844, time=0.0408\n",
      "Iter=5400, loss=1.3550, mse=1.3547, time=0.0408\n",
      "Iter=5600, loss=1.3401, mse=1.3398, time=0.0408\n",
      "Iter=5800, loss=1.3658, mse=1.3654, time=0.0408\n",
      "Iter=6000, loss=1.3966, mse=1.3963, time=0.0408\n",
      "Iter=6200, loss=1.3716, mse=1.3713, time=0.0408\n",
      "Iter=6400, loss=1.3828, mse=1.3825, time=0.0408\n",
      "Iter=6600, loss=1.3883, mse=1.3880, time=0.0408\n",
      "=== Epoch 31, train loss 1.387786, test rmse 1.165469 ===\n",
      "Epoch 32\n",
      "Iter=200, loss=1.3991, mse=1.3988, time=0.0401\n",
      "Iter=400, loss=1.3587, mse=1.3583, time=0.0392\n",
      "Iter=600, loss=1.3521, mse=1.3518, time=0.0390\n",
      "Iter=800, loss=1.3770, mse=1.3766, time=0.0389\n",
      "Iter=1000, loss=1.4182, mse=1.4179, time=0.0390\n",
      "Iter=1200, loss=1.3652, mse=1.3648, time=0.0394\n",
      "Iter=1400, loss=1.4056, mse=1.4052, time=0.0395\n",
      "Iter=1600, loss=1.3948, mse=1.3944, time=0.0397\n",
      "Iter=1800, loss=1.3877, mse=1.3874, time=0.0399\n",
      "Iter=2000, loss=1.3829, mse=1.3826, time=0.0399\n",
      "Iter=2200, loss=1.3929, mse=1.3925, time=0.0400\n",
      "Iter=2400, loss=1.3926, mse=1.3923, time=0.0401\n",
      "Iter=2600, loss=1.4073, mse=1.4070, time=0.0402\n",
      "Iter=2800, loss=1.4060, mse=1.4057, time=0.0402\n",
      "Iter=3000, loss=1.4014, mse=1.4010, time=0.0403\n",
      "Iter=3200, loss=1.3601, mse=1.3598, time=0.0402\n",
      "Iter=3400, loss=1.4039, mse=1.4036, time=0.0403\n",
      "Iter=3600, loss=1.3694, mse=1.3691, time=0.0403\n",
      "Iter=3800, loss=1.3773, mse=1.3770, time=0.0403\n",
      "Iter=4000, loss=1.4012, mse=1.4008, time=0.0403\n",
      "Iter=4200, loss=1.3753, mse=1.3749, time=0.0403\n",
      "Iter=4400, loss=1.3815, mse=1.3811, time=0.0403\n",
      "Iter=4600, loss=1.4001, mse=1.3998, time=0.0403\n",
      "Iter=4800, loss=1.3821, mse=1.3818, time=0.0403\n",
      "Iter=5000, loss=1.3809, mse=1.3806, time=0.0404\n",
      "Iter=5200, loss=1.4036, mse=1.4033, time=0.0404\n",
      "Iter=5400, loss=1.3627, mse=1.3624, time=0.0404\n",
      "Iter=5600, loss=1.3716, mse=1.3713, time=0.0404\n",
      "Iter=5800, loss=1.4147, mse=1.4144, time=0.0404\n",
      "Iter=6000, loss=1.3889, mse=1.3886, time=0.0404\n",
      "Iter=6200, loss=1.4294, mse=1.4291, time=0.0404\n",
      "Iter=6400, loss=1.3594, mse=1.3591, time=0.0404\n",
      "Iter=6600, loss=1.3926, mse=1.3923, time=0.0404\n",
      "=== Epoch 32, train loss 1.387842, test rmse 1.168886 ===\n",
      "Epoch 33\n",
      "Iter=200, loss=1.4185, mse=1.4182, time=0.0421\n",
      "Iter=400, loss=1.4053, mse=1.4050, time=0.0413\n",
      "Iter=600, loss=1.3505, mse=1.3502, time=0.0411\n",
      "Iter=800, loss=1.3938, mse=1.3935, time=0.0410\n",
      "Iter=1000, loss=1.3840, mse=1.3837, time=0.0411\n",
      "Iter=1200, loss=1.4235, mse=1.4232, time=0.0410\n",
      "Iter=1400, loss=1.3580, mse=1.3577, time=0.0410\n",
      "Iter=1600, loss=1.3738, mse=1.3735, time=0.0411\n",
      "Iter=1800, loss=1.3783, mse=1.3780, time=0.0410\n",
      "Iter=2000, loss=1.4067, mse=1.4064, time=0.0410\n",
      "Iter=2200, loss=1.3753, mse=1.3750, time=0.0410\n",
      "Iter=2400, loss=1.4070, mse=1.4067, time=0.0410\n",
      "Iter=2600, loss=1.3730, mse=1.3727, time=0.0409\n",
      "Iter=2800, loss=1.3802, mse=1.3799, time=0.0409\n",
      "Iter=3000, loss=1.4011, mse=1.4008, time=0.0409\n",
      "Iter=3200, loss=1.4124, mse=1.4121, time=0.0409\n",
      "Iter=3400, loss=1.3939, mse=1.3936, time=0.0409\n",
      "Iter=3600, loss=1.4301, mse=1.4298, time=0.0409\n",
      "Iter=3800, loss=1.3715, mse=1.3712, time=0.0410\n",
      "Iter=4000, loss=1.3631, mse=1.3628, time=0.0409\n",
      "Iter=4200, loss=1.3772, mse=1.3769, time=0.0409\n",
      "Iter=4400, loss=1.3727, mse=1.3723, time=0.0409\n",
      "Iter=4600, loss=1.4007, mse=1.4004, time=0.0409\n",
      "Iter=4800, loss=1.3951, mse=1.3947, time=0.0409\n",
      "Iter=5000, loss=1.3744, mse=1.3741, time=0.0409\n",
      "Iter=5200, loss=1.4549, mse=1.4546, time=0.0409\n",
      "Iter=5400, loss=1.3772, mse=1.3769, time=0.0409\n",
      "Iter=5600, loss=1.3706, mse=1.3702, time=0.0409\n",
      "Iter=5800, loss=1.3818, mse=1.3815, time=0.0408\n",
      "Iter=6000, loss=1.3786, mse=1.3783, time=0.0408\n",
      "Iter=6200, loss=1.3835, mse=1.3832, time=0.0408\n",
      "Iter=6400, loss=1.3545, mse=1.3542, time=0.0408\n",
      "Iter=6600, loss=1.4025, mse=1.4022, time=0.0408\n",
      "=== Epoch 33, train loss 1.388302, test rmse 1.166135 ===\n",
      "Epoch 34\n",
      "Iter=200, loss=1.3620, mse=1.3617, time=0.0412\n",
      "Iter=400, loss=1.3675, mse=1.3671, time=0.0410\n",
      "Iter=600, loss=1.3831, mse=1.3827, time=0.0411\n",
      "Iter=800, loss=1.3672, mse=1.3669, time=0.0410\n",
      "Iter=1000, loss=1.4054, mse=1.4051, time=0.0408\n",
      "Iter=1200, loss=1.3881, mse=1.3878, time=0.0408\n",
      "Iter=1400, loss=1.4066, mse=1.4063, time=0.0408\n",
      "Iter=1600, loss=1.3970, mse=1.3967, time=0.0407\n",
      "Iter=1800, loss=1.3991, mse=1.3988, time=0.0408\n",
      "Iter=2000, loss=1.3788, mse=1.3785, time=0.0407\n",
      "Iter=2200, loss=1.3470, mse=1.3467, time=0.0407\n",
      "Iter=2400, loss=1.4183, mse=1.4180, time=0.0407\n",
      "Iter=2600, loss=1.4263, mse=1.4260, time=0.0407\n",
      "Iter=2800, loss=1.4128, mse=1.4124, time=0.0407\n",
      "Iter=3000, loss=1.3967, mse=1.3964, time=0.0407\n",
      "Iter=3200, loss=1.3967, mse=1.3963, time=0.0407\n",
      "Iter=3400, loss=1.3452, mse=1.3448, time=0.0407\n",
      "Iter=3600, loss=1.4248, mse=1.4245, time=0.0407\n",
      "Iter=3800, loss=1.3872, mse=1.3869, time=0.0407\n",
      "Iter=4000, loss=1.3907, mse=1.3904, time=0.0407\n",
      "Iter=4200, loss=1.3922, mse=1.3919, time=0.0407\n",
      "Iter=4400, loss=1.3261, mse=1.3259, time=0.0407\n",
      "Iter=4600, loss=1.3985, mse=1.3982, time=0.0407\n",
      "Iter=4800, loss=1.3971, mse=1.3968, time=0.0407\n",
      "Iter=5000, loss=1.3926, mse=1.3923, time=0.0407\n",
      "Iter=5200, loss=1.4013, mse=1.4010, time=0.0407\n",
      "Iter=5400, loss=1.3822, mse=1.3819, time=0.0406\n",
      "Iter=5600, loss=1.3705, mse=1.3702, time=0.0406\n",
      "Iter=5800, loss=1.4041, mse=1.4039, time=0.0406\n",
      "Iter=6000, loss=1.3723, mse=1.3720, time=0.0407\n",
      "Iter=6200, loss=1.3745, mse=1.3742, time=0.0406\n",
      "Iter=6400, loss=1.3714, mse=1.3711, time=0.0405\n",
      "Iter=6600, loss=1.3944, mse=1.3941, time=0.0405\n",
      "=== Epoch 34, train loss 1.386816, test rmse 1.167668 ===\n",
      "Epoch 35\n",
      "Iter=200, loss=1.3438, mse=1.3435, time=0.0422\n",
      "Iter=400, loss=1.3828, mse=1.3825, time=0.0413\n",
      "Iter=600, loss=1.3765, mse=1.3762, time=0.0409\n",
      "Iter=800, loss=1.4099, mse=1.4095, time=0.0409\n",
      "Iter=1000, loss=1.3801, mse=1.3798, time=0.0409\n",
      "Iter=1200, loss=1.3998, mse=1.3994, time=0.0409\n",
      "Iter=1400, loss=1.3751, mse=1.3748, time=0.0408\n",
      "Iter=1600, loss=1.3977, mse=1.3974, time=0.0408\n",
      "Iter=1800, loss=1.3548, mse=1.3545, time=0.0408\n",
      "Iter=2000, loss=1.3834, mse=1.3831, time=0.0408\n",
      "Iter=2200, loss=1.3941, mse=1.3938, time=0.0408\n",
      "Iter=2400, loss=1.3885, mse=1.3881, time=0.0409\n",
      "Iter=2600, loss=1.3976, mse=1.3973, time=0.0409\n",
      "Iter=2800, loss=1.4110, mse=1.4106, time=0.0409\n",
      "Iter=3000, loss=1.4520, mse=1.4517, time=0.0409\n",
      "Iter=3200, loss=1.3903, mse=1.3900, time=0.0409\n",
      "Iter=3400, loss=1.3920, mse=1.3917, time=0.0409\n",
      "Iter=3600, loss=1.4106, mse=1.4103, time=0.0408\n",
      "Iter=3800, loss=1.3592, mse=1.3589, time=0.0408\n",
      "Iter=4000, loss=1.3752, mse=1.3749, time=0.0408\n",
      "Iter=4200, loss=1.3663, mse=1.3660, time=0.0409\n",
      "Iter=4400, loss=1.3830, mse=1.3827, time=0.0410\n",
      "Iter=4600, loss=1.4467, mse=1.4465, time=0.0410\n",
      "Iter=4800, loss=1.3999, mse=1.3996, time=0.0410\n",
      "Iter=5000, loss=1.3822, mse=1.3819, time=0.0410\n",
      "Iter=5200, loss=1.3711, mse=1.3708, time=0.0409\n",
      "Iter=5400, loss=1.3692, mse=1.3689, time=0.0408\n",
      "Iter=5600, loss=1.3932, mse=1.3929, time=0.0408\n",
      "Iter=5800, loss=1.3578, mse=1.3575, time=0.0408\n",
      "Iter=6000, loss=1.3700, mse=1.3697, time=0.0408\n",
      "Iter=6200, loss=1.4004, mse=1.4001, time=0.0408\n",
      "Iter=6400, loss=1.4145, mse=1.4142, time=0.0408\n",
      "Iter=6600, loss=1.4047, mse=1.4044, time=0.0408\n",
      "=== Epoch 35, train loss 1.388913, test rmse 1.167388 ===\n",
      "Epoch 36\n",
      "Iter=200, loss=1.3734, mse=1.3731, time=0.0421\n",
      "Iter=400, loss=1.3984, mse=1.3981, time=0.0414\n",
      "Iter=600, loss=1.3884, mse=1.3880, time=0.0412\n",
      "Iter=800, loss=1.3735, mse=1.3732, time=0.0410\n",
      "Iter=1000, loss=1.3937, mse=1.3935, time=0.0409\n",
      "Iter=1200, loss=1.4098, mse=1.4095, time=0.0409\n",
      "Iter=1400, loss=1.3923, mse=1.3920, time=0.0409\n",
      "Iter=1600, loss=1.3909, mse=1.3906, time=0.0408\n",
      "Iter=1800, loss=1.3794, mse=1.3791, time=0.0409\n",
      "Iter=2000, loss=1.4019, mse=1.4016, time=0.0409\n",
      "Iter=2200, loss=1.3606, mse=1.3603, time=0.0408\n",
      "Iter=2400, loss=1.3806, mse=1.3803, time=0.0408\n",
      "Iter=2600, loss=1.3498, mse=1.3494, time=0.0407\n",
      "Iter=2800, loss=1.4234, mse=1.4231, time=0.0407\n",
      "Iter=3000, loss=1.3866, mse=1.3863, time=0.0407\n",
      "Iter=3200, loss=1.3628, mse=1.3625, time=0.0407\n",
      "Iter=3400, loss=1.3876, mse=1.3873, time=0.0407\n",
      "Iter=3600, loss=1.3686, mse=1.3683, time=0.0407\n",
      "Iter=3800, loss=1.4280, mse=1.4277, time=0.0407\n",
      "Iter=4000, loss=1.3939, mse=1.3936, time=0.0407\n",
      "Iter=4200, loss=1.3900, mse=1.3897, time=0.0406\n",
      "Iter=4400, loss=1.3873, mse=1.3870, time=0.0406\n",
      "Iter=4600, loss=1.4003, mse=1.4000, time=0.0405\n",
      "Iter=4800, loss=1.3506, mse=1.3503, time=0.0405\n",
      "Iter=5000, loss=1.4262, mse=1.4259, time=0.0406\n",
      "Iter=5200, loss=1.3805, mse=1.3802, time=0.0405\n",
      "Iter=5400, loss=1.3992, mse=1.3989, time=0.0406\n",
      "Iter=5600, loss=1.4023, mse=1.4020, time=0.0406\n",
      "Iter=5800, loss=1.4149, mse=1.4145, time=0.0406\n",
      "Iter=6000, loss=1.3908, mse=1.3905, time=0.0406\n",
      "Iter=6200, loss=1.3988, mse=1.3985, time=0.0406\n",
      "Iter=6400, loss=1.3882, mse=1.3879, time=0.0406\n",
      "Iter=6600, loss=1.3646, mse=1.3643, time=0.0406\n",
      "=== Epoch 36, train loss 1.388244, test rmse 1.168025 ===\n",
      "Epoch 37\n",
      "Iter=200, loss=1.3665, mse=1.3662, time=0.0416\n",
      "Iter=400, loss=1.3999, mse=1.3996, time=0.0414\n",
      "Iter=600, loss=1.4153, mse=1.4150, time=0.0411\n",
      "Iter=800, loss=1.3718, mse=1.3715, time=0.0415\n",
      "Iter=1000, loss=1.4024, mse=1.4022, time=0.0413\n",
      "Iter=1200, loss=1.3716, mse=1.3713, time=0.0412\n",
      "Iter=1400, loss=1.4516, mse=1.4513, time=0.0411\n",
      "Iter=1600, loss=1.3946, mse=1.3943, time=0.0410\n",
      "Iter=1800, loss=1.3420, mse=1.3417, time=0.0410\n",
      "Iter=2000, loss=1.3623, mse=1.3620, time=0.0409\n",
      "Iter=2200, loss=1.3959, mse=1.3956, time=0.0409\n",
      "Iter=2400, loss=1.3828, mse=1.3825, time=0.0409\n",
      "Iter=2600, loss=1.3718, mse=1.3715, time=0.0408\n",
      "Iter=2800, loss=1.4046, mse=1.4043, time=0.0408\n",
      "Iter=3000, loss=1.3885, mse=1.3882, time=0.0408\n",
      "Iter=3200, loss=1.3955, mse=1.3952, time=0.0407\n",
      "Iter=3400, loss=1.4067, mse=1.4063, time=0.0407\n",
      "Iter=3600, loss=1.4128, mse=1.4125, time=0.0405\n",
      "Iter=3800, loss=1.3602, mse=1.3599, time=0.0405\n",
      "Iter=4000, loss=1.3986, mse=1.3983, time=0.0405\n",
      "Iter=4200, loss=1.3406, mse=1.3403, time=0.0405\n",
      "Iter=4400, loss=1.3822, mse=1.3819, time=0.0406\n",
      "Iter=4600, loss=1.3984, mse=1.3981, time=0.0406\n",
      "Iter=4800, loss=1.4093, mse=1.4090, time=0.0406\n",
      "Iter=5000, loss=1.3947, mse=1.3944, time=0.0406\n",
      "Iter=5200, loss=1.3828, mse=1.3825, time=0.0406\n",
      "Iter=5400, loss=1.3872, mse=1.3869, time=0.0406\n",
      "Iter=5600, loss=1.3908, mse=1.3905, time=0.0406\n",
      "Iter=5800, loss=1.3821, mse=1.3818, time=0.0406\n",
      "Iter=6000, loss=1.3938, mse=1.3935, time=0.0406\n",
      "Iter=6200, loss=1.4017, mse=1.4014, time=0.0406\n",
      "Iter=6400, loss=1.3979, mse=1.3976, time=0.0406\n",
      "Iter=6600, loss=1.3822, mse=1.3819, time=0.0406\n",
      "=== Epoch 37, train loss 1.389375, test rmse 1.164503 ===\n",
      "Epoch 38\n",
      "Iter=200, loss=1.4085, mse=1.4082, time=0.0425\n",
      "Iter=400, loss=1.3764, mse=1.3761, time=0.0411\n",
      "Iter=600, loss=1.3827, mse=1.3824, time=0.0410\n",
      "Iter=800, loss=1.3792, mse=1.3789, time=0.0410\n",
      "Iter=1000, loss=1.3934, mse=1.3931, time=0.0408\n",
      "Iter=1200, loss=1.4058, mse=1.4055, time=0.0410\n",
      "Iter=1400, loss=1.3732, mse=1.3729, time=0.0409\n",
      "Iter=1600, loss=1.3875, mse=1.3872, time=0.0409\n",
      "Iter=1800, loss=1.3915, mse=1.3912, time=0.0408\n",
      "Iter=2000, loss=1.3903, mse=1.3900, time=0.0408\n",
      "Iter=2200, loss=1.3982, mse=1.3979, time=0.0408\n",
      "Iter=2400, loss=1.4059, mse=1.4056, time=0.0407\n",
      "Iter=2600, loss=1.3735, mse=1.3732, time=0.0406\n",
      "Iter=2800, loss=1.3724, mse=1.3721, time=0.0406\n",
      "Iter=3000, loss=1.4130, mse=1.4127, time=0.0406\n",
      "Iter=3200, loss=1.3905, mse=1.3902, time=0.0406\n",
      "Iter=3400, loss=1.3938, mse=1.3935, time=0.0406\n",
      "Iter=3600, loss=1.3920, mse=1.3917, time=0.0406\n",
      "Iter=3800, loss=1.4278, mse=1.4275, time=0.0406\n",
      "Iter=4000, loss=1.4190, mse=1.4186, time=0.0406\n",
      "Iter=4200, loss=1.3573, mse=1.3570, time=0.0407\n",
      "Iter=4400, loss=1.3799, mse=1.3796, time=0.0407\n",
      "Iter=4600, loss=1.3707, mse=1.3704, time=0.0407\n",
      "Iter=4800, loss=1.3780, mse=1.3777, time=0.0407\n",
      "Iter=5000, loss=1.3753, mse=1.3750, time=0.0407\n",
      "Iter=5200, loss=1.3845, mse=1.3842, time=0.0406\n",
      "Iter=5400, loss=1.4075, mse=1.4072, time=0.0407\n",
      "Iter=5600, loss=1.3922, mse=1.3919, time=0.0406\n",
      "Iter=5800, loss=1.3979, mse=1.3976, time=0.0407\n",
      "Iter=6000, loss=1.3885, mse=1.3882, time=0.0407\n",
      "Iter=6200, loss=1.3903, mse=1.3900, time=0.0407\n",
      "Iter=6400, loss=1.3551, mse=1.3548, time=0.0407\n",
      "Iter=6600, loss=1.3598, mse=1.3596, time=0.0406\n",
      "=== Epoch 38, train loss 1.387352, test rmse 1.166078 ===\n",
      "Epoch 39\n",
      "Iter=200, loss=1.3670, mse=1.3667, time=0.0413\n",
      "Iter=400, loss=1.3983, mse=1.3980, time=0.0409\n",
      "Iter=600, loss=1.3749, mse=1.3746, time=0.0408\n",
      "Iter=800, loss=1.3671, mse=1.3668, time=0.0406\n",
      "Iter=1000, loss=1.3937, mse=1.3934, time=0.0405\n",
      "Iter=1200, loss=1.4202, mse=1.4199, time=0.0404\n",
      "Iter=1400, loss=1.3843, mse=1.3840, time=0.0402\n",
      "Iter=1600, loss=1.3775, mse=1.3772, time=0.0400\n",
      "Iter=1800, loss=1.3921, mse=1.3918, time=0.0400\n",
      "Iter=2000, loss=1.3625, mse=1.3622, time=0.0401\n",
      "Iter=2200, loss=1.4170, mse=1.4167, time=0.0402\n",
      "Iter=2400, loss=1.3569, mse=1.3566, time=0.0402\n",
      "Iter=2600, loss=1.3530, mse=1.3527, time=0.0403\n",
      "Iter=2800, loss=1.3913, mse=1.3911, time=0.0404\n",
      "Iter=3000, loss=1.3929, mse=1.3927, time=0.0405\n",
      "Iter=3200, loss=1.3805, mse=1.3803, time=0.0405\n",
      "Iter=3400, loss=1.3839, mse=1.3836, time=0.0406\n",
      "Iter=3600, loss=1.3847, mse=1.3844, time=0.0406\n",
      "Iter=3800, loss=1.3870, mse=1.3867, time=0.0406\n",
      "Iter=4000, loss=1.4023, mse=1.4020, time=0.0406\n",
      "Iter=4200, loss=1.3998, mse=1.3995, time=0.0406\n",
      "Iter=4400, loss=1.4139, mse=1.4136, time=0.0406\n",
      "Iter=4600, loss=1.4268, mse=1.4265, time=0.0406\n",
      "Iter=4800, loss=1.4039, mse=1.4036, time=0.0406\n",
      "Iter=5000, loss=1.4095, mse=1.4092, time=0.0406\n",
      "Iter=5200, loss=1.3884, mse=1.3880, time=0.0406\n",
      "Iter=5400, loss=1.3670, mse=1.3667, time=0.0406\n",
      "Iter=5600, loss=1.3654, mse=1.3651, time=0.0406\n",
      "Iter=5800, loss=1.3470, mse=1.3467, time=0.0406\n",
      "Iter=6000, loss=1.3895, mse=1.3891, time=0.0406\n",
      "Iter=6200, loss=1.3879, mse=1.3876, time=0.0406\n",
      "Iter=6400, loss=1.4119, mse=1.4116, time=0.0406\n",
      "Iter=6600, loss=1.4080, mse=1.4077, time=0.0406\n",
      "=== Epoch 39, train loss 1.389387, test rmse 1.164018 ===\n",
      "Epoch 40\n",
      "Iter=200, loss=1.4257, mse=1.4254, time=0.0422\n",
      "Iter=400, loss=1.3828, mse=1.3824, time=0.0409\n",
      "Iter=600, loss=1.3810, mse=1.3807, time=0.0403\n",
      "Iter=800, loss=1.3920, mse=1.3917, time=0.0399\n",
      "Iter=1000, loss=1.3798, mse=1.3795, time=0.0398\n",
      "Iter=1200, loss=1.4044, mse=1.4041, time=0.0399\n",
      "Iter=1400, loss=1.3686, mse=1.3683, time=0.0400\n",
      "Iter=1600, loss=1.3436, mse=1.3433, time=0.0401\n",
      "Iter=1800, loss=1.4114, mse=1.4112, time=0.0402\n",
      "Iter=2000, loss=1.4185, mse=1.4182, time=0.0403\n",
      "Iter=2200, loss=1.3848, mse=1.3845, time=0.0403\n",
      "Iter=2400, loss=1.3583, mse=1.3580, time=0.0404\n",
      "Iter=2600, loss=1.4090, mse=1.4088, time=0.0405\n",
      "Iter=2800, loss=1.3868, mse=1.3865, time=0.0405\n",
      "Iter=3000, loss=1.3588, mse=1.3585, time=0.0405\n",
      "Iter=3200, loss=1.3606, mse=1.3603, time=0.0405\n",
      "Iter=3400, loss=1.3537, mse=1.3534, time=0.0405\n",
      "Iter=3600, loss=1.4324, mse=1.4321, time=0.0405\n",
      "Iter=3800, loss=1.3966, mse=1.3963, time=0.0405\n",
      "Iter=4000, loss=1.3578, mse=1.3575, time=0.0405\n",
      "Iter=4200, loss=1.3938, mse=1.3935, time=0.0405\n",
      "Iter=4400, loss=1.3830, mse=1.3827, time=0.0405\n",
      "Iter=4600, loss=1.4307, mse=1.4304, time=0.0405\n",
      "Iter=4800, loss=1.4114, mse=1.4111, time=0.0405\n",
      "Iter=5000, loss=1.3759, mse=1.3756, time=0.0405\n",
      "Iter=5200, loss=1.4032, mse=1.4029, time=0.0405\n",
      "Iter=5400, loss=1.3946, mse=1.3943, time=0.0406\n",
      "Iter=5600, loss=1.3533, mse=1.3531, time=0.0406\n",
      "Iter=5800, loss=1.3916, mse=1.3914, time=0.0406\n",
      "Iter=6000, loss=1.3655, mse=1.3652, time=0.0406\n",
      "Iter=6200, loss=1.4020, mse=1.4017, time=0.0406\n",
      "Iter=6400, loss=1.3883, mse=1.3880, time=0.0406\n",
      "Iter=6600, loss=1.4092, mse=1.4089, time=0.0406\n",
      "=== Epoch 40, train loss 1.388251, test rmse 1.166653 ===\n",
      "Epoch 41\n",
      "Iter=200, loss=1.3714, mse=1.3711, time=0.0422\n",
      "Iter=400, loss=1.3973, mse=1.3970, time=0.0415\n",
      "Iter=600, loss=1.4076, mse=1.4073, time=0.0415\n",
      "Iter=800, loss=1.4297, mse=1.4294, time=0.0414\n",
      "Iter=1000, loss=1.4033, mse=1.4030, time=0.0413\n",
      "Iter=1200, loss=1.4054, mse=1.4051, time=0.0412\n",
      "Iter=1400, loss=1.3892, mse=1.3889, time=0.0413\n",
      "Iter=1600, loss=1.3644, mse=1.3641, time=0.0413\n",
      "Iter=1800, loss=1.3712, mse=1.3709, time=0.0412\n",
      "Iter=2000, loss=1.4080, mse=1.4077, time=0.0412\n",
      "Iter=2200, loss=1.3872, mse=1.3869, time=0.0412\n",
      "Iter=2400, loss=1.3771, mse=1.3768, time=0.0411\n",
      "Iter=2600, loss=1.3729, mse=1.3726, time=0.0411\n",
      "Iter=2800, loss=1.3854, mse=1.3851, time=0.0410\n",
      "Iter=3000, loss=1.3723, mse=1.3720, time=0.0410\n",
      "Iter=3200, loss=1.3857, mse=1.3854, time=0.0410\n",
      "Iter=3400, loss=1.3965, mse=1.3962, time=0.0410\n",
      "Iter=3600, loss=1.3512, mse=1.3509, time=0.0412\n",
      "Iter=3800, loss=1.3881, mse=1.3878, time=0.0411\n",
      "Iter=4000, loss=1.3532, mse=1.3529, time=0.0411\n",
      "Iter=4200, loss=1.3696, mse=1.3693, time=0.0411\n",
      "Iter=4400, loss=1.3733, mse=1.3730, time=0.0411\n",
      "Iter=4600, loss=1.3941, mse=1.3938, time=0.0411\n",
      "Iter=4800, loss=1.3718, mse=1.3715, time=0.0411\n",
      "Iter=5000, loss=1.3929, mse=1.3926, time=0.0411\n",
      "Iter=5200, loss=1.3903, mse=1.3900, time=0.0410\n",
      "Iter=5400, loss=1.3851, mse=1.3848, time=0.0410\n",
      "Iter=5600, loss=1.3827, mse=1.3823, time=0.0410\n",
      "Iter=5800, loss=1.4110, mse=1.4107, time=0.0410\n",
      "Iter=6000, loss=1.3960, mse=1.3957, time=0.0410\n",
      "Iter=6200, loss=1.4262, mse=1.4259, time=0.0410\n",
      "Iter=6400, loss=1.3547, mse=1.3544, time=0.0410\n",
      "Iter=6600, loss=1.3895, mse=1.3892, time=0.0410\n",
      "=== Epoch 41, train loss 1.386287, test rmse 1.165340 ===\n",
      "Epoch 42\n",
      "Iter=200, loss=1.3714, mse=1.3711, time=0.0418\n",
      "Iter=400, loss=1.4361, mse=1.4358, time=0.0416\n",
      "Iter=600, loss=1.3586, mse=1.3582, time=0.0412\n",
      "Iter=800, loss=1.3842, mse=1.3839, time=0.0411\n",
      "Iter=1000, loss=1.4235, mse=1.4232, time=0.0411\n",
      "Iter=1200, loss=1.3913, mse=1.3910, time=0.0411\n",
      "Iter=1400, loss=1.4070, mse=1.4067, time=0.0410\n",
      "Iter=1600, loss=1.3726, mse=1.3723, time=0.0409\n",
      "Iter=1800, loss=1.3584, mse=1.3581, time=0.0409\n",
      "Iter=2000, loss=1.4129, mse=1.4126, time=0.0409\n",
      "Iter=2200, loss=1.4039, mse=1.4036, time=0.0409\n",
      "Iter=2400, loss=1.3516, mse=1.3513, time=0.0409\n",
      "Iter=2600, loss=1.3757, mse=1.3754, time=0.0408\n",
      "Iter=2800, loss=1.4230, mse=1.4227, time=0.0408\n",
      "Iter=3000, loss=1.4120, mse=1.4117, time=0.0410\n",
      "Iter=3200, loss=1.3770, mse=1.3767, time=0.0413\n",
      "Iter=3400, loss=1.4070, mse=1.4067, time=0.0414\n",
      "Iter=3600, loss=1.4043, mse=1.4040, time=0.0413\n",
      "Iter=3800, loss=1.3863, mse=1.3860, time=0.0413\n",
      "Iter=4000, loss=1.3730, mse=1.3727, time=0.0413\n",
      "Iter=4200, loss=1.3769, mse=1.3766, time=0.0413\n",
      "Iter=4400, loss=1.3896, mse=1.3893, time=0.0412\n",
      "Iter=4600, loss=1.4016, mse=1.4013, time=0.0412\n",
      "Iter=4800, loss=1.3863, mse=1.3860, time=0.0412\n",
      "Iter=5000, loss=1.3763, mse=1.3760, time=0.0412\n",
      "Iter=5200, loss=1.3637, mse=1.3634, time=0.0412\n",
      "Iter=5400, loss=1.3815, mse=1.3812, time=0.0411\n",
      "Iter=5600, loss=1.3754, mse=1.3751, time=0.0411\n",
      "Iter=5800, loss=1.3808, mse=1.3805, time=0.0411\n",
      "Iter=6000, loss=1.4036, mse=1.4033, time=0.0410\n",
      "Iter=6200, loss=1.3901, mse=1.3898, time=0.0409\n",
      "Iter=6400, loss=1.3588, mse=1.3585, time=0.0409\n",
      "Iter=6600, loss=1.3824, mse=1.3820, time=0.0409\n",
      "=== Epoch 42, train loss 1.388018, test rmse 1.174273 ===\n",
      "Epoch 43\n",
      "Iter=200, loss=1.4149, mse=1.4146, time=0.0416\n",
      "Iter=400, loss=1.4030, mse=1.4027, time=0.0408\n",
      "Iter=600, loss=1.3979, mse=1.3976, time=0.0408\n",
      "Iter=800, loss=1.4061, mse=1.4058, time=0.0408\n",
      "Iter=1000, loss=1.4055, mse=1.4051, time=0.0406\n",
      "Iter=1200, loss=1.4154, mse=1.4151, time=0.0409\n",
      "Iter=1400, loss=1.3701, mse=1.3697, time=0.0408\n",
      "Iter=1600, loss=1.3780, mse=1.3777, time=0.0408\n",
      "Iter=1800, loss=1.4002, mse=1.3998, time=0.0407\n",
      "Iter=2000, loss=1.3845, mse=1.3842, time=0.0407\n",
      "Iter=2200, loss=1.3862, mse=1.3859, time=0.0407\n",
      "Iter=2400, loss=1.3793, mse=1.3790, time=0.0407\n",
      "Iter=2600, loss=1.3528, mse=1.3524, time=0.0406\n",
      "Iter=2800, loss=1.3657, mse=1.3653, time=0.0407\n",
      "Iter=3000, loss=1.3962, mse=1.3958, time=0.0407\n",
      "Iter=3200, loss=1.3726, mse=1.3723, time=0.0407\n",
      "Iter=3400, loss=1.3943, mse=1.3939, time=0.0407\n",
      "Iter=3600, loss=1.3704, mse=1.3700, time=0.0407\n",
      "Iter=3800, loss=1.3540, mse=1.3536, time=0.0407\n",
      "Iter=4000, loss=1.3916, mse=1.3912, time=0.0407\n",
      "Iter=4200, loss=1.3924, mse=1.3920, time=0.0407\n",
      "Iter=4400, loss=1.3723, mse=1.3720, time=0.0406\n",
      "Iter=4600, loss=1.4088, mse=1.4084, time=0.0406\n",
      "Iter=4800, loss=1.3761, mse=1.3758, time=0.0406\n",
      "Iter=5000, loss=1.3886, mse=1.3883, time=0.0406\n",
      "Iter=5200, loss=1.3838, mse=1.3835, time=0.0405\n",
      "Iter=5400, loss=1.3948, mse=1.3945, time=0.0405\n",
      "Iter=5600, loss=1.3868, mse=1.3865, time=0.0405\n",
      "Iter=5800, loss=1.3430, mse=1.3426, time=0.0405\n",
      "Iter=6000, loss=1.4213, mse=1.4209, time=0.0405\n",
      "Iter=6200, loss=1.4041, mse=1.4038, time=0.0405\n",
      "Iter=6400, loss=1.3646, mse=1.3642, time=0.0405\n",
      "Iter=6600, loss=1.4115, mse=1.4112, time=0.0405\n",
      "=== Epoch 43, train loss 1.387266, test rmse 1.166730 ===\n",
      "Epoch 44\n",
      "Iter=200, loss=1.4239, mse=1.4235, time=0.0413\n",
      "Iter=400, loss=1.3755, mse=1.3752, time=0.0413\n",
      "Iter=600, loss=1.4078, mse=1.4075, time=0.0411\n",
      "Iter=800, loss=1.4098, mse=1.4095, time=0.0409\n",
      "Iter=1000, loss=1.3870, mse=1.3867, time=0.0409\n",
      "Iter=1200, loss=1.3780, mse=1.3777, time=0.0408\n",
      "Iter=1400, loss=1.4138, mse=1.4135, time=0.0408\n",
      "Iter=1600, loss=1.3835, mse=1.3832, time=0.0407\n",
      "Iter=1800, loss=1.3798, mse=1.3795, time=0.0408\n",
      "Iter=2000, loss=1.3630, mse=1.3627, time=0.0408\n",
      "Iter=2200, loss=1.3790, mse=1.3787, time=0.0408\n",
      "Iter=2400, loss=1.4035, mse=1.4032, time=0.0408\n",
      "Iter=2600, loss=1.3983, mse=1.3979, time=0.0408\n",
      "Iter=2800, loss=1.3818, mse=1.3815, time=0.0407\n",
      "Iter=3000, loss=1.3888, mse=1.3885, time=0.0407\n",
      "Iter=3200, loss=1.3755, mse=1.3752, time=0.0407\n",
      "Iter=3400, loss=1.3758, mse=1.3755, time=0.0408\n",
      "Iter=3600, loss=1.3706, mse=1.3703, time=0.0408\n",
      "Iter=3800, loss=1.3888, mse=1.3884, time=0.0408\n",
      "Iter=4000, loss=1.4049, mse=1.4045, time=0.0407\n",
      "Iter=4200, loss=1.3921, mse=1.3918, time=0.0406\n",
      "Iter=4400, loss=1.3996, mse=1.3993, time=0.0405\n",
      "Iter=4600, loss=1.3761, mse=1.3758, time=0.0405\n",
      "Iter=4800, loss=1.4107, mse=1.4104, time=0.0405\n",
      "Iter=5000, loss=1.3844, mse=1.3841, time=0.0405\n",
      "Iter=5200, loss=1.3980, mse=1.3977, time=0.0406\n",
      "Iter=5400, loss=1.3817, mse=1.3814, time=0.0406\n",
      "Iter=5600, loss=1.4070, mse=1.4067, time=0.0406\n",
      "Iter=5800, loss=1.3446, mse=1.3443, time=0.0406\n",
      "Iter=6000, loss=1.4099, mse=1.4096, time=0.0406\n",
      "Iter=6200, loss=1.4142, mse=1.4138, time=0.0406\n",
      "Iter=6400, loss=1.3674, mse=1.3671, time=0.0406\n",
      "Iter=6600, loss=1.3730, mse=1.3726, time=0.0406\n",
      "=== Epoch 44, train loss 1.389566, test rmse 1.163687 ===\n",
      "Epoch 45\n",
      "Iter=200, loss=1.4080, mse=1.4077, time=0.0461\n",
      "Iter=400, loss=1.3896, mse=1.3893, time=0.0442\n",
      "Iter=600, loss=1.3537, mse=1.3534, time=0.0436\n",
      "Iter=800, loss=1.4232, mse=1.4229, time=0.0431\n",
      "Iter=1000, loss=1.3888, mse=1.3885, time=0.0425\n",
      "Iter=1200, loss=1.3960, mse=1.3957, time=0.0423\n",
      "Iter=1400, loss=1.3764, mse=1.3761, time=0.0421\n",
      "Iter=1600, loss=1.3642, mse=1.3639, time=0.0420\n",
      "Iter=1800, loss=1.4144, mse=1.4141, time=0.0418\n",
      "Iter=2000, loss=1.3980, mse=1.3977, time=0.0416\n",
      "Iter=2200, loss=1.3827, mse=1.3824, time=0.0416\n",
      "Iter=2400, loss=1.3949, mse=1.3946, time=0.0415\n",
      "Iter=2600, loss=1.3989, mse=1.3986, time=0.0414\n",
      "Iter=2800, loss=1.3829, mse=1.3826, time=0.0413\n",
      "Iter=3000, loss=1.3707, mse=1.3703, time=0.0413\n",
      "Iter=3200, loss=1.3604, mse=1.3601, time=0.0411\n",
      "Iter=3400, loss=1.3667, mse=1.3664, time=0.0411\n",
      "Iter=3600, loss=1.4167, mse=1.4164, time=0.0410\n",
      "Iter=3800, loss=1.3796, mse=1.3793, time=0.0410\n",
      "Iter=4000, loss=1.3967, mse=1.3964, time=0.0410\n",
      "Iter=4200, loss=1.3959, mse=1.3956, time=0.0410\n",
      "Iter=4400, loss=1.3995, mse=1.3992, time=0.0410\n",
      "Iter=4600, loss=1.3910, mse=1.3907, time=0.0410\n",
      "Iter=4800, loss=1.3522, mse=1.3518, time=0.0410\n",
      "Iter=5000, loss=1.3675, mse=1.3671, time=0.0410\n",
      "Iter=5200, loss=1.4160, mse=1.4156, time=0.0410\n",
      "Iter=5400, loss=1.3518, mse=1.3515, time=0.0410\n",
      "Iter=5600, loss=1.4031, mse=1.4027, time=0.0410\n",
      "Iter=5800, loss=1.3752, mse=1.3749, time=0.0410\n",
      "Iter=6000, loss=1.3663, mse=1.3660, time=0.0410\n",
      "Iter=6200, loss=1.4214, mse=1.4211, time=0.0410\n",
      "Iter=6400, loss=1.4085, mse=1.4081, time=0.0410\n",
      "Iter=6600, loss=1.3922, mse=1.3919, time=0.0409\n",
      "=== Epoch 45, train loss 1.388323, test rmse 1.171120 ===\n",
      "Epoch 46\n",
      "Iter=200, loss=1.3985, mse=1.3982, time=0.0420\n",
      "Iter=400, loss=1.3601, mse=1.3598, time=0.0414\n",
      "Iter=600, loss=1.3866, mse=1.3863, time=0.0413\n",
      "Iter=800, loss=1.3899, mse=1.3895, time=0.0411\n",
      "Iter=1000, loss=1.3836, mse=1.3833, time=0.0410\n",
      "Iter=1200, loss=1.3611, mse=1.3608, time=0.0409\n",
      "Iter=1400, loss=1.3764, mse=1.3760, time=0.0409\n",
      "Iter=1600, loss=1.3938, mse=1.3935, time=0.0408\n",
      "Iter=1800, loss=1.4065, mse=1.4061, time=0.0408\n",
      "Iter=2000, loss=1.3863, mse=1.3860, time=0.0408\n",
      "Iter=2200, loss=1.3903, mse=1.3899, time=0.0408\n",
      "Iter=2400, loss=1.3838, mse=1.3835, time=0.0406\n",
      "Iter=2600, loss=1.3848, mse=1.3845, time=0.0406\n",
      "Iter=2800, loss=1.4269, mse=1.4265, time=0.0406\n",
      "Iter=3000, loss=1.3879, mse=1.3876, time=0.0407\n",
      "Iter=3200, loss=1.3769, mse=1.3765, time=0.0407\n",
      "Iter=3400, loss=1.3731, mse=1.3727, time=0.0407\n",
      "Iter=3600, loss=1.3577, mse=1.3574, time=0.0407\n",
      "Iter=3800, loss=1.3945, mse=1.3941, time=0.0407\n",
      "Iter=4000, loss=1.4037, mse=1.4034, time=0.0407\n",
      "Iter=4200, loss=1.3860, mse=1.3856, time=0.0407\n",
      "Iter=4400, loss=1.3776, mse=1.3773, time=0.0407\n",
      "Iter=4600, loss=1.3993, mse=1.3990, time=0.0407\n",
      "Iter=4800, loss=1.4043, mse=1.4039, time=0.0407\n",
      "Iter=5000, loss=1.4368, mse=1.4365, time=0.0407\n",
      "Iter=5200, loss=1.3843, mse=1.3839, time=0.0407\n",
      "Iter=5400, loss=1.3891, mse=1.3887, time=0.0407\n",
      "Iter=5600, loss=1.3994, mse=1.3991, time=0.0407\n",
      "Iter=5800, loss=1.4073, mse=1.4069, time=0.0407\n",
      "Iter=6000, loss=1.3817, mse=1.3814, time=0.0407\n",
      "Iter=6200, loss=1.3613, mse=1.3610, time=0.0408\n",
      "Iter=6400, loss=1.4125, mse=1.4122, time=0.0407\n",
      "Iter=6600, loss=1.3832, mse=1.3829, time=0.0407\n",
      "=== Epoch 46, train loss 1.388210, test rmse 1.164152 ===\n",
      "Epoch 47\n",
      "Iter=200, loss=1.3411, mse=1.3408, time=0.0413\n",
      "Iter=400, loss=1.3677, mse=1.3674, time=0.0412\n",
      "Iter=600, loss=1.3892, mse=1.3889, time=0.0409\n",
      "Iter=800, loss=1.4051, mse=1.4048, time=0.0408\n",
      "Iter=1000, loss=1.3735, mse=1.3732, time=0.0408\n",
      "Iter=1200, loss=1.3778, mse=1.3775, time=0.0406\n",
      "Iter=1400, loss=1.3788, mse=1.3785, time=0.0403\n",
      "Iter=1600, loss=1.3659, mse=1.3656, time=0.0401\n",
      "Iter=1800, loss=1.4096, mse=1.4093, time=0.0403\n",
      "Iter=2000, loss=1.3864, mse=1.3861, time=0.0403\n",
      "Iter=2200, loss=1.3975, mse=1.3972, time=0.0403\n",
      "Iter=2400, loss=1.3834, mse=1.3831, time=0.0405\n",
      "Iter=2600, loss=1.3774, mse=1.3771, time=0.0407\n",
      "Iter=2800, loss=1.3848, mse=1.3845, time=0.0407\n",
      "Iter=3000, loss=1.4114, mse=1.4110, time=0.0408\n",
      "Iter=3200, loss=1.3788, mse=1.3784, time=0.0410\n",
      "Iter=3400, loss=1.3553, mse=1.3550, time=0.0410\n",
      "Iter=3600, loss=1.3944, mse=1.3941, time=0.0410\n",
      "Iter=3800, loss=1.4125, mse=1.4121, time=0.0410\n",
      "Iter=4000, loss=1.3683, mse=1.3679, time=0.0409\n",
      "Iter=4200, loss=1.3694, mse=1.3691, time=0.0409\n",
      "Iter=4400, loss=1.3918, mse=1.3915, time=0.0409\n",
      "Iter=4600, loss=1.4023, mse=1.4020, time=0.0409\n",
      "Iter=4800, loss=1.4050, mse=1.4047, time=0.0409\n",
      "Iter=5000, loss=1.4070, mse=1.4067, time=0.0409\n",
      "Iter=5200, loss=1.4215, mse=1.4212, time=0.0409\n",
      "Iter=5400, loss=1.3879, mse=1.3876, time=0.0409\n",
      "Iter=5600, loss=1.3820, mse=1.3817, time=0.0409\n",
      "Iter=5800, loss=1.3803, mse=1.3800, time=0.0409\n",
      "Iter=6000, loss=1.4278, mse=1.4275, time=0.0409\n",
      "Iter=6200, loss=1.3909, mse=1.3906, time=0.0409\n",
      "Iter=6400, loss=1.3812, mse=1.3809, time=0.0409\n",
      "Iter=6600, loss=1.3945, mse=1.3941, time=0.0408\n",
      "=== Epoch 47, train loss 1.388119, test rmse 1.166285 ===\n",
      "Epoch 48\n",
      "Iter=200, loss=1.3873, mse=1.3870, time=0.0413\n",
      "Iter=400, loss=1.3981, mse=1.3978, time=0.0399\n",
      "Iter=600, loss=1.4106, mse=1.4103, time=0.0397\n",
      "Iter=800, loss=1.3831, mse=1.3828, time=0.0395\n",
      "Iter=1000, loss=1.3853, mse=1.3850, time=0.0396\n",
      "Iter=1200, loss=1.3815, mse=1.3812, time=0.0399\n",
      "Iter=1400, loss=1.3724, mse=1.3721, time=0.0401\n",
      "Iter=1600, loss=1.3940, mse=1.3936, time=0.0402\n",
      "Iter=1800, loss=1.4054, mse=1.4050, time=0.0403\n",
      "Iter=2000, loss=1.3840, mse=1.3837, time=0.0403\n",
      "Iter=2200, loss=1.3801, mse=1.3797, time=0.0404\n",
      "Iter=2400, loss=1.4029, mse=1.4025, time=0.0405\n",
      "Iter=2600, loss=1.3903, mse=1.3900, time=0.0406\n",
      "Iter=2800, loss=1.4141, mse=1.4138, time=0.0406\n",
      "Iter=3000, loss=1.3927, mse=1.3924, time=0.0406\n",
      "Iter=3200, loss=1.3909, mse=1.3906, time=0.0406\n",
      "Iter=3400, loss=1.3919, mse=1.3916, time=0.0406\n",
      "Iter=3600, loss=1.3701, mse=1.3698, time=0.0406\n",
      "Iter=3800, loss=1.3932, mse=1.3928, time=0.0406\n",
      "Iter=4000, loss=1.3880, mse=1.3877, time=0.0406\n",
      "Iter=4200, loss=1.3623, mse=1.3619, time=0.0406\n",
      "Iter=4400, loss=1.4049, mse=1.4045, time=0.0406\n",
      "Iter=4600, loss=1.3684, mse=1.3680, time=0.0407\n",
      "Iter=4800, loss=1.3659, mse=1.3655, time=0.0406\n",
      "Iter=5000, loss=1.3870, mse=1.3867, time=0.0406\n",
      "Iter=5200, loss=1.3671, mse=1.3668, time=0.0407\n",
      "Iter=5400, loss=1.3624, mse=1.3620, time=0.0407\n",
      "Iter=5600, loss=1.3791, mse=1.3788, time=0.0407\n",
      "Iter=5800, loss=1.3596, mse=1.3593, time=0.0407\n",
      "Iter=6000, loss=1.3824, mse=1.3821, time=0.0407\n",
      "Iter=6200, loss=1.3710, mse=1.3706, time=0.0406\n",
      "Iter=6400, loss=1.4051, mse=1.4048, time=0.0406\n",
      "Iter=6600, loss=1.4447, mse=1.4443, time=0.0406\n",
      "=== Epoch 48, train loss 1.387361, test rmse 1.165508 ===\n",
      "Epoch 49\n",
      "Iter=200, loss=1.4082, mse=1.4078, time=0.0422\n",
      "Iter=400, loss=1.3841, mse=1.3837, time=0.0414\n",
      "Iter=600, loss=1.3857, mse=1.3854, time=0.0413\n",
      "Iter=800, loss=1.3856, mse=1.3853, time=0.0411\n",
      "Iter=1000, loss=1.3501, mse=1.3497, time=0.0410\n",
      "Iter=1200, loss=1.3869, mse=1.3866, time=0.0410\n",
      "Iter=1400, loss=1.4101, mse=1.4098, time=0.0411\n",
      "Iter=1600, loss=1.3859, mse=1.3855, time=0.0410\n",
      "Iter=1800, loss=1.3878, mse=1.3875, time=0.0410\n",
      "Iter=2000, loss=1.3797, mse=1.3794, time=0.0410\n",
      "Iter=2200, loss=1.4051, mse=1.4048, time=0.0410\n",
      "Iter=2400, loss=1.3874, mse=1.3871, time=0.0410\n",
      "Iter=2600, loss=1.4083, mse=1.4080, time=0.0409\n",
      "Iter=2800, loss=1.3745, mse=1.3742, time=0.0409\n",
      "Iter=3000, loss=1.3821, mse=1.3818, time=0.0409\n",
      "Iter=3200, loss=1.3979, mse=1.3976, time=0.0409\n",
      "Iter=3400, loss=1.3661, mse=1.3657, time=0.0409\n",
      "Iter=3600, loss=1.3813, mse=1.3810, time=0.0409\n",
      "Iter=3800, loss=1.3939, mse=1.3935, time=0.0409\n",
      "Iter=4000, loss=1.3868, mse=1.3865, time=0.0409\n",
      "Iter=4200, loss=1.3589, mse=1.3586, time=0.0409\n",
      "Iter=4400, loss=1.4319, mse=1.4316, time=0.0409\n",
      "Iter=4600, loss=1.3915, mse=1.3912, time=0.0409\n",
      "Iter=4800, loss=1.4007, mse=1.4003, time=0.0409\n",
      "Iter=5000, loss=1.3870, mse=1.3866, time=0.0409\n",
      "Iter=5200, loss=1.4282, mse=1.4279, time=0.0409\n",
      "Iter=5400, loss=1.3615, mse=1.3612, time=0.0409\n",
      "Iter=5600, loss=1.3773, mse=1.3770, time=0.0409\n",
      "Iter=5800, loss=1.3393, mse=1.3390, time=0.0409\n",
      "Iter=6000, loss=1.3997, mse=1.3994, time=0.0408\n",
      "Iter=6200, loss=1.3908, mse=1.3904, time=0.0409\n",
      "Iter=6400, loss=1.3975, mse=1.3972, time=0.0409\n",
      "Iter=6600, loss=1.3862, mse=1.3859, time=0.0409\n",
      "=== Epoch 49, train loss 1.388542, test rmse 1.165987 ===\n",
      "Epoch 50\n",
      "Iter=200, loss=1.3985, mse=1.3981, time=0.0425\n",
      "Iter=400, loss=1.4111, mse=1.4107, time=0.0421\n",
      "Iter=600, loss=1.3759, mse=1.3755, time=0.0416\n",
      "Iter=800, loss=1.3841, mse=1.3837, time=0.0415\n",
      "Iter=1000, loss=1.3485, mse=1.3481, time=0.0413\n",
      "Iter=1200, loss=1.3805, mse=1.3801, time=0.0414\n",
      "Iter=1400, loss=1.3755, mse=1.3752, time=0.0413\n",
      "Iter=1600, loss=1.3766, mse=1.3762, time=0.0413\n",
      "Iter=1800, loss=1.3957, mse=1.3953, time=0.0413\n",
      "Iter=2000, loss=1.4294, mse=1.4290, time=0.0412\n",
      "Iter=2200, loss=1.4089, mse=1.4086, time=0.0412\n",
      "Iter=2400, loss=1.4073, mse=1.4070, time=0.0411\n",
      "Iter=2600, loss=1.3698, mse=1.3694, time=0.0411\n",
      "Iter=2800, loss=1.3800, mse=1.3797, time=0.0410\n",
      "Iter=3000, loss=1.3735, mse=1.3732, time=0.0410\n",
      "Iter=3200, loss=1.3942, mse=1.3939, time=0.0410\n",
      "Iter=3400, loss=1.3629, mse=1.3626, time=0.0410\n",
      "Iter=3600, loss=1.3690, mse=1.3687, time=0.0410\n",
      "Iter=3800, loss=1.3780, mse=1.3777, time=0.0409\n",
      "Iter=4000, loss=1.3567, mse=1.3564, time=0.0409\n",
      "Iter=4200, loss=1.4043, mse=1.4039, time=0.0409\n",
      "Iter=4400, loss=1.3635, mse=1.3631, time=0.0409\n",
      "Iter=4600, loss=1.3927, mse=1.3924, time=0.0409\n",
      "Iter=4800, loss=1.4165, mse=1.4162, time=0.0409\n",
      "Iter=5000, loss=1.3753, mse=1.3749, time=0.0408\n",
      "Iter=5200, loss=1.4250, mse=1.4247, time=0.0408\n",
      "Iter=5400, loss=1.3739, mse=1.3735, time=0.0408\n",
      "Iter=5600, loss=1.3708, mse=1.3704, time=0.0408\n",
      "Iter=5800, loss=1.3981, mse=1.3977, time=0.0408\n",
      "Iter=6000, loss=1.4017, mse=1.4013, time=0.0407\n",
      "Iter=6200, loss=1.3883, mse=1.3880, time=0.0407\n",
      "Iter=6400, loss=1.3763, mse=1.3760, time=0.0407\n",
      "Iter=6600, loss=1.4002, mse=1.3998, time=0.0406\n",
      "=== Epoch 50, train loss 1.386687, test rmse 1.164353 ===\n",
      "Epoch 51\n",
      "Iter=200, loss=1.3805, mse=1.3802, time=0.0421\n",
      "Iter=400, loss=1.3628, mse=1.3625, time=0.0413\n",
      "Iter=600, loss=1.3884, mse=1.3881, time=0.0413\n",
      "Iter=800, loss=1.4016, mse=1.4013, time=0.0410\n",
      "Iter=1000, loss=1.4183, mse=1.4179, time=0.0409\n",
      "Iter=1200, loss=1.4256, mse=1.4253, time=0.0410\n",
      "Iter=1400, loss=1.4076, mse=1.4073, time=0.0409\n",
      "Iter=1600, loss=1.3755, mse=1.3752, time=0.0409\n",
      "Iter=1800, loss=1.3928, mse=1.3925, time=0.0408\n",
      "Iter=2000, loss=1.3643, mse=1.3640, time=0.0409\n",
      "Iter=2200, loss=1.3795, mse=1.3791, time=0.0408\n",
      "Iter=2400, loss=1.3962, mse=1.3958, time=0.0409\n",
      "Iter=2600, loss=1.3679, mse=1.3676, time=0.0408\n",
      "Iter=2800, loss=1.3659, mse=1.3656, time=0.0408\n",
      "Iter=3000, loss=1.3813, mse=1.3810, time=0.0408\n",
      "Iter=3200, loss=1.3818, mse=1.3815, time=0.0408\n",
      "Iter=3400, loss=1.4190, mse=1.4187, time=0.0407\n",
      "Iter=3600, loss=1.3869, mse=1.3866, time=0.0407\n",
      "Iter=3800, loss=1.3916, mse=1.3913, time=0.0407\n",
      "Iter=4000, loss=1.3787, mse=1.3784, time=0.0407\n",
      "Iter=4200, loss=1.3830, mse=1.3826, time=0.0408\n",
      "Iter=4400, loss=1.3709, mse=1.3706, time=0.0407\n",
      "Iter=4600, loss=1.3683, mse=1.3680, time=0.0407\n",
      "Iter=4800, loss=1.4004, mse=1.4001, time=0.0407\n",
      "Iter=5000, loss=1.3923, mse=1.3920, time=0.0406\n",
      "Iter=5200, loss=1.3672, mse=1.3668, time=0.0406\n",
      "Iter=5400, loss=1.3725, mse=1.3722, time=0.0406\n",
      "Iter=5600, loss=1.3941, mse=1.3938, time=0.0406\n",
      "Iter=5800, loss=1.4085, mse=1.4082, time=0.0406\n",
      "Iter=6000, loss=1.3605, mse=1.3602, time=0.0406\n",
      "Iter=6200, loss=1.3708, mse=1.3705, time=0.0406\n",
      "Iter=6400, loss=1.4265, mse=1.4262, time=0.0406\n",
      "Iter=6600, loss=1.4017, mse=1.4013, time=0.0406\n",
      "=== Epoch 51, train loss 1.388168, test rmse 1.164867 ===\n",
      "Epoch 52\n",
      "Iter=200, loss=1.4169, mse=1.4166, time=0.0416\n",
      "Iter=400, loss=1.3781, mse=1.3779, time=0.0411\n",
      "Iter=600, loss=1.3648, mse=1.3645, time=0.0408\n",
      "Iter=800, loss=1.4016, mse=1.4013, time=0.0407\n",
      "Iter=1000, loss=1.3927, mse=1.3924, time=0.0409\n",
      "Iter=1200, loss=1.3917, mse=1.3914, time=0.0408\n",
      "Iter=1400, loss=1.4309, mse=1.4306, time=0.0408\n",
      "Iter=1600, loss=1.3832, mse=1.3829, time=0.0408\n",
      "Iter=1800, loss=1.3804, mse=1.3801, time=0.0408\n",
      "Iter=2000, loss=1.3878, mse=1.3875, time=0.0408\n",
      "Iter=2200, loss=1.3675, mse=1.3672, time=0.0408\n",
      "Iter=2400, loss=1.4054, mse=1.4051, time=0.0408\n",
      "Iter=2600, loss=1.3868, mse=1.3865, time=0.0408\n",
      "Iter=2800, loss=1.3546, mse=1.3543, time=0.0408\n",
      "Iter=3000, loss=1.4015, mse=1.4012, time=0.0408\n",
      "Iter=3200, loss=1.3734, mse=1.3731, time=0.0408\n",
      "Iter=3400, loss=1.3797, mse=1.3794, time=0.0408\n",
      "Iter=3600, loss=1.4033, mse=1.4029, time=0.0408\n",
      "Iter=3800, loss=1.3588, mse=1.3584, time=0.0408\n",
      "Iter=4000, loss=1.4014, mse=1.4011, time=0.0408\n",
      "Iter=4200, loss=1.4078, mse=1.4075, time=0.0407\n",
      "Iter=4400, loss=1.4022, mse=1.4019, time=0.0407\n",
      "Iter=4600, loss=1.3993, mse=1.3990, time=0.0406\n",
      "Iter=4800, loss=1.3943, mse=1.3940, time=0.0406\n",
      "Iter=5000, loss=1.3593, mse=1.3590, time=0.0406\n",
      "Iter=5200, loss=1.3520, mse=1.3516, time=0.0406\n",
      "Iter=5400, loss=1.3686, mse=1.3682, time=0.0406\n",
      "Iter=5600, loss=1.4024, mse=1.4020, time=0.0406\n",
      "Iter=5800, loss=1.3993, mse=1.3990, time=0.0406\n",
      "Iter=6000, loss=1.3764, mse=1.3761, time=0.0407\n",
      "Iter=6200, loss=1.3899, mse=1.3895, time=0.0407\n",
      "Iter=6400, loss=1.3615, mse=1.3611, time=0.0407\n",
      "Iter=6600, loss=1.4070, mse=1.4067, time=0.0407\n",
      "=== Epoch 52, train loss 1.387437, test rmse 1.167923 ===\n",
      "Epoch 53\n",
      "Iter=200, loss=1.3826, mse=1.3822, time=0.0418\n",
      "Iter=400, loss=1.3728, mse=1.3724, time=0.0413\n",
      "Iter=600, loss=1.3949, mse=1.3946, time=0.0412\n",
      "Iter=800, loss=1.3916, mse=1.3912, time=0.0411\n",
      "Iter=1000, loss=1.3678, mse=1.3674, time=0.0410\n",
      "Iter=1200, loss=1.3972, mse=1.3969, time=0.0409\n",
      "Iter=1400, loss=1.4080, mse=1.4077, time=0.0409\n",
      "Iter=1600, loss=1.4150, mse=1.4147, time=0.0409\n",
      "Iter=1800, loss=1.3849, mse=1.3846, time=0.0407\n",
      "Iter=2000, loss=1.3953, mse=1.3950, time=0.0407\n",
      "Iter=2200, loss=1.3781, mse=1.3777, time=0.0407\n",
      "Iter=2400, loss=1.3672, mse=1.3669, time=0.0407\n",
      "Iter=2600, loss=1.3584, mse=1.3580, time=0.0407\n",
      "Iter=2800, loss=1.3959, mse=1.3955, time=0.0407\n",
      "Iter=3000, loss=1.3675, mse=1.3672, time=0.0408\n",
      "Iter=3200, loss=1.4067, mse=1.4063, time=0.0407\n",
      "Iter=3400, loss=1.3684, mse=1.3681, time=0.0406\n",
      "Iter=3600, loss=1.3925, mse=1.3921, time=0.0405\n",
      "Iter=3800, loss=1.4127, mse=1.4124, time=0.0405\n",
      "Iter=4000, loss=1.3846, mse=1.3843, time=0.0405\n",
      "Iter=4200, loss=1.4032, mse=1.4029, time=0.0405\n",
      "Iter=4400, loss=1.3640, mse=1.3637, time=0.0405\n",
      "Iter=4600, loss=1.3828, mse=1.3825, time=0.0405\n",
      "Iter=4800, loss=1.3711, mse=1.3707, time=0.0405\n",
      "Iter=5000, loss=1.3831, mse=1.3828, time=0.0406\n",
      "Iter=5200, loss=1.3327, mse=1.3323, time=0.0406\n",
      "Iter=5400, loss=1.3926, mse=1.3923, time=0.0406\n",
      "Iter=5600, loss=1.3828, mse=1.3825, time=0.0406\n",
      "Iter=5800, loss=1.3963, mse=1.3959, time=0.0406\n",
      "Iter=6000, loss=1.3873, mse=1.3869, time=0.0406\n",
      "Iter=6200, loss=1.4107, mse=1.4103, time=0.0406\n",
      "Iter=6400, loss=1.3910, mse=1.3907, time=0.0406\n",
      "Iter=6600, loss=1.4082, mse=1.4079, time=0.0407\n",
      "=== Epoch 53, train loss 1.387371, test rmse 1.162446 ===\n",
      "Epoch 54\n",
      "Iter=200, loss=1.3700, mse=1.3697, time=0.0429\n",
      "Iter=400, loss=1.3993, mse=1.3990, time=0.0416\n",
      "Iter=600, loss=1.3419, mse=1.3416, time=0.0413\n",
      "Iter=800, loss=1.4205, mse=1.4202, time=0.0412\n",
      "Iter=1000, loss=1.3713, mse=1.3710, time=0.0410\n",
      "Iter=1200, loss=1.3955, mse=1.3952, time=0.0408\n",
      "Iter=1400, loss=1.3701, mse=1.3698, time=0.0408\n",
      "Iter=1600, loss=1.3767, mse=1.3764, time=0.0408\n",
      "Iter=1800, loss=1.4193, mse=1.4190, time=0.0408\n",
      "Iter=2000, loss=1.4137, mse=1.4133, time=0.0408\n",
      "Iter=2200, loss=1.3641, mse=1.3638, time=0.0407\n",
      "Iter=2400, loss=1.3811, mse=1.3808, time=0.0406\n",
      "Iter=2600, loss=1.4234, mse=1.4231, time=0.0405\n",
      "Iter=2800, loss=1.3851, mse=1.3848, time=0.0404\n",
      "Iter=3000, loss=1.3721, mse=1.3718, time=0.0404\n",
      "Iter=3200, loss=1.3697, mse=1.3694, time=0.0404\n",
      "Iter=3400, loss=1.3823, mse=1.3820, time=0.0404\n",
      "Iter=3600, loss=1.3698, mse=1.3695, time=0.0405\n",
      "Iter=3800, loss=1.3637, mse=1.3633, time=0.0405\n",
      "Iter=4000, loss=1.3882, mse=1.3879, time=0.0406\n",
      "Iter=4200, loss=1.3846, mse=1.3843, time=0.0406\n",
      "Iter=4400, loss=1.3826, mse=1.3823, time=0.0406\n",
      "Iter=4600, loss=1.3953, mse=1.3950, time=0.0406\n",
      "Iter=4800, loss=1.3731, mse=1.3728, time=0.0407\n",
      "Iter=5000, loss=1.3717, mse=1.3713, time=0.0408\n",
      "Iter=5200, loss=1.3802, mse=1.3799, time=0.0408\n",
      "Iter=5400, loss=1.4050, mse=1.4046, time=0.0408\n",
      "Iter=5600, loss=1.4055, mse=1.4051, time=0.0408\n",
      "Iter=5800, loss=1.3565, mse=1.3561, time=0.0408\n",
      "Iter=6000, loss=1.3866, mse=1.3862, time=0.0408\n",
      "Iter=6200, loss=1.4038, mse=1.4034, time=0.0408\n",
      "Iter=6400, loss=1.4049, mse=1.4045, time=0.0409\n",
      "Iter=6600, loss=1.4226, mse=1.4222, time=0.0408\n",
      "=== Epoch 54, train loss 1.385826, test rmse 1.167027 ===\n",
      "Epoch 55\n",
      "Iter=200, loss=1.3858, mse=1.3854, time=0.0410\n",
      "Iter=400, loss=1.3661, mse=1.3657, time=0.0407\n",
      "Iter=600, loss=1.4135, mse=1.4131, time=0.0407\n",
      "Iter=800, loss=1.3974, mse=1.3970, time=0.0407\n",
      "Iter=1000, loss=1.3883, mse=1.3880, time=0.0407\n",
      "Iter=1200, loss=1.3616, mse=1.3612, time=0.0406\n",
      "Iter=1400, loss=1.3984, mse=1.3980, time=0.0406\n",
      "Iter=1600, loss=1.3861, mse=1.3857, time=0.0403\n",
      "Iter=1800, loss=1.4117, mse=1.4113, time=0.0402\n",
      "Iter=2000, loss=1.3697, mse=1.3694, time=0.0401\n",
      "Iter=2200, loss=1.3731, mse=1.3728, time=0.0401\n",
      "Iter=2400, loss=1.3812, mse=1.3808, time=0.0402\n",
      "Iter=2600, loss=1.3676, mse=1.3673, time=0.0403\n",
      "Iter=2800, loss=1.3893, mse=1.3889, time=0.0403\n",
      "Iter=3000, loss=1.3692, mse=1.3689, time=0.0404\n",
      "Iter=3200, loss=1.3667, mse=1.3663, time=0.0404\n",
      "Iter=3400, loss=1.3933, mse=1.3930, time=0.0404\n",
      "Iter=3600, loss=1.4271, mse=1.4267, time=0.0404\n",
      "Iter=3800, loss=1.3708, mse=1.3704, time=0.0405\n",
      "Iter=4000, loss=1.3710, mse=1.3706, time=0.0405\n",
      "Iter=4200, loss=1.4126, mse=1.4123, time=0.0405\n",
      "Iter=4400, loss=1.3652, mse=1.3649, time=0.0405\n",
      "Iter=4600, loss=1.3866, mse=1.3862, time=0.0405\n",
      "Iter=4800, loss=1.3946, mse=1.3943, time=0.0405\n",
      "Iter=5000, loss=1.4132, mse=1.4129, time=0.0405\n",
      "Iter=5200, loss=1.3973, mse=1.3970, time=0.0405\n",
      "Iter=5400, loss=1.3870, mse=1.3867, time=0.0405\n",
      "Iter=5600, loss=1.3573, mse=1.3569, time=0.0405\n",
      "Iter=5800, loss=1.4208, mse=1.4205, time=0.0405\n",
      "Iter=6000, loss=1.3995, mse=1.3992, time=0.0405\n",
      "Iter=6200, loss=1.3520, mse=1.3517, time=0.0405\n",
      "Iter=6400, loss=1.3908, mse=1.3905, time=0.0405\n",
      "Iter=6600, loss=1.4377, mse=1.4374, time=0.0405\n",
      "=== Epoch 55, train loss 1.387796, test rmse 1.164706 ===\n",
      "Epoch 56\n",
      "Iter=200, loss=1.4017, mse=1.4013, time=0.0419\n",
      "Iter=400, loss=1.3853, mse=1.3849, time=0.0412\n",
      "Iter=600, loss=1.4060, mse=1.4057, time=0.0407\n",
      "Iter=800, loss=1.3900, mse=1.3897, time=0.0402\n",
      "Iter=1000, loss=1.3842, mse=1.3839, time=0.0399\n",
      "Iter=1200, loss=1.4072, mse=1.4068, time=0.0400\n",
      "Iter=1400, loss=1.3888, mse=1.3885, time=0.0401\n",
      "Iter=1600, loss=1.3870, mse=1.3867, time=0.0402\n",
      "Iter=1800, loss=1.3612, mse=1.3609, time=0.0402\n",
      "Iter=2000, loss=1.3901, mse=1.3898, time=0.0403\n",
      "Iter=2200, loss=1.3939, mse=1.3936, time=0.0403\n",
      "Iter=2400, loss=1.3640, mse=1.3637, time=0.0404\n",
      "Iter=2600, loss=1.3617, mse=1.3614, time=0.0404\n",
      "Iter=2800, loss=1.3722, mse=1.3719, time=0.0405\n",
      "Iter=3000, loss=1.4185, mse=1.4181, time=0.0405\n",
      "Iter=3200, loss=1.3766, mse=1.3762, time=0.0405\n",
      "Iter=3400, loss=1.3914, mse=1.3910, time=0.0405\n",
      "Iter=3600, loss=1.3954, mse=1.3951, time=0.0406\n",
      "Iter=3800, loss=1.3734, mse=1.3731, time=0.0406\n",
      "Iter=4000, loss=1.3821, mse=1.3818, time=0.0406\n",
      "Iter=4200, loss=1.3774, mse=1.3771, time=0.0406\n",
      "Iter=4400, loss=1.3829, mse=1.3825, time=0.0406\n",
      "Iter=4600, loss=1.3764, mse=1.3760, time=0.0406\n",
      "Iter=4800, loss=1.4090, mse=1.4086, time=0.0406\n",
      "Iter=5000, loss=1.4024, mse=1.4021, time=0.0406\n",
      "Iter=5200, loss=1.4027, mse=1.4024, time=0.0406\n",
      "Iter=5400, loss=1.4028, mse=1.4024, time=0.0407\n",
      "Iter=5600, loss=1.3771, mse=1.3767, time=0.0406\n",
      "Iter=5800, loss=1.3835, mse=1.3831, time=0.0407\n",
      "Iter=6000, loss=1.4052, mse=1.4048, time=0.0407\n",
      "Iter=6200, loss=1.3815, mse=1.3812, time=0.0407\n",
      "Iter=6400, loss=1.3755, mse=1.3752, time=0.0407\n",
      "Iter=6600, loss=1.4110, mse=1.4107, time=0.0407\n",
      "=== Epoch 56, train loss 1.388479, test rmse 1.166208 ===\n",
      "Epoch 57\n",
      "Iter=200, loss=1.3803, mse=1.3799, time=0.0418\n",
      "Iter=400, loss=1.3736, mse=1.3733, time=0.0408\n",
      "Iter=600, loss=1.3856, mse=1.3853, time=0.0409\n",
      "Iter=800, loss=1.3614, mse=1.3610, time=0.0409\n",
      "Iter=1000, loss=1.4001, mse=1.3997, time=0.0408\n",
      "Iter=1200, loss=1.3748, mse=1.3744, time=0.0408\n",
      "Iter=1400, loss=1.3778, mse=1.3775, time=0.0408\n",
      "Iter=1600, loss=1.3769, mse=1.3765, time=0.0408\n",
      "Iter=1800, loss=1.3904, mse=1.3901, time=0.0409\n",
      "Iter=2000, loss=1.3587, mse=1.3584, time=0.0409\n",
      "Iter=2200, loss=1.3930, mse=1.3927, time=0.0409\n",
      "Iter=2400, loss=1.3828, mse=1.3825, time=0.0408\n",
      "Iter=2600, loss=1.3952, mse=1.3949, time=0.0408\n",
      "Iter=2800, loss=1.3945, mse=1.3942, time=0.0408\n",
      "Iter=3000, loss=1.4097, mse=1.4093, time=0.0408\n",
      "Iter=3200, loss=1.4058, mse=1.4054, time=0.0408\n",
      "Iter=3400, loss=1.4051, mse=1.4047, time=0.0408\n",
      "Iter=3600, loss=1.4057, mse=1.4054, time=0.0408\n",
      "Iter=3800, loss=1.4149, mse=1.4146, time=0.0408\n",
      "Iter=4000, loss=1.3952, mse=1.3948, time=0.0409\n",
      "Iter=4200, loss=1.3886, mse=1.3883, time=0.0408\n",
      "Iter=4400, loss=1.3960, mse=1.3956, time=0.0409\n",
      "Iter=4600, loss=1.3707, mse=1.3703, time=0.0408\n",
      "Iter=4800, loss=1.3724, mse=1.3720, time=0.0409\n",
      "Iter=5000, loss=1.3704, mse=1.3701, time=0.0409\n",
      "Iter=5200, loss=1.4046, mse=1.4043, time=0.0409\n",
      "Iter=5400, loss=1.3782, mse=1.3778, time=0.0409\n",
      "Iter=5600, loss=1.3794, mse=1.3790, time=0.0408\n",
      "Iter=5800, loss=1.3883, mse=1.3879, time=0.0408\n",
      "Iter=6000, loss=1.4239, mse=1.4236, time=0.0408\n",
      "Iter=6200, loss=1.3880, mse=1.3877, time=0.0408\n",
      "Iter=6400, loss=1.3798, mse=1.3794, time=0.0408\n",
      "Iter=6600, loss=1.3845, mse=1.3841, time=0.0408\n",
      "=== Epoch 57, train loss 1.388001, test rmse 1.161787 ===\n",
      "Epoch 58\n",
      "Iter=200, loss=1.3686, mse=1.3683, time=0.0417\n",
      "Iter=400, loss=1.3668, mse=1.3665, time=0.0412\n",
      "Iter=600, loss=1.4204, mse=1.4200, time=0.0411\n",
      "Iter=800, loss=1.3907, mse=1.3904, time=0.0412\n",
      "Iter=1000, loss=1.3663, mse=1.3660, time=0.0410\n",
      "Iter=1200, loss=1.3861, mse=1.3857, time=0.0411\n",
      "Iter=1400, loss=1.4012, mse=1.4009, time=0.0410\n",
      "Iter=1600, loss=1.3623, mse=1.3620, time=0.0409\n",
      "Iter=1800, loss=1.3669, mse=1.3666, time=0.0409\n",
      "Iter=2000, loss=1.3628, mse=1.3624, time=0.0408\n",
      "Iter=2200, loss=1.3993, mse=1.3989, time=0.0408\n",
      "Iter=2400, loss=1.3945, mse=1.3942, time=0.0408\n",
      "Iter=2600, loss=1.4049, mse=1.4046, time=0.0408\n",
      "Iter=2800, loss=1.3986, mse=1.3982, time=0.0408\n",
      "Iter=3000, loss=1.3846, mse=1.3842, time=0.0408\n",
      "Iter=3200, loss=1.3859, mse=1.3855, time=0.0408\n",
      "Iter=3400, loss=1.3793, mse=1.3790, time=0.0408\n",
      "Iter=3600, loss=1.3740, mse=1.3737, time=0.0408\n",
      "Iter=3800, loss=1.4073, mse=1.4069, time=0.0408\n",
      "Iter=4000, loss=1.3682, mse=1.3678, time=0.0408\n",
      "Iter=4200, loss=1.3812, mse=1.3808, time=0.0408\n",
      "Iter=4400, loss=1.3529, mse=1.3525, time=0.0408\n",
      "Iter=4600, loss=1.4081, mse=1.4078, time=0.0408\n",
      "Iter=4800, loss=1.3995, mse=1.3992, time=0.0408\n",
      "Iter=5000, loss=1.3766, mse=1.3763, time=0.0407\n",
      "Iter=5200, loss=1.3794, mse=1.3791, time=0.0408\n",
      "Iter=5400, loss=1.4082, mse=1.4079, time=0.0407\n",
      "Iter=5600, loss=1.4147, mse=1.4144, time=0.0407\n",
      "Iter=5800, loss=1.4010, mse=1.4007, time=0.0407\n",
      "Iter=6000, loss=1.3944, mse=1.3941, time=0.0407\n",
      "Iter=6200, loss=1.3854, mse=1.3850, time=0.0407\n",
      "Iter=6400, loss=1.4036, mse=1.4033, time=0.0406\n",
      "Iter=6600, loss=1.3763, mse=1.3760, time=0.0406\n",
      "=== Epoch 58, train loss 1.386497, test rmse 1.162519 ===\n",
      "Epoch 59\n",
      "Iter=200, loss=1.3554, mse=1.3551, time=0.0424\n",
      "Iter=400, loss=1.3587, mse=1.3584, time=0.0411\n",
      "Iter=600, loss=1.3690, mse=1.3687, time=0.0411\n",
      "Iter=800, loss=1.3860, mse=1.3857, time=0.0409\n",
      "Iter=1000, loss=1.4379, mse=1.4376, time=0.0409\n",
      "Iter=1200, loss=1.4089, mse=1.4086, time=0.0409\n",
      "Iter=1400, loss=1.3848, mse=1.3845, time=0.0409\n",
      "Iter=1600, loss=1.3795, mse=1.3792, time=0.0409\n",
      "Iter=1800, loss=1.3711, mse=1.3707, time=0.0409\n",
      "Iter=2000, loss=1.3770, mse=1.3766, time=0.0409\n",
      "Iter=2200, loss=1.3711, mse=1.3708, time=0.0409\n",
      "Iter=2400, loss=1.3977, mse=1.3974, time=0.0409\n",
      "Iter=2600, loss=1.4132, mse=1.4129, time=0.0408\n",
      "Iter=2800, loss=1.3832, mse=1.3828, time=0.0408\n",
      "Iter=3000, loss=1.3612, mse=1.3609, time=0.0408\n",
      "Iter=3200, loss=1.3950, mse=1.3946, time=0.0408\n",
      "Iter=3400, loss=1.3643, mse=1.3639, time=0.0408\n",
      "Iter=3600, loss=1.4181, mse=1.4177, time=0.0408\n",
      "Iter=3800, loss=1.3891, mse=1.3888, time=0.0408\n",
      "Iter=4000, loss=1.3993, mse=1.3989, time=0.0408\n",
      "Iter=4200, loss=1.4208, mse=1.4205, time=0.0408\n",
      "Iter=4400, loss=1.3913, mse=1.3909, time=0.0408\n",
      "Iter=4600, loss=1.3845, mse=1.3842, time=0.0408\n",
      "Iter=4800, loss=1.3437, mse=1.3434, time=0.0408\n",
      "Iter=5000, loss=1.3871, mse=1.3868, time=0.0408\n",
      "Iter=5200, loss=1.3697, mse=1.3693, time=0.0408\n",
      "Iter=5400, loss=1.4357, mse=1.4353, time=0.0407\n",
      "Iter=5600, loss=1.3910, mse=1.3907, time=0.0407\n",
      "Iter=5800, loss=1.3914, mse=1.3910, time=0.0406\n",
      "Iter=6000, loss=1.3779, mse=1.3776, time=0.0406\n",
      "Iter=6200, loss=1.4066, mse=1.4063, time=0.0406\n",
      "Iter=6400, loss=1.3864, mse=1.3860, time=0.0406\n",
      "Iter=6600, loss=1.3893, mse=1.3889, time=0.0406\n",
      "=== Epoch 59, train loss 1.387196, test rmse 1.167903 ===\n",
      "Epoch 60\n",
      "Iter=200, loss=1.3925, mse=1.3921, time=0.0419\n",
      "Iter=400, loss=1.3481, mse=1.3477, time=0.0412\n",
      "Iter=600, loss=1.4165, mse=1.4162, time=0.0409\n",
      "Iter=800, loss=1.3891, mse=1.3887, time=0.0410\n",
      "Iter=1000, loss=1.3902, mse=1.3899, time=0.0410\n",
      "Iter=1200, loss=1.3902, mse=1.3898, time=0.0409\n",
      "Iter=1400, loss=1.3758, mse=1.3755, time=0.0409\n",
      "Iter=1600, loss=1.3906, mse=1.3902, time=0.0409\n",
      "Iter=1800, loss=1.3505, mse=1.3502, time=0.0408\n",
      "Iter=2000, loss=1.3782, mse=1.3778, time=0.0409\n",
      "Iter=2200, loss=1.4088, mse=1.4085, time=0.0408\n",
      "Iter=2400, loss=1.3813, mse=1.3810, time=0.0408\n",
      "Iter=2600, loss=1.4173, mse=1.4170, time=0.0408\n",
      "Iter=2800, loss=1.3893, mse=1.3890, time=0.0407\n",
      "Iter=3000, loss=1.4014, mse=1.4011, time=0.0408\n",
      "Iter=3200, loss=1.3873, mse=1.3870, time=0.0407\n",
      "Iter=3400, loss=1.3938, mse=1.3934, time=0.0407\n",
      "Iter=3600, loss=1.3864, mse=1.3861, time=0.0408\n",
      "Iter=3800, loss=1.4285, mse=1.4281, time=0.0407\n",
      "Iter=4000, loss=1.3843, mse=1.3839, time=0.0407\n",
      "Iter=4200, loss=1.3772, mse=1.3769, time=0.0407\n",
      "Iter=4400, loss=1.3806, mse=1.3803, time=0.0407\n",
      "Iter=4600, loss=1.3690, mse=1.3687, time=0.0406\n",
      "Iter=4800, loss=1.3631, mse=1.3628, time=0.0406\n",
      "Iter=5000, loss=1.3528, mse=1.3524, time=0.0405\n",
      "Iter=5200, loss=1.4190, mse=1.4187, time=0.0405\n",
      "Iter=5400, loss=1.3983, mse=1.3980, time=0.0405\n",
      "Iter=5600, loss=1.3676, mse=1.3673, time=0.0405\n",
      "Iter=5800, loss=1.4169, mse=1.4166, time=0.0405\n",
      "Iter=6000, loss=1.4009, mse=1.4005, time=0.0405\n",
      "Iter=6200, loss=1.3705, mse=1.3702, time=0.0406\n",
      "Iter=6400, loss=1.3963, mse=1.3959, time=0.0406\n",
      "Iter=6600, loss=1.3935, mse=1.3931, time=0.0406\n",
      "=== Epoch 60, train loss 1.388277, test rmse 1.169016 ===\n",
      "Epoch 61\n",
      "Iter=200, loss=1.3857, mse=1.3853, time=0.0415\n",
      "Iter=400, loss=1.4011, mse=1.4007, time=0.0411\n",
      "Iter=600, loss=1.3819, mse=1.3815, time=0.0412\n",
      "Iter=800, loss=1.4059, mse=1.4055, time=0.0411\n",
      "Iter=1000, loss=1.3766, mse=1.3762, time=0.0409\n",
      "Iter=1200, loss=1.3763, mse=1.3759, time=0.0410\n",
      "Iter=1400, loss=1.3941, mse=1.3938, time=0.0408\n",
      "Iter=1600, loss=1.4015, mse=1.4012, time=0.0408\n",
      "Iter=1800, loss=1.4162, mse=1.4159, time=0.0407\n",
      "Iter=2000, loss=1.4033, mse=1.4030, time=0.0407\n",
      "Iter=2200, loss=1.3963, mse=1.3959, time=0.0406\n",
      "Iter=2400, loss=1.3963, mse=1.3960, time=0.0406\n",
      "Iter=2600, loss=1.3691, mse=1.3688, time=0.0406\n",
      "Iter=2800, loss=1.3581, mse=1.3578, time=0.0406\n",
      "Iter=3000, loss=1.3823, mse=1.3820, time=0.0406\n",
      "Iter=3200, loss=1.3878, mse=1.3875, time=0.0407\n",
      "Iter=3400, loss=1.3706, mse=1.3703, time=0.0406\n",
      "Iter=3600, loss=1.4196, mse=1.4193, time=0.0407\n",
      "Iter=3800, loss=1.3958, mse=1.3954, time=0.0405\n",
      "Iter=4000, loss=1.3612, mse=1.3609, time=0.0404\n",
      "Iter=4200, loss=1.4054, mse=1.4050, time=0.0404\n",
      "Iter=4400, loss=1.3791, mse=1.3787, time=0.0404\n",
      "Iter=4600, loss=1.3691, mse=1.3688, time=0.0404\n",
      "Iter=4800, loss=1.3887, mse=1.3884, time=0.0404\n",
      "Iter=5000, loss=1.3810, mse=1.3807, time=0.0404\n",
      "Iter=5200, loss=1.3550, mse=1.3546, time=0.0405\n",
      "Iter=5400, loss=1.3966, mse=1.3963, time=0.0405\n",
      "Iter=5600, loss=1.4089, mse=1.4086, time=0.0405\n",
      "Iter=5800, loss=1.4053, mse=1.4049, time=0.0405\n",
      "Iter=6000, loss=1.3751, mse=1.3747, time=0.0405\n",
      "Iter=6200, loss=1.3311, mse=1.3307, time=0.0405\n",
      "Iter=6400, loss=1.3915, mse=1.3911, time=0.0405\n",
      "Iter=6600, loss=1.3970, mse=1.3967, time=0.0405\n",
      "=== Epoch 61, train loss 1.387002, test rmse 1.166763 ===\n",
      "Epoch 62\n",
      "Iter=200, loss=1.3976, mse=1.3973, time=0.0415\n",
      "Iter=400, loss=1.3817, mse=1.3813, time=0.0415\n",
      "Iter=600, loss=1.4111, mse=1.4107, time=0.0413\n",
      "Iter=800, loss=1.3692, mse=1.3689, time=0.0410\n",
      "Iter=1000, loss=1.3905, mse=1.3902, time=0.0410\n",
      "Iter=1200, loss=1.3812, mse=1.3808, time=0.0409\n",
      "Iter=1400, loss=1.3854, mse=1.3850, time=0.0410\n",
      "Iter=1600, loss=1.3812, mse=1.3808, time=0.0409\n",
      "Iter=1800, loss=1.3993, mse=1.3989, time=0.0409\n",
      "Iter=2000, loss=1.4068, mse=1.4065, time=0.0409\n",
      "Iter=2200, loss=1.3678, mse=1.3675, time=0.0409\n",
      "Iter=2400, loss=1.3521, mse=1.3518, time=0.0409\n",
      "Iter=2600, loss=1.3704, mse=1.3701, time=0.0410\n",
      "Iter=2800, loss=1.3631, mse=1.3627, time=0.0409\n",
      "Iter=3000, loss=1.3944, mse=1.3941, time=0.0408\n",
      "Iter=3200, loss=1.3779, mse=1.3775, time=0.0407\n",
      "Iter=3400, loss=1.4041, mse=1.4037, time=0.0407\n",
      "Iter=3600, loss=1.4103, mse=1.4099, time=0.0407\n",
      "Iter=3800, loss=1.3971, mse=1.3967, time=0.0406\n",
      "Iter=4000, loss=1.3655, mse=1.3651, time=0.0407\n",
      "Iter=4200, loss=1.4185, mse=1.4182, time=0.0407\n",
      "Iter=4400, loss=1.3823, mse=1.3819, time=0.0407\n",
      "Iter=4600, loss=1.3847, mse=1.3843, time=0.0407\n",
      "Iter=4800, loss=1.3969, mse=1.3966, time=0.0407\n",
      "Iter=5000, loss=1.3839, mse=1.3836, time=0.0407\n",
      "Iter=5200, loss=1.3799, mse=1.3795, time=0.0407\n",
      "Iter=5400, loss=1.3747, mse=1.3744, time=0.0407\n",
      "Iter=5600, loss=1.3725, mse=1.3722, time=0.0407\n",
      "Iter=5800, loss=1.3827, mse=1.3824, time=0.0407\n",
      "Iter=6000, loss=1.3814, mse=1.3810, time=0.0407\n",
      "Iter=6200, loss=1.3658, mse=1.3655, time=0.0407\n",
      "Iter=6400, loss=1.3825, mse=1.3821, time=0.0407\n",
      "Iter=6600, loss=1.4130, mse=1.4126, time=0.0407\n",
      "=== Epoch 62, train loss 1.385764, test rmse 1.164202 ===\n",
      "Epoch 63\n",
      "Iter=200, loss=1.4123, mse=1.4119, time=0.0422\n",
      "Iter=400, loss=1.4235, mse=1.4231, time=0.0414\n",
      "Iter=600, loss=1.3868, mse=1.3864, time=0.0410\n",
      "Iter=800, loss=1.3640, mse=1.3636, time=0.0410\n",
      "Iter=1000, loss=1.3508, mse=1.3504, time=0.0409\n",
      "Iter=1200, loss=1.3771, mse=1.3767, time=0.0409\n",
      "Iter=1400, loss=1.3826, mse=1.3822, time=0.0409\n",
      "Iter=1600, loss=1.3801, mse=1.3798, time=0.0409\n",
      "Iter=1800, loss=1.4077, mse=1.4074, time=0.0408\n",
      "Iter=2000, loss=1.4027, mse=1.4024, time=0.0407\n",
      "Iter=2200, loss=1.3650, mse=1.3646, time=0.0405\n",
      "Iter=2400, loss=1.3882, mse=1.3878, time=0.0405\n",
      "Iter=2600, loss=1.3971, mse=1.3968, time=0.0404\n",
      "Iter=2800, loss=1.3753, mse=1.3750, time=0.0405\n",
      "Iter=3000, loss=1.3932, mse=1.3929, time=0.0405\n",
      "Iter=3200, loss=1.3762, mse=1.3759, time=0.0405\n",
      "Iter=3400, loss=1.3740, mse=1.3736, time=0.0406\n",
      "Iter=3600, loss=1.3680, mse=1.3676, time=0.0406\n",
      "Iter=3800, loss=1.3970, mse=1.3966, time=0.0406\n",
      "Iter=4000, loss=1.4126, mse=1.4122, time=0.0406\n",
      "Iter=4200, loss=1.3714, mse=1.3710, time=0.0407\n",
      "Iter=4400, loss=1.4061, mse=1.4057, time=0.0407\n",
      "Iter=4600, loss=1.3751, mse=1.3748, time=0.0407\n",
      "Iter=4800, loss=1.4137, mse=1.4134, time=0.0407\n",
      "Iter=5000, loss=1.4321, mse=1.4318, time=0.0407\n",
      "Iter=5200, loss=1.4282, mse=1.4278, time=0.0407\n",
      "Iter=5400, loss=1.3647, mse=1.3643, time=0.0407\n",
      "Iter=5600, loss=1.3528, mse=1.3524, time=0.0407\n",
      "Iter=5800, loss=1.3580, mse=1.3577, time=0.0407\n",
      "Iter=6000, loss=1.4196, mse=1.4192, time=0.0407\n",
      "Iter=6200, loss=1.3836, mse=1.3833, time=0.0407\n",
      "Iter=6400, loss=1.3931, mse=1.3928, time=0.0407\n",
      "Iter=6600, loss=1.3775, mse=1.3772, time=0.0407\n",
      "=== Epoch 63, train loss 1.387644, test rmse 1.163498 ===\n",
      "Epoch 64\n",
      "Iter=200, loss=1.3763, mse=1.3759, time=0.0420\n",
      "Iter=400, loss=1.3969, mse=1.3966, time=0.0411\n",
      "Iter=600, loss=1.4003, mse=1.3999, time=0.0414\n",
      "Iter=800, loss=1.3937, mse=1.3933, time=0.0419\n",
      "Iter=1000, loss=1.3804, mse=1.3801, time=0.0420\n",
      "Iter=1200, loss=1.3765, mse=1.3762, time=0.0414\n",
      "Iter=1400, loss=1.4088, mse=1.4084, time=0.0411\n",
      "Iter=1600, loss=1.3445, mse=1.3442, time=0.0409\n",
      "Iter=1800, loss=1.3584, mse=1.3581, time=0.0410\n",
      "Iter=2000, loss=1.3791, mse=1.3788, time=0.0410\n",
      "Iter=2200, loss=1.4276, mse=1.4273, time=0.0409\n",
      "Iter=2400, loss=1.3505, mse=1.3501, time=0.0410\n",
      "Iter=2600, loss=1.3598, mse=1.3595, time=0.0410\n",
      "Iter=2800, loss=1.3846, mse=1.3843, time=0.0410\n",
      "Iter=3000, loss=1.3939, mse=1.3936, time=0.0409\n",
      "Iter=3200, loss=1.4067, mse=1.4064, time=0.0410\n",
      "Iter=3400, loss=1.3959, mse=1.3955, time=0.0410\n",
      "Iter=3600, loss=1.3937, mse=1.3934, time=0.0410\n",
      "Iter=3800, loss=1.3744, mse=1.3741, time=0.0410\n",
      "Iter=4000, loss=1.4090, mse=1.4087, time=0.0410\n",
      "Iter=4200, loss=1.3838, mse=1.3835, time=0.0411\n",
      "Iter=4400, loss=1.3709, mse=1.3706, time=0.0411\n",
      "Iter=4600, loss=1.4113, mse=1.4110, time=0.0410\n",
      "Iter=4800, loss=1.3931, mse=1.3927, time=0.0410\n",
      "Iter=5000, loss=1.3672, mse=1.3668, time=0.0410\n",
      "Iter=5200, loss=1.3689, mse=1.3685, time=0.0410\n",
      "Iter=5400, loss=1.3846, mse=1.3843, time=0.0410\n",
      "Iter=5600, loss=1.4067, mse=1.4064, time=0.0410\n",
      "Iter=5800, loss=1.4098, mse=1.4095, time=0.0410\n",
      "Iter=6000, loss=1.4191, mse=1.4188, time=0.0410\n",
      "Iter=6200, loss=1.4096, mse=1.4092, time=0.0410\n",
      "Iter=6400, loss=1.3584, mse=1.3580, time=0.0410\n",
      "Iter=6600, loss=1.3860, mse=1.3857, time=0.0410\n",
      "=== Epoch 64, train loss 1.387228, test rmse 1.163702 ===\n",
      "Epoch 65\n",
      "Iter=200, loss=1.3559, mse=1.3556, time=0.0403\n",
      "Iter=400, loss=1.3559, mse=1.3556, time=0.0397\n",
      "Iter=600, loss=1.4003, mse=1.3999, time=0.0392\n",
      "Iter=800, loss=1.4033, mse=1.4029, time=0.0394\n",
      "Iter=1000, loss=1.4197, mse=1.4194, time=0.0395\n",
      "Iter=1200, loss=1.3743, mse=1.3740, time=0.0397\n",
      "Iter=1400, loss=1.4017, mse=1.4014, time=0.0399\n",
      "Iter=1600, loss=1.3752, mse=1.3749, time=0.0399\n",
      "Iter=1800, loss=1.3950, mse=1.3947, time=0.0401\n",
      "Iter=2000, loss=1.3597, mse=1.3594, time=0.0401\n",
      "Iter=2200, loss=1.4247, mse=1.4244, time=0.0402\n",
      "Iter=2400, loss=1.3263, mse=1.3260, time=0.0403\n",
      "Iter=2600, loss=1.3824, mse=1.3821, time=0.0403\n",
      "Iter=2800, loss=1.3775, mse=1.3772, time=0.0404\n",
      "Iter=3000, loss=1.3651, mse=1.3647, time=0.0404\n",
      "Iter=3200, loss=1.3703, mse=1.3699, time=0.0404\n",
      "Iter=3400, loss=1.3660, mse=1.3656, time=0.0404\n",
      "Iter=3600, loss=1.4251, mse=1.4248, time=0.0403\n",
      "Iter=3800, loss=1.3838, mse=1.3834, time=0.0404\n",
      "Iter=4000, loss=1.4220, mse=1.4217, time=0.0404\n",
      "Iter=4200, loss=1.4257, mse=1.4253, time=0.0404\n",
      "Iter=4400, loss=1.3763, mse=1.3760, time=0.0404\n",
      "Iter=4600, loss=1.4194, mse=1.4191, time=0.0404\n",
      "Iter=4800, loss=1.3709, mse=1.3705, time=0.0404\n",
      "Iter=5000, loss=1.3690, mse=1.3686, time=0.0404\n",
      "Iter=5200, loss=1.3586, mse=1.3583, time=0.0404\n",
      "Iter=5400, loss=1.4323, mse=1.4319, time=0.0404\n",
      "Iter=5600, loss=1.4094, mse=1.4091, time=0.0404\n",
      "Iter=5800, loss=1.3754, mse=1.3750, time=0.0404\n",
      "Iter=6000, loss=1.3916, mse=1.3913, time=0.0404\n",
      "Iter=6200, loss=1.3801, mse=1.3798, time=0.0404\n",
      "Iter=6400, loss=1.4135, mse=1.4132, time=0.0404\n",
      "Iter=6600, loss=1.3986, mse=1.3982, time=0.0403\n",
      "=== Epoch 65, train loss 1.387645, test rmse 1.167081 ===\n",
      "Epoch 66\n",
      "Iter=200, loss=1.3878, mse=1.3875, time=0.0421\n",
      "Iter=400, loss=1.4330, mse=1.4327, time=0.0413\n",
      "Iter=600, loss=1.3644, mse=1.3641, time=0.0409\n",
      "Iter=800, loss=1.4063, mse=1.4060, time=0.0409\n",
      "Iter=1000, loss=1.3600, mse=1.3596, time=0.0408\n",
      "Iter=1200, loss=1.4216, mse=1.4213, time=0.0409\n",
      "Iter=1400, loss=1.3777, mse=1.3774, time=0.0409\n",
      "Iter=1600, loss=1.3874, mse=1.3870, time=0.0409\n",
      "Iter=1800, loss=1.3759, mse=1.3755, time=0.0409\n",
      "Iter=2000, loss=1.3849, mse=1.3845, time=0.0408\n",
      "Iter=2200, loss=1.4066, mse=1.4063, time=0.0408\n",
      "Iter=2400, loss=1.3741, mse=1.3737, time=0.0408\n",
      "Iter=2600, loss=1.4003, mse=1.4000, time=0.0407\n",
      "Iter=2800, loss=1.3925, mse=1.3922, time=0.0407\n",
      "Iter=3000, loss=1.3999, mse=1.3995, time=0.0407\n",
      "Iter=3200, loss=1.3897, mse=1.3894, time=0.0408\n",
      "Iter=3400, loss=1.3918, mse=1.3914, time=0.0407\n",
      "Iter=3600, loss=1.4009, mse=1.4005, time=0.0408\n",
      "Iter=3800, loss=1.3765, mse=1.3762, time=0.0407\n",
      "Iter=4000, loss=1.3978, mse=1.3974, time=0.0407\n",
      "Iter=4200, loss=1.3737, mse=1.3733, time=0.0407\n",
      "Iter=4400, loss=1.3788, mse=1.3784, time=0.0407\n",
      "Iter=4600, loss=1.3756, mse=1.3752, time=0.0408\n",
      "Iter=4800, loss=1.4108, mse=1.4104, time=0.0407\n",
      "Iter=5000, loss=1.3703, mse=1.3699, time=0.0408\n",
      "Iter=5200, loss=1.3756, mse=1.3752, time=0.0408\n",
      "Iter=5400, loss=1.3823, mse=1.3819, time=0.0408\n",
      "Iter=5600, loss=1.3689, mse=1.3685, time=0.0408\n",
      "Iter=5800, loss=1.3851, mse=1.3847, time=0.0408\n",
      "Iter=6000, loss=1.3864, mse=1.3860, time=0.0408\n",
      "Iter=6200, loss=1.4008, mse=1.4004, time=0.0408\n",
      "Iter=6400, loss=1.3599, mse=1.3595, time=0.0408\n",
      "Iter=6600, loss=1.3835, mse=1.3831, time=0.0408\n",
      "=== Epoch 66, train loss 1.387388, test rmse 1.165684 ===\n",
      "Epoch 67\n",
      "Iter=200, loss=1.3928, mse=1.3924, time=0.0414\n",
      "Iter=400, loss=1.3711, mse=1.3707, time=0.0415\n",
      "Iter=600, loss=1.3906, mse=1.3902, time=0.0413\n",
      "Iter=800, loss=1.3404, mse=1.3400, time=0.0412\n",
      "Iter=1000, loss=1.3741, mse=1.3737, time=0.0410\n",
      "Iter=1200, loss=1.4095, mse=1.4091, time=0.0409\n",
      "Iter=1400, loss=1.3708, mse=1.3705, time=0.0409\n",
      "Iter=1600, loss=1.3771, mse=1.3767, time=0.0408\n",
      "Iter=1800, loss=1.4195, mse=1.4192, time=0.0409\n",
      "Iter=2000, loss=1.4211, mse=1.4207, time=0.0408\n",
      "Iter=2200, loss=1.3855, mse=1.3852, time=0.0408\n",
      "Iter=2400, loss=1.3727, mse=1.3723, time=0.0408\n",
      "Iter=2600, loss=1.4026, mse=1.4022, time=0.0408\n",
      "Iter=2800, loss=1.3870, mse=1.3866, time=0.0408\n",
      "Iter=3000, loss=1.3941, mse=1.3937, time=0.0408\n",
      "Iter=3200, loss=1.3929, mse=1.3926, time=0.0408\n",
      "Iter=3400, loss=1.3805, mse=1.3801, time=0.0408\n",
      "Iter=3600, loss=1.4128, mse=1.4124, time=0.0408\n",
      "Iter=3800, loss=1.3710, mse=1.3707, time=0.0408\n",
      "Iter=4000, loss=1.4006, mse=1.4003, time=0.0408\n",
      "Iter=4200, loss=1.3940, mse=1.3936, time=0.0408\n",
      "Iter=4400, loss=1.4144, mse=1.4140, time=0.0408\n",
      "Iter=4600, loss=1.3892, mse=1.3889, time=0.0408\n",
      "Iter=4800, loss=1.3691, mse=1.3687, time=0.0408\n",
      "Iter=5000, loss=1.4042, mse=1.4038, time=0.0407\n",
      "Iter=5200, loss=1.3664, mse=1.3660, time=0.0408\n",
      "Iter=5400, loss=1.3881, mse=1.3877, time=0.0407\n",
      "Iter=5600, loss=1.3905, mse=1.3901, time=0.0407\n",
      "Iter=5800, loss=1.3526, mse=1.3522, time=0.0407\n",
      "Iter=6000, loss=1.4114, mse=1.4110, time=0.0407\n",
      "Iter=6200, loss=1.4011, mse=1.4008, time=0.0406\n",
      "Iter=6400, loss=1.3639, mse=1.3635, time=0.0406\n",
      "Iter=6600, loss=1.3750, mse=1.3747, time=0.0406\n",
      "=== Epoch 67, train loss 1.386679, test rmse 1.165530 ===\n",
      "Epoch 68\n",
      "Iter=200, loss=1.3543, mse=1.3540, time=0.0417\n",
      "Iter=400, loss=1.3874, mse=1.3870, time=0.0408\n",
      "Iter=600, loss=1.3792, mse=1.3789, time=0.0407\n",
      "Iter=800, loss=1.4074, mse=1.4071, time=0.0407\n",
      "Iter=1000, loss=1.3704, mse=1.3700, time=0.0406\n",
      "Iter=1200, loss=1.3952, mse=1.3949, time=0.0407\n",
      "Iter=1400, loss=1.4081, mse=1.4078, time=0.0407\n",
      "Iter=1600, loss=1.4101, mse=1.4097, time=0.0407\n",
      "Iter=1800, loss=1.3758, mse=1.3755, time=0.0407\n",
      "Iter=2000, loss=1.3956, mse=1.3953, time=0.0407\n",
      "Iter=2200, loss=1.3917, mse=1.3913, time=0.0408\n",
      "Iter=2400, loss=1.3805, mse=1.3802, time=0.0408\n",
      "Iter=2600, loss=1.3640, mse=1.3636, time=0.0407\n",
      "Iter=2800, loss=1.3573, mse=1.3570, time=0.0407\n",
      "Iter=3000, loss=1.4168, mse=1.4165, time=0.0407\n",
      "Iter=3200, loss=1.3737, mse=1.3734, time=0.0407\n",
      "Iter=3400, loss=1.3789, mse=1.3786, time=0.0407\n",
      "Iter=3600, loss=1.3849, mse=1.3846, time=0.0408\n",
      "Iter=3800, loss=1.3879, mse=1.3875, time=0.0408\n",
      "Iter=4000, loss=1.4137, mse=1.4134, time=0.0408\n",
      "Iter=4200, loss=1.4003, mse=1.3999, time=0.0408\n",
      "Iter=4400, loss=1.3751, mse=1.3748, time=0.0407\n",
      "Iter=4600, loss=1.3657, mse=1.3654, time=0.0408\n",
      "Iter=4800, loss=1.3664, mse=1.3660, time=0.0407\n",
      "Iter=5000, loss=1.3891, mse=1.3887, time=0.0407\n",
      "Iter=5200, loss=1.4219, mse=1.4215, time=0.0406\n",
      "Iter=5400, loss=1.3657, mse=1.3653, time=0.0406\n",
      "Iter=5600, loss=1.4124, mse=1.4120, time=0.0406\n",
      "Iter=5800, loss=1.3907, mse=1.3903, time=0.0406\n",
      "Iter=6000, loss=1.3606, mse=1.3603, time=0.0406\n",
      "Iter=6200, loss=1.4086, mse=1.4083, time=0.0406\n",
      "Iter=6400, loss=1.3930, mse=1.3926, time=0.0406\n",
      "Iter=6600, loss=1.3682, mse=1.3679, time=0.0406\n",
      "=== Epoch 68, train loss 1.386893, test rmse 1.165476 ===\n",
      "Epoch 69\n",
      "Iter=200, loss=1.3701, mse=1.3697, time=0.0426\n",
      "Iter=400, loss=1.4040, mse=1.4037, time=0.0413\n",
      "Iter=600, loss=1.3707, mse=1.3704, time=0.0409\n",
      "Iter=800, loss=1.3965, mse=1.3962, time=0.0408\n",
      "Iter=1000, loss=1.3793, mse=1.3789, time=0.0409\n",
      "Iter=1200, loss=1.3883, mse=1.3880, time=0.0408\n",
      "Iter=1400, loss=1.3756, mse=1.3753, time=0.0408\n",
      "Iter=1600, loss=1.3963, mse=1.3960, time=0.0407\n",
      "Iter=1800, loss=1.3794, mse=1.3790, time=0.0408\n",
      "Iter=2000, loss=1.4092, mse=1.4089, time=0.0408\n",
      "Iter=2200, loss=1.3728, mse=1.3725, time=0.0408\n",
      "Iter=2400, loss=1.3852, mse=1.3849, time=0.0407\n",
      "Iter=2600, loss=1.3432, mse=1.3428, time=0.0408\n",
      "Iter=2800, loss=1.3841, mse=1.3837, time=0.0407\n",
      "Iter=3000, loss=1.3993, mse=1.3990, time=0.0407\n",
      "Iter=3200, loss=1.3747, mse=1.3744, time=0.0407\n",
      "Iter=3400, loss=1.3639, mse=1.3636, time=0.0407\n",
      "Iter=3600, loss=1.3733, mse=1.3729, time=0.0407\n",
      "Iter=3800, loss=1.3762, mse=1.3758, time=0.0407\n",
      "Iter=4000, loss=1.3874, mse=1.3870, time=0.0406\n",
      "Iter=4200, loss=1.4115, mse=1.4112, time=0.0406\n",
      "Iter=4400, loss=1.3904, mse=1.3901, time=0.0405\n",
      "Iter=4600, loss=1.3937, mse=1.3934, time=0.0405\n",
      "Iter=4800, loss=1.3871, mse=1.3868, time=0.0405\n",
      "Iter=5000, loss=1.4318, mse=1.4314, time=0.0405\n",
      "Iter=5200, loss=1.3905, mse=1.3902, time=0.0406\n",
      "Iter=5400, loss=1.3842, mse=1.3838, time=0.0405\n",
      "Iter=5600, loss=1.3904, mse=1.3901, time=0.0406\n",
      "Iter=5800, loss=1.3752, mse=1.3749, time=0.0406\n",
      "Iter=6000, loss=1.3807, mse=1.3804, time=0.0406\n",
      "Iter=6200, loss=1.4092, mse=1.4089, time=0.0406\n",
      "Iter=6400, loss=1.4024, mse=1.4020, time=0.0406\n",
      "Iter=6600, loss=1.3903, mse=1.3900, time=0.0406\n",
      "=== Epoch 69, train loss 1.387487, test rmse 1.169550 ===\n",
      "Epoch 70\n",
      "Iter=200, loss=1.3650, mse=1.3647, time=0.0434\n",
      "Iter=400, loss=1.3882, mse=1.3879, time=0.0439\n",
      "Iter=600, loss=1.4060, mse=1.4056, time=0.0437\n",
      "Iter=800, loss=1.3989, mse=1.3986, time=0.0430\n",
      "Iter=1000, loss=1.4037, mse=1.4033, time=0.0424\n",
      "Iter=1200, loss=1.4243, mse=1.4239, time=0.0422\n",
      "Iter=1400, loss=1.3943, mse=1.3939, time=0.0420\n",
      "Iter=1600, loss=1.3554, mse=1.3550, time=0.0419\n",
      "Iter=1800, loss=1.4184, mse=1.4181, time=0.0418\n",
      "Iter=2000, loss=1.3837, mse=1.3834, time=0.0417\n",
      "Iter=2200, loss=1.4048, mse=1.4045, time=0.0416\n",
      "Iter=2400, loss=1.3862, mse=1.3858, time=0.0415\n",
      "Iter=2600, loss=1.3800, mse=1.3796, time=0.0415\n",
      "Iter=2800, loss=1.3998, mse=1.3994, time=0.0414\n",
      "Iter=3000, loss=1.4111, mse=1.4107, time=0.0414\n",
      "Iter=3200, loss=1.3631, mse=1.3628, time=0.0412\n",
      "Iter=3400, loss=1.3629, mse=1.3626, time=0.0411\n",
      "Iter=3600, loss=1.4073, mse=1.4070, time=0.0411\n",
      "Iter=3800, loss=1.3708, mse=1.3705, time=0.0411\n",
      "Iter=4000, loss=1.4015, mse=1.4012, time=0.0410\n",
      "Iter=4200, loss=1.4077, mse=1.4074, time=0.0411\n",
      "Iter=4400, loss=1.3870, mse=1.3867, time=0.0410\n",
      "Iter=4600, loss=1.3601, mse=1.3598, time=0.0411\n",
      "Iter=4800, loss=1.3671, mse=1.3668, time=0.0411\n",
      "Iter=5000, loss=1.3900, mse=1.3897, time=0.0411\n",
      "Iter=5200, loss=1.4007, mse=1.4003, time=0.0411\n",
      "Iter=5400, loss=1.3745, mse=1.3741, time=0.0411\n",
      "Iter=5600, loss=1.3699, mse=1.3696, time=0.0410\n",
      "Iter=5800, loss=1.4038, mse=1.4033, time=0.0410\n",
      "Iter=6000, loss=1.3771, mse=1.3767, time=0.0410\n",
      "Iter=6200, loss=1.3689, mse=1.3685, time=0.0410\n",
      "Iter=6400, loss=1.3718, mse=1.3715, time=0.0410\n",
      "Iter=6600, loss=1.4046, mse=1.4042, time=0.0410\n",
      "=== Epoch 70, train loss 1.388240, test rmse 1.165187 ===\n",
      "Epoch 71\n",
      "Iter=200, loss=1.3767, mse=1.3764, time=0.0425\n",
      "Iter=400, loss=1.3766, mse=1.3763, time=0.0415\n",
      "Iter=600, loss=1.3747, mse=1.3744, time=0.0413\n",
      "Iter=800, loss=1.3654, mse=1.3650, time=0.0411\n",
      "Iter=1000, loss=1.3520, mse=1.3517, time=0.0409\n",
      "Iter=1200, loss=1.4255, mse=1.4252, time=0.0407\n",
      "Iter=1400, loss=1.3755, mse=1.3751, time=0.0408\n",
      "Iter=1600, loss=1.3898, mse=1.3895, time=0.0407\n",
      "Iter=1800, loss=1.4041, mse=1.4037, time=0.0406\n",
      "Iter=2000, loss=1.4061, mse=1.4058, time=0.0407\n",
      "Iter=2200, loss=1.4083, mse=1.4079, time=0.0407\n",
      "Iter=2400, loss=1.3592, mse=1.3588, time=0.0407\n",
      "Iter=2600, loss=1.3886, mse=1.3882, time=0.0407\n",
      "Iter=2800, loss=1.4180, mse=1.4176, time=0.0407\n",
      "Iter=3000, loss=1.4042, mse=1.4039, time=0.0407\n",
      "Iter=3200, loss=1.4017, mse=1.4014, time=0.0407\n",
      "Iter=3400, loss=1.3843, mse=1.3840, time=0.0406\n",
      "Iter=3600, loss=1.3986, mse=1.3982, time=0.0406\n",
      "Iter=3800, loss=1.3988, mse=1.3984, time=0.0405\n",
      "Iter=4000, loss=1.4121, mse=1.4118, time=0.0406\n",
      "Iter=4200, loss=1.4100, mse=1.4097, time=0.0405\n",
      "Iter=4400, loss=1.3941, mse=1.3938, time=0.0405\n",
      "Iter=4600, loss=1.4042, mse=1.4038, time=0.0405\n",
      "Iter=4800, loss=1.4029, mse=1.4025, time=0.0405\n",
      "Iter=5000, loss=1.3763, mse=1.3759, time=0.0405\n",
      "Iter=5200, loss=1.3578, mse=1.3574, time=0.0404\n",
      "Iter=5400, loss=1.3858, mse=1.3854, time=0.0405\n",
      "Iter=5600, loss=1.3925, mse=1.3922, time=0.0404\n",
      "Iter=5800, loss=1.4130, mse=1.4127, time=0.0403\n",
      "Iter=6000, loss=1.3346, mse=1.3343, time=0.0403\n",
      "Iter=6200, loss=1.4053, mse=1.4049, time=0.0403\n",
      "Iter=6400, loss=1.3618, mse=1.3614, time=0.0402\n",
      "Iter=6600, loss=1.3751, mse=1.3747, time=0.0402\n",
      "=== Epoch 71, train loss 1.388206, test rmse 1.162274 ===\n",
      "Epoch 72\n",
      "Iter=200, loss=1.3900, mse=1.3896, time=0.0416\n",
      "Iter=400, loss=1.3793, mse=1.3789, time=0.0409\n",
      "Iter=600, loss=1.3974, mse=1.3971, time=0.0404\n",
      "Iter=800, loss=1.3858, mse=1.3855, time=0.0411\n",
      "Iter=1000, loss=1.4415, mse=1.4412, time=0.0410\n",
      "Iter=1200, loss=1.4084, mse=1.4080, time=0.0407\n",
      "Iter=1400, loss=1.3607, mse=1.3604, time=0.0405\n",
      "Iter=1600, loss=1.3770, mse=1.3766, time=0.0405\n",
      "Iter=1800, loss=1.4252, mse=1.4248, time=0.0404\n",
      "Iter=2000, loss=1.3692, mse=1.3688, time=0.0404\n",
      "Iter=2200, loss=1.3964, mse=1.3960, time=0.0403\n",
      "Iter=2400, loss=1.3834, mse=1.3830, time=0.0404\n",
      "Iter=2600, loss=1.3520, mse=1.3516, time=0.0404\n",
      "Iter=2800, loss=1.4062, mse=1.4058, time=0.0404\n",
      "Iter=3000, loss=1.3841, mse=1.3837, time=0.0403\n",
      "Iter=3200, loss=1.4201, mse=1.4198, time=0.0402\n",
      "Iter=3400, loss=1.3753, mse=1.3749, time=0.0402\n",
      "Iter=3600, loss=1.4275, mse=1.4271, time=0.0402\n",
      "Iter=3800, loss=1.3957, mse=1.3954, time=0.0401\n",
      "Iter=4000, loss=1.3894, mse=1.3891, time=0.0402\n",
      "Iter=4200, loss=1.3780, mse=1.3776, time=0.0402\n",
      "Iter=4400, loss=1.4055, mse=1.4051, time=0.0401\n",
      "Iter=4600, loss=1.3729, mse=1.3726, time=0.0401\n",
      "Iter=4800, loss=1.3561, mse=1.3557, time=0.0401\n",
      "Iter=5000, loss=1.3681, mse=1.3678, time=0.0402\n",
      "Iter=5200, loss=1.3859, mse=1.3856, time=0.0403\n",
      "Iter=5400, loss=1.3649, mse=1.3646, time=0.0404\n",
      "Iter=5600, loss=1.3860, mse=1.3856, time=0.0404\n",
      "Iter=5800, loss=1.3917, mse=1.3914, time=0.0403\n",
      "Iter=6000, loss=1.4238, mse=1.4235, time=0.0403\n",
      "Iter=6200, loss=1.3641, mse=1.3637, time=0.0403\n",
      "Iter=6400, loss=1.3909, mse=1.3905, time=0.0403\n",
      "Iter=6600, loss=1.3720, mse=1.3717, time=0.0403\n",
      "=== Epoch 72, train loss 1.387693, test rmse 1.170200 ===\n",
      "Epoch 73\n",
      "Iter=200, loss=1.3786, mse=1.3782, time=0.0425\n",
      "Iter=400, loss=1.3699, mse=1.3696, time=0.0417\n",
      "Iter=600, loss=1.3973, mse=1.3970, time=0.0409\n",
      "Iter=800, loss=1.3666, mse=1.3663, time=0.0406\n",
      "Iter=1000, loss=1.4064, mse=1.4060, time=0.0401\n",
      "Iter=1200, loss=1.3586, mse=1.3582, time=0.0399\n",
      "Iter=1400, loss=1.3791, mse=1.3787, time=0.0399\n",
      "Iter=1600, loss=1.3611, mse=1.3608, time=0.0400\n",
      "Iter=1800, loss=1.3834, mse=1.3830, time=0.0401\n",
      "Iter=2000, loss=1.4198, mse=1.4194, time=0.0401\n",
      "Iter=2200, loss=1.3934, mse=1.3930, time=0.0402\n",
      "Iter=2400, loss=1.3779, mse=1.3775, time=0.0402\n",
      "Iter=2600, loss=1.3996, mse=1.3992, time=0.0402\n",
      "Iter=2800, loss=1.3965, mse=1.3961, time=0.0402\n",
      "Iter=3000, loss=1.4149, mse=1.4146, time=0.0402\n",
      "Iter=3200, loss=1.4019, mse=1.4015, time=0.0401\n",
      "Iter=3400, loss=1.4039, mse=1.4035, time=0.0401\n",
      "Iter=3600, loss=1.3540, mse=1.3536, time=0.0401\n",
      "Iter=3800, loss=1.4037, mse=1.4034, time=0.0401\n",
      "Iter=4000, loss=1.3820, mse=1.3817, time=0.0401\n",
      "Iter=4200, loss=1.3959, mse=1.3955, time=0.0401\n",
      "Iter=4400, loss=1.4197, mse=1.4194, time=0.0401\n",
      "Iter=4600, loss=1.3637, mse=1.3634, time=0.0401\n",
      "Iter=4800, loss=1.3640, mse=1.3637, time=0.0401\n",
      "Iter=5000, loss=1.4198, mse=1.4194, time=0.0400\n",
      "Iter=5200, loss=1.3777, mse=1.3774, time=0.0400\n",
      "Iter=5400, loss=1.3798, mse=1.3794, time=0.0400\n",
      "Iter=5600, loss=1.3782, mse=1.3778, time=0.0399\n",
      "Iter=5800, loss=1.4162, mse=1.4159, time=0.0399\n",
      "Iter=6000, loss=1.3983, mse=1.3980, time=0.0400\n",
      "Iter=6200, loss=1.3918, mse=1.3915, time=0.0399\n",
      "Iter=6400, loss=1.3573, mse=1.3570, time=0.0400\n",
      "Iter=6600, loss=1.3776, mse=1.3772, time=0.0400\n",
      "=== Epoch 73, train loss 1.387670, test rmse 1.164174 ===\n",
      "Epoch 74\n",
      "Iter=200, loss=1.4034, mse=1.4031, time=0.0416\n",
      "Iter=400, loss=1.4040, mse=1.4036, time=0.0411\n",
      "Iter=600, loss=1.3766, mse=1.3763, time=0.0413\n",
      "Iter=800, loss=1.3809, mse=1.3806, time=0.0409\n",
      "Iter=1000, loss=1.3802, mse=1.3798, time=0.0405\n",
      "Iter=1200, loss=1.3732, mse=1.3729, time=0.0405\n",
      "Iter=1400, loss=1.3875, mse=1.3872, time=0.0405\n",
      "Iter=1600, loss=1.3966, mse=1.3963, time=0.0404\n",
      "Iter=1800, loss=1.4020, mse=1.4016, time=0.0404\n",
      "Iter=2000, loss=1.3706, mse=1.3702, time=0.0404\n",
      "Iter=2200, loss=1.3961, mse=1.3957, time=0.0403\n",
      "Iter=2400, loss=1.3946, mse=1.3942, time=0.0404\n",
      "Iter=2600, loss=1.3886, mse=1.3882, time=0.0403\n",
      "Iter=2800, loss=1.3946, mse=1.3942, time=0.0402\n",
      "Iter=3000, loss=1.3634, mse=1.3631, time=0.0401\n",
      "Iter=3200, loss=1.3800, mse=1.3797, time=0.0401\n",
      "Iter=3400, loss=1.3991, mse=1.3988, time=0.0401\n",
      "Iter=3600, loss=1.3873, mse=1.3869, time=0.0400\n",
      "Iter=3800, loss=1.4157, mse=1.4154, time=0.0400\n",
      "Iter=4000, loss=1.4124, mse=1.4120, time=0.0400\n",
      "Iter=4200, loss=1.3569, mse=1.3566, time=0.0399\n",
      "Iter=4400, loss=1.3842, mse=1.3838, time=0.0399\n",
      "Iter=4600, loss=1.3682, mse=1.3678, time=0.0399\n",
      "Iter=4800, loss=1.3841, mse=1.3838, time=0.0399\n",
      "Iter=5000, loss=1.4030, mse=1.4027, time=0.0399\n",
      "Iter=5200, loss=1.3665, mse=1.3662, time=0.0398\n",
      "Iter=5400, loss=1.3849, mse=1.3846, time=0.0398\n",
      "Iter=5600, loss=1.3893, mse=1.3890, time=0.0398\n",
      "Iter=5800, loss=1.3614, mse=1.3611, time=0.0398\n",
      "Iter=6000, loss=1.4069, mse=1.4065, time=0.0398\n",
      "Iter=6200, loss=1.3796, mse=1.3792, time=0.0399\n",
      "Iter=6400, loss=1.3899, mse=1.3895, time=0.0399\n",
      "Iter=6600, loss=1.3877, mse=1.3873, time=0.0399\n",
      "=== Epoch 74, train loss 1.387169, test rmse 1.165391 ===\n",
      "Epoch 75\n",
      "Iter=200, loss=1.3676, mse=1.3672, time=0.0421\n",
      "Iter=400, loss=1.3936, mse=1.3932, time=0.0412\n",
      "Iter=600, loss=1.3919, mse=1.3915, time=0.0404\n",
      "Iter=800, loss=1.4026, mse=1.4023, time=0.0400\n",
      "Iter=1000, loss=1.3831, mse=1.3827, time=0.0406\n",
      "Iter=1200, loss=1.3655, mse=1.3651, time=0.0406\n",
      "Iter=1400, loss=1.4489, mse=1.4486, time=0.0407\n",
      "Iter=1600, loss=1.3837, mse=1.3833, time=0.0406\n",
      "Iter=1800, loss=1.3800, mse=1.3797, time=0.0407\n",
      "Iter=2000, loss=1.3937, mse=1.3933, time=0.0407\n",
      "Iter=2200, loss=1.3864, mse=1.3860, time=0.0406\n",
      "Iter=2400, loss=1.4003, mse=1.3999, time=0.0406\n",
      "Iter=2600, loss=1.4065, mse=1.4061, time=0.0406\n",
      "Iter=2800, loss=1.3900, mse=1.3897, time=0.0406\n",
      "Iter=3000, loss=1.3485, mse=1.3481, time=0.0405\n",
      "Iter=3200, loss=1.3983, mse=1.3980, time=0.0405\n",
      "Iter=3400, loss=1.4072, mse=1.4068, time=0.0406\n",
      "Iter=3600, loss=1.3779, mse=1.3775, time=0.0405\n",
      "Iter=3800, loss=1.4061, mse=1.4057, time=0.0405\n",
      "Iter=4000, loss=1.3912, mse=1.3909, time=0.0405\n",
      "Iter=4200, loss=1.4031, mse=1.4027, time=0.0405\n",
      "Iter=4400, loss=1.3604, mse=1.3601, time=0.0405\n",
      "Iter=4600, loss=1.3534, mse=1.3530, time=0.0404\n",
      "Iter=4800, loss=1.3582, mse=1.3578, time=0.0404\n",
      "Iter=5000, loss=1.3995, mse=1.3992, time=0.0404\n",
      "Iter=5200, loss=1.3675, mse=1.3671, time=0.0402\n",
      "Iter=5400, loss=1.3719, mse=1.3715, time=0.0402\n",
      "Iter=5600, loss=1.3971, mse=1.3967, time=0.0403\n",
      "Iter=5800, loss=1.3778, mse=1.3774, time=0.0403\n",
      "Iter=6000, loss=1.3929, mse=1.3926, time=0.0403\n",
      "Iter=6200, loss=1.3909, mse=1.3906, time=0.0404\n",
      "Iter=6400, loss=1.4066, mse=1.4062, time=0.0404\n",
      "Iter=6600, loss=1.3614, mse=1.3611, time=0.0403\n",
      "=== Epoch 75, train loss 1.387379, test rmse 1.166696 ===\n",
      "Epoch 76\n",
      "Iter=200, loss=1.4307, mse=1.4303, time=0.0429\n",
      "Iter=400, loss=1.3845, mse=1.3841, time=0.0413\n",
      "Iter=600, loss=1.4230, mse=1.4226, time=0.0409\n",
      "Iter=800, loss=1.3754, mse=1.3750, time=0.0404\n",
      "Iter=1000, loss=1.4146, mse=1.4142, time=0.0403\n",
      "Iter=1200, loss=1.3320, mse=1.3316, time=0.0403\n",
      "Iter=1400, loss=1.3639, mse=1.3635, time=0.0404\n",
      "Iter=1600, loss=1.4050, mse=1.4047, time=0.0403\n",
      "Iter=1800, loss=1.3938, mse=1.3934, time=0.0403\n",
      "Iter=2000, loss=1.4200, mse=1.4197, time=0.0402\n",
      "Iter=2200, loss=1.3619, mse=1.3616, time=0.0403\n",
      "Iter=2400, loss=1.4110, mse=1.4107, time=0.0403\n",
      "Iter=2600, loss=1.3849, mse=1.3846, time=0.0403\n",
      "Iter=2800, loss=1.3937, mse=1.3934, time=0.0403\n",
      "Iter=3000, loss=1.3935, mse=1.3932, time=0.0402\n",
      "Iter=3200, loss=1.3844, mse=1.3841, time=0.0401\n",
      "Iter=3400, loss=1.3896, mse=1.3893, time=0.0400\n",
      "Iter=3600, loss=1.3899, mse=1.3896, time=0.0399\n",
      "Iter=3800, loss=1.3953, mse=1.3950, time=0.0399\n",
      "Iter=4000, loss=1.4045, mse=1.4042, time=0.0399\n",
      "Iter=4200, loss=1.4070, mse=1.4067, time=0.0399\n",
      "Iter=4400, loss=1.3846, mse=1.3843, time=0.0399\n",
      "Iter=4600, loss=1.3704, mse=1.3700, time=0.0398\n",
      "Iter=4800, loss=1.3867, mse=1.3864, time=0.0398\n",
      "Iter=5000, loss=1.4042, mse=1.4039, time=0.0397\n",
      "Iter=5200, loss=1.3714, mse=1.3711, time=0.0397\n",
      "Iter=5400, loss=1.4089, mse=1.4086, time=0.0397\n",
      "Iter=5600, loss=1.3867, mse=1.3863, time=0.0397\n",
      "Iter=5800, loss=1.3550, mse=1.3546, time=0.0397\n",
      "Iter=6000, loss=1.3864, mse=1.3860, time=0.0397\n",
      "Iter=6200, loss=1.3714, mse=1.3711, time=0.0397\n",
      "Iter=6400, loss=1.3844, mse=1.3840, time=0.0397\n",
      "Iter=6600, loss=1.3626, mse=1.3623, time=0.0397\n",
      "=== Epoch 76, train loss 1.388023, test rmse 1.177480 ===\n",
      "Epoch 77\n",
      "Iter=200, loss=1.3670, mse=1.3666, time=0.0404\n",
      "Iter=400, loss=1.3802, mse=1.3798, time=0.0402\n",
      "Iter=600, loss=1.3759, mse=1.3755, time=0.0401\n",
      "Iter=800, loss=1.3988, mse=1.3985, time=0.0402\n",
      "Iter=1000, loss=1.3880, mse=1.3876, time=0.0402\n",
      "Iter=1200, loss=1.3852, mse=1.3849, time=0.0404\n",
      "Iter=1400, loss=1.3715, mse=1.3712, time=0.0403\n",
      "Iter=1600, loss=1.3852, mse=1.3848, time=0.0403\n",
      "Iter=1800, loss=1.3760, mse=1.3757, time=0.0403\n",
      "Iter=2000, loss=1.3918, mse=1.3915, time=0.0402\n",
      "Iter=2200, loss=1.4172, mse=1.4169, time=0.0403\n",
      "Iter=2400, loss=1.3990, mse=1.3987, time=0.0402\n",
      "Iter=2600, loss=1.3843, mse=1.3839, time=0.0402\n",
      "Iter=2800, loss=1.3874, mse=1.3870, time=0.0402\n",
      "Iter=3000, loss=1.3766, mse=1.3762, time=0.0402\n",
      "Iter=3200, loss=1.4087, mse=1.4084, time=0.0402\n",
      "Iter=3400, loss=1.4035, mse=1.4031, time=0.0401\n",
      "Iter=3600, loss=1.4038, mse=1.4035, time=0.0402\n",
      "Iter=3800, loss=1.3954, mse=1.3950, time=0.0401\n",
      "Iter=4000, loss=1.3434, mse=1.3430, time=0.0401\n",
      "Iter=4200, loss=1.4046, mse=1.4042, time=0.0401\n",
      "Iter=4400, loss=1.3520, mse=1.3517, time=0.0402\n",
      "Iter=4600, loss=1.3899, mse=1.3896, time=0.0401\n",
      "Iter=4800, loss=1.3803, mse=1.3799, time=0.0401\n",
      "Iter=5000, loss=1.3605, mse=1.3602, time=0.0401\n",
      "Iter=5200, loss=1.3532, mse=1.3528, time=0.0401\n",
      "Iter=5400, loss=1.3956, mse=1.3952, time=0.0401\n",
      "Iter=5600, loss=1.3847, mse=1.3844, time=0.0402\n",
      "Iter=5800, loss=1.4090, mse=1.4087, time=0.0402\n",
      "Iter=6000, loss=1.3586, mse=1.3582, time=0.0402\n",
      "Iter=6200, loss=1.3781, mse=1.3778, time=0.0402\n",
      "Iter=6400, loss=1.3999, mse=1.3996, time=0.0402\n",
      "Iter=6600, loss=1.4359, mse=1.4355, time=0.0402\n",
      "=== Epoch 77, train loss 1.385705, test rmse 1.164676 ===\n",
      "Epoch 78\n",
      "Iter=200, loss=1.3752, mse=1.3748, time=0.0433\n",
      "Iter=400, loss=1.4314, mse=1.4310, time=0.0417\n",
      "Iter=600, loss=1.3841, mse=1.3838, time=0.0410\n",
      "Iter=800, loss=1.3774, mse=1.3771, time=0.0410\n",
      "Iter=1000, loss=1.4035, mse=1.4032, time=0.0410\n",
      "Iter=1200, loss=1.3541, mse=1.3538, time=0.0409\n",
      "Iter=1400, loss=1.3990, mse=1.3986, time=0.0409\n",
      "Iter=1600, loss=1.3668, mse=1.3665, time=0.0409\n",
      "Iter=1800, loss=1.3846, mse=1.3843, time=0.0408\n",
      "Iter=2000, loss=1.3952, mse=1.3949, time=0.0409\n",
      "Iter=2200, loss=1.4160, mse=1.4156, time=0.0410\n",
      "Iter=2400, loss=1.4133, mse=1.4129, time=0.0410\n",
      "Iter=2600, loss=1.3715, mse=1.3711, time=0.0410\n",
      "Iter=2800, loss=1.3747, mse=1.3743, time=0.0409\n",
      "Iter=3000, loss=1.3727, mse=1.3723, time=0.0408\n",
      "Iter=3200, loss=1.3801, mse=1.3798, time=0.0407\n",
      "Iter=3400, loss=1.3802, mse=1.3798, time=0.0406\n",
      "Iter=3600, loss=1.3717, mse=1.3713, time=0.0405\n",
      "Iter=3800, loss=1.3676, mse=1.3672, time=0.0405\n",
      "Iter=4000, loss=1.3667, mse=1.3663, time=0.0404\n",
      "Iter=4200, loss=1.4219, mse=1.4215, time=0.0404\n",
      "Iter=4400, loss=1.3995, mse=1.3991, time=0.0403\n",
      "Iter=4600, loss=1.3828, mse=1.3824, time=0.0403\n",
      "Iter=4800, loss=1.3773, mse=1.3769, time=0.0403\n",
      "Iter=5000, loss=1.3793, mse=1.3789, time=0.0404\n",
      "Iter=5200, loss=1.3955, mse=1.3951, time=0.0404\n",
      "Iter=5400, loss=1.3797, mse=1.3793, time=0.0404\n",
      "Iter=5600, loss=1.4017, mse=1.4013, time=0.0404\n",
      "Iter=5800, loss=1.3892, mse=1.3888, time=0.0404\n",
      "Iter=6000, loss=1.3859, mse=1.3856, time=0.0404\n",
      "Iter=6200, loss=1.3779, mse=1.3776, time=0.0404\n",
      "Iter=6400, loss=1.3927, mse=1.3923, time=0.0404\n",
      "Iter=6600, loss=1.3886, mse=1.3883, time=0.0404\n",
      "=== Epoch 78, train loss 1.386915, test rmse 1.165367 ===\n",
      "Epoch 79\n",
      "Iter=200, loss=1.3681, mse=1.3678, time=0.0421\n",
      "Iter=400, loss=1.3742, mse=1.3739, time=0.0422\n",
      "Iter=600, loss=1.4164, mse=1.4160, time=0.0418\n",
      "Iter=800, loss=1.3517, mse=1.3514, time=0.0412\n",
      "Iter=1000, loss=1.4123, mse=1.4120, time=0.0413\n",
      "Iter=1200, loss=1.4297, mse=1.4293, time=0.0412\n",
      "Iter=1400, loss=1.4119, mse=1.4115, time=0.0412\n",
      "Iter=1600, loss=1.4041, mse=1.4037, time=0.0411\n",
      "Iter=1800, loss=1.3664, mse=1.3660, time=0.0411\n",
      "Iter=2000, loss=1.4125, mse=1.4122, time=0.0410\n",
      "Iter=2200, loss=1.3977, mse=1.3973, time=0.0409\n",
      "Iter=2400, loss=1.3956, mse=1.3953, time=0.0408\n",
      "Iter=2600, loss=1.4073, mse=1.4070, time=0.0407\n",
      "Iter=2800, loss=1.4326, mse=1.4323, time=0.0407\n",
      "Iter=3000, loss=1.3381, mse=1.3377, time=0.0406\n",
      "Iter=3200, loss=1.3936, mse=1.3933, time=0.0407\n",
      "Iter=3400, loss=1.4299, mse=1.4295, time=0.0405\n",
      "Iter=3600, loss=1.3721, mse=1.3718, time=0.0405\n",
      "Iter=3800, loss=1.3541, mse=1.3538, time=0.0404\n",
      "Iter=4000, loss=1.3946, mse=1.3943, time=0.0404\n",
      "Iter=4200, loss=1.3506, mse=1.3503, time=0.0403\n",
      "Iter=4400, loss=1.3804, mse=1.3800, time=0.0403\n",
      "Iter=4600, loss=1.3633, mse=1.3629, time=0.0402\n",
      "Iter=4800, loss=1.4054, mse=1.4050, time=0.0402\n",
      "Iter=5000, loss=1.3907, mse=1.3903, time=0.0402\n",
      "Iter=5200, loss=1.3910, mse=1.3906, time=0.0401\n",
      "Iter=5400, loss=1.3874, mse=1.3871, time=0.0401\n",
      "Iter=5600, loss=1.3714, mse=1.3710, time=0.0400\n",
      "Iter=5800, loss=1.3714, mse=1.3711, time=0.0400\n",
      "Iter=6000, loss=1.3767, mse=1.3764, time=0.0400\n",
      "Iter=6200, loss=1.3868, mse=1.3864, time=0.0400\n",
      "Iter=6400, loss=1.3488, mse=1.3484, time=0.0400\n",
      "Iter=6600, loss=1.4070, mse=1.4066, time=0.0401\n",
      "=== Epoch 79, train loss 1.387586, test rmse 1.166059 ===\n",
      "Training ends. The best testing rmse is 1.161787 at epoch 57\n",
      "  Training epoch took: 8:56:49\n"
     ]
    }
   ],
   "source": [
    "label_type = 'sentiment'\n",
    "\n",
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch_idx in range(1, 80):\n",
    "    print ('Epoch', epoch_idx)\n",
    "    \n",
    "    train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_s, loss_fn, optimizer_s, args.arr_lambda, \n",
    "                                                                   train_loader_s, args.device, args.train_log_interval)\n",
    "    valid_rmse, predict_valid_list, label_valid_list = evaluate(label_type, model_s, valid_loader_s, args.device)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(label_type, model_s, test_loader_s, args.device)\n",
    "    \n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model_s, optimizer_s)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_valid_list = predict_valid_list \n",
    "        best_label_valid_list = label_valid_list\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "\n",
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "35d01f21-2fb5-4361-86ef-ae9cbe7c1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_sentiment_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_sentiment_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "valid_sentiment_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "valid_sentiment_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_sentiment_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_sentiment_df.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2ae60ad8-2da2-4c0a-a74d-37d2d60a19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/rotten_tomato/ensemble/'\n",
    "train_sentiment_df.to_csv(path + 'train_sentiment.csv', index=False)\n",
    "valid_sentiment_df.to_csv(path + 'valid_sentiment.csv', index=False)\n",
    "test_sentiment_df.to_csv(path + 'test_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d6b0c-3aab-4512-8402-77a174a23725",
   "metadata": {},
   "source": [
    "### 3-3. emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d6c37c27-d219-465b-bec2-bc8796d483d8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=200, loss=1.1998, mse=1.1998, time=0.0424\n",
      "Iter=400, loss=1.2266, mse=1.2266, time=0.0413\n",
      "Iter=600, loss=1.2013, mse=1.2013, time=0.0411\n",
      "Iter=800, loss=1.2216, mse=1.2216, time=0.0410\n",
      "Iter=1000, loss=1.2213, mse=1.2213, time=0.0407\n",
      "Iter=1200, loss=1.2352, mse=1.2352, time=0.0402\n",
      "Iter=1400, loss=1.2343, mse=1.2343, time=0.0401\n",
      "Iter=1600, loss=1.2495, mse=1.2495, time=0.0397\n",
      "Iter=1800, loss=1.2810, mse=1.2810, time=0.0394\n",
      "Iter=2000, loss=1.2238, mse=1.2238, time=0.0392\n",
      "Iter=2200, loss=1.1690, mse=1.1690, time=0.0392\n",
      "Iter=2400, loss=1.2587, mse=1.2587, time=0.0391\n",
      "Iter=2600, loss=1.2564, mse=1.2564, time=0.0391\n",
      "Iter=2800, loss=1.2007, mse=1.2007, time=0.0390\n",
      "Iter=3000, loss=1.2310, mse=1.2310, time=0.0389\n",
      "Iter=3200, loss=1.2483, mse=1.2483, time=0.0389\n",
      "Iter=3400, loss=1.2365, mse=1.2365, time=0.0388\n",
      "Iter=3600, loss=1.2541, mse=1.2541, time=0.0388\n",
      "Iter=3800, loss=1.2518, mse=1.2518, time=0.0387\n",
      "Iter=4000, loss=1.2654, mse=1.2654, time=0.0386\n",
      "Iter=4200, loss=1.2160, mse=1.2160, time=0.0385\n",
      "Iter=4400, loss=1.2327, mse=1.2327, time=0.0385\n",
      "Iter=4600, loss=1.1849, mse=1.1849, time=0.0385\n",
      "Iter=4800, loss=1.2725, mse=1.2725, time=0.0384\n",
      "Iter=5000, loss=1.2463, mse=1.2463, time=0.0384\n",
      "Iter=5200, loss=1.2758, mse=1.2758, time=0.0384\n",
      "Iter=5400, loss=1.2662, mse=1.2662, time=0.0384\n",
      "Iter=5600, loss=1.2235, mse=1.2235, time=0.0383\n",
      "Iter=5800, loss=1.2466, mse=1.2466, time=0.0383\n",
      "Iter=6000, loss=1.2327, mse=1.2327, time=0.0384\n",
      "Iter=6200, loss=1.2026, mse=1.2026, time=0.0384\n",
      "Iter=6400, loss=1.2150, mse=1.2150, time=0.0384\n",
      "Iter=6600, loss=1.2533, mse=1.2533, time=0.0384\n",
      "=== Epoch 1, train loss 1.233737, test rmse 1.066802 ===\n",
      "Epoch 2\n",
      "Iter=200, loss=1.2225, mse=1.2225, time=0.0413\n",
      "Iter=400, loss=1.2182, mse=1.2182, time=0.0404\n",
      "Iter=600, loss=1.2750, mse=1.2750, time=0.0399\n",
      "Iter=800, loss=1.2659, mse=1.2659, time=0.0395\n",
      "Iter=1000, loss=1.2307, mse=1.2307, time=0.0394\n",
      "Iter=1200, loss=1.2090, mse=1.2090, time=0.0393\n",
      "Iter=1400, loss=1.2545, mse=1.2545, time=0.0392\n",
      "Iter=1600, loss=1.2266, mse=1.2266, time=0.0391\n",
      "Iter=1800, loss=1.2397, mse=1.2397, time=0.0391\n",
      "Iter=2000, loss=1.2553, mse=1.2553, time=0.0391\n",
      "Iter=2200, loss=1.2670, mse=1.2670, time=0.0391\n",
      "Iter=2400, loss=1.2271, mse=1.2271, time=0.0391\n",
      "Iter=2600, loss=1.2561, mse=1.2561, time=0.0391\n",
      "Iter=2800, loss=1.2494, mse=1.2494, time=0.0390\n",
      "Iter=3000, loss=1.2339, mse=1.2339, time=0.0390\n",
      "Iter=3200, loss=1.1840, mse=1.1840, time=0.0390\n",
      "Iter=3400, loss=1.1907, mse=1.1907, time=0.0390\n",
      "Iter=3600, loss=1.2611, mse=1.2611, time=0.0389\n",
      "Iter=3800, loss=1.2641, mse=1.2641, time=0.0388\n",
      "Iter=4000, loss=1.2682, mse=1.2682, time=0.0387\n",
      "Iter=4200, loss=1.2357, mse=1.2357, time=0.0387\n",
      "Iter=4400, loss=1.2236, mse=1.2236, time=0.0388\n",
      "Iter=4600, loss=1.1814, mse=1.1814, time=0.0388\n",
      "Iter=4800, loss=1.1801, mse=1.1801, time=0.0388\n",
      "Iter=5000, loss=1.2557, mse=1.2557, time=0.0387\n",
      "Iter=5200, loss=1.2122, mse=1.2122, time=0.0387\n",
      "Iter=5400, loss=1.2094, mse=1.2094, time=0.0387\n",
      "Iter=5600, loss=1.2575, mse=1.2575, time=0.0387\n",
      "Iter=5800, loss=1.2280, mse=1.2280, time=0.0387\n",
      "Iter=6000, loss=1.2446, mse=1.2446, time=0.0387\n",
      "Iter=6200, loss=1.2624, mse=1.2624, time=0.0387\n",
      "Iter=6400, loss=1.1938, mse=1.1938, time=0.0387\n",
      "Iter=6600, loss=1.2232, mse=1.2232, time=0.0387\n",
      "=== Epoch 2, train loss 1.233953, test rmse 1.066634 ===\n",
      "Epoch 3\n",
      "Iter=200, loss=1.2377, mse=1.2377, time=0.0416\n",
      "Iter=400, loss=1.2230, mse=1.2230, time=0.0401\n",
      "Iter=600, loss=1.2515, mse=1.2515, time=0.0392\n",
      "Iter=800, loss=1.2391, mse=1.2391, time=0.0388\n",
      "Iter=1000, loss=1.2008, mse=1.2008, time=0.0386\n",
      "Iter=1200, loss=1.2048, mse=1.2048, time=0.0387\n",
      "Iter=1400, loss=1.2259, mse=1.2259, time=0.0386\n",
      "Iter=1600, loss=1.2205, mse=1.2205, time=0.0385\n",
      "Iter=1800, loss=1.2473, mse=1.2473, time=0.0384\n",
      "Iter=2000, loss=1.2538, mse=1.2538, time=0.0384\n",
      "Iter=2200, loss=1.2624, mse=1.2624, time=0.0385\n",
      "Iter=2400, loss=1.2640, mse=1.2640, time=0.0384\n",
      "Iter=2600, loss=1.1738, mse=1.1738, time=0.0385\n",
      "Iter=2800, loss=1.2052, mse=1.2052, time=0.0385\n",
      "Iter=3000, loss=1.2347, mse=1.2347, time=0.0386\n",
      "Iter=3200, loss=1.2625, mse=1.2625, time=0.0386\n",
      "Iter=3400, loss=1.2671, mse=1.2671, time=0.0385\n",
      "Iter=3600, loss=1.2497, mse=1.2497, time=0.0385\n",
      "Iter=3800, loss=1.2183, mse=1.2183, time=0.0385\n",
      "Iter=4000, loss=1.2386, mse=1.2386, time=0.0385\n",
      "Iter=4200, loss=1.2306, mse=1.2306, time=0.0385\n",
      "Iter=4400, loss=1.2481, mse=1.2481, time=0.0385\n",
      "Iter=4600, loss=1.2062, mse=1.2062, time=0.0386\n",
      "Iter=4800, loss=1.2313, mse=1.2313, time=0.0387\n",
      "Iter=5000, loss=1.1964, mse=1.1964, time=0.0386\n",
      "Iter=5200, loss=1.2032, mse=1.2032, time=0.0386\n",
      "Iter=5400, loss=1.2509, mse=1.2509, time=0.0386\n",
      "Iter=5600, loss=1.2289, mse=1.2289, time=0.0386\n",
      "Iter=5800, loss=1.2431, mse=1.2431, time=0.0386\n",
      "Iter=6000, loss=1.2051, mse=1.2051, time=0.0386\n",
      "Iter=6200, loss=1.2439, mse=1.2439, time=0.0386\n",
      "Iter=6400, loss=1.2683, mse=1.2683, time=0.0386\n",
      "Iter=6600, loss=1.2871, mse=1.2871, time=0.0387\n",
      "=== Epoch 3, train loss 1.234537, test rmse 1.067858 ===\n",
      "Epoch 4\n",
      "Iter=200, loss=1.2305, mse=1.2305, time=0.0404\n",
      "Iter=400, loss=1.2615, mse=1.2615, time=0.0391\n",
      "Iter=600, loss=1.2189, mse=1.2189, time=0.0389\n",
      "Iter=800, loss=1.1795, mse=1.1795, time=0.0391\n",
      "Iter=1000, loss=1.1995, mse=1.1995, time=0.0391\n",
      "Iter=1200, loss=1.2432, mse=1.2432, time=0.0390\n",
      "Iter=1400, loss=1.2340, mse=1.2340, time=0.0390\n",
      "Iter=1600, loss=1.2780, mse=1.2780, time=0.0390\n",
      "Iter=1800, loss=1.2233, mse=1.2233, time=0.0390\n",
      "Iter=2000, loss=1.2704, mse=1.2704, time=0.0389\n",
      "Iter=2200, loss=1.2022, mse=1.2022, time=0.0389\n",
      "Iter=2400, loss=1.2027, mse=1.2027, time=0.0389\n",
      "Iter=2600, loss=1.2323, mse=1.2323, time=0.0388\n",
      "Iter=2800, loss=1.2487, mse=1.2487, time=0.0387\n",
      "Iter=3000, loss=1.2227, mse=1.2227, time=0.0387\n",
      "Iter=3200, loss=1.2384, mse=1.2384, time=0.0386\n",
      "Iter=3400, loss=1.2282, mse=1.2282, time=0.0385\n",
      "Iter=3600, loss=1.2404, mse=1.2404, time=0.0385\n",
      "Iter=3800, loss=1.2842, mse=1.2842, time=0.0385\n",
      "Iter=4000, loss=1.3000, mse=1.3000, time=0.0386\n",
      "Iter=4200, loss=1.1779, mse=1.1779, time=0.0385\n",
      "Iter=4400, loss=1.2617, mse=1.2617, time=0.0385\n",
      "Iter=4600, loss=1.2059, mse=1.2059, time=0.0385\n",
      "Iter=4800, loss=1.2544, mse=1.2544, time=0.0385\n",
      "Iter=5000, loss=1.2423, mse=1.2423, time=0.0384\n",
      "Iter=5200, loss=1.2519, mse=1.2519, time=0.0384\n",
      "Iter=5400, loss=1.2355, mse=1.2355, time=0.0384\n",
      "Iter=5600, loss=1.1940, mse=1.1940, time=0.0384\n",
      "Iter=5800, loss=1.2333, mse=1.2333, time=0.0384\n",
      "Iter=6000, loss=1.1981, mse=1.1981, time=0.0384\n",
      "Iter=6200, loss=1.2727, mse=1.2727, time=0.0384\n",
      "Iter=6400, loss=1.1850, mse=1.1850, time=0.0384\n",
      "Iter=6600, loss=1.2516, mse=1.2516, time=0.0384\n",
      "=== Epoch 4, train loss 1.234093, test rmse 1.066177 ===\n",
      "Epoch 5\n",
      "Iter=200, loss=1.2187, mse=1.2187, time=0.0399\n",
      "Iter=400, loss=1.2362, mse=1.2362, time=0.0389\n",
      "Iter=600, loss=1.2257, mse=1.2257, time=0.0389\n",
      "Iter=800, loss=1.2226, mse=1.2226, time=0.0391\n",
      "Iter=1000, loss=1.2332, mse=1.2332, time=0.0390\n",
      "Iter=1200, loss=1.2037, mse=1.2037, time=0.0388\n",
      "Iter=1400, loss=1.2243, mse=1.2243, time=0.0388\n",
      "Iter=1600, loss=1.2246, mse=1.2246, time=0.0388\n",
      "Iter=1800, loss=1.2450, mse=1.2450, time=0.0388\n",
      "Iter=2000, loss=1.2636, mse=1.2636, time=0.0388\n",
      "Iter=2200, loss=1.2457, mse=1.2457, time=0.0386\n",
      "Iter=2400, loss=1.2463, mse=1.2463, time=0.0387\n",
      "Iter=2600, loss=1.2376, mse=1.2376, time=0.0386\n",
      "Iter=2800, loss=1.2461, mse=1.2461, time=0.0387\n",
      "Iter=3000, loss=1.2336, mse=1.2336, time=0.0385\n",
      "Iter=3200, loss=1.1768, mse=1.1768, time=0.0384\n",
      "Iter=3400, loss=1.2217, mse=1.2217, time=0.0384\n",
      "Iter=3600, loss=1.2641, mse=1.2641, time=0.0385\n",
      "Iter=3800, loss=1.2163, mse=1.2163, time=0.0384\n",
      "Iter=4000, loss=1.2542, mse=1.2542, time=0.0383\n",
      "Iter=4200, loss=1.2321, mse=1.2321, time=0.0383\n",
      "Iter=4400, loss=1.2312, mse=1.2312, time=0.0383\n",
      "Iter=4600, loss=1.2524, mse=1.2524, time=0.0383\n",
      "Iter=4800, loss=1.2638, mse=1.2638, time=0.0384\n",
      "Iter=5000, loss=1.2449, mse=1.2449, time=0.0384\n",
      "Iter=5200, loss=1.2130, mse=1.2130, time=0.0384\n",
      "Iter=5400, loss=1.2468, mse=1.2468, time=0.0384\n",
      "Iter=5600, loss=1.2169, mse=1.2169, time=0.0384\n",
      "Iter=5800, loss=1.2657, mse=1.2657, time=0.0385\n",
      "Iter=6000, loss=1.2441, mse=1.2441, time=0.0385\n",
      "Iter=6200, loss=1.2482, mse=1.2482, time=0.0385\n",
      "Iter=6400, loss=1.1956, mse=1.1956, time=0.0385\n",
      "Iter=6600, loss=1.2204, mse=1.2204, time=0.0386\n",
      "=== Epoch 5, train loss 1.234405, test rmse 1.066224 ===\n",
      "Epoch 6\n",
      "Iter=200, loss=1.2287, mse=1.2287, time=0.0406\n",
      "Iter=400, loss=1.2737, mse=1.2737, time=0.0400\n",
      "Iter=600, loss=1.2511, mse=1.2511, time=0.0397\n",
      "Iter=800, loss=1.2398, mse=1.2398, time=0.0396\n",
      "Iter=1000, loss=1.2481, mse=1.2481, time=0.0396\n",
      "Iter=1200, loss=1.2244, mse=1.2244, time=0.0395\n",
      "Iter=1400, loss=1.2381, mse=1.2381, time=0.0393\n",
      "Iter=1600, loss=1.2362, mse=1.2362, time=0.0392\n",
      "Iter=1800, loss=1.2098, mse=1.2098, time=0.0390\n",
      "Iter=2000, loss=1.2009, mse=1.2009, time=0.0389\n",
      "Iter=2200, loss=1.2188, mse=1.2188, time=0.0389\n",
      "Iter=2400, loss=1.2296, mse=1.2296, time=0.0389\n",
      "Iter=2600, loss=1.2552, mse=1.2552, time=0.0388\n",
      "Iter=2800, loss=1.2398, mse=1.2398, time=0.0386\n",
      "Iter=3000, loss=1.2725, mse=1.2725, time=0.0385\n",
      "Iter=3200, loss=1.2669, mse=1.2669, time=0.0384\n",
      "Iter=3400, loss=1.2618, mse=1.2618, time=0.0384\n",
      "Iter=3600, loss=1.2331, mse=1.2331, time=0.0383\n",
      "Iter=3800, loss=1.2230, mse=1.2230, time=0.0382\n",
      "Iter=4000, loss=1.2227, mse=1.2227, time=0.0382\n",
      "Iter=4200, loss=1.2103, mse=1.2103, time=0.0382\n",
      "Iter=4400, loss=1.2343, mse=1.2343, time=0.0382\n",
      "Iter=4600, loss=1.2722, mse=1.2722, time=0.0382\n",
      "Iter=4800, loss=1.2425, mse=1.2425, time=0.0382\n",
      "Iter=5000, loss=1.2064, mse=1.2064, time=0.0382\n",
      "Iter=5200, loss=1.2405, mse=1.2405, time=0.0382\n",
      "Iter=5400, loss=1.2157, mse=1.2157, time=0.0382\n",
      "Iter=5600, loss=1.2129, mse=1.2129, time=0.0382\n",
      "Iter=5800, loss=1.2225, mse=1.2225, time=0.0382\n",
      "Iter=6000, loss=1.2298, mse=1.2298, time=0.0382\n",
      "Iter=6200, loss=1.2662, mse=1.2662, time=0.0382\n",
      "Iter=6400, loss=1.1926, mse=1.1926, time=0.0382\n",
      "Iter=6600, loss=1.2216, mse=1.2216, time=0.0382\n",
      "=== Epoch 6, train loss 1.234200, test rmse 1.066407 ===\n",
      "Epoch 7\n",
      "Iter=200, loss=1.2023, mse=1.2023, time=0.0411\n",
      "Iter=400, loss=1.2298, mse=1.2298, time=0.0400\n",
      "Iter=600, loss=1.1999, mse=1.1999, time=0.0396\n",
      "Iter=800, loss=1.2699, mse=1.2699, time=0.0395\n",
      "Iter=1000, loss=1.1830, mse=1.1830, time=0.0392\n",
      "Iter=1200, loss=1.1884, mse=1.1884, time=0.0391\n",
      "Iter=1400, loss=1.2307, mse=1.2307, time=0.0391\n",
      "Iter=1600, loss=1.2150, mse=1.2150, time=0.0392\n",
      "Iter=1800, loss=1.2055, mse=1.2055, time=0.0392\n",
      "Iter=2000, loss=1.1801, mse=1.1801, time=0.0390\n",
      "Iter=2200, loss=1.2424, mse=1.2424, time=0.0390\n",
      "Iter=2400, loss=1.2258, mse=1.2258, time=0.0389\n",
      "Iter=2600, loss=1.2540, mse=1.2540, time=0.0388\n",
      "Iter=2800, loss=1.2992, mse=1.2992, time=0.0387\n",
      "Iter=3000, loss=1.2966, mse=1.2966, time=0.0387\n",
      "Iter=3200, loss=1.2457, mse=1.2457, time=0.0387\n",
      "Iter=3400, loss=1.2724, mse=1.2724, time=0.0387\n",
      "Iter=3600, loss=1.2502, mse=1.2502, time=0.0388\n",
      "Iter=3800, loss=1.2628, mse=1.2628, time=0.0388\n",
      "Iter=4000, loss=1.1903, mse=1.1903, time=0.0388\n",
      "Iter=4200, loss=1.2188, mse=1.2188, time=0.0388\n",
      "Iter=4400, loss=1.2463, mse=1.2463, time=0.0389\n",
      "Iter=4600, loss=1.2732, mse=1.2732, time=0.0390\n",
      "Iter=4800, loss=1.2602, mse=1.2602, time=0.0390\n",
      "Iter=5000, loss=1.2607, mse=1.2607, time=0.0390\n",
      "Iter=5200, loss=1.2364, mse=1.2364, time=0.0389\n",
      "Iter=5400, loss=1.2475, mse=1.2475, time=0.0389\n",
      "Iter=5600, loss=1.2422, mse=1.2422, time=0.0389\n",
      "Iter=5800, loss=1.2415, mse=1.2415, time=0.0389\n",
      "Iter=6000, loss=1.1776, mse=1.1776, time=0.0389\n",
      "Iter=6200, loss=1.2321, mse=1.2321, time=0.0389\n",
      "Iter=6400, loss=1.2265, mse=1.2265, time=0.0389\n",
      "Iter=6600, loss=1.2401, mse=1.2401, time=0.0389\n",
      "=== Epoch 7, train loss 1.234044, test rmse 1.066081 ===\n",
      "Epoch 8\n",
      "Iter=200, loss=1.2488, mse=1.2488, time=0.0412\n",
      "Iter=400, loss=1.2212, mse=1.2212, time=0.0402\n",
      "Iter=600, loss=1.2634, mse=1.2634, time=0.0399\n",
      "Iter=800, loss=1.2392, mse=1.2392, time=0.0397\n",
      "Iter=1000, loss=1.2720, mse=1.2720, time=0.0395\n",
      "Iter=1200, loss=1.2007, mse=1.2007, time=0.0392\n",
      "Iter=1400, loss=1.1835, mse=1.1835, time=0.0391\n",
      "Iter=1600, loss=1.2186, mse=1.2186, time=0.0392\n",
      "Iter=1800, loss=1.1980, mse=1.1980, time=0.0390\n",
      "Iter=2000, loss=1.2822, mse=1.2822, time=0.0390\n",
      "Iter=2200, loss=1.2609, mse=1.2609, time=0.0389\n",
      "Iter=2400, loss=1.1926, mse=1.1926, time=0.0387\n",
      "Iter=2600, loss=1.2274, mse=1.2274, time=0.0387\n",
      "Iter=2800, loss=1.2694, mse=1.2694, time=0.0387\n",
      "Iter=3000, loss=1.2434, mse=1.2434, time=0.0387\n",
      "Iter=3200, loss=1.1622, mse=1.1622, time=0.0386\n",
      "Iter=3400, loss=1.2057, mse=1.2057, time=0.0386\n",
      "Iter=3600, loss=1.2385, mse=1.2385, time=0.0386\n",
      "Iter=3800, loss=1.2532, mse=1.2532, time=0.0386\n",
      "Iter=4000, loss=1.2332, mse=1.2332, time=0.0386\n",
      "Iter=4200, loss=1.2432, mse=1.2432, time=0.0385\n",
      "Iter=4400, loss=1.2335, mse=1.2335, time=0.0385\n",
      "Iter=4600, loss=1.2803, mse=1.2803, time=0.0385\n",
      "Iter=4800, loss=1.2183, mse=1.2183, time=0.0386\n",
      "Iter=5000, loss=1.1934, mse=1.1934, time=0.0386\n",
      "Iter=5200, loss=1.2477, mse=1.2477, time=0.0387\n",
      "Iter=5400, loss=1.2283, mse=1.2283, time=0.0387\n",
      "Iter=5600, loss=1.1932, mse=1.1932, time=0.0387\n",
      "Iter=5800, loss=1.2559, mse=1.2559, time=0.0386\n",
      "Iter=6000, loss=1.2336, mse=1.2336, time=0.0386\n",
      "Iter=6200, loss=1.2531, mse=1.2531, time=0.0386\n",
      "Iter=6400, loss=1.2547, mse=1.2547, time=0.0386\n",
      "Iter=6600, loss=1.2556, mse=1.2556, time=0.0386\n",
      "=== Epoch 8, train loss 1.234227, test rmse 1.067471 ===\n",
      "Epoch 9\n",
      "Iter=200, loss=1.2397, mse=1.2397, time=0.0407\n",
      "Iter=400, loss=1.2079, mse=1.2079, time=0.0394\n",
      "Iter=600, loss=1.1939, mse=1.1939, time=0.0389\n",
      "Iter=800, loss=1.1910, mse=1.1910, time=0.0386\n",
      "Iter=1000, loss=1.2322, mse=1.2322, time=0.0385\n",
      "Iter=1200, loss=1.2604, mse=1.2604, time=0.0384\n",
      "Iter=1400, loss=1.2313, mse=1.2313, time=0.0387\n",
      "Iter=1600, loss=1.2424, mse=1.2424, time=0.0387\n",
      "Iter=1800, loss=1.2384, mse=1.2384, time=0.0386\n",
      "Iter=2000, loss=1.2507, mse=1.2507, time=0.0385\n",
      "Iter=2200, loss=1.2499, mse=1.2499, time=0.0384\n",
      "Iter=2400, loss=1.2079, mse=1.2079, time=0.0385\n",
      "Iter=2600, loss=1.2309, mse=1.2309, time=0.0386\n",
      "Iter=2800, loss=1.2295, mse=1.2295, time=0.0385\n",
      "Iter=3000, loss=1.2282, mse=1.2282, time=0.0385\n",
      "Iter=3200, loss=1.2052, mse=1.2052, time=0.0386\n",
      "Iter=3400, loss=1.2586, mse=1.2586, time=0.0385\n",
      "Iter=3600, loss=1.2116, mse=1.2116, time=0.0385\n",
      "Iter=3800, loss=1.2556, mse=1.2556, time=0.0385\n",
      "Iter=4000, loss=1.1981, mse=1.1981, time=0.0385\n",
      "Iter=4200, loss=1.2528, mse=1.2528, time=0.0385\n",
      "Iter=4400, loss=1.2527, mse=1.2527, time=0.0384\n",
      "Iter=4600, loss=1.2986, mse=1.2986, time=0.0384\n",
      "Iter=4800, loss=1.2417, mse=1.2417, time=0.0383\n",
      "Iter=5000, loss=1.2075, mse=1.2075, time=0.0383\n",
      "Iter=5200, loss=1.2104, mse=1.2104, time=0.0383\n",
      "Iter=5400, loss=1.2536, mse=1.2536, time=0.0382\n",
      "Iter=5600, loss=1.2494, mse=1.2494, time=0.0382\n",
      "Iter=5800, loss=1.2347, mse=1.2347, time=0.0381\n",
      "Iter=6000, loss=1.1921, mse=1.1921, time=0.0381\n",
      "Iter=6200, loss=1.2323, mse=1.2323, time=0.0382\n",
      "Iter=6400, loss=1.2348, mse=1.2348, time=0.0381\n",
      "Iter=6600, loss=1.2599, mse=1.2599, time=0.0380\n",
      "=== Epoch 9, train loss 1.233967, test rmse 1.066616 ===\n",
      "Epoch 10\n",
      "Iter=200, loss=1.2363, mse=1.2363, time=0.0411\n",
      "Iter=400, loss=1.2356, mse=1.2356, time=0.0397\n",
      "Iter=600, loss=1.1686, mse=1.1686, time=0.0392\n",
      "Iter=800, loss=1.2510, mse=1.2510, time=0.0392\n",
      "Iter=1000, loss=1.2393, mse=1.2393, time=0.0392\n",
      "Iter=1200, loss=1.2241, mse=1.2241, time=0.0391\n",
      "Iter=1400, loss=1.2114, mse=1.2114, time=0.0390\n",
      "Iter=1600, loss=1.2125, mse=1.2125, time=0.0388\n",
      "Iter=1800, loss=1.2251, mse=1.2251, time=0.0387\n",
      "Iter=2000, loss=1.2201, mse=1.2201, time=0.0386\n",
      "Iter=2200, loss=1.2390, mse=1.2390, time=0.0386\n",
      "Iter=2400, loss=1.2486, mse=1.2486, time=0.0386\n",
      "Iter=2600, loss=1.2067, mse=1.2067, time=0.0386\n",
      "Iter=2800, loss=1.2504, mse=1.2504, time=0.0386\n",
      "Iter=3000, loss=1.2254, mse=1.2254, time=0.0385\n",
      "Iter=3200, loss=1.2428, mse=1.2428, time=0.0386\n",
      "Iter=3400, loss=1.2433, mse=1.2433, time=0.0386\n",
      "Iter=3600, loss=1.2353, mse=1.2353, time=0.0386\n",
      "Iter=3800, loss=1.2140, mse=1.2140, time=0.0385\n",
      "Iter=4000, loss=1.2637, mse=1.2637, time=0.0385\n",
      "Iter=4200, loss=1.2820, mse=1.2820, time=0.0386\n",
      "Iter=4400, loss=1.2420, mse=1.2420, time=0.0386\n",
      "Iter=4600, loss=1.2333, mse=1.2333, time=0.0386\n",
      "Iter=4800, loss=1.1795, mse=1.1795, time=0.0386\n",
      "Iter=5000, loss=1.2249, mse=1.2249, time=0.0386\n",
      "Iter=5200, loss=1.2149, mse=1.2149, time=0.0386\n",
      "Iter=5400, loss=1.2686, mse=1.2686, time=0.0386\n",
      "Iter=5600, loss=1.2550, mse=1.2550, time=0.0386\n",
      "Iter=5800, loss=1.2839, mse=1.2839, time=0.0386\n",
      "Iter=6000, loss=1.2015, mse=1.2015, time=0.0386\n",
      "Iter=6200, loss=1.2151, mse=1.2151, time=0.0385\n",
      "Iter=6400, loss=1.2089, mse=1.2089, time=0.0385\n",
      "Iter=6600, loss=1.2733, mse=1.2733, time=0.0385\n",
      "=== Epoch 10, train loss 1.234002, test rmse 1.066484 ===\n",
      "Epoch 11\n",
      "Iter=200, loss=1.2014, mse=1.2014, time=0.0416\n",
      "Iter=400, loss=1.2825, mse=1.2825, time=0.0401\n",
      "Iter=600, loss=1.2126, mse=1.2126, time=0.0393\n",
      "Iter=800, loss=1.2615, mse=1.2615, time=0.0391\n",
      "Iter=1000, loss=1.2657, mse=1.2657, time=0.0390\n",
      "Iter=1200, loss=1.1955, mse=1.1955, time=0.0390\n",
      "Iter=1400, loss=1.2303, mse=1.2303, time=0.0388\n",
      "Iter=1600, loss=1.2289, mse=1.2289, time=0.0386\n",
      "Iter=1800, loss=1.2827, mse=1.2827, time=0.0386\n",
      "Iter=2000, loss=1.2405, mse=1.2405, time=0.0387\n",
      "Iter=2200, loss=1.2556, mse=1.2556, time=0.0388\n",
      "Iter=2400, loss=1.2050, mse=1.2050, time=0.0387\n",
      "Iter=2600, loss=1.2423, mse=1.2423, time=0.0387\n",
      "Iter=2800, loss=1.2702, mse=1.2702, time=0.0387\n",
      "Iter=3000, loss=1.2246, mse=1.2246, time=0.0387\n",
      "Iter=3200, loss=1.1711, mse=1.1711, time=0.0387\n",
      "Iter=3400, loss=1.2249, mse=1.2249, time=0.0387\n",
      "Iter=3600, loss=1.2302, mse=1.2302, time=0.0387\n",
      "Iter=3800, loss=1.2204, mse=1.2204, time=0.0387\n",
      "Iter=4000, loss=1.1695, mse=1.1695, time=0.0388\n",
      "Iter=4200, loss=1.3055, mse=1.3055, time=0.0387\n",
      "Iter=4400, loss=1.2409, mse=1.2409, time=0.0387\n",
      "Iter=4600, loss=1.2672, mse=1.2672, time=0.0387\n",
      "Iter=4800, loss=1.2266, mse=1.2266, time=0.0387\n",
      "Iter=5000, loss=1.2211, mse=1.2211, time=0.0387\n",
      "Iter=5200, loss=1.2521, mse=1.2521, time=0.0386\n",
      "Iter=5400, loss=1.2512, mse=1.2512, time=0.0386\n",
      "Iter=5600, loss=1.2209, mse=1.2209, time=0.0386\n",
      "Iter=5800, loss=1.2000, mse=1.2000, time=0.0385\n",
      "Iter=6000, loss=1.2655, mse=1.2655, time=0.0384\n",
      "Iter=6200, loss=1.2214, mse=1.2214, time=0.0384\n",
      "Iter=6400, loss=1.2278, mse=1.2278, time=0.0385\n",
      "Iter=6600, loss=1.2146, mse=1.2146, time=0.0385\n",
      "=== Epoch 11, train loss 1.234410, test rmse 1.066739 ===\n",
      "Epoch 12\n",
      "Iter=200, loss=1.2075, mse=1.2075, time=0.0428\n",
      "Iter=400, loss=1.2504, mse=1.2504, time=0.0411\n",
      "Iter=600, loss=1.2260, mse=1.2260, time=0.0402\n",
      "Iter=800, loss=1.1962, mse=1.1962, time=0.0399\n",
      "Iter=1000, loss=1.1950, mse=1.1950, time=0.0397\n",
      "Iter=1200, loss=1.2257, mse=1.2257, time=0.0392\n",
      "Iter=1400, loss=1.2270, mse=1.2270, time=0.0388\n",
      "Iter=1600, loss=1.2660, mse=1.2660, time=0.0387\n",
      "Iter=1800, loss=1.2261, mse=1.2261, time=0.0388\n",
      "Iter=2000, loss=1.2518, mse=1.2518, time=0.0388\n",
      "Iter=2200, loss=1.2980, mse=1.2980, time=0.0389\n",
      "Iter=2400, loss=1.2589, mse=1.2589, time=0.0389\n",
      "Iter=2600, loss=1.2882, mse=1.2882, time=0.0388\n",
      "Iter=2800, loss=1.2069, mse=1.2069, time=0.0388\n",
      "Iter=3000, loss=1.1951, mse=1.1951, time=0.0389\n",
      "Iter=3200, loss=1.2167, mse=1.2167, time=0.0389\n",
      "Iter=3400, loss=1.2519, mse=1.2519, time=0.0390\n",
      "Iter=3600, loss=1.2178, mse=1.2178, time=0.0390\n",
      "Iter=3800, loss=1.1818, mse=1.1818, time=0.0390\n",
      "Iter=4000, loss=1.2234, mse=1.2234, time=0.0390\n",
      "Iter=4200, loss=1.2098, mse=1.2098, time=0.0390\n",
      "Iter=4400, loss=1.2326, mse=1.2326, time=0.0390\n",
      "Iter=4600, loss=1.2630, mse=1.2630, time=0.0389\n",
      "Iter=4800, loss=1.2537, mse=1.2537, time=0.0389\n",
      "Iter=5000, loss=1.2475, mse=1.2475, time=0.0389\n",
      "Iter=5200, loss=1.2182, mse=1.2182, time=0.0389\n",
      "Iter=5400, loss=1.2497, mse=1.2497, time=0.0389\n",
      "Iter=5600, loss=1.2162, mse=1.2162, time=0.0389\n",
      "Iter=5800, loss=1.2687, mse=1.2687, time=0.0389\n",
      "Iter=6000, loss=1.2349, mse=1.2349, time=0.0388\n",
      "Iter=6200, loss=1.2317, mse=1.2317, time=0.0388\n",
      "Iter=6400, loss=1.2722, mse=1.2722, time=0.0388\n",
      "Iter=6600, loss=1.2300, mse=1.2300, time=0.0388\n",
      "=== Epoch 12, train loss 1.234319, test rmse 1.066493 ===\n",
      "Epoch 13\n",
      "Iter=200, loss=1.2052, mse=1.2052, time=0.0398\n",
      "Iter=400, loss=1.2626, mse=1.2626, time=0.0390\n",
      "Iter=600, loss=1.2639, mse=1.2639, time=0.0393\n",
      "Iter=800, loss=1.2218, mse=1.2218, time=0.0392\n",
      "Iter=1000, loss=1.2507, mse=1.2507, time=0.0389\n",
      "Iter=1200, loss=1.2396, mse=1.2396, time=0.0388\n",
      "Iter=1400, loss=1.2574, mse=1.2574, time=0.0386\n",
      "Iter=1600, loss=1.2189, mse=1.2189, time=0.0386\n",
      "Iter=1800, loss=1.1994, mse=1.1994, time=0.0385\n",
      "Iter=2000, loss=1.2109, mse=1.2109, time=0.0386\n",
      "Iter=2200, loss=1.2448, mse=1.2448, time=0.0385\n",
      "Iter=2400, loss=1.2678, mse=1.2678, time=0.0385\n",
      "Iter=2600, loss=1.1944, mse=1.1944, time=0.0385\n",
      "Iter=2800, loss=1.2475, mse=1.2475, time=0.0385\n",
      "Iter=3000, loss=1.2236, mse=1.2236, time=0.0385\n",
      "Iter=3200, loss=1.2775, mse=1.2775, time=0.0385\n",
      "Iter=3400, loss=1.2073, mse=1.2073, time=0.0385\n",
      "Iter=3600, loss=1.2221, mse=1.2221, time=0.0385\n",
      "Iter=3800, loss=1.2017, mse=1.2017, time=0.0384\n",
      "Iter=4000, loss=1.2118, mse=1.2118, time=0.0384\n",
      "Iter=4200, loss=1.2075, mse=1.2075, time=0.0383\n",
      "Iter=4400, loss=1.2925, mse=1.2925, time=0.0383\n",
      "Iter=4600, loss=1.2168, mse=1.2168, time=0.0383\n",
      "Iter=4800, loss=1.2437, mse=1.2437, time=0.0383\n",
      "Iter=5000, loss=1.2003, mse=1.2003, time=0.0383\n",
      "Iter=5200, loss=1.2286, mse=1.2286, time=0.0383\n",
      "Iter=5400, loss=1.2516, mse=1.2516, time=0.0383\n",
      "Iter=5600, loss=1.2563, mse=1.2563, time=0.0382\n",
      "Iter=5800, loss=1.2299, mse=1.2299, time=0.0381\n",
      "Iter=6000, loss=1.2643, mse=1.2643, time=0.0381\n",
      "Iter=6200, loss=1.2396, mse=1.2396, time=0.0380\n",
      "Iter=6400, loss=1.2206, mse=1.2206, time=0.0380\n",
      "Iter=6600, loss=1.2469, mse=1.2469, time=0.0380\n",
      "=== Epoch 13, train loss 1.234168, test rmse 1.066070 ===\n",
      "Epoch 14\n",
      "Iter=200, loss=1.2535, mse=1.2535, time=0.0407\n",
      "Iter=400, loss=1.2508, mse=1.2508, time=0.0394\n",
      "Iter=600, loss=1.2179, mse=1.2179, time=0.0389\n",
      "Iter=800, loss=1.2357, mse=1.2357, time=0.0387\n",
      "Iter=1000, loss=1.2142, mse=1.2142, time=0.0382\n",
      "Iter=1200, loss=1.2462, mse=1.2462, time=0.0380\n",
      "Iter=1400, loss=1.2331, mse=1.2331, time=0.0382\n",
      "Iter=1600, loss=1.2456, mse=1.2456, time=0.0382\n",
      "Iter=1800, loss=1.2074, mse=1.2074, time=0.0383\n",
      "Iter=2000, loss=1.2040, mse=1.2040, time=0.0384\n",
      "Iter=2200, loss=1.2610, mse=1.2610, time=0.0385\n",
      "Iter=2400, loss=1.2387, mse=1.2387, time=0.0384\n",
      "Iter=2600, loss=1.2119, mse=1.2119, time=0.0384\n",
      "Iter=2800, loss=1.2335, mse=1.2335, time=0.0385\n",
      "Iter=3000, loss=1.2238, mse=1.2238, time=0.0385\n",
      "Iter=3200, loss=1.2345, mse=1.2345, time=0.0385\n",
      "Iter=3400, loss=1.1908, mse=1.1908, time=0.0385\n",
      "Iter=3600, loss=1.2183, mse=1.2183, time=0.0386\n",
      "Iter=3800, loss=1.2585, mse=1.2585, time=0.0387\n",
      "Iter=4000, loss=1.2437, mse=1.2437, time=0.0387\n",
      "Iter=4200, loss=1.2301, mse=1.2301, time=0.0387\n",
      "Iter=4400, loss=1.2586, mse=1.2586, time=0.0386\n",
      "Iter=4600, loss=1.2615, mse=1.2615, time=0.0387\n",
      "Iter=4800, loss=1.2436, mse=1.2436, time=0.0387\n",
      "Iter=5000, loss=1.2202, mse=1.2202, time=0.0387\n",
      "Iter=5200, loss=1.2610, mse=1.2610, time=0.0387\n",
      "Iter=5400, loss=1.2350, mse=1.2350, time=0.0388\n",
      "Iter=5600, loss=1.2165, mse=1.2165, time=0.0387\n",
      "Iter=5800, loss=1.2283, mse=1.2283, time=0.0387\n",
      "Iter=6000, loss=1.2558, mse=1.2558, time=0.0388\n",
      "Iter=6200, loss=1.1935, mse=1.1935, time=0.0388\n",
      "Iter=6400, loss=1.2763, mse=1.2763, time=0.0388\n",
      "Iter=6600, loss=1.2420, mse=1.2420, time=0.0388\n",
      "=== Epoch 14, train loss 1.233743, test rmse 1.066129 ===\n",
      "Epoch 15\n",
      "Iter=200, loss=1.2771, mse=1.2771, time=0.0405\n",
      "Iter=400, loss=1.2429, mse=1.2429, time=0.0396\n",
      "Iter=600, loss=1.2503, mse=1.2503, time=0.0394\n",
      "Iter=800, loss=1.2458, mse=1.2458, time=0.0391\n",
      "Iter=1000, loss=1.2367, mse=1.2367, time=0.0387\n",
      "Iter=1200, loss=1.2649, mse=1.2649, time=0.0387\n",
      "Iter=1400, loss=1.1828, mse=1.1828, time=0.0386\n",
      "Iter=1600, loss=1.2527, mse=1.2527, time=0.0386\n",
      "Iter=1800, loss=1.2425, mse=1.2425, time=0.0386\n",
      "Iter=2000, loss=1.2474, mse=1.2474, time=0.0387\n",
      "Iter=2200, loss=1.2309, mse=1.2309, time=0.0387\n",
      "Iter=2400, loss=1.2543, mse=1.2543, time=0.0387\n",
      "Iter=2600, loss=1.2288, mse=1.2288, time=0.0387\n",
      "Iter=2800, loss=1.2296, mse=1.2296, time=0.0387\n",
      "Iter=3000, loss=1.2104, mse=1.2104, time=0.0387\n",
      "Iter=3200, loss=1.2263, mse=1.2263, time=0.0387\n",
      "Iter=3400, loss=1.2405, mse=1.2405, time=0.0387\n",
      "Iter=3600, loss=1.2308, mse=1.2308, time=0.0387\n",
      "Iter=3800, loss=1.1917, mse=1.1917, time=0.0386\n",
      "Iter=4000, loss=1.2436, mse=1.2436, time=0.0387\n",
      "Iter=4200, loss=1.2569, mse=1.2569, time=0.0386\n",
      "Iter=4400, loss=1.2423, mse=1.2423, time=0.0387\n",
      "Iter=4600, loss=1.2262, mse=1.2262, time=0.0388\n",
      "Iter=4800, loss=1.2256, mse=1.2256, time=0.0388\n",
      "Iter=5000, loss=1.2255, mse=1.2255, time=0.0388\n",
      "Iter=5200, loss=1.2312, mse=1.2312, time=0.0388\n",
      "Iter=5400, loss=1.2320, mse=1.2320, time=0.0387\n",
      "Iter=5600, loss=1.2424, mse=1.2424, time=0.0387\n",
      "Iter=5800, loss=1.2095, mse=1.2095, time=0.0387\n",
      "Iter=6000, loss=1.2440, mse=1.2440, time=0.0387\n",
      "Iter=6200, loss=1.2791, mse=1.2791, time=0.0387\n",
      "Iter=6400, loss=1.2313, mse=1.2313, time=0.0387\n",
      "Iter=6600, loss=1.1937, mse=1.1937, time=0.0387\n",
      "=== Epoch 15, train loss 1.234560, test rmse 1.067449 ===\n",
      "Epoch 16\n",
      "Iter=200, loss=1.2768, mse=1.2768, time=0.0438\n",
      "Iter=400, loss=1.2172, mse=1.2172, time=0.0412\n",
      "Iter=600, loss=1.2157, mse=1.2157, time=0.0397\n",
      "Iter=800, loss=1.2831, mse=1.2831, time=0.0393\n",
      "Iter=1000, loss=1.2390, mse=1.2390, time=0.0392\n",
      "Iter=1200, loss=1.2080, mse=1.2080, time=0.0392\n",
      "Iter=1400, loss=1.2541, mse=1.2541, time=0.0394\n",
      "Iter=1600, loss=1.2889, mse=1.2889, time=0.0393\n",
      "Iter=1800, loss=1.2238, mse=1.2238, time=0.0392\n",
      "Iter=2000, loss=1.2407, mse=1.2407, time=0.0390\n",
      "Iter=2200, loss=1.2648, mse=1.2648, time=0.0390\n",
      "Iter=2400, loss=1.2139, mse=1.2139, time=0.0390\n",
      "Iter=2600, loss=1.2027, mse=1.2027, time=0.0390\n",
      "Iter=2800, loss=1.2217, mse=1.2217, time=0.0390\n",
      "Iter=3000, loss=1.2413, mse=1.2413, time=0.0391\n",
      "Iter=3200, loss=1.2660, mse=1.2660, time=0.0390\n",
      "Iter=3400, loss=1.2409, mse=1.2409, time=0.0390\n",
      "Iter=3600, loss=1.2070, mse=1.2070, time=0.0390\n",
      "Iter=3800, loss=1.2114, mse=1.2114, time=0.0390\n",
      "Iter=4000, loss=1.2414, mse=1.2414, time=0.0390\n",
      "Iter=4200, loss=1.2227, mse=1.2227, time=0.0389\n",
      "Iter=4400, loss=1.2054, mse=1.2054, time=0.0389\n",
      "Iter=4600, loss=1.2105, mse=1.2105, time=0.0388\n",
      "Iter=4800, loss=1.2146, mse=1.2146, time=0.0388\n",
      "Iter=5000, loss=1.2421, mse=1.2421, time=0.0387\n",
      "Iter=5200, loss=1.1908, mse=1.1908, time=0.0387\n",
      "Iter=5400, loss=1.2261, mse=1.2261, time=0.0387\n",
      "Iter=5600, loss=1.2830, mse=1.2830, time=0.0387\n",
      "Iter=5800, loss=1.2675, mse=1.2675, time=0.0387\n",
      "Iter=6000, loss=1.2438, mse=1.2438, time=0.0387\n",
      "Iter=6200, loss=1.2330, mse=1.2330, time=0.0388\n",
      "Iter=6400, loss=1.2244, mse=1.2244, time=0.0388\n",
      "Iter=6600, loss=1.2487, mse=1.2487, time=0.0388\n",
      "=== Epoch 16, train loss 1.234321, test rmse 1.066340 ===\n",
      "Epoch 17\n",
      "Iter=200, loss=1.2425, mse=1.2425, time=0.0400\n",
      "Iter=400, loss=1.2248, mse=1.2248, time=0.0385\n",
      "Iter=600, loss=1.2358, mse=1.2358, time=0.0385\n",
      "Iter=800, loss=1.2233, mse=1.2233, time=0.0388\n",
      "Iter=1000, loss=1.2196, mse=1.2196, time=0.0387\n",
      "Iter=1200, loss=1.2500, mse=1.2500, time=0.0385\n",
      "Iter=1400, loss=1.2040, mse=1.2040, time=0.0383\n",
      "Iter=1600, loss=1.2729, mse=1.2729, time=0.0383\n",
      "Iter=1800, loss=1.2890, mse=1.2890, time=0.0382\n",
      "Iter=2000, loss=1.2333, mse=1.2333, time=0.0382\n",
      "Iter=2200, loss=1.2564, mse=1.2564, time=0.0382\n",
      "Iter=2400, loss=1.2437, mse=1.2437, time=0.0383\n",
      "Iter=2600, loss=1.2262, mse=1.2262, time=0.0383\n",
      "Iter=2800, loss=1.2407, mse=1.2407, time=0.0384\n",
      "Iter=3000, loss=1.2357, mse=1.2357, time=0.0384\n",
      "Iter=3200, loss=1.2561, mse=1.2561, time=0.0383\n",
      "Iter=3400, loss=1.2491, mse=1.2491, time=0.0383\n",
      "Iter=3600, loss=1.2018, mse=1.2018, time=0.0382\n",
      "Iter=3800, loss=1.2269, mse=1.2269, time=0.0382\n",
      "Iter=4000, loss=1.2346, mse=1.2346, time=0.0382\n",
      "Iter=4200, loss=1.2136, mse=1.2136, time=0.0382\n",
      "Iter=4400, loss=1.1937, mse=1.1937, time=0.0383\n",
      "Iter=4600, loss=1.2592, mse=1.2592, time=0.0383\n",
      "Iter=4800, loss=1.2139, mse=1.2139, time=0.0383\n",
      "Iter=5000, loss=1.2243, mse=1.2243, time=0.0382\n",
      "Iter=5200, loss=1.2619, mse=1.2619, time=0.0382\n",
      "Iter=5400, loss=1.2377, mse=1.2377, time=0.0382\n",
      "Iter=5600, loss=1.2286, mse=1.2286, time=0.0383\n",
      "Iter=5800, loss=1.2076, mse=1.2076, time=0.0383\n",
      "Iter=6000, loss=1.2635, mse=1.2635, time=0.0383\n",
      "Iter=6200, loss=1.2192, mse=1.2192, time=0.0383\n",
      "Iter=6400, loss=1.2109, mse=1.2109, time=0.0384\n",
      "Iter=6600, loss=1.2399, mse=1.2399, time=0.0384\n",
      "=== Epoch 17, train loss 1.234449, test rmse 1.066344 ===\n",
      "Epoch 18\n",
      "Iter=200, loss=1.2775, mse=1.2775, time=0.0387\n",
      "Iter=400, loss=1.2379, mse=1.2379, time=0.0383\n",
      "Iter=600, loss=1.1984, mse=1.1984, time=0.0384\n",
      "Iter=800, loss=1.1787, mse=1.1787, time=0.0387\n",
      "Iter=1000, loss=1.2542, mse=1.2542, time=0.0389\n",
      "Iter=1200, loss=1.2451, mse=1.2451, time=0.0389\n",
      "Iter=1400, loss=1.2336, mse=1.2336, time=0.0388\n",
      "Iter=1600, loss=1.2413, mse=1.2413, time=0.0388\n",
      "Iter=1800, loss=1.1976, mse=1.1976, time=0.0388\n",
      "Iter=2000, loss=1.2597, mse=1.2597, time=0.0388\n",
      "Iter=2200, loss=1.2045, mse=1.2045, time=0.0388\n",
      "Iter=2400, loss=1.2454, mse=1.2454, time=0.0389\n",
      "Iter=2600, loss=1.2697, mse=1.2697, time=0.0388\n",
      "Iter=2800, loss=1.2323, mse=1.2323, time=0.0388\n",
      "Iter=3000, loss=1.2352, mse=1.2352, time=0.0387\n",
      "Iter=3200, loss=1.2073, mse=1.2073, time=0.0387\n",
      "Iter=3400, loss=1.2398, mse=1.2398, time=0.0386\n",
      "Iter=3600, loss=1.2706, mse=1.2706, time=0.0387\n",
      "Iter=3800, loss=1.2490, mse=1.2490, time=0.0387\n",
      "Iter=4000, loss=1.2306, mse=1.2306, time=0.0385\n",
      "Iter=4200, loss=1.2447, mse=1.2447, time=0.0385\n",
      "Iter=4400, loss=1.2080, mse=1.2080, time=0.0385\n",
      "Iter=4600, loss=1.1939, mse=1.1939, time=0.0384\n",
      "Iter=4800, loss=1.2740, mse=1.2740, time=0.0383\n",
      "Iter=5000, loss=1.2241, mse=1.2241, time=0.0383\n",
      "Iter=5200, loss=1.2090, mse=1.2090, time=0.0383\n",
      "Iter=5400, loss=1.2454, mse=1.2454, time=0.0383\n",
      "Iter=5600, loss=1.2247, mse=1.2247, time=0.0383\n",
      "Iter=5800, loss=1.2654, mse=1.2654, time=0.0383\n",
      "Iter=6000, loss=1.2284, mse=1.2284, time=0.0383\n",
      "Iter=6200, loss=1.2343, mse=1.2343, time=0.0383\n",
      "Iter=6400, loss=1.2373, mse=1.2373, time=0.0383\n",
      "Iter=6600, loss=1.2429, mse=1.2429, time=0.0384\n",
      "=== Epoch 18, train loss 1.234409, test rmse 1.066406 ===\n",
      "Epoch 19\n",
      "Iter=200, loss=1.2147, mse=1.2147, time=0.0408\n",
      "Iter=400, loss=1.2100, mse=1.2100, time=0.0411\n",
      "Iter=600, loss=1.2164, mse=1.2164, time=0.0411\n",
      "Iter=800, loss=1.2195, mse=1.2195, time=0.0410\n",
      "Iter=1000, loss=1.2454, mse=1.2454, time=0.0411\n",
      "Iter=1200, loss=1.2592, mse=1.2592, time=0.0413\n",
      "Iter=1400, loss=1.2180, mse=1.2180, time=0.0411\n",
      "Iter=1600, loss=1.2014, mse=1.2014, time=0.0411\n",
      "Iter=1800, loss=1.2112, mse=1.2112, time=0.0410\n",
      "Iter=2000, loss=1.2235, mse=1.2235, time=0.0410\n",
      "Iter=2200, loss=1.2407, mse=1.2407, time=0.0410\n",
      "Iter=2400, loss=1.2147, mse=1.2147, time=0.0410\n",
      "Iter=2600, loss=1.2150, mse=1.2150, time=0.0410\n",
      "Iter=2800, loss=1.2423, mse=1.2423, time=0.0409\n",
      "Iter=3000, loss=1.3051, mse=1.3051, time=0.0410\n",
      "Iter=3200, loss=1.2293, mse=1.2293, time=0.0410\n",
      "Iter=3400, loss=1.2077, mse=1.2077, time=0.0410\n",
      "Iter=3600, loss=1.2594, mse=1.2594, time=0.0410\n",
      "Iter=3800, loss=1.2785, mse=1.2785, time=0.0409\n",
      "Iter=4000, loss=1.2616, mse=1.2616, time=0.0407\n",
      "Iter=4200, loss=1.2211, mse=1.2211, time=0.0406\n",
      "Iter=4400, loss=1.2230, mse=1.2230, time=0.0406\n",
      "Iter=4600, loss=1.2752, mse=1.2752, time=0.0406\n",
      "Iter=4800, loss=1.2369, mse=1.2369, time=0.0407\n",
      "Iter=5000, loss=1.2247, mse=1.2247, time=0.0405\n",
      "Iter=5200, loss=1.2534, mse=1.2534, time=0.0405\n",
      "Iter=5400, loss=1.2171, mse=1.2171, time=0.0404\n",
      "Iter=5600, loss=1.2545, mse=1.2545, time=0.0404\n",
      "Iter=5800, loss=1.2178, mse=1.2178, time=0.0403\n",
      "Iter=6000, loss=1.2320, mse=1.2320, time=0.0403\n",
      "Iter=6200, loss=1.2400, mse=1.2400, time=0.0404\n",
      "Iter=6400, loss=1.2197, mse=1.2197, time=0.0403\n",
      "Iter=6600, loss=1.2418, mse=1.2418, time=0.0402\n",
      "=== Epoch 19, train loss 1.234277, test rmse 1.066751 ===\n",
      "Epoch 20\n",
      "Iter=200, loss=1.2028, mse=1.2028, time=0.0454\n",
      "Iter=400, loss=1.2129, mse=1.2129, time=0.0439\n",
      "Iter=600, loss=1.1963, mse=1.1963, time=0.0423\n",
      "Iter=800, loss=1.1978, mse=1.1978, time=0.0415\n",
      "Iter=1000, loss=1.2294, mse=1.2294, time=0.0413\n",
      "Iter=1200, loss=1.2501, mse=1.2501, time=0.0417\n",
      "Iter=1400, loss=1.2443, mse=1.2443, time=0.0415\n",
      "Iter=1600, loss=1.2620, mse=1.2620, time=0.0416\n",
      "Iter=1800, loss=1.2525, mse=1.2525, time=0.0418\n",
      "Iter=2000, loss=1.2880, mse=1.2880, time=0.0427\n",
      "Iter=2200, loss=1.2491, mse=1.2491, time=0.0430\n",
      "Iter=2400, loss=1.1664, mse=1.1664, time=0.0438\n",
      "Iter=2600, loss=1.2299, mse=1.2299, time=0.0437\n",
      "Iter=2800, loss=1.2184, mse=1.2184, time=0.0435\n",
      "Iter=3000, loss=1.2558, mse=1.2558, time=0.0437\n",
      "Iter=3200, loss=1.2015, mse=1.2015, time=0.0436\n",
      "Iter=3400, loss=1.1940, mse=1.1940, time=0.0435\n",
      "Iter=3600, loss=1.2043, mse=1.2043, time=0.0435\n",
      "Iter=3800, loss=1.2459, mse=1.2459, time=0.0434\n",
      "Iter=4000, loss=1.2270, mse=1.2270, time=0.0436\n",
      "Iter=4200, loss=1.2779, mse=1.2779, time=0.0437\n",
      "Iter=4400, loss=1.2818, mse=1.2818, time=0.0437\n",
      "Iter=4600, loss=1.2659, mse=1.2659, time=0.0436\n",
      "Iter=4800, loss=1.2924, mse=1.2924, time=0.0436\n",
      "Iter=5000, loss=1.2794, mse=1.2794, time=0.0436\n",
      "Iter=5200, loss=1.2492, mse=1.2492, time=0.0438\n",
      "Iter=5400, loss=1.2373, mse=1.2373, time=0.0438\n",
      "Iter=5600, loss=1.2515, mse=1.2515, time=0.0439\n",
      "Iter=5800, loss=1.2434, mse=1.2434, time=0.0440\n",
      "Iter=6000, loss=1.2137, mse=1.2137, time=0.0439\n",
      "Iter=6200, loss=1.2109, mse=1.2109, time=0.0440\n",
      "Iter=6400, loss=1.2010, mse=1.2010, time=0.0441\n",
      "Iter=6600, loss=1.2062, mse=1.2062, time=0.0441\n",
      "=== Epoch 20, train loss 1.234373, test rmse 1.066909 ===\n",
      "Epoch 21\n",
      "Iter=200, loss=1.2172, mse=1.2172, time=0.0450\n",
      "Iter=400, loss=1.2353, mse=1.2353, time=0.0443\n",
      "Iter=600, loss=1.2494, mse=1.2494, time=0.0456\n",
      "Iter=800, loss=1.2428, mse=1.2428, time=0.0457\n",
      "Iter=1000, loss=1.2257, mse=1.2257, time=0.0458\n",
      "Iter=1200, loss=1.2454, mse=1.2454, time=0.0457\n",
      "Iter=1400, loss=1.2324, mse=1.2324, time=0.0460\n",
      "Iter=1600, loss=1.2289, mse=1.2289, time=0.0461\n",
      "Iter=1800, loss=1.2231, mse=1.2231, time=0.0458\n",
      "Iter=2000, loss=1.2412, mse=1.2412, time=0.0454\n",
      "Iter=2200, loss=1.2231, mse=1.2231, time=0.0451\n",
      "Iter=2400, loss=1.2488, mse=1.2488, time=0.0449\n",
      "Iter=2600, loss=1.2037, mse=1.2037, time=0.0447\n",
      "Iter=2800, loss=1.2512, mse=1.2512, time=0.0444\n",
      "Iter=3000, loss=1.2367, mse=1.2367, time=0.0443\n",
      "Iter=3200, loss=1.2274, mse=1.2274, time=0.0443\n",
      "Iter=3400, loss=1.2466, mse=1.2466, time=0.0442\n",
      "Iter=3600, loss=1.2217, mse=1.2217, time=0.0440\n",
      "Iter=3800, loss=1.2398, mse=1.2398, time=0.0438\n",
      "Iter=4000, loss=1.2653, mse=1.2653, time=0.0438\n",
      "Iter=4200, loss=1.1855, mse=1.1855, time=0.0438\n",
      "Iter=4400, loss=1.2769, mse=1.2769, time=0.0439\n",
      "Iter=4600, loss=1.2624, mse=1.2624, time=0.0441\n",
      "Iter=4800, loss=1.2348, mse=1.2348, time=0.0445\n",
      "Iter=5000, loss=1.2394, mse=1.2394, time=0.0451\n",
      "Iter=5200, loss=1.1876, mse=1.1876, time=0.0456\n",
      "Iter=5400, loss=1.2447, mse=1.2447, time=0.0461\n",
      "Iter=5600, loss=1.2477, mse=1.2477, time=0.0465\n",
      "Iter=5800, loss=1.2105, mse=1.2105, time=0.0470\n",
      "Iter=6000, loss=1.2620, mse=1.2620, time=0.0473\n",
      "Iter=6200, loss=1.1912, mse=1.1912, time=0.0476\n",
      "Iter=6400, loss=1.2046, mse=1.2046, time=0.0480\n",
      "Iter=6600, loss=1.2901, mse=1.2901, time=0.0485\n",
      "=== Epoch 21, train loss 1.234387, test rmse 1.065909 ===\n",
      "Epoch 22\n",
      "Iter=200, loss=1.1990, mse=1.1990, time=0.0657\n",
      "Iter=400, loss=1.2551, mse=1.2551, time=0.0635\n",
      "Iter=600, loss=1.2428, mse=1.2428, time=0.0628\n",
      "Iter=800, loss=1.2727, mse=1.2727, time=0.0615\n",
      "Iter=1000, loss=1.2258, mse=1.2258, time=0.0611\n",
      "Iter=1200, loss=1.2562, mse=1.2562, time=0.0611\n",
      "Iter=1400, loss=1.2119, mse=1.2119, time=0.0610\n",
      "Iter=1600, loss=1.2873, mse=1.2873, time=0.0610\n",
      "Iter=1800, loss=1.2710, mse=1.2710, time=0.0613\n",
      "Iter=2000, loss=1.2419, mse=1.2419, time=0.0613\n",
      "Iter=2200, loss=1.2344, mse=1.2344, time=0.0613\n",
      "Iter=2400, loss=1.2257, mse=1.2257, time=0.0614\n",
      "Iter=2600, loss=1.2049, mse=1.2049, time=0.0639\n",
      "Iter=2800, loss=1.2576, mse=1.2576, time=0.0650\n",
      "Iter=3000, loss=1.2418, mse=1.2418, time=0.0662\n",
      "Iter=3200, loss=1.2318, mse=1.2318, time=0.0668\n",
      "Iter=3400, loss=1.2308, mse=1.2308, time=0.0668\n",
      "Iter=3600, loss=1.2242, mse=1.2242, time=0.0668\n",
      "Iter=3800, loss=1.2180, mse=1.2180, time=0.0667\n",
      "Iter=4000, loss=1.2050, mse=1.2050, time=0.0665\n",
      "Iter=4200, loss=1.2562, mse=1.2562, time=0.0667\n",
      "Iter=4400, loss=1.2336, mse=1.2336, time=0.0671\n",
      "Iter=4600, loss=1.2364, mse=1.2364, time=0.0672\n",
      "Iter=4800, loss=1.2586, mse=1.2586, time=0.0671\n",
      "Iter=5000, loss=1.2202, mse=1.2202, time=0.0669\n",
      "Iter=5200, loss=1.2406, mse=1.2406, time=0.0667\n",
      "Iter=5400, loss=1.2317, mse=1.2317, time=0.0665\n",
      "Iter=5600, loss=1.2068, mse=1.2068, time=0.0667\n",
      "Iter=5800, loss=1.2284, mse=1.2284, time=0.0667\n",
      "Iter=6000, loss=1.2499, mse=1.2499, time=0.0667\n",
      "Iter=6200, loss=1.2331, mse=1.2331, time=0.0665\n",
      "Iter=6400, loss=1.2108, mse=1.2108, time=0.0665\n",
      "Iter=6600, loss=1.2059, mse=1.2059, time=0.0664\n",
      "=== Epoch 22, train loss 1.234284, test rmse 1.067040 ===\n",
      "Epoch 23\n",
      "Iter=200, loss=1.2690, mse=1.2690, time=0.0699\n",
      "Iter=400, loss=1.2009, mse=1.2009, time=0.0711\n",
      "Iter=600, loss=1.2076, mse=1.2076, time=0.0710\n",
      "Iter=800, loss=1.2506, mse=1.2506, time=0.0696\n",
      "Iter=1000, loss=1.2648, mse=1.2648, time=0.0685\n",
      "Iter=1200, loss=1.2583, mse=1.2583, time=0.0687\n",
      "Iter=1400, loss=1.2216, mse=1.2216, time=0.0692\n",
      "Iter=1600, loss=1.2082, mse=1.2082, time=0.0692\n",
      "Iter=1800, loss=1.1967, mse=1.1967, time=0.0693\n",
      "Iter=2000, loss=1.2200, mse=1.2200, time=0.0687\n",
      "Iter=2200, loss=1.2616, mse=1.2616, time=0.0682\n",
      "Iter=2400, loss=1.2347, mse=1.2347, time=0.0696\n",
      "Iter=2600, loss=1.2625, mse=1.2625, time=0.0700\n",
      "Iter=2800, loss=1.2377, mse=1.2377, time=0.0720\n",
      "Iter=3000, loss=1.2419, mse=1.2419, time=0.0725\n",
      "Iter=3200, loss=1.2452, mse=1.2452, time=0.0724\n",
      "Iter=3400, loss=1.2489, mse=1.2489, time=0.0719\n",
      "Iter=3600, loss=1.2230, mse=1.2230, time=0.0719\n",
      "Iter=3800, loss=1.2319, mse=1.2319, time=0.0714\n",
      "Iter=4000, loss=1.2405, mse=1.2405, time=0.0710\n",
      "Iter=4200, loss=1.1967, mse=1.1967, time=0.0709\n",
      "Iter=4400, loss=1.2103, mse=1.2103, time=0.0711\n",
      "Iter=4600, loss=1.2479, mse=1.2479, time=0.0709\n",
      "Iter=4800, loss=1.2662, mse=1.2662, time=0.0707\n",
      "Iter=5000, loss=1.2306, mse=1.2306, time=0.0707\n",
      "Iter=5200, loss=1.2044, mse=1.2044, time=0.0703\n",
      "Iter=5400, loss=1.2617, mse=1.2617, time=0.0706\n",
      "Iter=5600, loss=1.2100, mse=1.2100, time=0.0701\n",
      "Iter=5800, loss=1.2290, mse=1.2290, time=0.0699\n",
      "Iter=6000, loss=1.2294, mse=1.2294, time=0.0698\n",
      "Iter=6200, loss=1.2449, mse=1.2449, time=0.0695\n",
      "Iter=6400, loss=1.2338, mse=1.2338, time=0.0692\n",
      "Iter=6600, loss=1.2743, mse=1.2743, time=0.0694\n",
      "=== Epoch 23, train loss 1.234593, test rmse 1.066220 ===\n",
      "Epoch 24\n",
      "Iter=200, loss=1.2155, mse=1.2155, time=0.0695\n",
      "Iter=400, loss=1.2119, mse=1.2119, time=0.0691\n",
      "Iter=600, loss=1.2357, mse=1.2357, time=0.0677\n",
      "Iter=800, loss=1.2658, mse=1.2658, time=0.0699\n",
      "Iter=1000, loss=1.2296, mse=1.2296, time=0.0687\n",
      "Iter=1200, loss=1.2300, mse=1.2300, time=0.0683\n",
      "Iter=1400, loss=1.2379, mse=1.2379, time=0.0677\n",
      "Iter=1600, loss=1.2657, mse=1.2657, time=0.0676\n",
      "Iter=1800, loss=1.2631, mse=1.2631, time=0.0673\n",
      "Iter=2000, loss=1.2183, mse=1.2183, time=0.0672\n",
      "Iter=2200, loss=1.2330, mse=1.2330, time=0.0665\n",
      "Iter=2400, loss=1.2440, mse=1.2440, time=0.0666\n",
      "Iter=2600, loss=1.2430, mse=1.2430, time=0.0666\n",
      "Iter=2800, loss=1.2423, mse=1.2423, time=0.0663\n",
      "Iter=3000, loss=1.2068, mse=1.2068, time=0.0662\n",
      "Iter=3200, loss=1.2037, mse=1.2037, time=0.0660\n",
      "Iter=3400, loss=1.2763, mse=1.2763, time=0.0660\n",
      "Iter=3600, loss=1.2586, mse=1.2586, time=0.0657\n",
      "Iter=3800, loss=1.2379, mse=1.2379, time=0.0654\n",
      "Iter=4000, loss=1.2524, mse=1.2524, time=0.0652\n",
      "Iter=4200, loss=1.2262, mse=1.2262, time=0.0648\n",
      "Iter=4400, loss=1.2259, mse=1.2259, time=0.0646\n",
      "Iter=4600, loss=1.2557, mse=1.2557, time=0.0646\n",
      "Iter=4800, loss=1.2518, mse=1.2518, time=0.0644\n",
      "Iter=5000, loss=1.1824, mse=1.1824, time=0.0642\n",
      "Iter=5200, loss=1.2291, mse=1.2291, time=0.0641\n",
      "Iter=5400, loss=1.2100, mse=1.2100, time=0.0639\n",
      "Iter=5600, loss=1.2321, mse=1.2321, time=0.0637\n",
      "Iter=5800, loss=1.2438, mse=1.2438, time=0.0634\n",
      "Iter=6000, loss=1.2261, mse=1.2261, time=0.0633\n",
      "Iter=6200, loss=1.2059, mse=1.2059, time=0.0633\n",
      "Iter=6400, loss=1.2249, mse=1.2249, time=0.0633\n",
      "Iter=6600, loss=1.2173, mse=1.2173, time=0.0635\n",
      "=== Epoch 24, train loss 1.234440, test rmse 1.066350 ===\n",
      "Epoch 25\n",
      "Iter=200, loss=1.2226, mse=1.2226, time=0.0637\n",
      "Iter=400, loss=1.2004, mse=1.2004, time=0.0653\n",
      "Iter=600, loss=1.2377, mse=1.2377, time=0.0700\n",
      "Iter=800, loss=1.2218, mse=1.2218, time=0.0680\n",
      "Iter=1000, loss=1.2233, mse=1.2233, time=0.0679\n",
      "Iter=1200, loss=1.2074, mse=1.2074, time=0.0706\n",
      "Iter=1400, loss=1.1849, mse=1.1849, time=0.0728\n",
      "Iter=1600, loss=1.3163, mse=1.3163, time=0.0760\n",
      "Iter=1800, loss=1.2398, mse=1.2398, time=0.0742\n",
      "Iter=2000, loss=1.2494, mse=1.2494, time=0.0724\n",
      "Iter=2200, loss=1.2559, mse=1.2559, time=0.0729\n",
      "Iter=2400, loss=1.2088, mse=1.2088, time=0.0741\n",
      "Iter=2600, loss=1.2596, mse=1.2596, time=0.0749\n",
      "Iter=2800, loss=1.2560, mse=1.2560, time=0.0765\n",
      "Iter=3000, loss=1.2238, mse=1.2238, time=0.0755\n",
      "Iter=3200, loss=1.2350, mse=1.2350, time=0.0747\n",
      "Iter=3400, loss=1.2764, mse=1.2764, time=0.0764\n",
      "Iter=3600, loss=1.2051, mse=1.2051, time=0.0772\n",
      "Iter=3800, loss=1.2312, mse=1.2312, time=0.0778\n",
      "Iter=4000, loss=1.2501, mse=1.2501, time=0.0783\n",
      "Iter=4200, loss=1.2287, mse=1.2287, time=0.0790\n",
      "Iter=4400, loss=1.2528, mse=1.2528, time=0.0796\n",
      "Iter=4600, loss=1.2233, mse=1.2233, time=0.0802\n",
      "Iter=4800, loss=1.1743, mse=1.1743, time=0.0808\n",
      "Iter=5000, loss=1.2714, mse=1.2714, time=0.0813\n",
      "Iter=5200, loss=1.2828, mse=1.2828, time=0.0819\n",
      "Iter=5400, loss=1.2357, mse=1.2357, time=0.0822\n",
      "Iter=5600, loss=1.2517, mse=1.2517, time=0.0822\n",
      "Iter=5800, loss=1.2293, mse=1.2293, time=0.0822\n",
      "Iter=6000, loss=1.1802, mse=1.1802, time=0.0825\n",
      "Iter=6200, loss=1.2322, mse=1.2322, time=0.0823\n",
      "Iter=6400, loss=1.2389, mse=1.2389, time=0.0829\n",
      "Iter=6600, loss=1.2369, mse=1.2369, time=0.0830\n",
      "=== Epoch 25, train loss 1.234494, test rmse 1.066706 ===\n",
      "Epoch 26\n",
      "Iter=200, loss=1.2660, mse=1.2660, time=0.0864\n",
      "Iter=400, loss=1.1878, mse=1.1878, time=0.0872\n",
      "Iter=600, loss=1.1957, mse=1.1957, time=0.0867\n",
      "Iter=800, loss=1.2668, mse=1.2668, time=0.0838\n",
      "Iter=1000, loss=1.1991, mse=1.1991, time=0.0835\n",
      "Iter=1200, loss=1.2664, mse=1.2664, time=0.0848\n",
      "Iter=1400, loss=1.2375, mse=1.2375, time=0.0853\n",
      "Iter=1600, loss=1.1987, mse=1.1987, time=0.0852\n",
      "Iter=1800, loss=1.2424, mse=1.2424, time=0.0856\n",
      "Iter=2000, loss=1.2416, mse=1.2416, time=0.0845\n",
      "Iter=2200, loss=1.2136, mse=1.2136, time=0.0831\n",
      "Iter=2400, loss=1.2385, mse=1.2385, time=0.0829\n",
      "Iter=2600, loss=1.2381, mse=1.2381, time=0.0833\n",
      "Iter=2800, loss=1.2383, mse=1.2383, time=0.0834\n",
      "Iter=3000, loss=1.2297, mse=1.2297, time=0.0838\n",
      "Iter=3200, loss=1.2439, mse=1.2439, time=0.0843\n",
      "Iter=3400, loss=1.2555, mse=1.2555, time=0.0841\n",
      "Iter=3600, loss=1.2546, mse=1.2546, time=0.0845\n",
      "Iter=3800, loss=1.2270, mse=1.2270, time=0.0846\n",
      "Iter=4000, loss=1.2542, mse=1.2542, time=0.0845\n",
      "Iter=4200, loss=1.2706, mse=1.2706, time=0.0845\n",
      "Iter=4400, loss=1.2249, mse=1.2249, time=0.0845\n",
      "Iter=4600, loss=1.2333, mse=1.2333, time=0.0843\n",
      "Iter=4800, loss=1.2415, mse=1.2415, time=0.0843\n",
      "Iter=5000, loss=1.2466, mse=1.2466, time=0.0843\n",
      "Iter=5200, loss=1.2806, mse=1.2806, time=0.0842\n",
      "Iter=5400, loss=1.2694, mse=1.2694, time=0.0841\n",
      "Iter=5600, loss=1.2171, mse=1.2171, time=0.0841\n",
      "Iter=5800, loss=1.1735, mse=1.1735, time=0.0842\n",
      "Iter=6000, loss=1.2395, mse=1.2395, time=0.0842\n",
      "Iter=6200, loss=1.2433, mse=1.2433, time=0.0841\n",
      "Iter=6400, loss=1.2119, mse=1.2119, time=0.0841\n",
      "Iter=6600, loss=1.1911, mse=1.1911, time=0.0843\n",
      "=== Epoch 26, train loss 1.234361, test rmse 1.066516 ===\n",
      "Epoch 27\n",
      "Iter=200, loss=1.2518, mse=1.2518, time=0.0808\n",
      "Iter=400, loss=1.2052, mse=1.2052, time=0.0842\n",
      "Iter=600, loss=1.3012, mse=1.3012, time=0.0860\n",
      "Iter=800, loss=1.2522, mse=1.2522, time=0.0834\n",
      "Iter=1000, loss=1.2806, mse=1.2806, time=0.0813\n",
      "Iter=1200, loss=1.2439, mse=1.2439, time=0.0802\n",
      "Iter=1400, loss=1.2277, mse=1.2277, time=0.0806\n",
      "Iter=1600, loss=1.1930, mse=1.1930, time=0.0797\n",
      "Iter=1800, loss=1.2085, mse=1.2085, time=0.0798\n",
      "Iter=2000, loss=1.2073, mse=1.2073, time=0.0794\n",
      "Iter=2200, loss=1.2491, mse=1.2491, time=0.0798\n",
      "Iter=2400, loss=1.1904, mse=1.1904, time=0.0804\n",
      "Iter=2600, loss=1.2409, mse=1.2409, time=0.0803\n",
      "Iter=2800, loss=1.2243, mse=1.2243, time=0.0810\n",
      "Iter=3000, loss=1.2304, mse=1.2304, time=0.0808\n",
      "Iter=3200, loss=1.1994, mse=1.1994, time=0.0808\n",
      "Iter=3400, loss=1.2031, mse=1.2031, time=0.0805\n",
      "Iter=3600, loss=1.2109, mse=1.2109, time=0.0804\n",
      "Iter=3800, loss=1.2706, mse=1.2706, time=0.0800\n",
      "Iter=4000, loss=1.2417, mse=1.2417, time=0.0798\n",
      "Iter=4200, loss=1.2556, mse=1.2556, time=0.0799\n",
      "Iter=4400, loss=1.2613, mse=1.2613, time=0.0799\n",
      "Iter=4600, loss=1.2574, mse=1.2574, time=0.0803\n",
      "Iter=4800, loss=1.2085, mse=1.2085, time=0.0806\n",
      "Iter=5000, loss=1.2338, mse=1.2338, time=0.0804\n",
      "Iter=5200, loss=1.2065, mse=1.2065, time=0.0811\n",
      "Iter=5400, loss=1.2446, mse=1.2446, time=0.0806\n",
      "Iter=5600, loss=1.2246, mse=1.2246, time=0.0808\n",
      "Iter=5800, loss=1.1843, mse=1.1843, time=0.0807\n",
      "Iter=6000, loss=1.2499, mse=1.2499, time=0.0804\n",
      "Iter=6200, loss=1.2240, mse=1.2240, time=0.0809\n",
      "Iter=6400, loss=1.2553, mse=1.2553, time=0.0814\n",
      "Iter=6600, loss=1.2882, mse=1.2882, time=0.0816\n",
      "=== Epoch 27, train loss 1.234830, test rmse 1.066077 ===\n",
      "Epoch 28\n",
      "Iter=200, loss=1.2669, mse=1.2669, time=0.0906\n",
      "Iter=400, loss=1.2684, mse=1.2684, time=0.0833\n",
      "Iter=600, loss=1.2148, mse=1.2148, time=0.0841\n",
      "Iter=800, loss=1.2504, mse=1.2504, time=0.0819\n",
      "Iter=1000, loss=1.1635, mse=1.1635, time=0.0828\n",
      "Iter=1200, loss=1.1981, mse=1.1981, time=0.0814\n",
      "Iter=1400, loss=1.2337, mse=1.2337, time=0.0806\n",
      "Iter=1600, loss=1.2516, mse=1.2516, time=0.0815\n",
      "Iter=1800, loss=1.2016, mse=1.2016, time=0.0806\n",
      "Iter=2000, loss=1.2222, mse=1.2222, time=0.0776\n",
      "Iter=2200, loss=1.2152, mse=1.2152, time=0.0748\n",
      "Iter=2400, loss=1.2198, mse=1.2198, time=0.0720\n",
      "Iter=2600, loss=1.1865, mse=1.1865, time=0.0694\n",
      "Iter=2800, loss=1.1787, mse=1.1787, time=0.0674\n",
      "Iter=3000, loss=1.2316, mse=1.2316, time=0.0657\n",
      "Iter=3200, loss=1.2272, mse=1.2272, time=0.0640\n",
      "Iter=3400, loss=1.2244, mse=1.2244, time=0.0628\n",
      "Iter=3600, loss=1.2731, mse=1.2731, time=0.0614\n",
      "Iter=3800, loss=1.2707, mse=1.2707, time=0.0601\n",
      "Iter=4000, loss=1.2445, mse=1.2445, time=0.0590\n",
      "Iter=4200, loss=1.2282, mse=1.2282, time=0.0580\n",
      "Iter=4400, loss=1.2543, mse=1.2543, time=0.0572\n",
      "Iter=4600, loss=1.2386, mse=1.2386, time=0.0563\n",
      "Iter=4800, loss=1.2283, mse=1.2283, time=0.0555\n",
      "Iter=5000, loss=1.2017, mse=1.2017, time=0.0548\n",
      "Iter=5200, loss=1.2683, mse=1.2683, time=0.0541\n",
      "Iter=5400, loss=1.2551, mse=1.2551, time=0.0535\n",
      "Iter=5600, loss=1.2322, mse=1.2322, time=0.0529\n",
      "Iter=5800, loss=1.2625, mse=1.2625, time=0.0525\n",
      "Iter=6000, loss=1.2482, mse=1.2482, time=0.0520\n",
      "Iter=6200, loss=1.2737, mse=1.2737, time=0.0516\n",
      "Iter=6400, loss=1.2585, mse=1.2585, time=0.0512\n",
      "Iter=6600, loss=1.2200, mse=1.2200, time=0.0508\n",
      "=== Epoch 28, train loss 1.234268, test rmse 1.066230 ===\n",
      "Epoch 29\n",
      "Iter=200, loss=1.1835, mse=1.1835, time=0.0414\n",
      "Iter=400, loss=1.2742, mse=1.2742, time=0.0403\n",
      "Iter=600, loss=1.2261, mse=1.2261, time=0.0399\n",
      "Iter=800, loss=1.2192, mse=1.2192, time=0.0398\n",
      "Iter=1000, loss=1.2421, mse=1.2421, time=0.0397\n",
      "Iter=1200, loss=1.2126, mse=1.2126, time=0.0396\n",
      "Iter=1400, loss=1.2687, mse=1.2687, time=0.0395\n",
      "Iter=1600, loss=1.1762, mse=1.1762, time=0.0395\n",
      "Iter=1800, loss=1.2548, mse=1.2548, time=0.0394\n",
      "Iter=2000, loss=1.2472, mse=1.2472, time=0.0393\n",
      "Iter=2200, loss=1.2612, mse=1.2612, time=0.0393\n",
      "Iter=2400, loss=1.2658, mse=1.2658, time=0.0393\n",
      "Iter=2600, loss=1.2211, mse=1.2211, time=0.0393\n",
      "Iter=2800, loss=1.2346, mse=1.2346, time=0.0393\n",
      "Iter=3000, loss=1.2008, mse=1.2008, time=0.0392\n",
      "Iter=3200, loss=1.2359, mse=1.2359, time=0.0392\n",
      "Iter=3400, loss=1.2054, mse=1.2054, time=0.0392\n",
      "Iter=3600, loss=1.2189, mse=1.2189, time=0.0390\n",
      "Iter=3800, loss=1.2997, mse=1.2997, time=0.0390\n",
      "Iter=4000, loss=1.1958, mse=1.1958, time=0.0390\n",
      "Iter=4200, loss=1.2182, mse=1.2182, time=0.0389\n",
      "Iter=4400, loss=1.2697, mse=1.2697, time=0.0389\n",
      "Iter=4600, loss=1.2238, mse=1.2238, time=0.0388\n",
      "Iter=4800, loss=1.2146, mse=1.2146, time=0.0388\n",
      "Iter=5000, loss=1.2628, mse=1.2628, time=0.0388\n",
      "Iter=5200, loss=1.2721, mse=1.2721, time=0.0388\n",
      "Iter=5400, loss=1.2080, mse=1.2080, time=0.0388\n",
      "Iter=5600, loss=1.2426, mse=1.2426, time=0.0388\n",
      "Iter=5800, loss=1.2936, mse=1.2936, time=0.0388\n",
      "Iter=6000, loss=1.2372, mse=1.2372, time=0.0388\n",
      "Iter=6200, loss=1.2202, mse=1.2202, time=0.0388\n",
      "Iter=6400, loss=1.1940, mse=1.1940, time=0.0387\n",
      "Iter=6600, loss=1.2304, mse=1.2304, time=0.0387\n",
      "=== Epoch 29, train loss 1.233970, test rmse 1.066541 ===\n",
      "Epoch 30\n",
      "Iter=200, loss=1.2589, mse=1.2589, time=0.0464\n",
      "Iter=400, loss=1.2019, mse=1.2019, time=0.0444\n",
      "Iter=600, loss=1.2070, mse=1.2070, time=0.0440\n",
      "Iter=800, loss=1.2247, mse=1.2247, time=0.0443\n",
      "Iter=1000, loss=1.2309, mse=1.2309, time=0.0442\n",
      "Iter=1200, loss=1.2323, mse=1.2323, time=0.0444\n",
      "Iter=1400, loss=1.2630, mse=1.2630, time=0.0439\n",
      "Iter=1600, loss=1.2178, mse=1.2178, time=0.0433\n",
      "Iter=1800, loss=1.2465, mse=1.2465, time=0.0432\n",
      "Iter=2000, loss=1.2410, mse=1.2410, time=0.0434\n",
      "Iter=2200, loss=1.2168, mse=1.2168, time=0.0435\n",
      "Iter=2400, loss=1.2246, mse=1.2246, time=0.0434\n",
      "Iter=2600, loss=1.2706, mse=1.2706, time=0.0436\n",
      "Iter=2800, loss=1.2130, mse=1.2130, time=0.0435\n",
      "Iter=3000, loss=1.2582, mse=1.2582, time=0.0434\n",
      "Iter=3200, loss=1.2691, mse=1.2691, time=0.0434\n",
      "Iter=3400, loss=1.2387, mse=1.2387, time=0.0434\n",
      "Iter=3600, loss=1.2174, mse=1.2174, time=0.0433\n",
      "Iter=3800, loss=1.1891, mse=1.1891, time=0.0432\n",
      "Iter=4000, loss=1.2576, mse=1.2576, time=0.0432\n",
      "Iter=4200, loss=1.2765, mse=1.2765, time=0.0432\n",
      "Iter=4400, loss=1.2288, mse=1.2288, time=0.0432\n",
      "Iter=4600, loss=1.2787, mse=1.2787, time=0.0431\n",
      "Iter=4800, loss=1.1980, mse=1.1980, time=0.0431\n",
      "Iter=5000, loss=1.2542, mse=1.2542, time=0.0432\n",
      "Iter=5200, loss=1.2066, mse=1.2066, time=0.0432\n",
      "Iter=5400, loss=1.2197, mse=1.2197, time=0.0432\n",
      "Iter=5600, loss=1.2505, mse=1.2505, time=0.0431\n",
      "Iter=5800, loss=1.2172, mse=1.2172, time=0.0432\n",
      "Iter=6000, loss=1.2532, mse=1.2532, time=0.0433\n",
      "Iter=6200, loss=1.1996, mse=1.1996, time=0.0432\n",
      "Iter=6400, loss=1.2276, mse=1.2276, time=0.0432\n",
      "Iter=6600, loss=1.2114, mse=1.2114, time=0.0431\n",
      "=== Epoch 30, train loss 1.234152, test rmse 1.066812 ===\n",
      "Epoch 31\n",
      "Iter=200, loss=1.2246, mse=1.2246, time=0.0420\n",
      "Iter=400, loss=1.1999, mse=1.1999, time=0.0416\n",
      "Iter=600, loss=1.1964, mse=1.1964, time=0.0413\n",
      "Iter=800, loss=1.2458, mse=1.2458, time=0.0410\n",
      "Iter=1000, loss=1.2528, mse=1.2528, time=0.0408\n",
      "Iter=1200, loss=1.1925, mse=1.1925, time=0.0406\n",
      "Iter=1400, loss=1.1862, mse=1.1862, time=0.0405\n",
      "Iter=1600, loss=1.2695, mse=1.2695, time=0.0404\n",
      "Iter=1800, loss=1.2756, mse=1.2756, time=0.0403\n",
      "Iter=2000, loss=1.2615, mse=1.2615, time=0.0403\n",
      "Iter=2200, loss=1.2634, mse=1.2634, time=0.0402\n",
      "Iter=2400, loss=1.1985, mse=1.1985, time=0.0402\n",
      "Iter=2600, loss=1.2086, mse=1.2086, time=0.0401\n",
      "Iter=2800, loss=1.2680, mse=1.2680, time=0.0401\n",
      "Iter=3000, loss=1.2416, mse=1.2416, time=0.0400\n",
      "Iter=3200, loss=1.2435, mse=1.2435, time=0.0399\n",
      "Iter=3400, loss=1.2170, mse=1.2170, time=0.0399\n",
      "Iter=3600, loss=1.1631, mse=1.1631, time=0.0398\n",
      "Iter=3800, loss=1.2678, mse=1.2678, time=0.0398\n",
      "Iter=4000, loss=1.2052, mse=1.2052, time=0.0398\n",
      "Iter=4200, loss=1.2663, mse=1.2663, time=0.0397\n",
      "Iter=4400, loss=1.2962, mse=1.2962, time=0.0397\n",
      "Iter=4600, loss=1.2571, mse=1.2571, time=0.0395\n",
      "Iter=4800, loss=1.2517, mse=1.2517, time=0.0395\n",
      "Iter=5000, loss=1.2464, mse=1.2464, time=0.0394\n",
      "Iter=5200, loss=1.2710, mse=1.2710, time=0.0394\n",
      "Iter=5400, loss=1.2036, mse=1.2036, time=0.0394\n",
      "Iter=5600, loss=1.2430, mse=1.2430, time=0.0394\n",
      "Iter=5800, loss=1.2263, mse=1.2263, time=0.0394\n",
      "Iter=6000, loss=1.2403, mse=1.2403, time=0.0394\n",
      "Iter=6200, loss=1.2282, mse=1.2282, time=0.0394\n",
      "Iter=6400, loss=1.2136, mse=1.2136, time=0.0393\n",
      "Iter=6600, loss=1.2101, mse=1.2101, time=0.0394\n",
      "=== Epoch 31, train loss 1.234442, test rmse 1.066504 ===\n",
      "Epoch 32\n",
      "Iter=200, loss=1.2755, mse=1.2755, time=0.0435\n",
      "Iter=400, loss=1.2233, mse=1.2233, time=0.0427\n",
      "Iter=600, loss=1.2274, mse=1.2274, time=0.0458\n",
      "Iter=800, loss=1.2516, mse=1.2516, time=0.0468\n",
      "Iter=1000, loss=1.2175, mse=1.2175, time=0.0459\n",
      "Iter=1200, loss=1.2323, mse=1.2323, time=0.0453\n",
      "Iter=1400, loss=1.2026, mse=1.2026, time=0.0445\n",
      "Iter=1600, loss=1.2229, mse=1.2229, time=0.0439\n",
      "Iter=1800, loss=1.2642, mse=1.2642, time=0.0433\n",
      "Iter=2000, loss=1.2398, mse=1.2398, time=0.0429\n",
      "Iter=2200, loss=1.2358, mse=1.2358, time=0.0436\n",
      "Iter=2400, loss=1.2499, mse=1.2499, time=0.0435\n",
      "Iter=2600, loss=1.2085, mse=1.2085, time=0.0436\n",
      "Iter=2800, loss=1.2643, mse=1.2643, time=0.0433\n",
      "Iter=3000, loss=1.2433, mse=1.2433, time=0.0431\n",
      "Iter=3200, loss=1.1870, mse=1.1870, time=0.0429\n",
      "Iter=3400, loss=1.2426, mse=1.2426, time=0.0429\n",
      "Iter=3600, loss=1.2410, mse=1.2410, time=0.0433\n",
      "Iter=3800, loss=1.2270, mse=1.2270, time=0.0442\n",
      "Iter=4000, loss=1.2422, mse=1.2422, time=0.0454\n",
      "Iter=4200, loss=1.2630, mse=1.2630, time=0.0463\n",
      "Iter=4400, loss=1.2454, mse=1.2454, time=0.0464\n",
      "Iter=4600, loss=1.2425, mse=1.2425, time=0.0462\n",
      "Iter=4800, loss=1.2295, mse=1.2295, time=0.0458\n",
      "Iter=5000, loss=1.2795, mse=1.2795, time=0.0455\n",
      "Iter=5200, loss=1.2365, mse=1.2365, time=0.0453\n",
      "Iter=5400, loss=1.1874, mse=1.1874, time=0.0450\n",
      "Iter=5600, loss=1.2718, mse=1.2718, time=0.0448\n",
      "Iter=5800, loss=1.2047, mse=1.2047, time=0.0447\n",
      "Iter=6000, loss=1.2049, mse=1.2049, time=0.0447\n",
      "Iter=6200, loss=1.1860, mse=1.1860, time=0.0448\n",
      "Iter=6400, loss=1.2540, mse=1.2540, time=0.0449\n",
      "Iter=6600, loss=1.2112, mse=1.2112, time=0.0448\n",
      "=== Epoch 32, train loss 1.234621, test rmse 1.066298 ===\n",
      "Epoch 33\n",
      "Iter=200, loss=1.2420, mse=1.2420, time=0.0402\n",
      "Iter=400, loss=1.2287, mse=1.2287, time=0.0391\n",
      "Iter=600, loss=1.2783, mse=1.2783, time=0.0390\n",
      "Iter=800, loss=1.2257, mse=1.2257, time=0.0389\n",
      "Iter=1000, loss=1.2463, mse=1.2463, time=0.0389\n",
      "Iter=1200, loss=1.2369, mse=1.2369, time=0.0388\n",
      "Iter=1400, loss=1.1965, mse=1.1965, time=0.0390\n",
      "Iter=1600, loss=1.2052, mse=1.2052, time=0.0390\n",
      "Iter=1800, loss=1.2203, mse=1.2203, time=0.0389\n",
      "Iter=2000, loss=1.2486, mse=1.2486, time=0.0388\n",
      "Iter=2200, loss=1.2507, mse=1.2507, time=0.0389\n",
      "Iter=2400, loss=1.2617, mse=1.2617, time=0.0391\n",
      "Iter=2600, loss=1.2178, mse=1.2178, time=0.0392\n",
      "Iter=2800, loss=1.2467, mse=1.2467, time=0.0394\n",
      "Iter=3000, loss=1.2456, mse=1.2456, time=0.0398\n",
      "Iter=3200, loss=1.2365, mse=1.2365, time=0.0398\n",
      "Iter=3400, loss=1.1914, mse=1.1914, time=0.0397\n",
      "Iter=3600, loss=1.3110, mse=1.3110, time=0.0396\n",
      "Iter=3800, loss=1.2814, mse=1.2814, time=0.0395\n",
      "Iter=4000, loss=1.2272, mse=1.2272, time=0.0394\n",
      "Iter=4200, loss=1.2091, mse=1.2091, time=0.0393\n",
      "Iter=4400, loss=1.2120, mse=1.2120, time=0.0392\n",
      "Iter=4600, loss=1.2134, mse=1.2134, time=0.0393\n",
      "Iter=4800, loss=1.2666, mse=1.2666, time=0.0391\n",
      "Iter=5000, loss=1.2552, mse=1.2552, time=0.0391\n",
      "Iter=5200, loss=1.2290, mse=1.2290, time=0.0392\n",
      "Iter=5400, loss=1.1978, mse=1.1978, time=0.0392\n",
      "Iter=5600, loss=1.2005, mse=1.2005, time=0.0392\n",
      "Iter=5800, loss=1.2784, mse=1.2784, time=0.0392\n",
      "Iter=6000, loss=1.2221, mse=1.2221, time=0.0392\n",
      "Iter=6200, loss=1.2055, mse=1.2055, time=0.0392\n",
      "Iter=6400, loss=1.2199, mse=1.2199, time=0.0391\n",
      "Iter=6600, loss=1.2367, mse=1.2367, time=0.0391\n",
      "=== Epoch 33, train loss 1.234434, test rmse 1.066873 ===\n",
      "Epoch 34\n",
      "Iter=200, loss=1.2637, mse=1.2637, time=0.0477\n",
      "Iter=400, loss=1.2049, mse=1.2049, time=0.0443\n",
      "Iter=600, loss=1.2216, mse=1.2216, time=0.0428\n",
      "Iter=800, loss=1.2179, mse=1.2179, time=0.0421\n",
      "Iter=1000, loss=1.2391, mse=1.2391, time=0.0416\n",
      "Iter=1200, loss=1.1703, mse=1.1703, time=0.0413\n",
      "Iter=1400, loss=1.2086, mse=1.2086, time=0.0411\n",
      "Iter=1600, loss=1.2126, mse=1.2126, time=0.0409\n",
      "Iter=1800, loss=1.2448, mse=1.2448, time=0.0407\n",
      "Iter=2000, loss=1.2393, mse=1.2393, time=0.0406\n",
      "Iter=2200, loss=1.2355, mse=1.2355, time=0.0405\n",
      "Iter=2400, loss=1.2335, mse=1.2335, time=0.0405\n",
      "Iter=2600, loss=1.2400, mse=1.2400, time=0.0405\n",
      "Iter=2800, loss=1.2453, mse=1.2453, time=0.0406\n",
      "Iter=3000, loss=1.2343, mse=1.2343, time=0.0405\n",
      "Iter=3200, loss=1.2818, mse=1.2818, time=0.0405\n",
      "Iter=3400, loss=1.2482, mse=1.2482, time=0.0404\n",
      "Iter=3600, loss=1.2549, mse=1.2549, time=0.0403\n",
      "Iter=3800, loss=1.2387, mse=1.2387, time=0.0404\n",
      "Iter=4000, loss=1.2458, mse=1.2458, time=0.0405\n",
      "Iter=4200, loss=1.2725, mse=1.2725, time=0.0404\n",
      "Iter=4400, loss=1.2649, mse=1.2649, time=0.0403\n",
      "Iter=4600, loss=1.1997, mse=1.1997, time=0.0403\n",
      "Iter=4800, loss=1.2177, mse=1.2177, time=0.0402\n",
      "Iter=5000, loss=1.2201, mse=1.2201, time=0.0401\n",
      "Iter=5200, loss=1.2058, mse=1.2058, time=0.0401\n",
      "Iter=5400, loss=1.2670, mse=1.2670, time=0.0400\n",
      "Iter=5600, loss=1.2465, mse=1.2465, time=0.0401\n",
      "Iter=5800, loss=1.2216, mse=1.2216, time=0.0402\n",
      "Iter=6000, loss=1.2087, mse=1.2087, time=0.0403\n",
      "Iter=6200, loss=1.2134, mse=1.2134, time=0.0405\n",
      "Iter=6400, loss=1.2151, mse=1.2151, time=0.0406\n",
      "Iter=6600, loss=1.2725, mse=1.2725, time=0.0406\n",
      "=== Epoch 34, train loss 1.234260, test rmse 1.066135 ===\n",
      "Epoch 35\n",
      "Iter=200, loss=1.1965, mse=1.1965, time=0.0414\n",
      "Iter=400, loss=1.2468, mse=1.2468, time=0.0415\n",
      "Iter=600, loss=1.2269, mse=1.2269, time=0.0415\n",
      "Iter=800, loss=1.1983, mse=1.1983, time=0.0428\n",
      "Iter=1000, loss=1.2104, mse=1.2104, time=0.0444\n",
      "Iter=1200, loss=1.2190, mse=1.2190, time=0.0445\n",
      "Iter=1400, loss=1.2223, mse=1.2223, time=0.0441\n",
      "Iter=1600, loss=1.2364, mse=1.2364, time=0.0436\n",
      "Iter=1800, loss=1.2273, mse=1.2273, time=0.0430\n",
      "Iter=2000, loss=1.2238, mse=1.2238, time=0.0428\n",
      "Iter=2200, loss=1.2664, mse=1.2664, time=0.0428\n",
      "Iter=2400, loss=1.3115, mse=1.3115, time=0.0430\n",
      "Iter=2600, loss=1.2326, mse=1.2326, time=0.0432\n",
      "Iter=2800, loss=1.2106, mse=1.2106, time=0.0430\n",
      "Iter=3000, loss=1.2733, mse=1.2733, time=0.0428\n",
      "Iter=3200, loss=1.2345, mse=1.2345, time=0.0426\n",
      "Iter=3400, loss=1.2404, mse=1.2404, time=0.0425\n",
      "Iter=3600, loss=1.2094, mse=1.2094, time=0.0423\n",
      "Iter=3800, loss=1.2127, mse=1.2127, time=0.0422\n",
      "Iter=4000, loss=1.2419, mse=1.2419, time=0.0420\n",
      "Iter=4200, loss=1.2487, mse=1.2487, time=0.0419\n",
      "Iter=4400, loss=1.2328, mse=1.2328, time=0.0418\n",
      "Iter=4600, loss=1.2583, mse=1.2583, time=0.0418\n",
      "Iter=4800, loss=1.2450, mse=1.2450, time=0.0417\n",
      "Iter=5000, loss=1.2047, mse=1.2047, time=0.0416\n",
      "Iter=5200, loss=1.2250, mse=1.2250, time=0.0415\n",
      "Iter=5400, loss=1.2490, mse=1.2490, time=0.0414\n",
      "Iter=5600, loss=1.2137, mse=1.2137, time=0.0415\n",
      "Iter=5800, loss=1.2378, mse=1.2378, time=0.0414\n",
      "Iter=6000, loss=1.2833, mse=1.2833, time=0.0414\n",
      "Iter=6200, loss=1.2520, mse=1.2520, time=0.0414\n",
      "Iter=6400, loss=1.2187, mse=1.2187, time=0.0414\n",
      "Iter=6600, loss=1.2199, mse=1.2199, time=0.0414\n",
      "=== Epoch 35, train loss 1.234868, test rmse 1.066456 ===\n",
      "Epoch 36\n",
      "Iter=200, loss=1.2176, mse=1.2176, time=0.0427\n",
      "Iter=400, loss=1.2472, mse=1.2472, time=0.0411\n",
      "Iter=600, loss=1.2011, mse=1.2011, time=0.0408\n",
      "Iter=800, loss=1.2169, mse=1.2169, time=0.0406\n",
      "Iter=1000, loss=1.2304, mse=1.2304, time=0.0407\n",
      "Iter=1200, loss=1.2478, mse=1.2478, time=0.0407\n",
      "Iter=1400, loss=1.2674, mse=1.2674, time=0.0406\n",
      "Iter=1600, loss=1.2514, mse=1.2514, time=0.0404\n",
      "Iter=1800, loss=1.1967, mse=1.1967, time=0.0405\n",
      "Iter=2000, loss=1.2552, mse=1.2552, time=0.0409\n",
      "Iter=2200, loss=1.1901, mse=1.1901, time=0.0407\n",
      "Iter=2400, loss=1.1712, mse=1.1712, time=0.0408\n",
      "Iter=2600, loss=1.2764, mse=1.2764, time=0.0408\n",
      "Iter=2800, loss=1.2557, mse=1.2557, time=0.0408\n",
      "Iter=3000, loss=1.2360, mse=1.2360, time=0.0408\n",
      "Iter=3200, loss=1.2470, mse=1.2470, time=0.0407\n",
      "Iter=3400, loss=1.2372, mse=1.2372, time=0.0407\n",
      "Iter=3600, loss=1.2548, mse=1.2548, time=0.0412\n",
      "Iter=3800, loss=1.2330, mse=1.2330, time=0.0415\n",
      "Iter=4000, loss=1.2219, mse=1.2219, time=0.0418\n",
      "Iter=4200, loss=1.2675, mse=1.2675, time=0.0419\n",
      "Iter=4400, loss=1.2191, mse=1.2191, time=0.0421\n",
      "Iter=4600, loss=1.2363, mse=1.2363, time=0.0422\n",
      "Iter=4800, loss=1.2347, mse=1.2347, time=0.0422\n",
      "Iter=5000, loss=1.2473, mse=1.2473, time=0.0422\n",
      "Iter=5200, loss=1.2678, mse=1.2678, time=0.0422\n",
      "Iter=5400, loss=1.2476, mse=1.2476, time=0.0422\n",
      "Iter=5600, loss=1.2421, mse=1.2421, time=0.0423\n",
      "Iter=5800, loss=1.1833, mse=1.1833, time=0.0423\n",
      "Iter=6000, loss=1.2509, mse=1.2509, time=0.0425\n",
      "Iter=6200, loss=1.2497, mse=1.2497, time=0.0425\n",
      "Iter=6400, loss=1.1866, mse=1.1866, time=0.0425\n",
      "Iter=6600, loss=1.2498, mse=1.2498, time=0.0424\n",
      "=== Epoch 36, train loss 1.234443, test rmse 1.067180 ===\n",
      "Epoch 37\n",
      "Iter=200, loss=1.2919, mse=1.2919, time=0.0399\n",
      "Iter=400, loss=1.2381, mse=1.2381, time=0.0396\n",
      "Iter=600, loss=1.1858, mse=1.1858, time=0.0397\n",
      "Iter=800, loss=1.2309, mse=1.2309, time=0.0395\n",
      "Iter=1000, loss=1.2225, mse=1.2225, time=0.0397\n",
      "Iter=1200, loss=1.2195, mse=1.2195, time=0.0398\n",
      "Iter=1400, loss=1.2324, mse=1.2324, time=0.0398\n",
      "Iter=1600, loss=1.1906, mse=1.1906, time=0.0398\n",
      "Iter=1800, loss=1.2534, mse=1.2534, time=0.0397\n",
      "Iter=2000, loss=1.2500, mse=1.2500, time=0.0401\n",
      "Iter=2200, loss=1.2750, mse=1.2750, time=0.0405\n",
      "Iter=2400, loss=1.2403, mse=1.2403, time=0.0406\n",
      "Iter=2600, loss=1.2473, mse=1.2473, time=0.0405\n",
      "Iter=2800, loss=1.2465, mse=1.2465, time=0.0406\n",
      "Iter=3000, loss=1.2014, mse=1.2014, time=0.0408\n",
      "Iter=3200, loss=1.2350, mse=1.2350, time=0.0407\n",
      "Iter=3400, loss=1.2202, mse=1.2202, time=0.0408\n",
      "Iter=3600, loss=1.2484, mse=1.2484, time=0.0407\n",
      "Iter=3800, loss=1.2227, mse=1.2227, time=0.0407\n",
      "Iter=4000, loss=1.2439, mse=1.2439, time=0.0406\n",
      "Iter=4200, loss=1.2316, mse=1.2316, time=0.0405\n",
      "Iter=4400, loss=1.2205, mse=1.2205, time=0.0404\n",
      "Iter=4600, loss=1.2479, mse=1.2479, time=0.0403\n",
      "Iter=4800, loss=1.2437, mse=1.2437, time=0.0402\n",
      "Iter=5000, loss=1.1947, mse=1.1947, time=0.0402\n",
      "Iter=5200, loss=1.2813, mse=1.2813, time=0.0403\n",
      "Iter=5400, loss=1.2425, mse=1.2425, time=0.0405\n",
      "Iter=5600, loss=1.2241, mse=1.2241, time=0.0406\n",
      "Iter=5800, loss=1.1980, mse=1.1980, time=0.0407\n",
      "Iter=6000, loss=1.2766, mse=1.2766, time=0.0408\n",
      "Iter=6200, loss=1.1867, mse=1.1867, time=0.0408\n",
      "Iter=6400, loss=1.1887, mse=1.1887, time=0.0408\n",
      "Iter=6600, loss=1.2946, mse=1.2946, time=0.0408\n",
      "=== Epoch 37, train loss 1.234432, test rmse 1.065923 ===\n",
      "Epoch 38\n",
      "Iter=200, loss=1.2213, mse=1.2213, time=0.0396\n",
      "Iter=400, loss=1.2100, mse=1.2100, time=0.0397\n",
      "Iter=600, loss=1.2372, mse=1.2372, time=0.0393\n",
      "Iter=800, loss=1.2555, mse=1.2555, time=0.0394\n",
      "Iter=1000, loss=1.2400, mse=1.2400, time=0.0393\n",
      "Iter=1200, loss=1.2272, mse=1.2272, time=0.0394\n",
      "Iter=1400, loss=1.2098, mse=1.2098, time=0.0394\n",
      "Iter=1600, loss=1.2605, mse=1.2605, time=0.0393\n",
      "Iter=1800, loss=1.2786, mse=1.2786, time=0.0392\n",
      "Iter=2000, loss=1.2775, mse=1.2775, time=0.0392\n",
      "Iter=2200, loss=1.1997, mse=1.1997, time=0.0392\n",
      "Iter=2400, loss=1.2223, mse=1.2223, time=0.0391\n",
      "Iter=2600, loss=1.2426, mse=1.2426, time=0.0390\n",
      "Iter=2800, loss=1.2133, mse=1.2133, time=0.0389\n",
      "Iter=3000, loss=1.2095, mse=1.2095, time=0.0393\n",
      "Iter=3200, loss=1.2163, mse=1.2163, time=0.0398\n",
      "Iter=3400, loss=1.2420, mse=1.2420, time=0.0401\n",
      "Iter=3600, loss=1.2430, mse=1.2430, time=0.0403\n",
      "Iter=3800, loss=1.2281, mse=1.2281, time=0.0403\n",
      "Iter=4000, loss=1.2624, mse=1.2624, time=0.0403\n",
      "Iter=4200, loss=1.2609, mse=1.2609, time=0.0403\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35260/260693645.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_e, loss_fn, optimizer_e, args.arr_lambda, \n\u001b[0m\u001b[0;32m     30\u001b[0m                                                                    train_loader_e, args.device, args.train_log_interval)\n\u001b[0;32m     31\u001b[0m     \u001b[0mvalid_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_valid_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_valid_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35260/3847565008.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(label_type, model, loss_fn, optimizer, arr_lambda, loader, device, log_interval)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'emotion'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter_project\\keejun\\IGMC_CX\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# edge mask zero denotes the edge dropped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             x = th.tanh(conv(block, x, block.edata['etype'], \n\u001b[0m\u001b[0;32m     66\u001b[0m                              norm=block.edata['edge_mask'].unsqueeze(1)))\n\u001b[0;32m     67\u001b[0m             \u001b[0mconcat_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\relgraphconv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, feat, etypes, norm)\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[1;31m# Sort the graph based on the etypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m                 \u001b[0msorted_etypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelabel_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m                 \u001b[1;31m# Create a new etypes to be an integer list of number of edges.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_searchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_etypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_rels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\subgraph.py\u001b[0m in \u001b[0;36medge_subgraph\u001b[1;34m(graph, edges, relabel_nodes, store_ids, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[0meids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcetype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0minduced_edges\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_process_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcetype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0msgi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minduced_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrelabel_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[0minduced_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minduced_nodes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrelabel_nodes\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_create_hetero_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstore_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\heterograph_index.py\u001b[0m in \u001b[0;36medge_subgraph\u001b[1;34m(self, induced_edges, preserve_nodes)\u001b[0m\n\u001b[0;32m    883\u001b[0m         \"\"\"\n\u001b[0;32m    884\u001b[0m         \u001b[0meids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dgl_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0medges\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minduced_edges\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroEdgeSubgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_unitgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mret_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDGLValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mret_tcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         check_call(_LIB.DGLFuncCall(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "label_type = 'emotion'\n",
    "\n",
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")\n",
    "\n",
    "# 마지막 epoch의 결과를 저장함.\n",
    "predict_train_list = list()\n",
    "label_train_list = list()\n",
    "\n",
    "predict_valid_list = list()\n",
    "label_valid_list = list()\n",
    "best_predict_valid_list = list()\n",
    "best_label_valid_list = list()\n",
    "\n",
    "predict_test_list = list()\n",
    "label_test_list = list()\n",
    "best_predict_test_list = list()\n",
    "best_label_test_list = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch_idx in range(1, 80):\n",
    "    print ('Epoch', epoch_idx)\n",
    "    \n",
    "    train_loss, predict_train_list, label_train_list = train_epoch(label_type, model_e, loss_fn, optimizer_e, args.arr_lambda, \n",
    "                                                                   train_loader_e, args.device, args.train_log_interval)\n",
    "    valid_rmse, predict_valid_list, label_valid_list = evaluate(label_type, model_e, valid_loader_e, args.device)\n",
    "    test_rmse, predict_test_list, label_test_list = evaluate(label_type, model_e, test_loader_e, args.device)\n",
    "    \n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model_e, optimizer_e)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "        \n",
    "        best_predict_valid_list = predict_valid_list \n",
    "        best_label_valid_list = label_valid_list\n",
    "        \n",
    "        best_predict_test_list = predict_test_list \n",
    "        best_label_test_list = label_test_list\n",
    "    \n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))\n",
    "\n",
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "print(\" Total Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ad780abf-5e0a-4837-ad83-07a6b15f164a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.065909012649887"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109d317-e856-40aa-a3c4-ffe8b030fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_emotion_df = pd.DataFrame([x for x in zip(predict_train_list, label_train_list)])\n",
    "train_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "valid_emotion_df = pd.DataFrame([x for x in zip(predict_valid_list, label_valid_list)])\n",
    "valid_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)\n",
    "\n",
    "test_emotion_df = pd.DataFrame([x for x in zip(best_predict_test_list, best_label_test_list)])\n",
    "test_emotion_df.rename(columns={0:'predict', 1:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ae4ab-1fef-4f42-8c1b-ab21c9b522a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/rotten_tomato/ensemble/'\n",
    "train_emotion_df.to_csv(path + 'train_emotion.csv', index=False)\n",
    "valid_emotion_df.to_csv(path + 'valid_emotion.csv', index=False)\n",
    "test_emotion_df.to_csv(path + 'test_emotion.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e8a82-6b5d-472d-a679-e85e57fc7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c728cd9-f005-491f-84dc-d63650c2700a",
   "metadata": {},
   "source": [
    "## 4. Train_epoch 함수 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1185d5-2266-46da-9245-351215a28540",
   "metadata": {},
   "source": [
    "### - Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f4bec73f-8cab-45aa-a3cb-beccdda9bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'rating'\n",
    "model = model_r\n",
    "loss_fn = loss_fn\n",
    "optimizer = optimizer_r\n",
    "arr_lambda = args.arr_lambda\n",
    "loader = train_loader_r\n",
    "device = args.device\n",
    "log_interval = args.train_log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b454620b-9795-4b72-b151-73be1461b119",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=200, loss=2.6334, mse=2.6295, time=0.0434\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35260/1789257228.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'emotion'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter_project\\keejun\\IGMC_CX\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# edge mask zero denotes the edge dropped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             x = th.tanh(conv(block, x, block.edata['etype'], \n\u001b[0m\u001b[0;32m     66\u001b[0m                              norm=block.edata['edge_mask'].unsqueeze(1)))\n\u001b[0;32m     67\u001b[0m             \u001b[0mconcat_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graph\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\relgraphconv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, feat, etypes, norm)\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[0mnode_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_repr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m                 \u001b[0mnode_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_repr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_loop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m                 \u001b[0mnode_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_repr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloop_message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.train()\n",
    "\n",
    "epoch_loss = 0.\n",
    "iter_loss = 0.\n",
    "iter_mse = 0.\n",
    "iter_cnt = 0\n",
    "iter_dur = []\n",
    "\n",
    "# 저장 리스트(예측, 정답)\n",
    "predict_list = list()\n",
    "label_list = list()\n",
    "\n",
    "# 서브그래프 단위로 학습\n",
    "for iter_idx, batch in enumerate(loader, start=1):\n",
    "    t_start = time.time()\n",
    "\n",
    "    inputs = batch[0].to(device)\n",
    "    labels = batch[1].to(device)\n",
    "    preds = model(inputs)\n",
    "    \n",
    "    if label_type == 'emotion':\n",
    "        loss = loss_fn(preds, labels).mean()\n",
    "    else:\n",
    "        loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item() * preds.shape[0]\n",
    "    iter_loss += loss.item() * preds.shape[0]\n",
    "    iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "    iter_cnt += preds.shape[0]\n",
    "    iter_dur.append(time.time() - t_start)\n",
    "\n",
    "    if label_type == 'rating':\n",
    "        preds  = (preds + 1)/2\n",
    "        labels = (labels + 1)/2\n",
    "    else:\n",
    "        preds  = preds + 1\n",
    "        labels = labels + 1\n",
    "\n",
    "    predict_list.append(preds.tolist()) # 예측값 저장\n",
    "    label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "    if iter_idx % log_interval == 0:\n",
    "        print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "            iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "        iter_loss = 0.\n",
    "        iter_mse = 0.\n",
    "        iter_cnt = 0\n",
    "\n",
    "# 2차원 -> 1차원 리스트 변형\n",
    "predict_list = [element for array in predict_list for element in array]\n",
    "label_list = [element for array in label_list for element in array]\n",
    "\n",
    "train_epoch_loss = epoch_loss / len(loader.dataset)  \n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "41de0e18-f974-42c6-9381-5c522d4271b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a6f11dc9-55c6-4490-a882-4b3bfa677093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc90f7b1-ec60-4c53-8b42-f63c06868808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.474928617477417,\n",
       " 4.432092189788818,\n",
       " 1.6393139362335205,\n",
       " 3.679456949234009,\n",
       " 2.2003211975097656,\n",
       " 3.414210081100464,\n",
       " 2.7713494300842285,\n",
       " 3.535055160522461,\n",
       " 3.712036371231079,\n",
       " 2.852395534515381]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "228b6092-4141-4df7-881c-74c1ac40727d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5, 3.0, 1.0, 3.0, 2.0, 2.5, 4.5, 3.0, 3.5, 2.0]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6bc06-0a33-414c-a73b-e409bca5e421",
   "metadata": {},
   "source": [
    "### Evaluate 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb2b26d9-25c4-4328-802b-068c674c8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'rating'\n",
    "model = model_r\n",
    "loader = test_loader_r\n",
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "47e1a54f-e56b-4650-a9c1-498ad5893824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time took: 0:00:26\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict_list = list()\n",
    "label_list = list()\n",
    "\n",
    "# Evaluate RMSE\n",
    "model.eval()\n",
    "mse = 0.\n",
    "for batch in loader:\n",
    "    with th.no_grad():\n",
    "        preds = model(batch[0].to(device))\n",
    "    labels = batch[1].to(device)\n",
    "    \n",
    "    if label_type == 'rating':\n",
    "        preds  = (preds + 1)/2\n",
    "        labels = (labels + 1)/2\n",
    "    else:\n",
    "        preds  = preds + 1\n",
    "        labels = labels + 1\n",
    "    mse += ((preds - labels) ** 2).sum().item()\n",
    "    \n",
    "    predict_list.append(preds.tolist()) # 예측값 저장\n",
    "    label_list.append(labels.tolist()) # 정답값 저장\n",
    "\n",
    "# 2차원 -> 1차원 리스트 변형\n",
    "predict_list = [element for array in predict_list for element in array]\n",
    "label_list = [element for array in label_list for element in array]    \n",
    "    \n",
    "mse /= len(loader.dataset)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "54927b7e-515f-481e-b8ed-d746e8de230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208980129263855"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f0465-ef4c-424f-8a7d-1bd31800fc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae685cc-df32-47d9-ab80-320e40749f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda367ca-52b8-4455-87ec-c8cc7b71562b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
