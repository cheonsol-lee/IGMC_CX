{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee754ff-2a3d-4760-9dde-f35b5079e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training epoch took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5af6c94-0780-4733-88b7-286a4a08728a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training IGMC model on the MovieLens dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "from shutil import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import IGMC\n",
    "from data_rotten import RottenTomato\n",
    "from dataset_rotten import RottenTomatoDataset, collate_rotten_tomato\n",
    "from utils import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c1bb83-260d-40b8-900b-6c27d7da5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    # Evaluate RMSE\n",
    "    model.eval()\n",
    "    mse = 0.\n",
    "    for batch in loader:\n",
    "        with th.no_grad():\n",
    "            preds = model(batch[0].to(device))\n",
    "        labels = batch[1].to(device)\n",
    "        mse += ((preds - labels) ** 2).sum().item()\n",
    "    mse /= len(loader.dataset)\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def adj_rating_reg(model):\n",
    "    arr_loss = 0\n",
    "    for conv in model.convs:\n",
    "        weight = conv.weight.view(conv.num_bases, conv.in_feat * conv.out_feat)\n",
    "        weight = th.matmul(conv.w_comp, weight).view(conv.num_rels, conv.in_feat, conv.out_feat)\n",
    "        arr_loss += th.sum((weight[1:, :, :] - weight[:-1, :, :])**2)\n",
    "    return arr_loss\n",
    "\n",
    "# @profile\n",
    "def train_epoch(model, loss_fn, optimizer, arr_lambda, loader, device, log_interval):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.\n",
    "    iter_loss = 0.\n",
    "    iter_mse = 0.\n",
    "    iter_cnt = 0\n",
    "    iter_dur = []\n",
    "\n",
    "    for iter_idx, batch in enumerate(loader, start=1):\n",
    "        t_start = time.time()\n",
    "\n",
    "        inputs = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "        preds = model(inputs)\n",
    "        loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * preds.shape[0]\n",
    "        iter_loss += loss.item() * preds.shape[0]\n",
    "        iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "        iter_cnt += preds.shape[0]\n",
    "        iter_dur.append(time.time() - t_start)\n",
    "\n",
    "        if iter_idx % log_interval == 0:\n",
    "            print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "                iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "            iter_loss = 0.\n",
    "            iter_mse = 0.\n",
    "            iter_cnt = 0\n",
    "\n",
    "    return epoch_loss / len(loader.dataset)\n",
    "\n",
    "def train(args):\n",
    "    movielens = MovieLens(args.data_name, testing=args.testing,\n",
    "                            test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "    if args.testing:\n",
    "        test_dataset = RottenTomatoDataset(\n",
    "            movielens.test_rating_pairs, movielens.test_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "    else:\n",
    "        test_dataset = RottenTomatoDataset(\n",
    "            movielens.valid_rating_pairs, movielens.valid_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "    train_dataset = RottenTomatoDataset(\n",
    "        movielens.train_rating_pairs, movielens.train_rating_values, movielens.train_graph, \n",
    "        args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "    train_loader = th.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "    test_loader = th.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "\n",
    "    in_feats = (args.hop+1)*2 #+ movielens.train_graph.ndata['refex'].shape[1]\n",
    "    model = IGMC(in_feats=in_feats, \n",
    "                 latent_dim=[32, 32, 32, 32],\n",
    "                 num_relations=5, # movielens.num_rating, \n",
    "                 num_bases=4, \n",
    "                 regression=True, \n",
    "                 edge_dropout=args.edge_dropout,\n",
    "                #  side_features=args.use_features,\n",
    "                #  n_side_features=n_features,\n",
    "                #  multiply_by=args.multiply_by\n",
    "            ).to(args.device)\n",
    "    loss_fn = nn.MSELoss().to(args.device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "    print(\"Loading network finished ...\\n\")\n",
    "\n",
    "    ### prepare the logger\n",
    "    logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "    \n",
    "    best_epoch = 0\n",
    "    best_rmse = np.inf\n",
    "    ### declare the loss information\n",
    "    print(\"Start training ...\")\n",
    "    for epoch_idx in range(1, args.train_epochs+1):\n",
    "        print ('Epoch', epoch_idx)\n",
    "    \n",
    "        train_loss = train_epoch(model, loss_fn, optimizer, args.arr_lambda, \n",
    "                                train_loader, args.device, args.train_log_interval)\n",
    "        test_rmse = evaluate(model, test_loader, args.device)\n",
    "        eval_info = {\n",
    "            'epoch': epoch_idx,\n",
    "            'train_loss': train_loss,\n",
    "            'test_rmse': test_rmse,\n",
    "        }\n",
    "        print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "        if epoch_idx % args.train_lr_decay_step == 0:\n",
    "            for param in optimizer.param_groups:\n",
    "                param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "        logger.log(eval_info, model, optimizer)\n",
    "        if best_rmse > test_rmse:\n",
    "            best_rmse = test_rmse\n",
    "            best_epoch = epoch_idx\n",
    "    eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "    print(eval_info)\n",
    "    with open(os.path.join(args.save_dir, 'log.txt'), 'a') as f:\n",
    "        f.write(eval_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fbabcc-6d45-4d08-8d5e-f9f483e56aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def config():\n",
    "    parser = argparse.ArgumentParser(description='IGMC')\n",
    "    # general settings\n",
    "    parser.add_argument('--testing', action='store_true', default=False,\n",
    "                        help='if set, use testing mode which splits all ratings into train/test;\\\n",
    "                        otherwise, use validation model which splits all ratings into \\\n",
    "                        train/val/test and evaluate on val only')\n",
    "    parser.add_argument('--device', default='0', type=int,\n",
    "                        help='Running device. E.g `--device 0`, if using cpu, set `--device -1`')\n",
    "    parser.add_argument('--seed', type=int, default=1234, metavar='S',\n",
    "                        help='random seed (default: 1234)')\n",
    "    parser.add_argument('--data_name', default='ml-100k', type=str,\n",
    "                        help='The dataset name: ml-100k, ml-1m')\n",
    "    parser.add_argument('--data_test_ratio', type=float, default=0.1) # for ml-100k the test ration is 0.2\n",
    "    parser.add_argument('--num_workers', type=int, default=8)\n",
    "    parser.add_argument('--data_valid_ratio', type=float, default=0.2)\n",
    "    # parser.add_argument('--ensemble', action='store_true', default=False,\n",
    "    #                     help='if True, load a series of model checkpoints and ensemble the results')               \n",
    "    parser.add_argument('--train_log_interval', type=int, default=100)\n",
    "    parser.add_argument('--valid_log_interval', type=int, default=10)\n",
    "    parser.add_argument('--save_appendix', type=str, default='debug', \n",
    "                        help='what to append to save-names when saving results')\n",
    "    # subgraph extraction settings\n",
    "    parser.add_argument('--hop', default=1, metavar='S', \n",
    "                        help='enclosing subgraph hop number')\n",
    "    parser.add_argument('--sample_ratio', type=float, default=1.0, \n",
    "                        help='if < 1, subsample nodes per hop according to the ratio')\n",
    "    parser.add_argument('--max_nodes_per_hop', type=int, default=200, \n",
    "                        help='if > 0, upper bound the # nodes per hop by another subsampling')\n",
    "    # parser.add_argument('--use_features', action='store_true', default=False,\n",
    "    #                     help='whether to use node features (side information)')\n",
    "    # edge dropout settings\n",
    "    parser.add_argument('--edge_dropout', type=float, default=0.2, \n",
    "                        help='if not 0, random drops edges from adjacency matrix with this prob')\n",
    "    parser.add_argument('--force_undirected', action='store_true', default=False, \n",
    "                        help='in edge dropout, force (x, y) and (y, x) to be dropped together')\n",
    "    # optimization settings\n",
    "    parser.add_argument('--train_lr', type=float, default=1e-3)\n",
    "    parser.add_argument('--train_min_lr', type=float, default=1e-6)\n",
    "    parser.add_argument('--train_lr_decay_factor', type=float, default=0.1)\n",
    "    parser.add_argument('--train_lr_decay_step', type=int, default=50)\n",
    "    parser.add_argument('--train_epochs', type=int, default=80)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--arr_lambda', type=float, default=0.001)\n",
    "    parser.add_argument('--num_rgcn_bases', type=int, default=4)\n",
    "                \n",
    "    args = parser.parse_args()\n",
    "    args.device = th.device(args.device) if args.device >= 0 and th.cuda.is_available() else th.device('cpu')\n",
    "    \n",
    "    ### set save_dir according to localtime and test mode\n",
    "    file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "    val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "    local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "    args.save_dir = os.path.join(\n",
    "        file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "            args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "        )\n",
    "    )\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir) \n",
    "    print(args)\n",
    "\n",
    "    # backup current .py files\n",
    "    for f in glob.glob(r\"*.py\"):\n",
    "        copy(f, args.save_dir)\n",
    "\n",
    "    # save command line input\n",
    "    cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "    with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "        f.write(cmd_input)\n",
    "        f.write(\"\\n\")\n",
    "    print('Command line input: ' + cmd_input + ' is saved.')\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a24e649-365e-4f54-b4bd-7796c685b165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     args = config()\n",
    "#     random.seed(args.seed)\n",
    "#     np.random.seed(args.seed)\n",
    "#     th.manual_seed(args.seed)\n",
    "#     if th.cuda.is_available():\n",
    "#         th.cuda.manual_seed_all(args.seed)\n",
    "#     train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff187c-d0a5-44d6-bf40-12a1c7927a3b",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0218e93a-7bb0-4007-a0d4-194dfbf0fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({ \n",
    "    'data_name':            'rotten',\n",
    "    'testing':     \t        True,\n",
    "    'device':      \t        0,\n",
    "    'seed':        \t        1234,\n",
    "    'data_test_ratio':      0.1,\n",
    "    'num_workers':   \t    8,\n",
    "    'data_valid_ratio':     0.2,\n",
    "    'train_log_interval':   200,\n",
    "    'valid_log_interval':   10,\n",
    "    'save_appendix':   \t    'debug',\n",
    "    'hop':   \t            1,\n",
    "    'sample_ratio':    \t    1.0,\n",
    "    'max_nodes_per_hop':    100,\n",
    "    'edge_dropout':   \t    0.2,\n",
    "    'force_undirected':     False,\n",
    "    'train_lr':   \t        1e-3,\n",
    "    'train_min_lr':   \t    1e-6,\n",
    "    'train_lr_decay_factor':0.1,\n",
    "    'train_lr_decay_step':  50,\n",
    "    'train_epochs':   \t    1,\n",
    "    'batch_size':   \t    32,\n",
    "    'arr_lambda':   \t    0.001,\n",
    "    'num_rgcn_bases':   \t4,\n",
    "    'train_epochs':   \t    1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eefc4e0-e1a6-47fa-af1b-3f79a748f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_name': 'rotten', 'testing': True, 'device': 0, 'seed': 1234, 'data_test_ratio': 0.1, 'num_workers': 8, 'data_valid_ratio': 0.2, 'train_log_interval': 200, 'valid_log_interval': 10, 'save_appendix': 'debug', 'hop': 1, 'sample_ratio': 1.0, 'max_nodes_per_hop': 100, 'edge_dropout': 0.2, 'force_undirected': False, 'train_lr': 0.001, 'train_min_lr': 1e-06, 'train_lr_decay_factor': 0.1, 'train_lr_decay_step': 50, 'train_epochs': 1, 'batch_size': 32, 'arr_lambda': 0.001, 'num_rgcn_bases': 4, 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\graph\\\\IGMC_kirc\\\\log/rotten_debug_testmode_2111112152'}\n",
      "Command line input: python3 C:\\Users\\user\\anaconda3\\envs\\graph\\lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\user\\AppData\\Roaming\\jupyter\\runtime\\kernel-06857397-42d0-4553-9b07-b1e2f1697dfd.json is saved.\n"
     ]
    }
   ],
   "source": [
    "### set save_dir according to localtime and test mode\n",
    "file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "args.save_dir = os.path.join(\n",
    "    file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "        args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "    )\n",
    ")\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir) \n",
    "print(args)\n",
    "\n",
    "# backup current .py files\n",
    "for f in glob.glob(r\"*.py\"):\n",
    "    copy(f, args.save_dir)\n",
    "\n",
    "# save command line input\n",
    "cmd_input = 'python3 ' + ' '.join(sys.argv)\n",
    "with open(os.path.join(args.save_dir, 'cmd_input.txt'), 'a') as f:\n",
    "    f.write(cmd_input)\n",
    "    f.write(\"\\n\")\n",
    "print('Command line input: ' + cmd_input + ' is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0952c8a-5880-48c8-a6b0-76fa1226074e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_name': 'rotten',\n",
       " 'testing': True,\n",
       " 'device': 0,\n",
       " 'seed': 1234,\n",
       " 'data_test_ratio': 0.1,\n",
       " 'num_workers': 8,\n",
       " 'data_valid_ratio': 0.2,\n",
       " 'train_log_interval': 200,\n",
       " 'valid_log_interval': 10,\n",
       " 'save_appendix': 'debug',\n",
       " 'hop': 1,\n",
       " 'sample_ratio': 1.0,\n",
       " 'max_nodes_per_hop': 100,\n",
       " 'edge_dropout': 0.2,\n",
       " 'force_undirected': False,\n",
       " 'train_lr': 0.001,\n",
       " 'train_min_lr': 1e-06,\n",
       " 'train_lr_decay_factor': 0.1,\n",
       " 'train_lr_decay_step': 50,\n",
       " 'train_epochs': 1,\n",
       " 'batch_size': 32,\n",
       " 'arr_lambda': 0.001,\n",
       " 'num_rgcn_bases': 4,\n",
       " 'save_dir': 'C:\\\\Users\\\\user\\\\Jupyter_project\\\\keejun\\\\graph\\\\IGMC_kirc\\\\log/rotten_debug_testmode_2111112152'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e5af39-9646-43f8-87d2-8d9c498b7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "th.manual_seed(args.seed)\n",
    "if th.cuda.is_available():\n",
    "    th.cuda.manual_seed_all(args.seed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3522af7d-43ff-4eb3-85c2-8168f73dcfa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# train(args)\n",
    "\n",
    "# print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd9d7e-1617-4c32-a8bc-006d4a49ca35",
   "metadata": {},
   "source": [
    "## 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c44d14-7115-4e81-9c99-99f370f93129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create RottenTomato Class...\n",
      "\tTrain rating pairs : 178320\n",
      "\tValid rating pairs : 35664\n",
      "\tTest rating pairs  : 26851\n"
     ]
    }
   ],
   "source": [
    "### prepare data and set model\n",
    "path = './raw_data/rotten_tomato/'\n",
    "rotten_tomato = RottenTomato(path, testing=args.testing,test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "110a614c-d291-4d33-9185-49c44feae073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_rotten.RottenTomato at 0x233e84a8250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_tomato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a64167d-fcca-4bd7-b0f4-7dfa290178bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3ff8769-41d9-4fe5-938f-51c370d372cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.testing:\n",
    "    test_dataset = RottenTomatoDataset(\n",
    "        rotten_tomato.test_rating_pairs, rotten_tomato.test_rating_values, rotten_tomato.train_graph, \n",
    "        args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "else:\n",
    "    test_dataset = RottenTomatoDataset(\n",
    "        rotten_tomato.valid_rating_pairs, rotten_tomato.valid_rating_values, rotten_tomato.train_graph, \n",
    "        args.hop, args.sample_ratio, args.max_nodes_per_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5e9ce45-2ab8-4a5a-bae3-17a9871aad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RottenTomatoDataset(\n",
    "    rotten_tomato.train_rating_pairs, rotten_tomato.train_rating_values, rotten_tomato.train_graph, \n",
    "    args.hop, args.sample_ratio, args.max_nodes_per_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "621bf1ca-2328-439c-bfe9-fd51f892552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = th.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)\n",
    "test_loader = th.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, \n",
    "                        num_workers=args.num_workers, collate_fn=collate_rotten_tomato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c679b72-a7a2-4abb-9c4d-efdebf97dbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network finished ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_feats = (args.hop+1)*2 #+ rotten_tomato.train_graph.ndata['refex'].shape[1]\n",
    "model = IGMC(in_feats=in_feats, \n",
    "             latent_dim=[32, 32, 32, 32],\n",
    "             num_relations=5, # rotten_tomato.num_rating, \n",
    "             num_bases=4, \n",
    "             regression=True, \n",
    "             edge_dropout=args.edge_dropout,\n",
    "            #  side_features=args.use_features,\n",
    "            #  n_side_features=n_features,\n",
    "            #  multiply_by=args.multiply_by\n",
    "        ).to(args.device)\n",
    "loss_fn = nn.MSELoss().to(args.device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "print(\"Loading network finished ...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85169726-bfc2-4901-9fec-5762453098ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a33c4cb1-b163-4368-8bd7-555f86a56943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3569ea7d-b812-486f-8681-b08d1b9b382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n"
     ]
    }
   ],
   "source": [
    "### prepare the logger\n",
    "logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "\n",
    "best_epoch = 0\n",
    "best_rmse = np.inf\n",
    "### declare the loss information\n",
    "print(\"Start training ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67b4b350-a659-41eb-8f85-4baf5495fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Iter=200, loss=4.5522, mse=4.5504, time=0.0478\n",
      "Iter=400, loss=3.5049, mse=3.5029, time=0.0431\n",
      "Iter=600, loss=3.5270, mse=3.5249, time=0.0417\n",
      "Iter=800, loss=3.3964, mse=3.3941, time=0.0408\n",
      "Iter=1000, loss=3.4752, mse=3.4728, time=0.0403\n",
      "Iter=1200, loss=3.4616, mse=3.4590, time=0.0399\n",
      "Iter=1400, loss=3.2917, mse=3.2891, time=0.0397\n",
      "Iter=1600, loss=3.3451, mse=3.3423, time=0.0395\n",
      "Iter=1800, loss=3.3051, mse=3.3022, time=0.0394\n",
      "Iter=2000, loss=3.4012, mse=3.3982, time=0.0393\n",
      "Iter=2200, loss=3.3259, mse=3.3228, time=0.0393\n",
      "Iter=2400, loss=3.1612, mse=3.1580, time=0.0392\n",
      "Iter=2600, loss=3.3353, mse=3.3320, time=0.0391\n",
      "Iter=2800, loss=3.3132, mse=3.3098, time=0.0391\n",
      "Iter=3000, loss=3.2377, mse=3.2342, time=0.0390\n",
      "Iter=3200, loss=3.2108, mse=3.2072, time=0.0390\n",
      "Iter=3400, loss=3.2462, mse=3.2426, time=0.0391\n",
      "Iter=3600, loss=3.1450, mse=3.1413, time=0.0390\n",
      "Iter=3800, loss=3.2914, mse=3.2875, time=0.0390\n",
      "Iter=4000, loss=3.2469, mse=3.2431, time=0.0390\n",
      "Iter=4200, loss=3.2484, mse=3.2444, time=0.0390\n",
      "Iter=4400, loss=3.1132, mse=3.1094, time=0.0390\n",
      "Iter=4600, loss=3.3128, mse=3.3087, time=0.0390\n",
      "Iter=4800, loss=3.2205, mse=3.2164, time=0.0389\n",
      "Iter=5000, loss=3.2349, mse=3.2308, time=0.0389\n",
      "Iter=5200, loss=3.1925, mse=3.1883, time=0.0389\n",
      "Iter=5400, loss=3.1878, mse=3.1836, time=0.0389\n",
      "=== Epoch 1, train loss 3.337978, test rmse 1.898806 ===\n",
      "  Training epoch took: 0:04:23\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch_idx in range(1, args.train_epochs+1):\n",
    "    print ('Epoch', epoch_idx)\n",
    "\n",
    "    train_loss = train_epoch(model, loss_fn, optimizer, args.arr_lambda, \n",
    "                            train_loader, args.device, args.train_log_interval)\n",
    "    test_rmse = evaluate(model, test_loader, args.device)\n",
    "    eval_info = {\n",
    "        'epoch': epoch_idx,\n",
    "        'train_loss': train_loss,\n",
    "        'test_rmse': test_rmse,\n",
    "    }\n",
    "    print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "    if epoch_idx % args.train_lr_decay_step == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "    logger.log(eval_info, model, optimizer)\n",
    "    if best_rmse > test_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_epoch = epoch_idx\n",
    "\n",
    "print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "646f6c55-8dc5-4999-b2b0-70af13b2248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ends. The best testing rmse is 1.898806 at epoch 1\n"
     ]
    }
   ],
   "source": [
    "eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "print(eval_info)\n",
    "with open(os.path.join(args.save_dir, 'log.txt'), 'a') as f:\n",
    "    f.write(eval_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acc35c-e77b-4764-bdb3-47977a789154",
   "metadata": {},
   "source": [
    "- IGMC의 users, items 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "919e8a82-6b5d-472d-a679-e85e57fc7ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=242, num_edges=1298,\n",
       "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'nlabel': Scheme(shape=(4,), dtype=torch.float32), 'x': Scheme(shape=(4,), dtype=torch.float32)}\n",
       "      edata_schemes={'etype': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64), 'edge_mask': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b673cd3-2dca-471d-b361-5e0106ebd0db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_ID': tensor([ 711,  517,  278,  493,  548,  418,  444,   96,  249,  698,  154,  425,\n",
       "         323,  675,  822,  296,  210,  522,  401,  186,  416,  466,  385,  261,\n",
       "         687,  433,  701,  304,  700,  671,  341,  362,   60,  610,  136,  247,\n",
       "         108,  311,  779,  733,  562,  223,  107,  714,   18,  841,  688,  215,\n",
       "         497,  685,  455,  553,  690,  620,  326,  431,  113,  629,  736,  706,\n",
       "         827,  360,  140,  782,  189,  719,  366,  348,  267,   59,  482,  386,\n",
       "         657,   97,  231,  409,  550,   98,  235,  308,  321,  626,   46,  697,\n",
       "         391,  317,  850,  410,  823,  798,  130,  786,  300,  393,  659,  357,\n",
       "         518,  141,  774,  381,  543, 5527, 5582,  181,  415,  455,  575,  594,\n",
       "         686,  700,  729,  737, 1626, 5279, 7234, 4896, 1825, 6842, 2769, 8564,\n",
       "        2349, 2518, 4837, 7503, 2205, 3452, 2729, 5383, 3992, 4854, 4818, 6152,\n",
       "        2886, 2202, 5941, 8462, 5708, 7862, 1785, 4635, 4060, 1992, 8640, 7104,\n",
       "        5113, 8361, 7634, 2792, 7183, 1879, 1593, 5450, 4549, 8169, 1823, 2370,\n",
       "        1864, 4182, 2972, 1333, 5867, 7166, 7300, 3013, 2814, 3535, 2312, 3480,\n",
       "        4453, 1890, 2277, 6550, 4366, 6200, 5196, 2505, 6265, 7169, 5338, 7074,\n",
       "        6069, 5047, 7997, 6462, 7082, 3211, 7368, 5566, 2819, 5827, 6445, 2384,\n",
       "        4720, 6183, 4170, 1822, 4265, 4774, 8193, 4852, 2526, 2888, 3494, 3335,\n",
       "        5276, 8641, 3127, 5306, 3939, 2456, 2440, 5717, 6950,  192,  133,  322,\n",
       "         404,  444,  687,  692,  700,  774, 1590, 1982, 1986, 2273, 3152, 3582,\n",
       "        4615, 5306, 5647, 5675, 5736, 5813, 6660, 7004, 7265, 7906, 7965, 8307,\n",
       "        8402, 8443], device='cuda:0'), 'nlabel': tensor([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]], device='cuda:0'), 'x': tensor([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]], device='cuda:0')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e5ecab8-943f-455e-aaf0-35ca5e3eb057",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.ndata['nlabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d8a6255-f09c-4c0f-ae0c-76b87f5b5670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([242, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.ndata['nlabel'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "209864b6-e545-446e-b566-391921f47b04",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.ndata['nlabel'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20e81e3a-81b3-4e30-a7a2-ecffbbafb7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2057, -0.9095,  0.8907,  ..., -0.9173,  0.7441,  0.9805],\n",
       "        [-0.1511, -0.8892,  0.8495,  ..., -0.8813,  0.7189,  0.9660],\n",
       "        [-0.7094, -0.8141,  0.7197,  ..., -0.5087,  0.2565,  0.9730],\n",
       "        ...,\n",
       "        [-0.9994, -0.3894, -0.9118,  ...,  0.9001, -0.8125,  0.6751],\n",
       "        [ 0.3903, -0.7851,  0.4084,  ..., -0.4084,  0.6968,  0.4396],\n",
       "        [ 0.3903, -0.7851,  0.4084,  ..., -0.4084,  0.6968,  0.4396]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eac9276d-09af-4230-93a4-28fe437b04e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([242])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3d26473-4f82-4488-9d27-35678e86770a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([242])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bb98d62-2a20-4a65-a020-3fd17b8884ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([242, 128])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.concat_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce6db82a-6550-4093-b637-bbd670ba4c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6358, -0.2797, -0.6337,  ..., -0.9173,  0.7441,  0.9805],\n",
       "        [-0.5393, -0.4982, -0.4925,  ..., -0.8813,  0.7189,  0.9660],\n",
       "        [-0.5468, -0.5067, -0.4928,  ..., -0.5087,  0.2565,  0.9730],\n",
       "        ...,\n",
       "        [ 0.0579, -0.1061, -0.1119,  ...,  0.9001, -0.8125,  0.6751],\n",
       "        [-0.0142, -0.0400, -0.1710,  ..., -0.4084,  0.6968,  0.4396],\n",
       "        [-0.0142, -0.0400, -0.1710,  ..., -0.4084,  0.6968,  0.4396]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.concat_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3532cf35-110f-4746-a77a-dfc08acd2786",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6358, -0.2797, -0.6337, -0.5025,  0.4910, -0.2071, -0.7283,  0.0339,\n",
       "          0.6825,  0.4217, -0.1271,  0.6621, -0.4415, -0.2291, -0.3042,  0.4808,\n",
       "         -0.2599, -0.5215,  0.2434,  0.5987,  0.0722, -0.6885,  0.5980,  0.4211,\n",
       "         -0.5975, -0.0746, -0.0844,  0.2512,  0.3852,  0.1114,  0.1747,  0.7297,\n",
       "         -0.6110, -0.4318,  0.4377, -0.4292, -0.7702,  0.8885, -0.8244,  0.6679,\n",
       "         -0.4753,  0.7979, -0.7246,  0.3284, -0.3571, -0.7500,  0.1002,  0.6705,\n",
       "          0.5953,  0.8478,  0.7451,  0.8772,  0.4188, -0.3666, -0.8656, -0.1272,\n",
       "          0.6151, -0.8673,  0.8561,  0.8328,  0.7235,  0.6067,  0.8411,  0.5652,\n",
       "          0.0814, -0.7639,  0.7591,  0.7039,  0.5658,  0.8375,  0.9523, -0.9454,\n",
       "          0.9709,  0.9799,  0.8497,  0.6416, -0.8626, -0.9059,  0.7033,  0.7907,\n",
       "         -0.9101, -0.5427, -0.9290,  0.9404, -0.4945,  0.5848, -0.8710,  0.4651,\n",
       "         -0.9262, -0.8005,  0.8705,  0.9492, -0.8259, -0.9300,  0.9682,  0.9265,\n",
       "         -0.2057, -0.9095,  0.8907, -0.8446, -0.2466, -0.7317,  0.3691, -0.9036,\n",
       "          0.8437, -0.8453, -0.4857,  0.7744,  0.8094,  0.9621,  0.2633, -0.9912,\n",
       "          0.7409,  0.9317, -0.5296, -0.6427,  0.9388,  0.1605,  0.6667, -0.6059,\n",
       "          0.7121,  0.1203,  0.3350, -0.9514,  0.3170, -0.9173,  0.7441,  0.9805],\n",
       "        [-1.0000, -0.9557, -1.0000, -1.0000,  1.0000,  0.7373, -0.9996,  0.3593,\n",
       "          1.0000, -0.8203, -0.6226,  0.9999, -1.0000,  0.8809, -0.9999,  1.0000,\n",
       "         -0.0923, -1.0000,  0.2767,  1.0000,  0.8023, -1.0000,  1.0000,  1.0000,\n",
       "         -0.9685, -0.2618, -0.4490, -0.2918,  1.0000,  0.2445, -0.5275,  1.0000,\n",
       "         -0.8369, -0.9287,  0.9921, -0.9758, -0.9956,  0.9983, -0.9989,  0.8519,\n",
       "         -0.9857,  0.9985, -0.9874,  0.7455, -0.9626, -0.9962,  0.2122,  0.9920,\n",
       "          0.9894,  0.9997,  0.9972,  0.9998,  0.9374, -0.8387, -0.9988, -0.5116,\n",
       "          0.9587, -0.9971,  0.9976,  0.9987,  0.9318,  0.9907,  0.9927,  0.8376,\n",
       "          0.9923, -1.0000,  0.9998,  0.9976,  0.9999,  1.0000,  1.0000, -1.0000,\n",
       "          1.0000,  1.0000,  0.9999, -0.7804, -1.0000, -1.0000,  0.9996,  0.9960,\n",
       "         -1.0000, -0.7240, -1.0000,  1.0000,  0.3185,  0.0374, -1.0000,  0.9879,\n",
       "         -1.0000, -0.9999,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,\n",
       "         -0.9803,  0.9393,  1.0000,  0.9850,  1.0000,  0.9514, -0.9964, -1.0000,\n",
       "          0.8622, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -0.8993, -1.0000,\n",
       "         -1.0000, -0.4749,  0.7409,  0.9710,  0.9999, -0.5213,  0.9181, -0.2088,\n",
       "         -0.6656,  1.0000,  0.9992, -0.9380,  0.6604, -0.9914,  0.9995,  1.0000],\n",
       "        [-0.9646, -0.5287, -0.9920, -0.9734,  0.9525, -0.0857, -0.9398,  0.3146,\n",
       "          0.9969, -0.0076, -0.0627,  0.9368, -0.9776,  0.1390, -0.7860,  0.9908,\n",
       "         -0.2456, -0.9794,  0.1757,  0.9929,  0.4895, -0.9671,  0.9895,  0.9788,\n",
       "         -0.6456,  0.0876, -0.4036,  0.0501,  0.9446, -0.0987, -0.1865,  0.9715,\n",
       "         -0.7721, -0.6849,  0.7994, -0.8340, -0.9509,  0.9860, -0.9805,  0.8700,\n",
       "         -0.8171,  0.9751, -0.9416,  0.6348, -0.7645, -0.9574,  0.0155,  0.9547,\n",
       "          0.9170,  0.9839,  0.9519,  0.9889,  0.7265, -0.5112, -0.9789, -0.3692,\n",
       "          0.8895, -0.9809,  0.9750,  0.9777,  0.8687,  0.9062,  0.9555,  0.7891,\n",
       "          0.3343, -0.9504,  0.9631,  0.9335,  0.9781,  0.9655,  0.9993, -0.9989,\n",
       "          0.9995,  0.9997,  0.9952, -0.2167, -0.9845, -0.9904,  0.9668,  0.9307,\n",
       "         -0.9871, -0.8815, -0.9966,  0.9991,  0.5281,  0.2840, -0.9917,  0.8862,\n",
       "         -0.9976, -0.9869,  0.9788,  0.9985, -0.9727, -0.9972,  0.9995,  0.9860,\n",
       "         -0.9942, -0.8646,  0.4060,  0.3903,  0.9975,  0.6933, -0.9461, -0.8662,\n",
       "          0.6925, -0.9830,  0.9978, -0.9909,  0.9871,  0.9920,  0.5236, -0.9960,\n",
       "         -0.4972,  0.9542,  0.9038,  0.9794,  0.5761, -0.4867, -0.4926,  0.9476,\n",
       "         -0.8184,  0.3755,  0.6558, -0.9763, -0.7964,  0.5136, -0.3712,  0.9976]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.concat_states[model.users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f1a4405-6171-465e-ab4a-358eac28cdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.concat_states[model.users].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ddfd412-4dbd-4821-b9e4-6e4e82c04f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.concat_states[model.items].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c604fefa-8687-4f37-b9ad-3d5c5e5431a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = th.cat([model.concat_states[model.users], model.concat_states[model.items]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "039cd241-2c02-4ae3-9489-1165498a5a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user, item vector들을 합침\n",
    "concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03faa981-c0e4-438c-846b-bdd142d583ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c728cd9-f005-491f-84dc-d63650c2700a",
   "metadata": {},
   "source": [
    "### Train_epoch 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4bec73f-8cab-45aa-a3cb-beccdda9bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "loss_fn = loss_fn\n",
    "optimizer = optimizer\n",
    "arr_lambda = args.arr_lambda\n",
    "loader = train_loader\n",
    "device = args.device\n",
    "log_interval = args.train_log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df6fd326-b5dc-4acd-8832-9aae253d90a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b454620b-9795-4b72-b151-73be1461b119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=200, loss=3.0832, mse=3.0790, time=0.0394\n",
      "Iter=400, loss=3.1369, mse=3.1323, time=0.0390\n",
      "Iter=600, loss=3.2943, mse=3.2898, time=0.0387\n",
      "Iter=800, loss=3.1302, mse=3.1256, time=0.0388\n",
      "Iter=1000, loss=3.1018, mse=3.0971, time=0.0387\n",
      "Iter=1200, loss=3.2010, mse=3.1962, time=0.0386\n",
      "Iter=1400, loss=3.0876, mse=3.0827, time=0.0385\n",
      "Iter=1600, loss=3.1327, mse=3.1278, time=0.0385\n",
      "Iter=1800, loss=3.2319, mse=3.2268, time=0.0385\n",
      "Iter=2000, loss=3.0849, mse=3.0798, time=0.0386\n",
      "Iter=2200, loss=3.1549, mse=3.1498, time=0.0385\n",
      "Iter=2400, loss=3.1133, mse=3.1082, time=0.0385\n",
      "Iter=2600, loss=3.0773, mse=3.0721, time=0.0385\n",
      "Iter=2800, loss=3.0440, mse=3.0387, time=0.0385\n",
      "Iter=3000, loss=3.1351, mse=3.1297, time=0.0385\n",
      "Iter=3200, loss=3.1349, mse=3.1295, time=0.0386\n",
      "Iter=3400, loss=2.9213, mse=2.9158, time=0.0388\n",
      "Iter=3600, loss=3.0939, mse=3.0884, time=0.0388\n",
      "Iter=3800, loss=3.2014, mse=3.1956, time=0.0388\n",
      "Iter=4000, loss=3.1302, mse=3.1243, time=0.0388\n",
      "Iter=4200, loss=2.9488, mse=2.9426, time=0.0388\n",
      "Iter=4400, loss=3.0304, mse=3.0243, time=0.0388\n",
      "Iter=4600, loss=3.1617, mse=3.1557, time=0.0390\n",
      "Iter=4800, loss=3.1635, mse=3.1575, time=0.0390\n",
      "Iter=5000, loss=3.0558, mse=3.0500, time=0.0390\n",
      "Iter=5200, loss=2.9553, mse=2.9492, time=0.0390\n",
      "Iter=5400, loss=2.9369, mse=2.9306, time=0.0390\n",
      "  Time took: 0:03:57\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.train()\n",
    "\n",
    "epoch_loss = 0.\n",
    "iter_loss = 0.\n",
    "iter_mse = 0.\n",
    "iter_cnt = 0\n",
    "iter_dur = []\n",
    "\n",
    "# 서브그래프 단위로 학습\n",
    "for iter_idx, batch in enumerate(loader, start=1):\n",
    "    t_start = time.time()\n",
    "\n",
    "    inputs = batch[0].to(device)\n",
    "    labels = batch[1].to(device)\n",
    "    preds = model(inputs)\n",
    "    loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item() * preds.shape[0]\n",
    "    iter_loss += loss.item() * preds.shape[0]\n",
    "    iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "    iter_cnt += preds.shape[0]\n",
    "    iter_dur.append(time.time() - t_start)\n",
    "\n",
    "    if iter_idx % log_interval == 0:\n",
    "        print(\"Iter={}, loss={:.4f}, mse={:.4f}, time={:.4f}\".format(\n",
    "            iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "        iter_loss = 0.\n",
    "        iter_mse = 0.\n",
    "        iter_cnt = 0\n",
    "\n",
    "train_epoch_loss = epoch_loss / len(loader.dataset)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d54b44e-f603-4327-9a87-904041c70d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2171, num_edges=61386,\n",
       "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'nlabel': Scheme(shape=(4,), dtype=torch.float32), 'x': Scheme(shape=(4,), dtype=torch.float32)}\n",
       "      edata_schemes={'etype': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64), 'edge_mask': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "992ba225-8165-40a2-8384-81b354d23b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7., 9., 7., 6., 7., 3., 6., 3., 5., 4., 9., 5., 0., 3., 3., 6.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41f4dcf4-1350-4831-9dc5-c356e1daf391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8209, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "987146e4-6ad1-4339-b27f-851e94945000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f305240a-7b5c-4100-8d58-5dab9f972c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0991868031297685"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "613c9bbf-4877-49bd-9cb2-f5927bcd8038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.1299, 4.7555, 4.8841, 7.2973, 5.3850, 4.8987, 5.6385, 3.1361, 6.1342,\n",
       "        3.5716, 6.9831, 4.8422, 4.7172, 2.8222, 4.1561, 6.7424],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198de4d4-9dc0-4184-84f4-1a40cc509972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37162a-ee65-4af9-9cab-e4a795fc5099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4c6bc06-0a33-414c-a73b-e409bca5e421",
   "metadata": {},
   "source": [
    "### Evaluate 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb2b26d9-25c4-4328-802b-068c674c8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "loader = test_loader\n",
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47e1a54f-e56b-4650-a9c1-498ad5893824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time took: 0:00:29\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict_ratings = list()\n",
    "real_ratings = list()\n",
    "\n",
    "# Evaluate RMSE\n",
    "model.eval()\n",
    "mse = 0.\n",
    "for batch in loader:\n",
    "    with th.no_grad():\n",
    "        preds = model(batch[0].to(device))\n",
    "    labels = batch[1].to(device)\n",
    "    mse += ((preds - labels) ** 2).sum().item()\n",
    "    \n",
    "    real_ratings.append(labels)\n",
    "    predict_ratings.append(preds)\n",
    "    \n",
    "mse /= len(loader.dataset)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"  Time took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "437b02ec-0ac8-45fd-aa39-d9ebfe9daa56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.8086, 6.6340, 3.9050], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3292c796-c71b-4078-8fd9-a07f58be62b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 6., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54927b7e-515f-481e-b8ed-d746e8de230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7701252440065876"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ab427bd-4cc3-4e74-94f9-b88194b22936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset_rotten.RottenTomatoDataset at 0x233e84a8be0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dca19d71-2874-4586-a7a6-5547ed60a2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0884, 7.3267, 6.4094, 7.2519, 7.1850, 5.3218, 4.9718, 4.8634, 5.7870,\n",
       "        7.2103, 4.7904, 6.2181, 7.4301, 4.4984, 5.3829, 4.2108, 4.3310, 6.7832,\n",
       "        6.8143, 5.5623, 6.2674, 6.1137, 6.4566, 5.4044, 4.6298, 6.1769, 7.2690,\n",
       "        6.2197, 4.9070, 5.4487, 2.7218, 3.0106], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ratings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a41bd92d-e324-4a86-9656-da4c8c516a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7., 6., 6., 6., 7., 8., 4., 3., 6., 7., 6., 5., 6., 4., 4., 5., 3., 6.,\n",
       "        9., 4., 5., 7., 6., 6., 6., 6., 6., 6., 7., 6., 6., 4.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_ratings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f0465-ef4c-424f-8a7d-1bd31800fc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae685cc-df32-47d9-ab80-320e40749f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda367ca-52b8-4455-87ec-c8cc7b71562b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
